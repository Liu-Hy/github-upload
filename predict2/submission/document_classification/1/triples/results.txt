(Ft ( XLM ) results||without the help of||unlabeled data)
(unlabeled data||from||target domain)
(substantial gap||between||model performance)
(substantial gap||between||monolingual baselines)
(substantial gap||when using||state - of - the - art pre-trained cross -lingual representations)
(UDA algorithm and MLM pre-training||offer||significant improvements)
(significant improvements||by utilizing||unlabeled data)
(UDA algorithm and MLM pre-training||has||significant improvements)
(Results||has||UDA algorithm and MLM pre-training)
(sentiment classification task||where||unlabeled data size)
(unlabeled data size||is||larger)
(Ft ( XLM ft ) model usnig MLM pre-training||consistently provides||larger improvements)
(larger improvements||compared with||UDA method)
(sentiment classification task||has||unlabeled data size)
(unlabeled data size||has||larger)
(Results||In||sentiment classification task)
(MLM method||is||relatively more resource intensive)
(MLM method||takes||longer)
(MLM method||has||relatively more resource intensive)
(Results||has||MLM method)
(MLdoc dataset||when||size)
(size||of||unlabeled samples)
(size||is||limited)
(unlabeled samples||is||limited)
(UDA method||is||more helpful)
(MLdoc dataset||has||size)
(UDA method||has||more helpful)
(Results||in||MLdoc dataset)
(sentiment classification task||observe||self - training technique)
(consistently improves||over||teacher model)
(sentiment classification task||has||self - training technique)
(self - training technique||has||consistently improves)
(Results||In||sentiment classification task)
(best results||in||XLM and XLM ft based classifiers)
(self - training||achieves||best results)
(MLdoc dataset||has||self - training)
(Results||In||MLdoc dataset)
(monolingual fine - tune baseline||completely close||performance gap)
(performance gap||by utilizing||unlabeled data)
(unlabeled data||in||target language)
(Results||comparing with||best cross - lingual results)
(our framework||reaches||new state - of - the - art results)
(our framework||improving over||vanilla XLM baselines)
(new state - of - the - art results||improving over||vanilla XLM baselines)
(vanilla XLM baselines||by||44 %)
(Results||has||our framework)
(Contribution||has||Results)
