2	0	14	Face Alignment
23	17	24	present
23	29	81	3 DDE ( 3D Deeply - initialized Ensemble ) regressor
23	86	131	robust and efficient face alignment algorithm
23	132	140	based on
23	143	177	coarse - to - fine cascade of ERTs
25	6	20	initialized by
25	21	37	robustly fitting
25	40	54	3 D face model
25	55	57	to
25	62	78	probability maps
25	79	90	produced by
25	93	96	CNN
27	24	27	ERT
27	28	46	implicitly imposes
27	49	65	prior face shape
27	66	68	on
27	73	81	solution
27	84	94	addressing
27	99	111	shortcomings
27	112	114	of
27	115	126	deep models
27	127	131	when
28	14	42	coarse - to - fine structure
28	43	50	tackles
28	55	78	combinatorial explosion
28	79	81	of
28	82	99	parts deformation
31	9	16	improve
31	21	35	initialization
31	36	44	by using
31	47	70	RANSAC - like procedure
31	76	85	increases
31	90	100	robustness
31	101	103	in
31	120	130	occlusions
32	13	23	introduced
32	24	38	early stopping
32	24	78	early stopping and better data augmentation techniques
32	79	93	for increasing
32	98	112	regularization
32	113	126	when training
32	136	151	ERT and the CNN
210	3	6	use
210	7	35	Adam stochastic optimization
210	36	40	with
210	41	89	? 1 = 0.9 , ? 2 = 0.999 and = 1 e ? 8 parameters
211	3	8	train
211	9	26	until convergence
211	15	26	convergence
211	27	31	with
211	35	66	initial learning rate ? = 0.001
212	0	4	When
212	5	21	validation error
212	22	36	levels out for
212	37	46	10 epochs
212	52	60	multiply
212	65	78	learning rate
212	79	81	by
212	82	94	decay = 0.05
214	3	8	apply
214	9	28	batch normalization
214	29	34	after
214	35	51	each convolution
215	0	10	All layers
215	11	18	contain
215	19	29	68 filters
215	30	41	to describe
215	46	72	required landmark features
216	3	8	apply
216	11	26	Gaussian filter
216	27	31	with
216	32	38	? = 33
216	39	41	to
216	46	69	output probability maps
216	70	82	to stabilize
216	87	101	initialization
216	87	107	initialization , g 0
217	3	8	train
217	13	35	coarse - to - fine ERT
217	36	40	with
217	45	72	Gradient Boosting algorithm
218	3	11	requires
218	14	38	maximum of T = 20 stages
218	39	41	of
218	42	75	K = 50 regression trees per stage
219	4	9	depth
219	10	12	of
219	13	18	trees
219	22	28	set to
219	29	30	4
220	4	19	number of tests
220	20	29	to choose
220	34	55	best split parameters
220	65	71	set to
220	72	75	200
221	3	9	resize
221	10	20	each image
221	21	27	to set
221	32	41	face size
221	42	44	to
221	45	58	160160 pixels
223	3	11	generate
223	12	34	Z = 25 initializations
223	35	37	in
223	42	66	robust soft POSIT scheme
223	67	69	of
223	70	73	g 0
224	3	10	augment
224	15	21	shapes
224	22	24	of
224	25	49	each face training image
224	50	59	to create
224	62	65	set
224	68	70	SA
224	73	75	of
224	76	104	at least N A = 60000 samples
224	105	113	to train
224	118	125	cascade
225	0	8	To avoid
225	9	20	overfitting
225	24	27	use
225	59	85	subsampling factor ? = 0.5
225	86	88	in
225	93	96	ERT
227	0	8	Training
227	13	61	CNN and the coarse - to - fine ensemble of trees
227	62	67	takes
227	68	76	48 hours
227	77	82	using
227	85	125	NVidia GeForce GTX 1080 Ti ( 11 GB ) GPU
227	133	164	dual Intel Xeon Silver 4114 CPU
227	165	167	at
227	168	176	2.20 GHz
227	220	224	with
227	227	237	batch size
227	238	240	of
227	241	250	32 images
237	10	15	3 DDE
237	16	18	is
237	19	30	better than
237	31	40	any other
237	41	50	providing
237	53	74	public implementation
239	18	25	able to
239	26	33	improve
239	34	36	by
239	39	51	large margin
239	52	69	other ERT methods
239	70	72	as
239	73	77	RCPR
239	80	83	ERT
239	87	93	c GPRT
240	8	18	outperform
240	19	22	RCN
240	59	75	CNN architecture
241	5	16	DAN and LAB
241	24	33	implement
241	36	61	cascade of CNN regressors
241	89	103	regularization
241	104	121	obtained by using
241	126	140	cascade of ERT
241	141	143	in
241	144	149	3 DDE
247	0	12	Our approach
247	13	20	obtains
247	25	49	best overall performance
247	50	52	in
247	57	83	indoor and outdoor subsets
247	84	86	of
247	91	110	private competition
247	123	125	in
247	130	141	full subset
247	142	144	of
247	149	169	300W public test set
249	0	2	In
249	7	25	challenging subset
249	26	28	of
249	33	56	300W public competition
249	59	62	SHN
249	63	67	gets
249	68	82	better results
249	83	87	than
249	88	92	3DDE
296	5	18	combined with
296	23	35	cascaded ERT
296	42	59	3D initialization
296	63	66	key
296	67	77	to achieve
296	78	101	top overall performance
296	104	107	see
296	108	121	CNN + MS + DE
296	125	138	CNN + 3D + DE
296	139	141	in
296	146	157	full subset
299	16	33	3D initialization
299	60	76	good performance
299	77	91	in presence of
299	92	112	large face rotations
302	4	26	large receptive fields
302	27	29	of
302	30	34	CNNs
302	39	56	specially helpful
302	57	59	in
302	60	82	challenging situations
302	111	137	pose and occlusion subsets
303	4	31	coarse - to - fine strategy
303	32	34	in
303	52	60	provides
303	61	93	significative local improvements
303	94	96	in
303	97	112	difficult cases
303	115	119	with
303	120	149	rare facial part combinations
