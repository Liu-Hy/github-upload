2	72	97	Facial Landmark Detection
30	19	26	propose
30	29	60	novel Semantic Alignment method
30	67	74	reduces
30	79	116	' semantic ambiguity ' intrinsi-cally
32	3	8	model
32	13	36	' real ' ground - truth
32	37	39	as
32	42	57	latent variable
32	58	60	to
32	61	69	optimize
32	80	113	optimized ' real ' ground - truth
32	119	129	supervises
32	134	169	landmark detection network training
33	17	24	propose
33	27	46	probabilistic model
33	57	78	simultaneously search
33	83	106	' real ' ground - truth
33	111	116	train
33	121	147	landmark detection network
33	148	150	in
33	154	172	end - to - end way
34	34	45	prior model
34	49	61	to constrain
34	66	81	latent variable
34	82	87	to be
34	88	96	close to
34	101	113	observations
34	114	116	of
34	121	142	' real ' ground truth
35	4	20	likelihood model
35	24	33	to reduce
35	38	65	Pearson Chi-square distance
35	66	73	between
35	78	118	expected and the predicted distributions
35	119	121	of
35	122	145	' real ' ground - truth
36	4	11	heatmap
36	12	24	generated by
36	29	51	hourglass architecture
36	52	62	represents
36	67	77	confidence
36	78	80	of
36	81	91	each pixel
36	101	124	confidence distribution
36	146	182	predicted distribution of likelihood
37	61	68	propose
37	71	110	global heatmap correction unit ( GHCU )
37	117	126	maintains
37	131	159	global face shape constraint
37	164	172	recovers
37	177	210	unconfidently predicted landmarks
37	211	220	caused by
37	221	240	challenging factors
37	241	248	such as
37	249	259	occlusions
201	0	10	To perform
201	11	28	data augmentation
201	34	49	randomly sample
201	54	98	angle of rotation and the bounding box scale
201	99	103	from
201	104	125	Gaussian distribution
202	3	6	use
202	9	47	four - stage stacked hourglass network
202	48	50	as
202	51	63	our backbone
202	73	83	trained by
202	88	105	optimizer RMSprop
207	0	13	When training
207	5	13	training
207	18	41	roughly converged model
207	42	46	with
207	47	64	human annotations
207	71	92	initial learning rate
207	93	95	is
207	96	105	2.5 10 ?4
207	115	125	decayed to
207	126	136	2.5 10 ? 6
207	137	142	after
207	143	153	120 epochs
208	0	4	When
208	5	18	training with
208	19	37	Semantic Alignment
208	38	42	from
208	47	56	beginning
208	57	59	of
208	109	130	initial learning rate
208	131	133	is
208	134	144	2.5 10 ? 6
208	152	162	divided by
208	163	174	5 , 2 and 2
208	175	177	at
208	178	198	epoch 30 , 60 and 90
211	3	6	set
211	7	17	batch size
211	18	20	to
211	21	23	10
211	24	27	for
211	28	44	network training
213	23	35	trained with
213	36	43	PyTorch
213	51	53	on
213	54	68	2 Titan X GPUs
215	0	5	300 W
220	11	19	see that
220	20	23	HGs
220	24	28	with
220	29	64	our Semantic Alignment ( HGs + SA )
220	65	83	greatly outperform
220	84	106	hourglass ( HGs ) only
220	109	125	4.37 % vs 5.04 %
220	126	137	in terms of
220	138	141	NME
220	142	144	on
220	145	153	Full set
221	3	9	adding
221	10	14	GHCU
221	24	32	see that
221	33	48	HGs + SA + GHCU
221	49	69	slightly outperforms
221	74	82	HGs + SA
223	20	29	normalize
223	34	55	in - plane - rotation
223	56	67	by training
223	70	91	preprocessing network
223	97	104	conduct
223	155	162	achieve
223	163	191	state of the art performance
223	192	194	on
223	195	221	Challenge set and Full set
223	224	241	6.38 % and 4.02 %
224	16	18	on
224	19	32	Challenge set
224	38	62	significantly outperform
224	67	90	state of the art method
224	93	125	6.38 % ( HGs + SA +GHCU + Norm )
224	129	143	6.98 % ( LAB )
225	0	11	AFLW . 300W
225	16	32	68 facial points
225	39	46	contain
225	47	75	many weak semantic landmarks
230	21	29	HGs + SA
230	30	41	outperforms
231	0	3	HGs
231	6	22	1.62 % vs 1.95 %
233	11	24	observed that
233	11	19	observed
233	25	40	HGs + SA + GHCU
233	41	46	works
233	54	58	than
233	59	67	HGs + SA
234	0	8	300 - VW
238	11	19	see that
238	20	28	HGs + SA
238	29	48	greatly outperforms
238	49	52	HGs
239	14	27	compared with
239	28	36	HGs + SA
239	39	54	HGs + SA + GHCU
239	55	61	reduce
239	66	85	error rate ( RMSE )
239	86	88	by
239	89	93	18 %
239	94	96	on
239	97	116	Category 3 test set
287	102	104	on
287	105	113	300 - VW
290	4	22	Semantic alignment
290	27	47	consistently improve
290	52	63	performance
290	64	66	on
290	67	82	all subset sets
290	85	98	demonstrating
291	0	4	GHCU
291	5	7	is
291	8	22	more effective
291	23	25	on
291	30	48	challenge data set
291	66	82	8.15 % vs 9.91 %
291	85	94	Combining
291	107	112	works
291	113	119	better
291	120	124	than
