(our model||used||stochastic gradient descent)
(stochastic gradient descent||with||ADAM optimizer)
(stochastic gradient descent||with||initial learning rate)
(stochastic gradient descent||with||initial learning rate)
(initial learning rate||of||0.001)
(word embeddings||drawing from||uniform distribution)
(initialized randomly||drawing from||uniform distribution)
(initialized||drawing from||uniform distribution)
(randomly||drawing from||uniform distribution)
(word embeddings||has||initialized randomly)
(initialized||has||randomly)
(Experimental setup||has||word embeddings)
(batches||of||32 examples)
(patience||of||2 epochs)
(early stopping||with||patience)
(patience||of||2 epochs)
(Experimental setup||used||batches)
(Theano||using||Keras framework)
(Experimental setup||implement in||Theano)
(2 - regularization||at||0.001 , ? = 50 , and ? = 0.04)
(Experimental setup||used||2 - regularization)
(Contribution||has||Experimental setup)
