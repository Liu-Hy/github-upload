2	25	63	Multi - Document Reading Comprehension
13	0	37	Machine reading comprehension ( MRC )
29	35	42	propose
29	45	63	deep cascade model
29	70	78	combines
29	83	93	advantages
29	94	96	of
29	97	109	both methods
29	110	112	in
29	115	140	coarse - to - fine manner
30	4	22	deep cascade model
30	26	51	designed to properly keep
30	56	63	balance
30	64	71	between
30	76	104	effectiveness and efficiency
31	0	2	At
31	3	15	early stages
31	31	68	simple features and ranking functions
31	78	87	to select
31	90	103	candidate set
31	104	106	of
31	107	129	most relevant contents
31	132	145	filtering out
31	150	185	irrelevant documents and paragraphs
32	9	28	selected paragraphs
32	33	42	passed to
32	47	79	attention - based deep MRC model
32	80	94	for extracting
32	99	117	actual answer span
32	118	120	at
32	121	131	word level
33	50	59	introduce
33	64	83	document extraction
33	88	108	paragraph extraction
34	3	19	jointly optimize
34	20	39	all the three tasks
34	40	42	in
34	45	67	unified deep MRC model
34	76	82	shares
34	83	108	some common bottom layers
35	5	23	cascaded structure
35	24	31	enables
35	36	42	models
35	43	53	to perform
35	56	82	coarse - to - fine pruning
35	83	85	at
35	86	102	different stages
35	105	118	better models
36	62	73	consists of
36	74	87	three modules
36	90	108	document retrieval
36	111	130	paragraph retrieval
36	135	152	answer extraction
37	4	16	first module
37	17	22	takes
37	27	35	question
37	42	69	collection of raw documents
37	70	72	as
37	73	78	input
38	4	10	module
38	11	13	at
38	14	35	each subsequent stage
38	36	44	consumes
38	49	55	output
38	56	60	from
38	65	79	previous stage
38	86	100	further prunes
38	105	144	documents , paragraphs and answer spans
38	145	150	given
38	155	163	question
40	4	20	ranking function
40	30	37	used as
40	40	58	preliminary filter
40	59	69	to discard
40	70	116	most of the irrelevant documents or paragraphs
41	4	23	extraction function
41	32	53	designed to deal with
41	58	107	auxiliary document and paragraph extraction tasks
41	119	141	jointly optimized with
41	146	176	final answer extraction module
41	177	180	for
41	181	210	better extraction performance
208	3	9	choose
208	10	25	K = 4 and N = 2
208	26	29	for
208	34	50	good performance
208	74	81	dev set
211	0	3	For
211	8	43	multi-task deep attention framework
211	49	54	adopt
211	59	73	Adam optimizer
211	74	77	for
211	78	86	training
211	89	93	with
211	96	111	mini-batch size
211	112	114	of
211	115	117	32
211	122	143	initial learning rate
211	144	146	of
211	147	153	0.0005
212	3	6	use
212	11	48	GloVe 300 dimensional word embeddings
212	49	51	in
212	52	60	TriviaQA
212	65	70	train
212	73	98	word2 vec word embeddings
212	99	103	with
212	108	129	whole DuReader corpus
212	130	133	for
212	134	142	DuReader
213	4	19	word embeddings
213	24	36	fixed during
213	37	45	training
214	4	15	hidden size
214	16	18	of
214	19	23	LSTM
214	27	33	set as
214	34	37	150
214	38	41	for
214	42	50	TriviaQA
214	55	58	128
214	59	62	for
214	63	71	DuReader
215	4	38	task - specific hyper - parameters
215	66	72	set as
215	73	88	? 1 = ? 2 = 0.5
215	91	115	Regularization parameter
216	6	12	set as
216	15	26	small value
216	27	29	of
216	30	34	0.01
217	15	25	trained on
217	26	46	Nvidia Tesla M40 GPU
217	47	51	with
217	52	67	Cudnn LSTM cell
217	68	70	in
217	71	85	Tensorflow 1.3
221	7	10	see
221	16	27	by adopting
221	32	63	deep cascade learning framework
221	70	84	proposed model
221	85	96	outperforms
221	101	140	previous state - of - the - art methods
221	141	143	by
221	147	161	evident margin
221	162	164	on
221	165	178	both datasets
226	45	56	shared LSTM
226	57	62	plays
226	66	80	important role
226	81	83	in
226	84	101	answer extraction
226	102	107	among
226	108	126	multiple documents
226	191	216	content probability score
226	217	221	from
226	222	240	multiple documents
226	334	338	keep
226	343	356	ranking order
226	357	361	from
226	362	388	document ranking component
227	21	36	manual features
227	43	54	performance
227	62	87	further improved slightly
228	13	82	preliminary cascade ranking and multi-task answer extraction strategy
228	87	96	vital for
228	101	118	final performance
228	127	135	serve as
228	138	154	good trade - off
228	155	162	between
228	167	187	pure pipeline method
228	192	219	fully joint learning method
230	0	16	Jointly training
230	21	43	three extraction tasks
230	48	55	provide
230	56	70	great benefits
230	143	148	boost
230	149	159	each other
230	160	164	with
230	165	187	shared representations
230	188	190	at
230	191	204	bottom layers
