{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.models'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cf78cabd34f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m from simpletransformers.classification import (\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mClassificationArgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mClassificationModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\simpletransformers\\classification\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_label_classification_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiLabelClassificationModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_modal_classification_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiModalClassificationModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m from simpletransformers.config.model_args import (\n\u001b[0;32m      5\u001b[0m     \u001b[0mClassificationArgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malbert_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAlbertForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcamembert_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCamembertForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistilbert_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\simpletransformers\\classification\\transformer_models\\bert_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodeling_bert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertPreTrainedModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval as load\n",
    "import sklearn\n",
    "\n",
    "from simpletransformers.classification import (\n",
    "    ClassificationArgs,\n",
    "    ClassificationModel,\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../interim/try1.csv')\n",
    "df = df.rename(columns={'idx': 'indx'})\n",
    "df = df[(df['predicates']!='[]')&(df['subj/obj']!='[]')]\n",
    "df.insert(loc=0, column='idx', value=np.arange(len(df)))\n",
    "df = df.sample(frac=1, random_state=1)\n",
    "bound = int(0.9*len(df))\n",
    "t_df = df[:bound]\n",
    "e_df = df[bound:]\n",
    "t_df = t_df.values\n",
    "e_df = e_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(arr, is_eval):\n",
    "    missed=0\n",
    "    ls=[]\n",
    "    for i in range(len(arr)):\n",
    "        pre = load(arr[i,3])[0]\n",
    "        np = load(arr[i,4])[0]\n",
    "        if pre[1][0]>np[1][0]:\n",
    "            missed+=len(load(arr[i,7]))\n",
    "        else:\n",
    "            word_ls = arr[i,2].split(' ')\n",
    "            word_ls.insert(pre[1][0], '<<')\n",
    "            word_ls.insert(pre[1][1]+1, '>>')\n",
    "            word_ls.insert(np[1][0]+2, '[[')\n",
    "            word_ls.insert(np[1][1]+3, ']]')\n",
    "            unit = arr[i,1]\n",
    "            unit = (unit[0].upper()+unit[1:]).replace('-',' ')\n",
    "            unit_ls = ['[[']+(unit.split(' '))+[']]']\n",
    "            word_ls = unit_ls+[':']+word_ls\n",
    "            flg=0\n",
    "            if arr[i,7]=='[]':\n",
    "                trip_ls = []\n",
    "            else:\n",
    "                trip_ls = load(arr[i,7])\n",
    "                for trip in trip_ls:\n",
    "                    if trip[1]==pre[0] and trip[2]==np[0]:\n",
    "                        flg=1\n",
    "                        break\n",
    "            ls.append([unit, pre[0], np[0], trip_ls, ' '.join(word_ls), flg])\n",
    "    dataframe = pd.DataFrame(ls)\n",
    "    dataframe.columns = ['info_unit', 'pre', 'np', 'triples', 'text', 'labels']\n",
    "    if is_eval:\n",
    "        print(f'missed {missed} triples in the eval set')\n",
    "        return dataframe, missed\n",
    "    else:\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = convert(t_df,0)\n",
    "eval_df, missed = convert(e_df,1)\n",
    "num_pos = len(train_df[train_df['labels']==1])\n",
    "num_neg = len(train_df[train_df['labels']==0])\n",
    "imbalance_ratio = num_neg/num_pos\n",
    "train_df.to_csv('train_C.csv')\n",
    "eval_df.to_csv('eval_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "missed 7 triples in the eval set\n"
     ]
    }
   ],
   "source": [
    "model_args = ClassificationArgs()\n",
    "# arguments for early stop\n",
    "model_args.use_early_stopping = True\n",
    "# model_args.early_stopping_delta = 0.01\n",
    "model_args.early_stopping_metric = \"F1_score\"\n",
    "model_args.early_stopping_metric_minimize = False\n",
    "model_args.early_stopping_patience = 1\n",
    "model_args.early_stopping_consider_epochs = True\n",
    "# model_args.evaluate_during_training_steps = 500\n",
    "model_args.evaluate_during_training_verbose = True\n",
    "\n",
    "model_args.train_batch_size = 16\n",
    "model_args.learning_rate = 1e-5\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.no_save = True\n",
    "model_args.fp16 = False\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.manual_seed = 1\n",
    "model_args.use_multiprocessing = True\n",
    "model_args.num_train_epochs = 2\n",
    "model_args.gradient_accumulation_steps = 4\n",
    "# model_args.learning_rate = 1e-4\n",
    "# model_args.num_labels = 2 # SHOULD it be here?\n",
    "# model_args.weight = [1, 3] # SHOULD it be here?\n",
    "model_args.do_lower_case = True  # when using uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_F1(ref, pred):\n",
    "    TP=FP=FN=0\n",
    "    for i in range(len(pred)):\n",
    "        pred_ls = []\n",
    "        ref_ls = eval_df.iloc[i,3]\n",
    "        trip = [eval_df.iloc[i,0], eval_df.iloc[i,1], eval_df.iloc[i,2]]\n",
    "        pred_ls.append(trip)\n",
    "        TP+=len([t for t in pred_ls if t in ref_ls])\n",
    "        FP+=len([t for t in pred_ls if t not in ref_ls]) \n",
    "        FN+=len([t for t in ref_ls if t not in pred_ls])\n",
    "    FN+=missed\n",
    "    pc=TP/(TP+FP)\n",
    "    rc=TP/(TP+FN)\n",
    "    F1=2*pc*rc/(pc+rc)\n",
    "    print(f'precision {pc}, recall {rc}, F1 {F1}')\n",
    "    return F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationModel(\n",
    "    \"bert\",\n",
    "    \"allenai/scibert_scivocab_uncased\",\n",
    "    weight=[1,imbalance_ratio],\n",
    "    args=model_args,\n",
    ")\n",
    "print(f'imbalance ratio: {imbalance_ratio}')\n",
    "# Train the model\n",
    "model.train_model(train_df, eval_df=eval_df,F1_score=triple_F1)\n",
    "# Evaluate the model\n",
    "#result, model_outputs, wrong_predictions = model.eval_model(eval_df, F1_score=triple_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Res gd'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}