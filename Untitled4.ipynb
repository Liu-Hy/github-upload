{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('d2l': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bae6546355a940aef21a1ec3c358906dbfda972b422ba2c211a5d8f2f4cba271"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_data_s2s():\n",
    "    data_file = './parallel_train.csv'\n",
    "    with open(data_file, 'r') as f:\n",
    "        return f.read()\n",
    "        \n",
    "raw_text = read_data_s2s()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_s2s(batch_size, num_steps, num_examples=1000):\n",
    "    text = d2l.preprocess_nmt(read_data_s2s())\n",
    "    source, target = d2l.tokenize_nmt(text, num_examples)\n",
    "    src_vocab = d2l.Vocab(source, min_freq=3,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = d2l.Vocab(target, min_freq=3,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = d2l.build_array(\n",
    "        source, src_vocab, num_steps, True)\n",
    "    tgt_array, tgt_valid_len = d2l.build_array(\n",
    "        target, tgt_vocab, num_steps, False)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = d2l.load_array(data_arrays, batch_size)\n",
    "    return src_vocab, tgt_vocab, data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab, tgt_vocab, train_iter = load_data_s2s(batch_size=2, num_steps=8)\n",
    "for X, X_vlen, Y, Y_vlen in train_iter:\n",
    "    print('X:', X.type(torch.int32))\n",
    "    print('valid lengths for X:', X_vlen)\n",
    "    print('Y:', Y.type(torch.int32))\n",
    "    print('valid lengths for Y:', Y_vlen)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab['<ukn>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 100, d2l.try_gpu()\n",
    "\n",
    "src_vocab, tgt_vocab, train_iter = load_data_s2s(batch_size, num_steps)\n",
    "encoder = d2l.Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = d2l.Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = d2l.EncoderDecoder(encoder, decoder)\n",
    "d2l.train_s2s_ch9(model, train_iter, lr, num_epochs, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = pd.read_csv('./parallel_eval.csv', sep = '\\t', header = None)\n",
    "eval.columns = ['source', 'reference']\n",
    "eval.insert(2, 'output', [0]*len(eval))\n",
    "for i in range(len(eval)):\n",
    "    eval.loc[i, 'output'] = d2l.predict_s2s_ch9(model, sentence, src_vocab, tgt_vocab, num_steps, device)\n",
    "eval.to_csv('./eval_result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_vocab[tgt_vocab.to_tokens([3,6,7,10,234])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tgt_vocab.idx_to_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand = src_tokens + [src_vocab['['], src_vocab[']'], src_vocab['{'], src_vocab['}'], src_vocab[':'], src_vocab[',']]\n",
    "cand = list(set(cand))\n",
    "if src_vocab['<pad>'] in src_tokens:\n",
    "    cand.remove(src_vocab['<pad>'])\n",
    "cand = sorted(cand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_vocab['aspect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sorted([5, 2, 3, 2, 1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [] \n",
    "[res.append(x) for x in test_list if x not in res] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[2,4,6,6,3,37,999]\n",
    "g=[3]\n",
    "f+=g\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(set(f))\n",
    "k.remove(999)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f += [src_vocab['['], src_vocab[']'], src_vocab['{'], src_vocab['}'], src_vocab[':'], src_vocab[',']]\n",
    "f.remove([9,8,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=sorted(f)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[42453,48865,309,66464,24442,454,2535,8686]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.ones((2,3))\n",
    "a[1,2]=4\n",
    "a[0,1]=3\n",
    "a[0,0]=6\n",
    "a[1,0]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[6., 3., 1.],\n",
       "        [5., 1., 4.]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a[:,1:2]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=c[:,:]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.topk(a, 3, dim=1).indices\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=x.flatten()\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(d.shape[0]):\n",
    "    print(d[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0,0]=999\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.tensor([2])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(tensor([[6., 3., 1.],\n",
       "          [5., 1., 4.]]),\n",
       "  tensor([5., 1., 4.])),\n",
       " (tensor([[6., 3., 1.],\n",
       "          [5., 1., 4.]]),\n",
       "  tensor([5., 1., 4.])),\n",
       " (tensor([[6., 3., 1.],\n",
       "          [5., 1., 4.]]),\n",
       "  tensor([5., 1., 4.]))]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "b=[(a, a[1])]*3\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [([],) for b in range(5)]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[([],) for b in range(beam_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      idx                                               text  \\\n",
       "0       2  Learning Phrase Representations using RNN Enco...   \n",
       "1      15  Along this line of research on using neural ne...   \n",
       "2      16  The proposed neural network architecture , whi...   \n",
       "3      17  The encoder maps a variable - length source se...   \n",
       "4      18  The two networks are trained jointly to maximi...   \n",
       "...   ...                                                ...   \n",
       "6123  362  presents the classification results on Fisher ...   \n",
       "6124  367  We can see that our proposed systems achieve c...   \n",
       "6125  370  presents classification results on 20 Newsgrou...   \n",
       "6126  376  We see that the topic ID systems based on Baye...   \n",
       "6127  377  We can also see that all the topic ID systems ...   \n",
       "\n",
       "             main_heading              heading                topic  \\\n",
       "0                   title                title  machine-translation   \n",
       "1            Introduction         Introduction  machine-translation   \n",
       "2            Introduction         Introduction  machine-translation   \n",
       "3            Introduction         Introduction  machine-translation   \n",
       "4            Introduction         Introduction  machine-translation   \n",
       "...                   ...                  ...                  ...   \n",
       "6123  D. Topic ID results  D. Topic ID results         topic_models   \n",
       "6124  D. Topic ID results  D. Topic ID results         topic_models   \n",
       "6125  D. Topic ID results  D. Topic ID results         topic_models   \n",
       "6126  D. Topic ID results  D. Topic ID results         topic_models   \n",
       "6127  D. Topic ID results  D. Topic ID results         topic_models   \n",
       "\n",
       "      paper_idx                                                BIO  \\\n",
       "0             0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "1             0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "2             0  ['O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', ...   \n",
       "3             0  ['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', ...   \n",
       "4             0  ['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', ...   \n",
       "...         ...                                                ...   \n",
       "6123          0  ['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', ...   \n",
       "6124          0  ['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', ...   \n",
       "6125          0           ['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']   \n",
       "6126          0  ['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', ...   \n",
       "6127          0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', ...   \n",
       "\n",
       "                                                  BIO_1  \\\n",
       "0     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "1     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "2     ['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O',...   \n",
       "3                                                   NaN   \n",
       "4     ['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p...   \n",
       "...                                                 ...   \n",
       "6123  ['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n',...   \n",
       "6124  ['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', ...   \n",
       "6125     ['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']   \n",
       "6126  ['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', ...   \n",
       "6127  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-...   \n",
       "\n",
       "                                                  BIO_2  offset  mask  \\\n",
       "0     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...       1     1   \n",
       "1     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...       6     1   \n",
       "2     ['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O',...       7     1   \n",
       "3                                                   NaN       8     1   \n",
       "4     ['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p...       9     1   \n",
       "...                                                 ...     ...   ...   \n",
       "6123  ['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b',...       4     1   \n",
       "6124  ['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', ...       9     1   \n",
       "6125     ['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']      12     1   \n",
       "6126  ['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', ...      18     1   \n",
       "6127  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-...      19     1   \n",
       "\n",
       "      bi_labels            labels  \n",
       "0             1  research-problem  \n",
       "1             1  research-problem  \n",
       "2             1             model  \n",
       "3             1             model  \n",
       "4             1             model  \n",
       "...         ...               ...  \n",
       "6123          1           results  \n",
       "6124          1           results  \n",
       "6125          1           results  \n",
       "6126          1           results  \n",
       "6127          1           results  \n",
       "\n",
       "[6128 rows x 13 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>text</th>\n      <th>main_heading</th>\n      <th>heading</th>\n      <th>topic</th>\n      <th>paper_idx</th>\n      <th>BIO</th>\n      <th>BIO_1</th>\n      <th>BIO_2</th>\n      <th>offset</th>\n      <th>mask</th>\n      <th>bi_labels</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Learning Phrase Representations using RNN Enco...</td>\n      <td>title</td>\n      <td>title</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>research-problem</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>Along this line of research on using neural ne...</td>\n      <td>Introduction</td>\n      <td>Introduction</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>research-problem</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>The proposed neural network architecture , whi...</td>\n      <td>Introduction</td>\n      <td>Introduction</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>['O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', ...</td>\n      <td>['O', 'O', 'B-n', 'I-n', 'I-n', 'O', 'O', 'O',...</td>\n      <td>['O', 'O', 'B-b', 'I-b', 'I-b', 'O', 'O', 'O',...</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>model</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>The encoder maps a variable - length source se...</td>\n      <td>Introduction</td>\n      <td>Introduction</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>['O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>model</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>The two networks are trained jointly to maximi...</td>\n      <td>Introduction</td>\n      <td>Introduction</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>['O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'O', ...</td>\n      <td>['O', 'O', 'O', 'O', 'B-p', 'B-n', 'B-p', 'I-p...</td>\n      <td>['O', 'O', 'O', 'O', 'B-p', 'B-b', 'B-p', 'I-p...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>model</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6123</th>\n      <td>362</td>\n      <td>presents the classification results on Fisher ...</td>\n      <td>D. Topic ID results</td>\n      <td>D. Topic ID results</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n',...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b',...</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>results</td>\n    </tr>\n    <tr>\n      <th>6124</th>\n      <td>367</td>\n      <td>We can see that our proposed systems achieve c...</td>\n      <td>D. Topic ID results</td>\n      <td>D. Topic ID results</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>['O', 'O', 'B', 'I', 'B', 'I', 'I', 'B', 'B', ...</td>\n      <td>['O', 'O', 'B-p', 'I-p', 'B-n', 'I-n', 'I-n', ...</td>\n      <td>['O', 'O', 'B-p', 'I-p', 'B-b', 'I-b', 'I-b', ...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>results</td>\n    </tr>\n    <tr>\n      <th>6125</th>\n      <td>370</td>\n      <td>presents classification results on 20 Newsgrou...</td>\n      <td>D. Topic ID results</td>\n      <td>D. Topic ID results</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']</td>\n      <td>['O', 'O', 'O', 'O', 'B-n', 'I-n', 'I-n', 'O']</td>\n      <td>['O', 'O', 'O', 'O', 'B-b', 'I-b', 'I-b', 'O']</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>results</td>\n    </tr>\n    <tr>\n      <th>6126</th>\n      <td>376</td>\n      <td>We see that the topic ID systems based on Baye...</td>\n      <td>D. Topic ID results</td>\n      <td>D. Topic ID results</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>['O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', ...</td>\n      <td>['O', 'B-p', 'I-p', 'O', 'B-n', 'I-n', 'I-n', ...</td>\n      <td>['O', 'B-p', 'I-p', 'O', 'B-b', 'I-b', 'I-b', ...</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1</td>\n      <td>results</td>\n    </tr>\n    <tr>\n      <th>6127</th>\n      <td>377</td>\n      <td>We can also see that all the topic ID systems ...</td>\n      <td>D. Topic ID results</td>\n      <td>D. Topic ID results</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-n', 'I-...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-b', 'I-...</td>\n      <td>19</td>\n      <td>1</td>\n      <td>1</td>\n      <td>results</td>\n    </tr>\n  </tbody>\n</table>\n<p>6128 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "a=pd.read_csv('./interim/pos_sent.csv')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      idx                                               text  \\\n",
       "14     31  The ByteNet is the instance within this family...   \n",
       "15     32  The two CNNs use increasing factors of dilatio...   \n",
       "16     33  The convolutions in the decoder CNN are masked...   \n",
       "129    26  The following is a list of the five MT systems...   \n",
       "130    27  Constrained English - Estonian and Estonian - ...   \n",
       "...   ...                                                ...   \n",
       "5427  182  Moreover , our M - ACNN also achieves slightly...   \n",
       "5450  215  Fine - tuning the LM is most beneficial for la...   \n",
       "5639  189  For different tasks , one should design specif...   \n",
       "5802  204  We use Adam ( Kingma and Ba , 2015 ) optimizer...   \n",
       "6102  104  Our final Elman architecture ( RAS - Elman ) u...   \n",
       "\n",
       "                 main_heading                     heading  \\\n",
       "14               Introduction                Introduction   \n",
       "15               Introduction                Introduction   \n",
       "16               Introduction                Introduction   \n",
       "129           System Overview             System Overview   \n",
       "130           System Overview             System Overview   \n",
       "...                       ...                         ...   \n",
       "5427     Experimental Results     Document Classification   \n",
       "5450    Impact of pretraining  Impact of LM fine - tuning   \n",
       "5639         Training Setting            Training Setting   \n",
       "5802   Implementation details      Implementation details   \n",
       "6102  Datasets and Evaluation       Architectural Choices   \n",
       "\n",
       "                    topic  paper_idx  \\\n",
       "14    machine-translation          1   \n",
       "15    machine-translation          1   \n",
       "16    machine-translation          1   \n",
       "129   machine-translation          5   \n",
       "130   machine-translation          5   \n",
       "...                   ...        ...   \n",
       "5427  text-classification          4   \n",
       "5450  text-classification          5   \n",
       "5639      text_generation          0   \n",
       "5802   text_summarization          1   \n",
       "6102   text_summarization          9   \n",
       "\n",
       "                                                    BIO BIO_1 BIO_2  offset  \\\n",
       "14    ['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', ...   NaN   NaN      18   \n",
       "15    ['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', ...   NaN   NaN      19   \n",
       "16    ['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', ...   NaN   NaN      20   \n",
       "129   ['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', ...   NaN   NaN       2   \n",
       "130   ['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', ...   NaN   NaN       3   \n",
       "...                                                 ...   ...   ...     ...   \n",
       "5427  ['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', ...   NaN   NaN      10   \n",
       "5450  ['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', ...   NaN   NaN      10   \n",
       "5639  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   NaN   NaN       5   \n",
       "5802  ['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', ...   NaN   NaN       4   \n",
       "6102  ['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', ...   NaN   NaN      16   \n",
       "\n",
       "      mask  bi_labels labels  \n",
       "14       1          1    NaN  \n",
       "15       1          1    NaN  \n",
       "16       1          1    NaN  \n",
       "129      1          1    NaN  \n",
       "130      1          1    NaN  \n",
       "...    ...        ...    ...  \n",
       "5427     1          1    NaN  \n",
       "5450     1          1    NaN  \n",
       "5639     1          1    NaN  \n",
       "5802     1          1    NaN  \n",
       "6102     1          1    NaN  \n",
       "\n",
       "[64 rows x 13 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>text</th>\n      <th>main_heading</th>\n      <th>heading</th>\n      <th>topic</th>\n      <th>paper_idx</th>\n      <th>BIO</th>\n      <th>BIO_1</th>\n      <th>BIO_2</th>\n      <th>offset</th>\n      <th>mask</th>\n      <th>bi_labels</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>31</td>\n      <td>The ByteNet is the instance within this family...</td>\n      <td>Introduction</td>\n      <td>Introduction</td>\n      <td>machine-translation</td>\n      <td>1</td>\n      <td>['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>32</td>\n      <td>The two CNNs use increasing factors of dilatio...</td>\n      <td>Introduction</td>\n      <td>Introduction</td>\n      <td>machine-translation</td>\n      <td>1</td>\n      <td>['O', 'B', 'I', 'B', 'B', 'I', 'I', 'I', 'O', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>33</td>\n      <td>The convolutions in the decoder CNN are masked...</td>\n      <td>Introduction</td>\n      <td>Introduction</td>\n      <td>machine-translation</td>\n      <td>1</td>\n      <td>['O', 'B', 'B', 'O', 'B', 'I', 'O', 'B', 'O', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>26</td>\n      <td>The following is a list of the five MT systems...</td>\n      <td>System Overview</td>\n      <td>System Overview</td>\n      <td>machine-translation</td>\n      <td>5</td>\n      <td>['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>27</td>\n      <td>Constrained English - Estonian and Estonian - ...</td>\n      <td>System Overview</td>\n      <td>System Overview</td>\n      <td>machine-translation</td>\n      <td>5</td>\n      <td>['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5427</th>\n      <td>182</td>\n      <td>Moreover , our M - ACNN also achieves slightly...</td>\n      <td>Experimental Results</td>\n      <td>Document Classification</td>\n      <td>text-classification</td>\n      <td>4</td>\n      <td>['O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5450</th>\n      <td>215</td>\n      <td>Fine - tuning the LM is most beneficial for la...</td>\n      <td>Impact of pretraining</td>\n      <td>Impact of LM fine - tuning</td>\n      <td>text-classification</td>\n      <td>5</td>\n      <td>['B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'I', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5639</th>\n      <td>189</td>\n      <td>For different tasks , one should design specif...</td>\n      <td>Training Setting</td>\n      <td>Training Setting</td>\n      <td>text_generation</td>\n      <td>0</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5802</th>\n      <td>204</td>\n      <td>We use Adam ( Kingma and Ba , 2015 ) optimizer...</td>\n      <td>Implementation details</td>\n      <td>Implementation details</td>\n      <td>text_summarization</td>\n      <td>1</td>\n      <td>['O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6102</th>\n      <td>104</td>\n      <td>Our final Elman architecture ( RAS - Elman ) u...</td>\n      <td>Datasets and Evaluation</td>\n      <td>Architectural Choices</td>\n      <td>text_summarization</td>\n      <td>9</td>\n      <td>['O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "a[pd.isnull(a['labels'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}