(goal - directed endto - end deep reinforcement learning framework||to resolve||coreference)
(Model||propose||goal - directed endto - end deep reinforcement learning framework)
(neural architecture||as||our policy network)
(our policy network||includes||learning)
(span representation||scoring||potential entity mentions)
(our policy network||generating||probability distribution)
(learning||generating||probability distribution)
(over all possible coreference linking actions||from||current mention)
(current mention||to||antecedents)
(neural architecture||name||our policy network)
(learning||has||span representation)
(probability distribution||has||over all possible coreference linking actions)
(Model||leverage||neural architecture)
(sequence||of||linking actions)
(our reward function||measure||how good)
(how good||directly related to||coreference evaluation metrics)
(generated coreference clusters||directly related to||coreference evaluation metrics)
(sequence||has||linking actions)
(how good||has||generated coreference clusters)
(Model||has||sequence)
(entropy regularization term||to encourage||exploration)
(entropy regularization term||prevent||policy)
(policy||from||prematurely converging)
(prematurely converging||to||bad local optimum)
(Model||introduce||entropy regularization term)
(regularized policy network parameters||based on||rewards)
(rewards||associated with||sequences)
(sequences||of||sampled actions)
(sampled actions||computed on||whole input document)
(Model||update||regularized policy network parameters)
(Contribution||has||Model)
