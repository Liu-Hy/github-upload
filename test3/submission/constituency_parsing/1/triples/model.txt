(even larger performance gains||jointly pretraining||both directions)
(possible||jointly pretraining||both directions)
(both directions||of||large language - model - inspired self - attention cloze model)
(even larger performance gains||has||possible)
(Model||show||even larger performance gains)
(every token||in||training data)
(Our bi-directional transformer architecture||has||predicts)
(predicts||has||every token)
(Model||has||Our bi-directional transformer architecture)
(cloze - style training objective||where||model)
(model||predict||center word)
(center word||given||left - to - right and right - to - left context representations)
(cloze - style training objective||has||model)
(Model||introducing||cloze - style training objective)
(Our model||separately computes||both forward and backward states)
(both forward and backward states||with||Equal contribution)
(Model||has||Our model)
(Contribution||has||Model)
