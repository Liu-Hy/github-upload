(single attention model||gets to||88.3)
(ensemble of 5 LSTM + A+D models||achieves||90.5)
(90.5||matching||single - model BerkeleyParser)
(single - model BerkeleyParser||on||WSJ)
(single attention model||has||88.3)
(single LSTM + A model||achieves||92.5)
(large high - confidence corpus||has||single LSTM + A model)
(outperforms||has||best single model)
(Results||trained on||large high - confidence corpus)
(ensemble of 5 LSTM+ A models||further improves||score)
(score||to||92.8)
(ensemble of 5 LSTM+ A models||has||score)
(LSTM + A model||trained on||WSJ dataset)
(WSJ dataset||produced||malformed trees)
(malformed trees||for||25)
(25||of||1700 sentences)
(1700 sentences||in||our development set ( 1.5 % of all cases ))
(full high - confidence dataset||for||14 sentences ( 0.8 % ))
(Results||has||LSTM + A model)
(difference||between||F 1 score)
(F 1 score||on||sentences)
(sentences||of||length)
(1.3||for||BerkeleyParser)
(1.3||for||baseline LSTM)
(1.3||for||0.7)
(1.7||for||baseline LSTM)
(0.7||for||LSTM + A)
(Results||has||difference)
(LSTM + A||on||high - confidence corpus)
(trained||on||high - confidence corpus)
(95.7||on||QTB)
(high - confidence corpus||achieved||F 1 score)
(F 1 score||of||95.7)
(F 1 score||of||84.6)
(95.7||on||QTB)
(95.7||on||84.6)
(LSTM + A||has||trained)
(Results||has||LSTM + A)
(Contribution||has||Results)
