(small dataset||additionally used||2 dropout layers)
(Hyperparameters||Training on||small dataset)
(embedding layer||for||our 90K vocabulary)
(our 90K vocabulary||initialized||randomly)
(embedding layer||using||pre-trained word - vector embeddings)
(Hyperparameters||has||embedding layer)
(skip - gram embeddings||of||size 512)
(skip - gram embeddings||using||word2vec)
(word2vec||on||10B - word corpus)
(Hyperparameters||pre-trained||skip - gram embeddings)
(Contribution||has||Hyperparameters)
