(Our proposed 2 DASL||implemented with||Pytorch)
(Experimental setup||has||Our proposed 2 DASL)
(SGD optimizer||for||CNN regressor)
(CNN regressor||with||learning rate)
(CNN regressor||with||decays exponentially)
(optimizer||with||fixed learning rate)
(learning rate||beginning at||5 10 ?5)
(discriminator||uses||Adam)
(Adam||as||optimizer)
(Adam||with||fixed learning rate)
(optimizer||with||fixed learning rate)
(fixed learning rate||has||1 10 ?4)
(two - stage strategy||to train||our model)
(Experimental setup||use||two - stage strategy)
(first stage||train||model)
(model||using||overall loss L)
(Experimental setup||In||first stage)
(second stage||fine - tune||our model)
(our model||using||Vertex Distance Cost)
(Contribution||has||Experimental setup)
