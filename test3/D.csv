triple_D
[]
[]
"[['Model', 'has', 'RNNGs']]"
[]
"[['Model', 'has', 'discriminative model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'bi-directional transformer architecture']]"
[]
[]
[]
"[['Experimental setup', 'has', 'CNN models']]"
"[['Experimental setup', 'has', 'learning rate']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our CNN base model']]"
"[['Results', 'has', 'Named Entity Recognition']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'beam size']]"
[]
[]
"[['Results', 'has', 'Seq2seq approach']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'embedding layer']]"
[]
[]
[]
[]
"[['Results', 'has', 'LSTM + A model']]"
"[['Results', 'has', 'difference']]"
"[['Results', 'has', 'LSTM + A']]"
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'RG']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'Ensembling']]"
"[['Ablation analysis', 'has', 'Performance']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'bottom - up system']]"
"[['Results', 'has', 'inorder system']]"
[]
"[['Results', 'has', 'English constituent results']]"
[]
"[['Results', 'has', 'Chinese dependency results']]"
"[['Results', 'has', 'our final model']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'three LSTM layers']]"
[]
"[['Hyperparameters', 'has', 'forget gate bias']]"
"[['Hyperparameters', 'has', 'Dropout']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'RNNG']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'Gated Attention RNNG']]"
"[['Results', 'has', 'model']]"
"[['Results', 'has', 'Headedness in Phrases']]"
[]
"[['Results', 'has', 'attention - based tree output']]"
"[['Results', 'has', 'conversion accuracy']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'mention - ranking model']]"
"[['Results', 'has', 'cluster - ranking model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our full model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'reward - rescaled max - margin loss']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our full approach']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'representations']]"
"[['Model', 'has', 'learned score']]"
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Glo Ve word embeddings']]"
"[['Hyperparameters', 'has', 'Vocabulary']]"
"[['Hyperparameters', 'has', 'size']]"
[]
"[['Hyperparameters', 'has', 'first feed - forward layer size']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Dropout']]"
[]
[]
"[['Results', 'has', 'Performance']]"
[]
"[['Results', 'has', 'MR - LSTM']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'RNN']]"
"[['Results', 'has', 'RNN performance']]"
[]
[]
[]
"[['Model', 'has', 'Co-reference resolution']]"
[]
"[['Model', 'has', 'external memory block']]"
[]
"[['Hyperparameters', 'has', 'LSTM modules']]"
[]
"[['Hyperparameters', 'has', 'initial learning rate']]"
"[['Hyperparameters', 'has', 'model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'posits']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'reasons']]"
[]
[]
"[['Model', 'has', 'attention component']]"
[]
"[['Hyperparameters', 'has', 'word embeddings']]"
"[['Hyperparameters', 'has', 'Outof - vocabulary words']]"
[]
"[['Hyperparameters', 'has', 'convolutions']]"
"[['Hyperparameters', 'has', 'hidden states']]"
"[['Hyperparameters', 'has', 'feedforward neural network']]"
[]
"[['Hyperparameters', 'has', 'LSTM weights']]"
[]
[]
"[['Hyperparameters', 'has', 'Dropout masks']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
[]
[]
"[['Results', 'has', 'Coreference Results']]"
[]
[]
"[['Results', 'has', 'most significant gains']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Paragraph Level : GAP']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'Wiseman']]"
"[['Baselines', 'has', 'Li']]"
"[['Baselines', 'has', 'Puduppully - plan']]"
"[['Baselines', 'has', 'Puduppully - updt']]"
[]
[]
"[['Hyperparameters', 'has', 'size']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'scenario Hierarchical - kv and Hierarchical -k']]"
"[['Ablation analysis', 'has', 'Our hierarchical models']]"
[]
"[['Ablation analysis', 'has', 'Our hierarchical models']]"
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'individual LSTM models']]"
"[['Experimental setup', 'has', 'decoder']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'our ensemble model']]"
[]
[]
[]
[]
"[['Results', 'has', 'WebNLG task']]"
[]
"[['Results', 'has', 'GCN model']]"
"[['Results', 'has', 'GCN EC model']]"
"[['Results', 'has', 'SR11 Deep task']]"
[]
"[['Ablation analysis', 'has', 'importance']]"
"[['Ablation analysis', 'has', 'Residual and dense connections']]"
"[['Ablation analysis', 'has', 'Dense connections']]"
[]
[]
[]
"[['Approach', 'has', 'canonical presentation']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Input feeding']]"
[]
"[['Hyperparameters', 'has', 'Models']]"
[]
[]
[]
[]
"[['Results', 'has', 'NCP']]"
"[['Results', 'has', 'NCP']]"
"[['Results', 'has', 'NCP + CC']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'text planner']]"
"[['Model', 'has', 'plan']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'StrongNeural and BestPlan systems']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our model EDA_CS']]"
[]
[]
"[['Results', 'has', 'EDA_CS TL']]"
"[['Results', 'has', 'baseline model']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'joint model']]"
"[['Experimental setup', 'has', 'jPTDP v 2.0']]"
"[['Experimental setup', 'has', 'Word embeddings']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'BiLSTM']]"
[]
[]
"[['Hyperparameters', 'has', 'parsers']]"
[]
[]
[]
[]
"[['Results', 'has', 'greedy transition based parser']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'POS tagging results']]"
"[['Results', 'has', 'BiLSTM - CRF and Mar - MoT']]"
"[['Results', 'has', 'jPTDP']]"
"[['Results', 'has', 'MarMoT']]"
"[['Results', 'has', 'BiLSTM - CRF']]"
[]
[]
"[['Results', 'has', 'Overall dependency parsing results']]"
[]
[]
"[['Results', 'has', 'pre-trained NNdep and Biaffine models']]"
[]
[]
"[['Model', 'has', 'STACKPTR']]"
"[['Model', 'has', 'STACKPTR parser']]"
"[['Model', 'has', 'STACKPTR parser']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'interpolating']]"
[]
[]
"[['Results', 'has', 'Chinese score']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'Beam search']]"
[]
[]
[]
[]
"[['Results', 'has', 'our model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our accuracy']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'unsupervised data augmentation ( UDA ) )']]"
"[['Baselines', 'has', 'Fine-tune ( Ft )']]"
"[['Baselines', 'has', 'Fine - tune with UDA ( UDA )']]"
[]
"[['Baselines', 'has', 'Self - training']]"
[]
"[['Baselines', 'has', 'teacher model']]"
[]
"[['Results', 'has', 'UDA algorithm and MLM pre-training']]"
[]
"[['Results', 'has', 'MLM method']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'our framework']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'weights']]"
"[['Model', 'has', 'attention mechanism']]"
[]
"[['Hyperparameters', 'has', 'size']]"
[]
"[['Baselines', 'has', 'BoW']]"
[]
"[['Baselines', 'has', 'FTS- BRNN']]"
[]
"[['Baselines', 'has', 'NTEE']]"
[]
[]
"[['Results', 'has', 'NABoE - full model']]"
[]
[]
[]
"[['Model', 'has', ""words ' contextual information and task information""]]"
[]
"[['Baselines', 'has', 'BOW method']]"
[]
"[['Baselines', 'has', 'Word2 Vec method']]"
"[['Results', 'has', 'Our method']]"
[]
"[['Results', 'has', 'word embedding methods']]"
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', 'Our method']]"
[]
[]
[]
[]
"[['Model', 'has', 'edge']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'TF - IDF + LR']]"
"[['Baselines', 'has', 'Logistic Regression']]"
"[['Baselines', 'has', 'CNN']]"
[]
"[['Baselines', 'has', 'LSTM']]"
"[['Baselines', 'has', 'Bi- LSTM']]"
"[['Baselines', 'has', 'PV - DBOW']]"
[]
"[['Baselines', 'has', 'PV - DM']]"
[]
"[['Baselines', 'has', 'PTE']]"
"[['Baselines', 'has', 'fast Text']]"
"[['Baselines', 'has', 'SWEM']]"
"[['Baselines', 'has', 'LEAM']]"
[]
"[['Baselines', 'has', 'Graph - CNN - C']]"
"[['Baselines', 'has', 'Graph - CNN - S']]"
"[['Baselines', 'has', 'Graph - CNN - F']]"
[]
[]
[]
"[['Results', 'has', 'Text GCN']]"
[]
"[['Results', 'has', 'LSTM - based models']]"
"[['Results', 'has', 'PV - DBOW']]"
"[['Results', 'has', 'PV - DM']]"
[]
[]
[]
[]
"[['Model', 'has', 'network depth']]"
"[['Model', 'has', 'computational complexity']]"
[]
"[['Model', 'has', 'first layer']]"
[]
"[['Model', 'has', 'final pooling layer']]"
[]
[]
"[['Results', 'has', 'Large data results']]"
[]
"[['Results', 'has', 'Small data results']]"
[]
"[['Results', 'has', 'ShallowCNN']]"
[]
[]
[]
[]
"[['Model', 'has', 'LSTM']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'one - hot CNN']]"
"[['Results', 'has', 'previous best performance']]"
[]
[]
"[['Results', 'has', 'pre-trained wv - LSTM']]"
[]
[]
"[['Results', 'has', 'LSTM']]"
[]
[]
[]
[]
"[['Model', 'has', 'Adversarial perturbations']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our unidirectional LSTM model']]"
[]
"[['Results', 'has', 'Adversarial training']]"
[]
[]
[]
[]
"[['Model', 'has', 'CNN']]"
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'word vector layer and the LSTM layer']]"
[]
[]
"[['Results', 'has', 'Sentiment Classification']]"
[]
[]
"[['Results', 'has', 'Question Type Classification']]"
"[['Results', 'has', 'consistently outperforms']]"
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'dictionary']]"
"[['Experimental setup', 'has', 'input text']]"
"[['Experimental setup', 'has', 'character embedding']]"
"[['Experimental setup', 'has', 'Training']]"
"[['Experimental setup', 'has', 'implementation']]"
[]
[]
"[['Results', 'has', 'deep architecture']]"
[]
"[['Results', 'has', 'most important decrease']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'Bag - of - words']]"
[]
"[['Baselines', 'has', 'Bag - of - ngrams']]"
"[['Hyperparameters', 'has', 'bag - of - ngrams models']]"
[]
[]
[]
"[['Baselines', 'has', 'Word - based ConvNets']]"
[]
[]
"[['Results', 'has', 'Traditional methods']]"
"[['Results', 'has', 'Conv Nets']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'dimension']]"
[]
[]
[]
[]
"[['Results', 'has', 'BLSTM - 2DCNN model']]"
[]
"[['Results', 'has', 'BLSTM - 2DPooling']]"
"[['Results', 'has', 'BLSTM - CNN']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'LR model']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'non-neural LR and SVM baselines']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Binary Sentiment Tweets']]"
"[['Results', 'has', 'Transformer']]"
"[['Results', 'has', 'Multi - Label Emotion Tweets']]"
[]
"[['Results', 'has', 'Sem Eval Tweets']]"
"[['Results', 'has', 'Our model']]"
[]
"[['Results', 'has', 'Our models']]"
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'SVDCNN experimental settings']]"
"[['Experimental setup', 'has', 'training']]"
[]
[]
"[['Results', 'has', 'network reduction']]"
[]
[]
"[['Results', 'has', 'most in - depth model']]"
"[['Ablation analysis', 'has', 'accuracy results']]"
"[['Results', 'has', 'performance difference']]"
[]
[]
"[['Model', 'has', 'proposed LEAM']]"
"[['Model', 'has', 'label embedding framework']]"
"[['Model', 'has', 'LEAM learning procedure']]"
[]
"[['Experimental setup', 'has', 'Out - Of - Vocabulary ( OOV ) words']]"
"[['Baselines', 'has', 'final classifier']]"
[]
"[['Experimental setup', 'has', 'Dropout regularization']]"
[]
[]
[]
[]
"[['Results', 'has', 'LEAM']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'HDLTex']]"
[]
"[['Experimental setup', 'has', 'processing']]"
[]
[]
[]
[]
"[['Results', 'has', 'CNN']]"
"[['Results', 'has', 'term weighting']]"
"[['Results', 'has', 'nave Bayes']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'proposed framework']]"
"[['Model', 'has', 'word - level encoder']]"
"[['Model', 'has', 'interaction layer']]"
"[['Model', 'has', 'last layer']]"
[]
"[['Results', 'has', 'Multi - Class Classification']]"
[]
"[['Experimental setup', 'has', 'region size']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'baselines']]"
"[['Baselines', 'has', 'models']]"
[]
"[['Results', 'has', 'Models']]"
"[['Results', 'has', 'Char - based models']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'Multi - Label Classification']]"
[]
[]
[]
"[['Experimental setup', 'has', 'accumulated MLP']]"
[]
"[['Experimental setup', 'has', 'validation set']]"
"[['Results', 'has', 'Word - based models']]"
"[['Results', 'has', 'Our models']]"
[]
[]
[]
[]
"[['Results', 'has', 'Zero - shot cross - lingual document classification']]"
"[['Results', 'has', 'classifiers']]"
"[['Results', 'has', 'system']]"
[]
[]
[]
[]
"[['Results', 'has', 'Joint multilingual document classification']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'hyperparameter']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our model DRNN']]"
[]
[]
[]
[]
"[['Model', 'has', 'Three strategies']]"
[]
[]
[]
"[['Baselines', 'has', 'LSTM / Bi - LSTM']]"
[]
[]
"[['Ablation analysis', 'has', 'Single - Label to Multi - Label Text Classification']]"
[]
[]
"[['Ablation analysis', 'has', 'larger improvement']]"
"[['Ablation analysis', 'has', 'capsule network']]"
[]
"[['Ablation analysis', 'has', 'Connection Strength Visualization']]"
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Entity vectors']]"
[]
[]
[]
"[['Experimental setup', 'has', 'Training']]"
"[['Experimental setup', 'has', 'Our local and global ED models']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our models']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'ELMo representations']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'GAS']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Orthogonal initialization']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Training']]"
[]
"[['Baselines', 'has', 'Babelfy']]"
[]
"[['Baselines', 'has', 'IMS']]"
"[['Baselines', 'has', 'IMS +emb']]"
[]
"[['Baselines', 'has', 'Bi- LSTM']]"
[]
"[['Results', 'has', 'English all - words results']]"
"[['Results', 'has', 'GAS and GAS ext']]"
[]
[]
"[['Results', 'has', 'Multiple Passes Analysis']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'embeddings']]"
"[['Experimental setup', 'has', 'Words']]"
"[['Results', 'has', 'Our proposed model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'proposed method']]"
[]
"[['Results', 'has', 'proposed system']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'Each level of granularity']]"
"[['Model', 'has', 'token - level component']]"
[]
"[['Model', 'has', 'aggregated']]"
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'Simplified VCG']]"
[]
"[['Results', 'has', 'VCG model']]"
"[['Results', 'has', 'our model']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Between - all - models comparisons']]"
[]
[]
"[['Results', 'has', 'Within - our - model comparisons']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'English All - words WSD']]"
"[['Results', 'has', 'RNN - based architectures']]"
[]
"[['Results', 'has', 'Multilingual All - words WSD']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Contextualized Embeddings']]"
[]
[]
[]
"[['Results', 'has', 'similarity']]"
[]
"[['Results', 'has', 'CWEs']]"
"[['Results', 'has', 'Nearest Neighbors']]"
"[['Baselines', 'has', 'K- Optimization']]"
[]
[]
"[['Results', 'has', 'Senses in CWE space']]"
[]
"[['Results', 'has', 'Flair embeddings']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'KB entities']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'BOW']]"
"[['Baselines', 'has', 'BOW - DT']]"
"[['Baselines', 'has', 'QANTA']]"
"[['Baselines', 'has', 'FTS - BRNN']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'sense reduction method']]"
"[['Results', 'has', 'ensembling']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'GAS']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'Orthogonal initialization']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Training']]"
"[['Results', 'has', 'English all - words results']]"
"[['Results', 'has', 'GAS and GAS ext']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our proposed algorithms']]"
"[['Results', 'has', 'Unified WSD']]"
"[['Results', 'has', 'Word2 Vec vectors']]"
[]
[]
"[['Results', 'has', 'Sem Cor Vs. OMSTI']]"
[]
"[['Baselines', 'has', 'our naive nearest neighbor classifiers']]"
[]
[]
"[['Baselines', 'has', 'Most frequent sense']]"
"[['Results', 'has', 'LSTM']]"
[]
"[['Results', 'has', 'SemCor ( or MASC ) trained classifier']]"
"[['Ablation analysis', 'has', 'Change of language model capacity']]"
[]
"[['Ablation analysis', 'has', 'Semi-supervised WSD']]"
"[['Results', 'has', 'LP']]"
[]
"[['Ablation analysis', 'has', 'Change of seed data']]"
"[['Ablation analysis', 'has', 'LP']]"
"[['Ablation analysis', 'has', 'Change of graph density']]"
[]
"[['Ablation analysis', 'has', 'F1 scores']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'ENTITY - LEVEL FINE TYPING']]"
[]
[]
"[['Results', 'has', 'EFFECT OF MASKING']]"
"[['Results', 'has', 'masking mentions']]"
[]
[]
"[['Results', 'has', 'FEW - SHOT CATEGORY COMPLETION']]"
[]
"[['Results', 'has', 'TRIVIA QUESTION ANSWERING']]"
[]
"[['Results', 'has', 'ORQA']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'similar words and entities']]"
[]
[]
[]
"[['Model', 'has', 'conventional skip - gram model']]"
[]
"[['Model', 'has', 'NED method']]"
"[['Results', 'has', 'Our method']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Classic model']]"
"[['Results', 'has', 'texture - free Linear model']]"
[]
"[['Results', 'has', 'Quantitative Normal Recovery']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'input samples']]"
[]
"[['Results', 'has', 'Volumetric Regression Networks']]"
[]
"[['Results', 'has', 'All VRNs']]"
"[['Results', 'has', 'best performing VRN']]"
"[['Results', 'has', 'VRN - Multitask']]"
"[['Ablation analysis', 'has', 'Effect of pose']]"
"[['Ablation analysis', 'has', 'performance']]"
"[['Ablation analysis', 'has', 'Effect of expression']]"
[]
"[['Ablation analysis', 'has', 'Effect of Gaussian size']]"
"[['Ablation analysis', 'has', 'performance']]"
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'training and testing']]"
[]
[]
[]
"[['Experimental setup', 'has', 'standard ReLu function']]"
[]
[]
[]
"[['Experimental setup', 'has', 'parameters']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'CNN - 6/7 network']]"
[]
[]
"[['Experimental setup', 'has', '300 W']]"
[]
"[['Results', 'has', 'error']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Face Recognition Results']]"
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', ""Our method 's results""]]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'minibatch size']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', 'performance']]"
"[['Ablation analysis', 'has', 'accuracy']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'Each decoder']]"
[]
"[['Model', 'has', 'encoder']]"
"[['Model', 'has', '3 D face and texture']]"
[]
"[['Model', 'has', 'endto - end learning scheme']]"
[]
[]
"[['Hyperparameters', 'has', 'model']]"
[]
"[['Results', 'has', 'Representation Power']]"
[]
"[['Results', 'has', 'nonlinear texture']]"
"[['Results', 'has', 'nonlinear model']]"
[]
"[['Results', 'has', 'Quantitative evaluation of 3D reconstruction']]"
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'patchGAN']]"
[]
[]
[]
"[['Experimental setup', 'has', 'Our network']]"
[]
[]
[]
"[['Experimental setup', 'has', '2D landmark regression']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'Weighted Parameter Distance Cost ( WPDC )']]"
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'Error Reduction in Cascade']]"
"[['Ablation analysis', 'has', 'testing error']]"
[]
[]
"[['Results', 'has', 'Performance with Different Costs']]"
[]
"[['Baselines', 'has', 'WPDC']]"
"[['Baselines', 'has', 'Large Pose Face Alignment']]"
[]
"[['Results', 'has', '3DDFA']]"
"[['Results', 'has', 'minimum standard deviation']]"
[]
"[['Baselines', 'has', '3D Face Alignment']]"
[]
"[['Results', 'has', 'Common Challenging Full TSPM']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'entire framework']]"
"[['Experimental setup', 'has', 'Uniform scaling and translation']]"
"[['Experimental setup', 'has', 'training samples']]"
[]
"[['Experimental setup', 'has', 'input face patch']]"
"[['Experimental setup', 'has', 'more complex model']]"
"[['Experimental setup', 'has', 'type of solver']]"
"[['Experimental setup', 'has', 'maximum learning iterations']]"
"[['Experimental setup', 'has', 'learning rate']]"
[]
"[['Results', 'has', 'MCL']]"
[]
"[['Results', 'has', 'MCL']]"
[]
"[['Results', 'has', 'average running speed']]"
"[['Ablation analysis', 'has', 'Global Average Pooling vs. Full Connection']]"
"[['Ablation analysis', 'has', 'BM']]"
[]
"[['Ablation analysis', 'has', 'Robustness of Weighting']]"
[]
"[['Ablation analysis', 'has', 'Analysis of Shape Prediction Layers']]"
[]
"[['Ablation analysis', 'has', 'assembled AM']]"
"[['Ablation analysis', 'has', 'two models']]"
[]
"[['Ablation analysis', 'has', 'accuracy']]"
"[['Ablation analysis', 'has', 'Weighting Simplified AM']]"
[]
"[['Ablation analysis', 'has', 'localization accuracy']]"
"[['Ablation analysis', 'has', 'MCL']]"
"[['Ablation analysis', 'has', 'correlations']]"
[]
"[['Ablation analysis', 'has', 'results']]"
"[['Ablation analysis', 'has', 'WM and AM']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'WFLW']]"
[]
[]
[]
[]
"[['Baselines', 'has', '300W']]"
"[['Results', 'has', 'our model']]"
[]
"[['Results', 'has', 'Our model']]"
"[['Baselines', 'has', 'AFLW']]"
[]
"[['Results', 'has', 'our method']]"
[]
"[['Ablation analysis', 'has', 'style and structure']]"
"[['Ablation analysis', 'has', 'Style - augmented synthetic images']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Training']]"
[]
[]
"[['Experimental setup', 'has', 'Python implementation']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'DeCaFA']]"
[]
"[['Hyperparameters', 'has', 'DeCaFA models']]"
"[['Hyperparameters', 'has', 'input images']]"
"[['Hyperparameters', 'has', 'Each convolution']]"
[]
"[['Hyperparameters', 'has', 'whole architecture']]"
[]
"[['Ablation analysis', 'has', 'accuracy']]"
"[['Ablation analysis', 'has', 'Coarsely annotated data ( 5 landmarks )']]"
[]
[]
"[['Ablation analysis', 'has', 'F 5 - Equation fusion']]"
[]
[]
"[['Ablation analysis', 'has', 'DeCaFA']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Data augmentation']]"
"[['Hyperparameters', 'has', 'Random Gaussian blur , noise and occlusion']]"
[]
"[['Results', 'has', 'Our method']]"
[]
[]
[]
[]
"[['Results', 'has', 'Our method']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'detected faces']]"
[]
[]
"[['Results', 'has', 'NME results']]"
[]
"[['Results', 'has', 'SIR method']]"
[]
[]
[]
[]
[]
"[['Approach', 'has', 'boundary - aware face alignment algorithm']]"
[]
[]
"[['Approach', 'has', 'boundary heatmap estimator']]"
[]
"[['Approach', 'has', 'boundary heatmaps']]"
[]
[]
"[['Results', 'has', 'Our method']]"
[]
[]
"[['Results', 'has', 'Cross - dataset evaluation']]"
[]
[]
"[['Results', 'has', 'failure rate']]"
"[['Results', 'has', 'our method']]"
[]
"[['Ablation analysis', 'has', 'Boundary information fusion']]"
[]
[]
"[['Results', 'has', 'comparison']]"
"[['Results', 'has', 'comparison']]"
[]
"[['Results', 'has', 'Adversarial learning']]"
[]
[]
[]
"[['Model', 'has', 'ERT']]"
"[['Model', 'has', 'coarse - to - fine structure']]"
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'All layers']]"
[]
[]
[]
"[['Experimental setup', 'has', 'depth']]"
"[['Experimental setup', 'has', 'number of tests']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our approach']]"
[]
[]
"[['Ablation analysis', 'has', '3D initialization']]"
"[['Ablation analysis', 'has', 'large receptive fields']]"
"[['Ablation analysis', 'has', 'coarse - to - fine strategy']]"
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'batch size']]"
"[['Experimental setup', 'has', 'training codes']]"
"[['Results', 'has', '3D Face Alignment']]"
"[['Results', 'has', 'our result']]"
[]
[]
[]
"[['Results', 'has', 'our method']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'proposed 2 DASL']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our method']]"
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'self - critic learning']]"
"[['Ablation analysis', 'has', 'self - supervision scheme']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'prior model']]"
"[['Model', 'has', 'likelihood model']]"
"[['Model', 'has', 'heatmap']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'AFLW . 300W']]"
"[['Results', 'has', 'HGs + SA']]"
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'Semantic alignment']]"
"[['Ablation analysis', 'has', 'GHCU']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'backbone network']]"
[]
"[['Experimental setup', 'has', 'stochastic gradient descent ( SGD ) algorithm']]"
"[['Experimental setup', 'has', 'warmup strategy']]"
[]
"[['Experimental setup', 'has', 'full training and testing codes']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'sharing']]"
"[['Model', 'has', 'proposed iterative architecture']]"
"[['Model', 'has', 'baseline framework']]"
[]
[]
"[['Hyperparameters', 'has', 'negative slope']]"
[]
[]
"[['Results', 'has', 'margin']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'backbone networks']]"
"[['Hyperparameters', 'has', ""newly added convolution layers ' parameters""]]"
[]
"[['Hyperparameters', 'has', 'batch size']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
"[['Hyperparameters', 'has', 'Non-maximum suppression']]"
[]
[]
[]
"[['Baselines', 'has', 'Feature Enhance Module']]"
[]
"[['Baselines', 'has', 'Progressive Anchor Loss']]"
[]
[]
[]
"[['Results', 'has', 'WIDER FACE Dataset']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'learned end - to - end']]"
"[['Model', 'has', 'object detection']]"
"[['Model', 'has', 'complimentary detectors']]"
"[['Results', 'has', 'performance']]"
[]
"[['Experimental setup', 'has', 'implementation']]"
"[['Experimental setup', 'has', 'NVIDIA Titan GPU']]"
"[['Results', 'has', 'MS - CNN']]"
[]
[]
"[['Results', 'has', 'MS - CNN']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'learning rate']]"
"[['Experimental setup', 'has', 'training process']]"
"[['Experimental setup', 'has', 'Testing Details']]"
[]
"[['Experimental setup', 'has', 'Box voting']]"
[]
[]
[]
"[['Results', 'has', 'Face box Accuracy']]"
"[['Results', 'has', 'RetinaFace']]"
[]
"[['Results', 'has', 'RetinaFace']]"
"[['Results', 'has', 'Five Facial Landmark Accuracy']]"
[]
[]
"[['Results', 'has', 'Dense Facial Landmark Accuracy']]"
[]
[]
[]
"[['Results', 'has', 'Face Recognition Accuracy']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'performance']]"
[]
[]
"[['Results', 'has', 'results']]"
"[['Results', 'has', 'Occlusion']]"
[]
"[['Results', 'has', 'maximum AP']]"
"[['Results', 'has', 'Pose']]"
"[['Results', 'has', 'best performance']]"
[]
[]
[]
[]
"[['Model', 'has', 'proposed method']]"
"[['Model', 'has', 'RDCL']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'FaceBoxes Anchor densification strategy']]"
"[['Ablation analysis', 'has', 'anchor densification strategy']]"
[]
"[['Ablation analysis', 'has', 'RDCL']]"
"[['Results', 'has', 'AFW dataset']]"
"[['Results', 'has', 'our FaceBoxes']]"
"[['Results', 'has', 'PASCAL face dataset']]"
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', 'FDDB dataset']]"
"[['Results', 'has', 'Our FaceBoxes']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'deep CNN']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'HF - ResNet']]"
"[['Results', 'has', 'Gender Recognition']]"
[]
"[['Results', 'has', 'HF - ResNet']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'FDDB Dataset']]"
"[['Results', 'has', 'PyramidBox']]"
"[['Results', 'has', 'WIDER FACE Dataset']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'designed region - based CNN architecture']]"
[]
"[['Model', 'has', 'CMS - RCNN method']]"
"[['Experimental setup', 'has', 'CMS - RCNN']]"
"[['Experimental setup', 'has', 'first 5 sets of convolution layers']]"
[]
"[['Baselines', 'has', 'conv3']]"
"[['Experimental setup', 'has', ""' conv3 ' , ' conv4 ' , and ' conv5 '""]]"
[]
[]
[]
"[['Experimental setup', 'has', 'features']]"
"[['Experimental setup', 'has', 'MS - RPN and the CMS - CNN']]"
[]
[]
[]
[]
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', 'proposed CMS - RCNN approach']]"
[]
[]
[]
[]
"[['Model', 'has', 'multi-scale training and testing strategy']]"
"[['Experimental setup', 'has', 'Single NVIDIA Tesla K80']]"
"[['Experimental setup', 'has', 'Mini batch size']]"
"[['Experimental setup', 'has', 'ResNet_v1_101']]"
"[['Experimental setup', 'has', 'Aspect ratios ( 1 , 1.5 , 2 ) and scales ( 16 2 , 32 2 , 64 2 , 128 2 , 256 2 , 512 2 )']]"
"[['Experimental setup', 'has', 'batch size']]"
"[['Experimental setup', 'has', 'initial learning rate']]"
"[['Experimental setup', 'has', 'Weight decay']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'STC']]"
[]
"[['Experimental setup', 'has', 'loss function']]"
"[['Experimental setup', 'has', 'backbone network']]"
[]
[]
[]
"[['Results', 'has', 'AFW Dataset']]"
[]
"[['Results', 'has', 'PASCAL Face Dataset']]"
"[['Results', 'has', 'SRN']]"
"[['Results', 'has', 'FDDB Dataset']]"
"[['Results', 'has', 'our SRN']]"
"[['Results', 'has', 'WIDER FACE Dataset']]"
"[['Results', 'has', 'SRN']]"
[]
[]
[]
[]
"[['Model', 'has', 'aggregate channel features']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our detector']]"
[]
[]
[]
"[['Model', 'has', 'first stage']]"
[]
"[['Model', 'has', 'network']]"
"[['Model', 'has', 'aligned candidate face region']]"
[]
[]
"[['Model', 'has', 'canonical positions']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'DNN operations']]"
[]
[]
[]
"[['Results', 'has', 'Our non - top K suppression']]"
[]
[]
"[['Baselines', 'has', 'Headhunter']]"
[]
[]
[]
[]
"[['Model', 'has', 'NPD']]"
"[['Model', 'has', 'NPD feature']]"
[]
[]
"[['Model', 'has', 'different types of faces']]"
[]
"[['Model', 'has', 'resulting face detector']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'final detector']]"
[]
"[['Hyperparameters', 'has', 'subset']]"
"[['Hyperparameters', 'has', 'detection template']]"
"[['Hyperparameters', 'has', 'detector cascade']]"
[]
[]
"[['Results', 'has', 'proposed NPD face detector']]"
[]
"[['Results', 'has', 'Joint Cascade algorithm']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'optimization method']]"
"[['Experimental setup', 'has', 'initial learning rate']]"
[]
"[['Experimental setup', 'has', 'training time']]"
"[['Experimental setup', 'has', 'Our method']]"
[]
"[['Results', 'has', 'FDDB dataset']]"
[]
"[['Results', 'has', 'proposed LFFD']]"
[]
"[['Results', 'has', 'WIDER FACE dataset']]"
"[['Results', 'has', 'performance drop']]"
"[['Results', 'has', 'Pyramid Box']]"
"[['Results', 'has', 'FaceBoxes']]"
[]
"[['Results', 'has', 'LFFD']]"
[]
[]
[]
"[['Model', 'has', 'proposed CNNs']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'hard sample mining']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'our detector']]"
[]
[]
[]
"[['Experimental setup', 'has', 'first two blocks']]"
[]
[]
[]
"[['Results', 'has', 'our method']]"
[]
[]
[]
"[['Results', 'has', 'our method']]"
"[['Results', 'has', 'Our model']]"
"[['Results', 'has', 'HIM']]"
"[['Results', 'has', 'DH']]"
[]
"[['Ablation analysis', 'has', 'photometric distortion and cropping']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'RSA unit']]"
"[['Model', 'has', 'unit']]"
[]
"[['Model', 'has', 'scale - forecast network']]"
"[['Model', 'has', 'landmark retracing network']]"
"[['Model', 'has', 'final score']]"
"[['Model', 'has', 'three components']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'minimum operation']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'on - line hard example mining ( OHEM ) technique']]"
"[['Hyperparameters', 'has', 'training hyper - parameters']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'RPN and R - FCN']]"
"[['Hyperparameters', 'has', 'Non- maximum suppression ( NMS )']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'final approach']]"
[]
[]
"[['Results', 'has', 'WIDER FACE']]"
[]
"[['Baselines', 'has', 'FDDB']]"
[]
[]
"[['Hyperparameters', 'has', 'regressor']]"
[]
[]
"[['Model', 'has', 'ADAPT']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'diagonal variant']]"
[]
[]
"[['Experimental setup', 'has', 'hidden dimension']]"
"[['Experimental setup', 'has', 'batch size']]"
[]
"[['Baselines', 'has', 'Convolution or recurrent gated mechanisms']]"
[]
[]
"[['Results', 'has', 'outperform']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Unsupervised Measures']]"
[]
[]
"[['Results', 'has', 'new SLQS variants']]"
[]
[]
"[['Results', 'has', 'over all performance']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'best configuration']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'DefIE']]"
[]
"[['Results', 'has', 'Yago and WiBi']]"
"[['Results', 'has', 'TAXOEM - BED']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'Word2vec']]"
"[['Hyperparameters', 'has', 'skip - gram model ( - cbow 0 )']]"
[]
[]
"[['Results', 'has', 'projection learning method']]"
[]
"[['Results', 'has', 'performance']]"
[]
[]
[]
"[['Model', 'has', 'hypernym discovery']]"
"[['Results', 'has', 'hybrid system']]"
"[['Results', 'has', 'scores']]"
[]
[]
"[['Results', 'has', 'cross-evaluation results']]"
"[['Results', 'has', 'unsupervised system']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'hidden states']]"
[]
"[['Results', 'has', 'BAbi AI tasks']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'ConZNet architecture']]"
[]
"[['Model', 'has', 'second phase']]"
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'weights']]"
[]
"[['Experimental setup', 'has', 'words']]"
[]
"[['Experimental setup', 'has', 'number of hidden units']]"
[]
"[['Results', 'has', 'performance']]"
[]
"[['Results', 'has', 'performance']]"
"[['Ablation analysis', 'has', 'self - attention mechanism']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', '3 - layer feed - forward neural network']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Sentinel vectors']]"
[]
[]
[]
"[['Results', 'has', 'performance']]"
"[['Ablation analysis', 'has', 'model']]"
[]
[]
[]
"[['Model', 'has', 'Relation Memory Network "" ( RMN )']]"
[]
"[['Model', 'has', 'RMN']]"
[]
"[['Model', 'has', 'Embedding component']]"
[]
[]
"[['Hyperparameters', 'has', 'softmax output']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'number of unnecessary object pairs']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'EpiReader']]"
"[['Model', 'has', 'first component']]"
"[['Model', 'has', 'second component']]"
"[['Model', 'has', 'semantic comparisons']]"
"[['Model', 'has', 'Extractor']]"
"[['Model', 'has', 'Extractor']]"
[]
"[['Model', 'has', 'Extractor']]"
"[['Model', 'has', 'Reasoner']]"
[]
[]
[]
"[['Experimental setup', 'has', 'word embeddings']]"
[]
[]
[]
"[['Results', 'has', 'EpiReader']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Weights']]"
[]
"[['Baselines', 'has', 'MemNN']]"
"[['Baselines', 'has', 'MemNN- WSH']]"
"[['Baselines', 'has', 'weakly supervised heuristic version']]"
"[['Baselines', 'has', 'LSTM']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'dimension']]"
"[['Hyperparameters', 'has', 'word embeddings']]"
"[['Hyperparameters', 'has', 'Adam ( Kingma and Ba , 2014 )']]"
"[['Hyperparameters', 'has', 'mini - batch size']]"
[]
"[['Results', 'has', 'difference']]"
[]
"[['Results', 'has', 'baseline ESIM']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Weights']]"
[]
"[['Results', 'has', 'mance']]"
"[['Results', 'has', 'ensemble of our models']]"
[]
"[['Results', 'has', 'average performance']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'GLUE']]"
[]
[]
[]
"[['Model', 'has', 'simplest baseline architecture']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'improved weight initialization']]"
"[['Model', 'has', 'adaptive prior']]"
[]
[]
[]
[]
"[['Results', 'has', 'CBS schedules']]"
[]
[]
[]
"[['Results', 'has', 'Image Classification Results']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'pooling layer']]"
"[['Model', 'has', ""two sentences ' information""]]"
[]
"[['Hyperparameters', 'has', 'Word embeddings']]"
[]
"[['Hyperparameters', 'has', 'Initial learning rate']]"
[]
[]
"[['Results', 'has', 'Model Variant']]"
[]
[]
[]
"[['Results', 'has', 'full TBCNN - pair model']]"
[]
[]
[]
"[['Model', 'has', 'model']]"
"[['Experimental setup', 'has', 'spaCy tool']]"
[]
[]
"[['Experimental setup', 'has', 'lexicon embeddings']]"
"[['Experimental setup', 'has', 'embedding']]"
"[['Experimental setup', 'has', 'hidden size']]"
"[['Experimental setup', 'has', 'projection size']]"
[]
"[['Experimental setup', 'has', 'dropout rate']]"
"[['Experimental setup', 'has', 'mini - batch size']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'NTI']]"
"[['Model', 'has', 'Each node']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Sentence Classification']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'Embedding Layer']]"
"[['Experimental setup', 'has', 'embedding weights']]"
"[['Experimental setup', 'has', 'Hidden Layer']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'language model features']]"
"[['Experimental setup', 'has', 'Implementation']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'character embedding']]"
[]
"[['Hyperparameters', 'has', 'Dropout layer']]"
"[['Hyperparameters', 'has', 'Adam optimizer']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
"[['Baselines', 'has', 'ESIM']]"
"[['Baselines', 'has', 'BiMPM']]"
"[['Baselines', 'has', 'SSE']]"
"[['Baselines', 'has', 'DIIN']]"
"[['Results', 'has', 'Quora dataset']]"
"[['Results', 'has', 'LCQMC dataset']]"
[]
"[['Results', 'has', 'BQ dataset']]"
"[['Results', 'has', 'our model']]"
"[['Results', 'has', 'TCS dataset']]"
[]
[]
"[['Ablation analysis', 'has', 'accuracy']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'DF - LSTMs']]"
"[['Model', 'has', 'output vector']]"
"[['Baselines', 'has', 'Neural bag - of - words ( NBOW )']]"
"[['Baselines', 'has', 'Each sequence']]"
"[['Baselines', 'has', 'Single LSTM']]"
"[['Baselines', 'has', 'Parallel LSTMs']]"
"[['Baselines', 'has', 'Attention LSTMs']]"
"[['Baselines', 'has', 'Word - by - word Attention LSTMs']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'our approach']]"
[]
[]
[]
"[['Experimental setup', 'has', 'training examples']]"
[]
"[['Experimental setup', 'has', 'Dropout']]"
"[['Results', 'has', 'Our system ( single model )']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'deep cascade model']]"
[]
"[['Model', 'has', 'selected paragraphs']]"
[]
[]
"[['Model', 'has', 'cascaded structure']]"
[]
"[['Model', 'has', 'first module']]"
"[['Model', 'has', 'module']]"
"[['Model', 'has', 'ranking function']]"
"[['Model', 'has', 'extraction function']]"
[]
[]
[]
"[['Experimental setup', 'has', 'word embeddings']]"
"[['Experimental setup', 'has', 'hidden size']]"
"[['Experimental setup', 'has', 'task - specific hyper - parameters']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'shared LSTM']]"
[]
"[['Ablation analysis', 'has', 'preliminary cascade ranking and multi-task answer extraction strategy']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'universal node']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'LSTM blocks']]"
[]
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'SDNet']]"
[]
[]
"[['Results', 'has', 'SDNet']]"
[]
"[['Results', 'has', 'Ensemble SDNet model']]"
"[['Results', 'has', 'SDNet']]"
[]
[]
[]
[]
"[['Model', 'has', 'Each cell']]"
"[['Model', 'has', 'EntNet']]"
"[['Model', 'has', 'hidden state']]"
"[['Model', 'has', 'keys']]"
[]
[]
"[['Hyperparameters', 'has', 'EntNet']]"
[]
"[['Results', 'has', 'MemN2N']]"
"[['Results', 'has', 'LSTM']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'question - passage attention models']]"
"[['Results', 'has', 'EM result']]"
"[['Results', 'has', 'RNET']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'SQuAD dataset']]"
[]
"[['Hyperparameters', 'has', 'Out - of - vocabulary ( OOV ) words']]"
"[['Hyperparameters', 'has', 'CharCNN filter length']]"
"[['Hyperparameters', 'has', 'cluster number K']]"
"[['Hyperparameters', 'has', 'Adam method']]"
"[['Hyperparameters', 'has', 'first momentum']]"
"[['Hyperparameters', 'has', 'initial learning rate']]"
"[['Hyperparameters', 'has', 'hidden states']]"
[]
"[['Hyperparameters', 'has', 'Explicit question - type dimension d ET']]"
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'ARC - II']]"
"[['Results', 'has', 'SENNA + MLP']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Scaling with a curriculum']]"
[]
[]
[]
"[['Results', 'has', 'SDNC']]"
[]
[]
[]
"[['Results', 'has', 'MANNs']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'NLTK']]"
[]
"[['Experimental setup', 'has', 'hidden vector dimension l']]"
[]
"[['Experimental setup', 'has', 'batch size']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'composed feature vector']]"
"[['Results', 'has', 'QASent dataset']]"
[]
[]
"[['Results', 'has', 'Wiki QA dataset']]"
"[['Results', 'has', 'best performance']]"
"[['Results', 'has', 'MSRP dataset']]"
"[['Results', 'has', 'our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Sentiment Analysis Results']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Word distance benchmark']]"
[]
[]
[]
"[['Baselines', 'has', 'Deep LSTM']]"
"[['Results', 'has', 'Reader']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'basic model']]"
"[['Model', 'has', 'basic mean pooling encoder']]"
[]
"[['Hyperparameters', 'has', 'training objective']]"
"[['Hyperparameters', 'has', 'batch size']]"
"[['Hyperparameters', 'has', 'dropout layer']]"
[]
"[['Hyperparameters', 'has', 'Out - of - vocabulary words']]"
[]
"[['Baselines', 'has', 'mean pooling']]"
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Evaluation']]"
"[['Results', 'has', 'BERT model']]"
"[['Results', 'has', 'Our model']]"
