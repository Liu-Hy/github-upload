triple_A
[]
[]
"[['RNNGs', 'operate via', 'recursive syntactic process'], ['decisions', 'parameterized using', 'RNNs'], ['RNNs', 'condition on', 'entire syntactic derivation history']]"
"[['two variants', 'of', 'algorithm']]"
"[['ancestor sampling', 'to obtain', 'samples'], ['samples', 'of', 'parse trees'], ['parse trees', 'for', 'sentences'], ['RNNGs', 'approximating', 'marginal likelihood and MAP tree']]"
"[['simple importance sampling algorithm', 'uses', 'samples'], ['samples', 'from', 'discriminative parser'], ['samples', 'to solve', 'inference problems'], ['discriminative parser', 'to solve', 'inference problems'], ['inference problems', 'in', 'generative model']]"
"[['discriminative model', 'used', 'hidden dimensions'], ['hidden dimensions', 'of', '128 and 2 - layer LSTMs']]"
"[['generative model', 'used', '256 dimensions'], ['generative model', 'used', '2 layer LSTMs']]"
"[['dropout rate', 'to maximize', 'validation set likelihood'], ['dropout rate', 'obtaining', 'optimal rates'], ['validation set likelihood', 'obtaining', 'optimal rates']]"
"[['sequential LSTM baseline', 'For', 'language model'], ['sequential LSTM baseline', 'for', 'language model'], ['sequential LSTM baseline', 'found', 'optimal dropout rate'], ['optimal dropout rate', 'of', '0.3']]"
"[['training', 'used', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', 'learning rate'], ['learning rate', 'of', '0.1']]"
[]
"[['bi-directional transformer model', 'provides', 'significant performance gains']]"
[]
"[['even larger performance gains', 'jointly pretraining', 'both directions'], ['both directions', 'of', 'large language - model - inspired self - attention cloze model']]"
"[['every token', 'in', 'training data']]"
"[['cloze - style training objective', 'where', 'model'], ['center word', 'given', 'left - to - right and right - to - left context representations']]"
[]
[]
"[['CNN models', 'use', 'adaptive softmax'], ['adaptive softmax', 'in', 'output'], ['headband', 'contains', '60K most frequent types'], ['60K most frequent types', 'with', 'dimensionality'], ['dimensionality', 'followed by', '160 K band'], ['1024', 'followed by', '160 K band'], ['160 K band', 'with', 'dimensionality'], ['160 K band', 'with', 'momentum'], ['dimensionality', 'with', 'momentum'], ['momentum', 'of', '0.99'], ['gradients', 'if', 'norm'], ['norm', 'exceeds', '0.1']]"
"[['linearly warmed up', 'from', '10 ? 7 to 1'], ['10 ? 7 to 1', 'for', '16 K steps'], ['learning rate', 'annealed using', 'cosine learning rate schedule'], ['cosine learning rate schedule', 'with', 'single phase'], ['single phase', 'to', '0.0001']]"
"[['experiments', 'on', 'DGX - 1 machines'], ['DGX - 1 machines', 'with', '8 NVIDIA V100 GPUs']]"
[]
[]
[]
[]
"[['Our CNN base model', 'performs', 'STILTs'], ['Our CNN base model', 'as well as', 'STILTs'], ['STILTs', 'in', 'aggregate'], ['STILTs', 'performs', 'much better']]"
[]
"[['fine tuning', 'gives', 'biggest gain']]"
[]
"[['bilm loss', 'dominating', 'triplet loss'], ['scaling', 'by', 'factor'], ['bilm term', 'by', 'factor'], ['factor', 'of', '0.15'], ['0.15', 'results in', 'better performance']]"
"[['cloze loss', 'performs', 'significantly better'], ['significantly better', 'than', 'bilm loss'], ['cloze loss', 'combining', 'two loss types']]"
[]
"[['Seq2seq approach', 'as', 'stronger baseline'], ['stronger baseline', 'of', 'constituency parsing']]"
"[['gradient clipping G', 'provided', 'better performance']]"
"[['beam size', 'have', 'little impact'], ['little impact', 'on', 'performance'], ['L = 2 , H = 200 , and B = 5', 'looks', 'adequate'], ['adequate', 'in terms of', 'speed / performance trade - off']]"
"[['subword split', 'as', 'input token unit'], ['input token unit', 'instead of', 'standard tokenized word unit']]"
"[['subword information', 'as', 'features']]"
"[['Seq2seq approach', 'successfully achieved', 'competitive level'], ['competitive level', 'as', 'current top - notch methods']]"
[]
"[['artificial dataset', 'by labelling', 'large corpus'], ['large corpus', 'with', 'BerkeleyParser']]"
"[['sequence - to - sequence model', 'with', 'attention'], ['attention', 'on', 'small human - annotated parsing dataset'], ['sequence - to - sequence model', 'able to achieve', 'F 1 score'], ['F 1 score', 'of', '88.3'], ['90.5', 'with', 'ensemble'], ['ensemble', 'matches', 'performance']]"
"[['second artificial dataset', 'consisting of', 'high - confidence parse trees'], ['high - confidence parse trees', 'measured by', 'agreement'], ['agreement', 'of', 'two parsers']]"
"[['sequence - to - sequence model', 'with', 'attention'], ['F 1 score', 'of', '92.5']]"
"[['model', 'with', '3 LSTM layers'], ['model', 'with', '256 units'], ['256 units', 'in', 'each layer']]"
[]
"[['embedding layer', 'for', '90K vocabulary'], ['90K vocabulary', 'can be', 'initialized randomly'], ['90K vocabulary', 'can be', 'pre-trained word - vector embeddings'], ['embedding layer', 'using', 'pre-trained word - vector embeddings']]"
"[['skip - gram embeddings', 'of size', '512'], ['skip - gram embeddings', 'using', 'word2vec'], ['512', 'using', 'word2vec'], ['word2vec', 'on', '10B - word corpus']]"
"[['single attention model', 'gets to', '88.3'], ['ensemble of 5 LSTM + A+D models', 'achieves', '90.5'], ['90.5', 'matching', 'single - model BerkeleyParser'], ['single - model BerkeleyParser', 'on', 'WSJ']]"
"[['single LSTM + A model', 'achieves', '92.5']]"
"[['ensemble', 'of', '5 LSTM+ A models'], ['5 LSTM+ A models', 'improves', 'score'], ['score', 'to', '92.8']]"
"[['LSTM + A model', 'trained on', 'WSJ dataset'], ['WSJ dataset', 'produced', 'malformed trees'], ['malformed trees', 'for', '25 of the 1700 sentences'], ['25 of the 1700 sentences', 'in', 'our development set'], ['full high - confidence dataset', 'for', '14 sentences ( 0.8 % )']]"
"[['difference', 'between', 'F 1 score'], ['F 1 score', 'on', 'sentences'], ['1.3', 'for', 'BerkeleyParser'], ['1.3', 'for', 'baseline LSTM'], ['1.3', 'for', '0.7'], ['1.7', 'for', 'baseline LSTM'], ['0.7', 'for', 'LSTM + A']]"
"[['LSTM + A', 'trained on', 'high - confidence corpus'], ['high - confidence corpus', 'achieved', 'F 1 score'], ['F 1 score', 'of', '95.7'], ['F 1 score', 'of', '84.6'], ['95.7', 'on', 'QTB'], ['95.7', 'on', '84.6'], ['84.6', 'on', 'WEB']]"
[]
[]
[]
"[['beam - based search procedure', 'with', 'augmented state space'], ['augmented state space', 'search directly in', 'generative models']]"
"[['weighted average', 'of', 'scores'], ['scores', 'of', 'both models'], ['scores', 'of', 'both models'], ['scores', 'when selecting', 'parse'], ['both models', 'when selecting', 'parse'], ['parse', 'from', ""base parser 's candidate list""], ['score', 'of', 'generative model']]"
[]
"[['performance', 'from', '93.45 F1'], ['93.45 F1', 'to', '92.78 F1'], ['92.78 F1', 'on', 'development set']]"
[]
"[['scores', 'of', 'both models'], ['score', 'of', 'either model alone'], ['score', 'of', 'either model alone']]"
[]
"[['candidates and scores', 'from', 'all three models'], ['candidates and scores', 'obtain', '93.94 F1 .'], ['candidates and scores', 'obtain', '93.94 F1'], ['all three models', 'obtain', '93.94 F1 .'], ['all three models', 'obtain', '93.94 F1']]"
"[['same model type', 'trained from', 'different random initializations']]"
"[['Performance', 'when using', 'ensembled RD models'], ['ensembled RD models', 'is', 'lower'], ['lower', 'rescoring', 'single RD model'], ['single RD model', 'with', 'score combinations']]"
"[['ensembling', 'with', 'score combination'], ['ensembling', 'achieves', 'best over all result'], ['score combination', 'achieves', 'best over all result'], ['best over all result', 'of', '94.25']]"
[]
[]
"[['novel transition system', 'for', 'constituent parsing']]"
[]
[]
"[['bottom - up system', 'performs', 'slightly better'], ['slightly better', 'than', 'top - down system']]"
"[['inorder system', 'outperforms', 'bottom - up and the top - down system']]"
"[['bottom - up parser and the top - down parser', 'have', 'similar results'], ['similar results', 'under', 'greedy setting']]"
[]
"[['inorder parser', 'outperforms', 'state - of - the - art discrete parser'], ['inorder parser', 'outperforms', 'state - of - the - art neural parsers']]"
[]
"[['our final model', 'achieves', 'best results'], ['best results', 'among', 'transitionbased parsing'], ['our final model', 'obtains', 'comparable results'], ['comparable results', 'to', 'state - of - the - art graph - based models']]"
[]
"[['2 - 21', 'as', 'training']]"
[]
"[['neural - net parse reranker', 'achieves', 'very good results'], ['very good results', 'with', 'comparatively simple architecture']]"
"[['three LSTM layers', 'with', '1,500 units'], ['three LSTM layers', 'trained with', 'truncated backpropagation'], ['truncated backpropagation', 'through', 'time'], ['truncated backpropagation', 'with', 'step size 50'], ['time', 'with', 'mini-batch size 20'], ['time', 'with', 'step size 50']]"
"[['starting states', 'with', ""previous minibatch 's last hidden states""]]"
"[['forget gate bias', 'initialized to be', 'one'], ['rest of model parameters', 'sampled from', 'U ( ? 0.05 , 0.05 )']]"
"[['Dropout', 'applied to', 'non-recurrent connections'], ['clipped', 'when', 'norm'], ['norm', 'bigger than', '20']]"
"[['learning rate', 'is', '0.25 0.85 max']]"
"[['vanilla softmax', 'over', 'entire vocabulary']]"
[]
"[['single LSTM - LM ( GS )', 'together with', 'Charniak ( GS )'], ['Charniak ( GS )', 'reaches', '93.6'], ['Charniak ( GS )', 'achieves', 'new state of the art']]"
"[['trees', 'converted to', 'Stanford dependencies'], ['UAS and LAS', 'are', '95.9 % and 94.1 %']]"
[]
[]
"[['RNNGs', 'as', 'generative probabilistic models'], ['generative probabilistic models', 'over', 'trees']]"
"[['inductive bias', 'of', 'RNNGs'], ['inductive bias', 'to test', 'linguistic hypotheses'], ['RNNGs', 'to test', 'linguistic hypotheses']]"
"[['importance', 'of', 'composition function']]"
"[['RNNG composition function', 'with', 'novel gated attention mechanism'], ['novel gated attention mechanism', 'leading to', 'GA - RNNG'], ['novel gated attention mechanism', 'to incorporate', 'more interpretability'], ['more interpretability', 'into', 'model']]"
"[['GA - RNNG', 'investigating', 'role']]"
"[['RNNG', 'with', 'only a stack'], ['"" full "" RNNG', 'with', 'all three data structures'], ['RNNG', 'outperforms', '"" full "" RNNG'], ['"" full "" RNNG', 'with', 'all three data structures']]"
"[['stack', 'gives', 'worst'], ['worst', 'among', 'new results']]"
"[['stack - only RNNG', 'achieves', 'best performance'], ['stack', 'is', 'most harmful']]"
"[['syntax', 'without', 'explicit composition'], ['syntax', 'provides', 'little benefit'], ['little benefit', 'over', 'sequential LSTM language model']]"
"[['stack - only results', 'are', 'best published PTB results'], ['best published PTB results', 'for', 'phrasestructure and dependency parsing'], ['phrasestructure and dependency parsing', 'among', 'supervised models']]"
[]
"[['model', 'outperforms', 'baseline RNNG'], ['baseline RNNG', 'with', 'all three structures'], ['competitive performance', 'with', 'strongest , stack - only , RNNG variant'], ['model', 'achieves', 'competitive performance'], ['competitive performance', 'with', 'strongest , stack - only , RNNG variant']]"
[]
"[['higher overlap', 'with', 'conversion'], ['conversion', 'using', 'Collins head rules ( 49.8 UAS )']]"
"[['high error rate ( ? 90 % )', 'when', 'dependent'], ['dependent', 'is', 'verb']]"
"[['conversion accuracy', 'better for', 'nouns ( ? 50 % error )'], ['conversion accuracy', 'much better for', 'determiners ( 30 % ) and particles ( 6 % )'], ['much better', 'for', 'determiners ( 30 % ) and particles ( 6 % )'], ['determiners ( 30 % ) and particles ( 6 % )', 'with respect to', 'Collins head rules']]"
[]
"[['test data', 'with', 'usual split'], ['GA - RNNG', 'achieves', '94.2 %'], ['U - GA - RNNG', 'achieves', '93.5 %']]"
[]
"[['parser', 'combines', 'encoder'], ['decoder', 'customized for', 'parsing']]"
"[['character LSTM', 'performs', 'better'], ['better', 'than', 'other lexical representationseven']]"
[]
[]
"[['test score', 'of', '93.55 F1'], ['93.55 F1', 'for', 'our CharLSTM parser'], ['previous best numbers', 'for', 'single - system parsers'], ['our CharLSTM parser', 'exceeds', 'previous best numbers'], ['previous best numbers', 'for', 'single - system parsers'], ['single - system parsers', 'trained on', 'Penn Treebank']]"
"[['our parser', 'augmented with', 'ELMo word representations'], ['our parser', 'achieves', 'new state - of - the - art score'], ['ELMo word representations', 'achieves', 'new state - of - the - art score'], ['new state - of - the - art score', 'of', '95.13 F1'], ['95.13 F1', 'on', 'WSJ test set']]"
[]
"[['Development set results', 'addition of', 'word embeddings'], ['word embeddings', 'to', 'model'], ['model', 'that uses', 'character LSTM'], ['performance', 'for', 'some languages'], ['hurts', 'for', 'others']]"
"[['test set result', 'exceeds', 'previous best - published numbers']]"
[]
"[['deep neural network', 'to build', 'distributed representations'], ['distributed representations', 'of', 'pairs']]"
"[['entity - level information', 'with', 'large number of learned , continuous features'], ['large number of learned , continuous features', 'instead of', 'small number of hand - crafted categorical ones']]"
"[['two coreference clusters', 'is', 'desirable']]"
"[['test time', 'builds up', 'coreference clusters'], ['coreference clusters', 'starting with', 'each mention'], ['each mention', 'in', 'own cluster'], ['coreference clusters', 'merging', 'pair of clusters']]"
"[['novel easy - first cluster - ranking procedure', 'combines', 'strengths']]"
"[['learning - to - search algorithm', 'inspired by', 'SEARN'], ['learning - to - search algorithm', 'to train', 'neural network'], ['SEARN', 'to train', 'neural network']]"
[]
"[['mention - ranking model', 'surpasses', 'all previous systems']]"
"[['cluster - ranking model', 'improves', 'results'], ['results', 'across', 'both languages and all evaluation metrics'], ['further', 'across', 'both languages and all evaluation metrics']]"
[]
"[['goal - directed endto - end deep reinforcement learning framework', 'to resolve', 'coreference']]"
"[['policy network', 'includes', 'learning'], ['span representation', 'scoring', 'potential entity mentions'], ['policy network', 'generating', 'probability distribution'], ['learning', 'generating', 'probability distribution'], ['actions', 'from', 'current mention'], ['actions', 'to', 'antecedents'], ['current mention', 'to', 'antecedents']]"
"[['sequence of linking actions', 'made', 'reward function'], ['linking actions', 'made', 'reward function'], ['reward function', 'to measure', 'how good']]"
"[['entropy regularization term', 'to encourage', 'exploration'], ['entropy regularization term', 'prevent', 'policy'], ['policy', 'prematurely converging to', 'bad local optimum']]"
"[['regularized policy network parameters', 'based on', 'rewards'], ['rewards', 'associated with', 'sequences of sampled actions'], ['sequences of sampled actions', 'computed on', 'whole input document']]"
[]
"[['learned parameters', 'for', 'initialization'], ['our model', 'use', 'learned parameters'], ['learned parameters', 'for', 'initialization']]"
"[['number of sampled trajectories N s', '=', '100'], ['number of sampled trajectories N s', 'tune', 'regularization parameter'], ['regularization parameter', 'in', '{ 10 ?5 , 10 ?4 , 0.001 , 0.01 , 0.1 , 1 }'], ['regularization parameter', 'set it to', '10 ? 4']]"
[]
"[['our base reinforced model', 'improves', 'average F 1 score'], ['average F 1 score', 'around', '2 points']]"
"[['entropy regularization', 'to encourage', 'exploration'], ['entropy regularization', 'improve', 'result'], ['exploration', 'improve', 'result'], ['result', 'by', '1 point']]"
"[['context - dependent ELMo embedding', 'to', 'our base model']]"
"[['our full model', 'achieves', 'state - of the - art performance'], ['state - of the - art performance', 'of', '73.8 % F1 - score'], ['73.8 % F1 - score', 'when using', 'ELMo and entropy regularization'], ['best F1 -score', 'of', '70.5 %'], ['70.5 %', 'when using', 'fixed word embedding only']]"
[]
"[['two variants of reinforcement learning', 'to directly optimize', 'coreference system'], ['coreference system', 'for', 'coreference evaluation metrics']]"
"[['max-margin coreference objective', 'by incorporating', 'reward'], ['reward', 'associated with', 'each coreference decision'], ['reward', 'into', ""loss 's slack rescaling""]]"
[]
[]
[]
"[['REINFORCE', 'does', 'slightly better'], ['slightly better', 'than', 'heuristic loss'], ['reward rescaling', 'performs', 'significantly better'], ['significantly better', 'than', 'both'], ['significantly better', 'on', 'both languages'], ['both', 'on', 'both languages']]"
"[['reward - rescaled max - margin loss', 'combines', 'best of both worlds'], ['best of both worlds', 'resulting in', 'superior performance']]"
[]
"[['approximation', 'of', 'higher - order inference'], ['higher - order inference', 'uses', 'span - ranking architecture'], ['span - ranking architecture', 'in', 'iterative manner']]"
"[['antecedent distribution', 'used as', 'attention mechanism'], ['attention mechanism', 'to optionally update', 'existing span representations'], ['existing span representations', 'enabling', 'later corefer']]"
"[['coarseto - fine approach', 'learned with', 'single endto - end objective']]"
"[['less accurate but more efficient coarse factor', 'in', 'pairwise scoring function']]"
"[['extra pruning step', 'during', 'inference'], ['number of antecedents', 'considered by', 'more accurate but inefficient fine factor']]"
"[['rough sketch', 'of', 'likely antecedents'], ['rough sketch', 'before applying', 'more expensive scoring function']]"
[]
"[['span - ranking model', 'augmented with', 'ELMo and hyperparameter tuning'], ['span - ranking model', 'achieves', '72.3 F1']]"
"[['Our full approach', 'achieves', '73.0 F1']]"
[]
"[['much higher recall', 'when adopting', 'coarse - to - fine approach']]"
"[['further improvement', 'including', 'second - order inference']]"
[]
[]
"[['mention - ranking model', 'for', 'coreference resolution'], ['Siamese Net', 'for learning', 'similarity']]"
"[['LSTM - Siamese Net', 'learns', 'representations'], ['representations', 'for', 'candidate and the anaphoric sentence'], ['candidate and the anaphoric sentence', 'in', 'shared space']]"
"[['representations', 'combined into', 'joint representation'], ['joint representation', 'used to calculate', 'score'], ['score', 'characterizes', 'relation']]"
"[['highest - scoring antecedent candidate', 'for', 'given anaphoric sentence']]"
"[['embedding', 'of', 'context'], ['embedding', 'of', 'embedding'], ['context', 'of', 'anaphor'], ['context', 'of', 'anaphor'], ['embedding', 'of', 'head of the anaphoric phrase'], ['embedding', 'of', 'head of the anaphoric phrase'], ['head of the anaphoric phrase', 'to', 'input'], ['input', 'to characterize', 'each individual anaphorsimilar']]"
"[['model', 'learns', 'relation'], ['relation', 'between', 'anaphor'], ['anaphor', 'in', 'anaphoric sentence'], ['anaphor', 'in', 'antecedent']]"
"[['large amounts of instances', 'easily adaptable to', 'other languages']]"
[]
[]
"[['preceding sentence baseline ( PS BL )', 'chooses', 'previous sentence'], ['preceding sentence baseline ( PS BL )', 'chooses', 'TAGbaseline ( TAG BL )'], ['previous sentence', 'for', 'antecedent'], ['previous sentence', 'for', 'TAGbaseline ( TAG BL )'], ['TAGbaseline ( TAG BL )', 'randomly chooses', 'candidate'], ['candidate', 'with', 'constituent tag label'], ['constituent tag label', 'in', '{S , VP , ROOT , SBAR }']]"
"[['Glo Ve word embeddings', 'pre-trained on', 'Gigaword and Wikipedia']]"
"[['Vocabulary', 'built from', 'words'], ['words', 'in', 'training data'], ['frequency', 'in', '{ 3 , U ( 1 , 10 ) }'], ['words', 'with', 'frequency'], ['training data', 'with', 'frequency'], ['frequency', 'in', '{ 3 , U ( 1 , 10 ) }'], ['OOV words', 'replaced with', 'UNK token']]"
"[['size', 'of', 'LSTMs hidden states'], ['LSTMs hidden states', 'set to', '{ 100 , qlog - U ( 30 , 150 ) }']]"
"[['weight matrices', 'of', 'LSTMs'], ['LSTMs', 'with', 'random orthogonal matrices']]"
"[['first feed - forward layer size', 'set to', 'value'], ['value', 'in', 'Optimization']]"
"[['our model', 'in', 'minibatches'], ['minibatches', 'using', 'Adam ( Kingma and Ba , 2015 )'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'learning rate'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'maximal batch size'], ['learning rate', 'of', '10 ? 4']]"
"[['gradients', 'by', 'global norm'], ['global norm', 'with', 'clipping value'], ['clipping value', 'in', '{ 1.0 , U ( 1 , 100 ) }']]"
"[['model', 'performs', 'best'], ['best', 'on', 'devset']]"
[]
"[['input', 'with', 'k p ? U (0.8 , 1.0 )'], ['outputs', 'of', 'LSTMs'], ['input', 'with', 'k p ? U (0.8 , 1.0 )']]"
[]
"[['HPs', 'tuned on', 'ARRAU - AA'], ['HPs', 'obtain', 'results'], ['results', 'well beyond', 'KZH13'], ['all ablated model variants', 'perform', 'worse'], ['worse', 'than', 'full model']]"
"[['Performance', 'of', '68.10 s@1 score'], ['68.10 s@1 score', 'indicates', 'model']]"
[]
"[['more successful', 'in resolving', 'nominal']]"
"[['shell noun resolution', 'in', ""KZH13 's dataset""], ['s@1 scores', 'in', 'range'], ['nominal anaphors', 'in', 'ARRAU - AA'], ['MR - LSTM', 'achieved', 's@1 scores'], ['s@1 scores', 'in', 'range'], ['51.89 s@1 score', 'for', 'nominal anaphors'], ['nominal anaphors', 'in', 'ARRAU - AA']]"
"[['MR - LSTM without context embedding ( ctx )', 'achieves', 'comparable s@ 2 score'], ['comparable s@ 2 score', 'with', 'variant'], ['variant', 'that omits', 'syntactic information']]"
[]
"[['coreference prediction', 'benefit from', 'modeling'], ['global information', 'about', 'entity - clusters']]"
"[['global context', 'necessary for', 'further improvements'], ['further improvements', 'in', 'coreference resolution']]"
"[['representations', 'of', 'mention clusters'], ['representations', 'by embedding them', 'sequentially'], ['sequentially', 'using', 'recurrent neural network']]"
"[['global representation', 'from', 'individual mentions'], ['individual mentions', 'present in', 'each cluster']]"
[]
"[['mention - ranking sub-system', 'trained', 'end - to - end'], ['end - to - end', 'on', 'coreference task']]"
"[['model', 'as', 'local classifier'], ['local classifier', 'with', 'fixed context']]"
"[['training', 'use', 'document - size minibatches'], ['document - size minibatches', 'allows for', 'efficient pre-computation'], ['efficient pre-computation', 'of', 'RNN states'], ['document - size minibatches', 'minimize', 'loss'], ['loss', 'with', 'AdaGrad'], ['AdaGrad', 'after clipping', 'LSTM gradients']]"
"[['initial learning rate', 'chosen for', 'AdaGrad'], ['significant impact', 'on', 'results'], ['initial learning rate', 'choose', 'learning rates'], ['learning rates', 'for', 'each layer'], ['each layer', 'out of', '{ 0.1 , 0.02 , 0.01 , 0.002 , 0.001 }']]"
"[['ha ( x n ) , h c ( x n ) , and h ( m )', 'to be', '? R 200']]"
"[['single - layer LSTM', 'implemented in', 'element - rnn library']]"
"[['regularization', 'apply', 'Dropout'], ['Dropout', 'with', 'rate'], ['Dropout', 'with', 'rate'], ['rate', 'of', '0.4'], ['rate', 'of', '0.3'], ['rate', 'before applying', 'linear weights u'], ['0.4', 'before applying', 'linear weights u'], ['Dropout', 'apply', 'Dropout'], ['Dropout', 'with', 'rate'], ['rate', 'of', '0.3'], ['0.3', 'to', 'LSTM states'], ['LSTM states', 'before forming', 'dot -product scores']]"
[]
"[['GPU', 'for', 'training']]"
[]
"[['statistically significant improvement', 'of', 'over 0.8 Co NLL points'], ['over 0.8 Co NLL points', 'over', 'previous state of the art']]"
"[['performance', 'with', 'most dramatic improve - ments'], ['most dramatic improve - ments', 'on', 'non-anaphoric pronouns']]"
"[['RNN performance', 'is', 'significantly better'], ['significantly better', 'than', 'Avg baseline'], ['significantly better', 'barely improves over', 'mention - ranking'], ['Avg baseline', 'barely improves over', 'mention - ranking']]"
[]
"[['word embedding model', 'learns', 'cross - sentence dependency'], ['cross - sentence dependency', 'for improving', 'end - to - end co-reference resolution ( E2E - CR )']]"
"[['attentional sentence linking models', 'to learn', 'crosssentence dependency']]"
[]
"[['cross - sentence encoder', 'for', 'end - to - end co-reference ( E2E - CR )']]"
"[['external memory block', 'containing', 'syntactic and semantic information'], ['syntactic and semantic information', 'from', 'context sentences'], ['syntactic and semantic information', 'added to', 'standard LSTM model']]"
"[['proposed model', 'able to encode', 'input sentences'], ['input sentences', 'as', 'batch'], ['proposed model', 'calculate', 'representations'], ['representations', 'of', 'input words'], ['input words', 'by taking', 'target sentences and context sentences'], ['input words', 'by taking', 'into consideration']]"
"[['LSTM modules', 'have', '200 output units']]"
"[['ASL', 'calculate', 'cross - sentence dependency'], ['cross - sentence dependency', 'using', 'multilayer perceptron'], ['multilayer perceptron', 'with', 'one hidden layer'], ['one hidden layer', 'consisting of', '150 hidden units']]"
"[['initial learning rate', 'set as', '0.001'], ['initial learning rate', 'decays', '0.001 %'], ['0.001 %', 'every', '100 steps']]"
"[['model', 'optimized with', 'Adam algorithm']]"
"[['up to 40 continuous sentences', 'for', 'training'], ['up to 40 continuous sentences', 'if', 'input'], ['training', 'if', 'input'], ['input', 'is', 'too long']]"
[]
"[['baseline model', 'achieved', '67.2 % F1 score'], ['ASL model', 'improved', 'performance'], ['performance', 'by', '0.6 %'], ['ASL model', 'achieved', '67.8 % average F1']]"
"[['models', 'consider', 'cross - sentence dependency'], ['cross - sentence dependency', 'significantly outperform', 'baseline model'], ['baseline model', 'encodes', 'each sentence'], ['each sentence', 'from', 'input document']]"
"[['better performance', 'than', 'LSL model']]"
[]
"[['entity - level representation', 'in', 'simple and intuitive manner'], ['entity - level representation', 'facilitates', 'end - to - end optimization']]"
[]
"[['contextual embeddings', 'as', 'input mention representations']]"
[]
"[['BERT', 'in', 'fully convolutional manner']]"
[]
"[['span - ranking model', 'from with', 'ELMo input features'], ['span - ranking model', 'from with', 'second - order span representations'], ['second - order span representations', 'achieves', '73.0 % Avg.']]"
"[['ELMo features', 'with', 'BERT features'], ['ELMo features', 'achieves', '76. 25 % average F1'], ['BERT features', 'achieves', '76. 25 % average F1']]"
"[['second - order span - representations', 'while using', 'BERT features'], ['BERT features', 'achieves', '76.37 % F1'], ['76.37 % F1', 'achieving', 'higher recall and lower precision'], ['higher recall and lower precision', 'on', 'all evaluation metrics']]"
"[['secondorder span representations', 'with', 'Entity Equalization'], ['secondorder span representations', 'achieves', '76. 64 % average F1'], ['Entity Equalization', 'achieves', '76. 64 % average F1'], ['secondorder span representations', 'consistently achieving', 'highest F 1 score']]"
"[['new state of the art', 'for', 'coreference resolution'], ['new state of the art', 'improving', 'previous state of the art'], ['previous state of the art', 'by', '3.6 % average F1']]"
[]
[]
"[['end - toend', 'given', 'gold mention clusters']]"
[]
"[['space', 'of', 'all spans'], ['marginal likelihood', 'of', 'antecedent spans'], ['all spans', 'up to', 'maximum length'], ['marginal likelihood', 'of', 'antecedent spans'], ['antecedent spans', 'from', 'gold coreference clusters']]"
"[['each span', 'is', 'good antecedent']]"
"[['vector embeddings', 'representing', 'spans'], ['vector embeddings', 'combine', 'context - dependent boundary representations'], ['context - dependent boundary representations', 'with', 'head - finding attention mechanism'], ['head - finding attention mechanism', 'over', 'span']]"
"[['attention component', 'inspired by', 'parser - derived head - word matching features'], ['parser - derived head - word matching features', 'from', 'previous systems'], ['attention component', 'less susceptible to', 'cascading errors']]"
[]
"[['word embeddings', 'area', 'fixed concatenation'], ['fixed concatenation', 'of', '300 - dimensional GloVe embeddings'], ['fixed concatenation', 'of', '50 - dimensional embeddings'], ['normalized', 'to be', 'unit vectors']]"
"[['Outof - vocabulary words', 'represented by', 'vector'], ['vector', 'of', 'zeros']]"
"[['characters', 'represented as', 'learned 8 - dimensional embeddings']]"
"[['convolutions', 'have', 'window sizes'], ['window sizes', 'of', '3 , 4 , and 5 characters'], ['3 , 4 , and 5 characters', 'consisting of', '50 filters']]"
"[['hidden states', 'in', 'LSTMs'], ['hidden states', 'have', '200 dimensions'], ['LSTMs', 'have', '200 dimensions']]"
"[['feedforward neural network', 'consists of', 'two hidden layers'], ['feedforward neural network', 'consists of', 'rectified linear units'], ['two hidden layers', 'with', '150 dimensions']]"
"[['ADAM', 'for', 'learning'], ['learning', 'with', 'minibatch size'], ['minibatch size', 'of', '1']]"
"[['LSTM weights', 'initialized with', 'random orthonormal matrices']]"
"[['0.5 dropout', 'to', 'word embeddings and character CNN outputs']]"
"[['0.2 dropout', 'to', 'all hidden layers and feature embeddings']]"
"[['Dropout masks', 'shared across', 'timesteps'], ['Dropout masks', 'to preserve', 'long - distance information']]"
"[['learning rate', 'decayed by', '0.1 %'], ['0.1 %', 'every', '100 steps']]"
"[['up to 150 epochs', 'with', 'early stopping'], ['early stopping', 'based on', 'development set']]"
[]
[]
[]
"[['previous systems', 'in', 'all metrics']]"
"[['our single model', 'improves', 'state - of - the - art average F1'], ['our single model', 'improves', 'our 5 - model ensemble'], ['state - of - the - art average F1', 'by', '1.5'], ['improves', 'by', '3.1']]"
"[['most significant gains', 'come from', 'improvements'], ['improvements', 'in', 'recall']]"
"[['spans and the width of spans', 'are', 'crucial signals'], ['crucial signals', 'for', 'coreference resolution']]"
"[['3.8 F1', 'to', 'final result']]"
"[['contribution', 'of', '0.9 F1'], ['0.9 F1', 'from', 'character - level modeling']]"
"[['1.3 F1 degradation', 'in', 'performance'], ['1.3 F1 degradation', 'without', 'attention mechanism'], ['attention mechanism', 'for finding', 'task - specific heads']]"
"[['mention candidates', 'detected by', 'rule - based system'], ['mention candidates', 'over', 'predicted parse trees'], ['rule - based system', 'over', 'predicted parse trees'], ['mention candidates', 'degrades', 'performance'], ['rule - based system', 'degrades', 'performance'], ['predicted parse trees', 'degrades', 'performance'], ['performance', 'by', '1 F1']]"
"[['oracle mentions', 'see', 'improvement'], ['improvement', 'of', '17.5 F1']]"
[]
"[['BERT', 'to', 'coreference resolution']]"
[]
[]
"[['original Tensorflow implementations', 'of', 'c 2f - coref'], ['original Tensorflow implementations', 'of', 'BERT']]"
"[['all models', 'on', 'OntoNotes English data'], ['OntoNotes English data', 'for', '20 epochs'], ['20 epochs', 'using', 'dropout'], ['20 epochs', 'using', 'learning rates'], ['dropout', 'of', '0.3'], ['learning rates', 'of', '1 10 ?5 and 2 10 ? 4'], ['1 10 ?5 and 2 10 ? 4', 'with', 'linear decay'], ['linear decay', 'for', 'BERT parameters']]"
"[['separate models', 'with', 'max segment len'], ['max segment len', 'of', '128 , 256 , 384 , and 512'], ['models', 'trained on', '128 and 384 word pieces'], ['128 and 384 word pieces', 'performed', 'best'], ['best', 'for', 'BERT - base and BERT - large']]"
[]
"[['BERT', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', '9 % and 11.5 %'], ['9 % and 11.5 %', 'for', 'base and large models']]"
[]
"[['BERT - base', 'offers', 'improvement'], ['improvement', 'of', '0.9 %'], ['0.9 %', 'over', 'ELMo - based c2 fcoref model']]"
"[['BERT - large', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', 'much larger margin'], ['much larger margin', 'of', '3.9 %']]"
"[['overlap variant', 'offers', 'no improvement'], ['no improvement', 'over', 'independent']]"
[]
[]
"[['new structured - data encoder', 'assuming', 'structures'], ['new structured - data encoder', 'assuming that', 'structures'], ['structures', 'should be', 'hierarchically captured']]"
"[['encoding', 'of', 'data - structure'], ['decoder', 'chosen to be', 'classical module']]"
"[['general structure', 'of', 'data'], ['data', 'using', 'two - level architecture'], ['two - level architecture', 'first encoding', 'all entities'], ['all entities', 'on the basis of', 'elements'], ['data structure', 'on the basis of', 'entities'], ['Transformer encoder', 'in', 'data - to - text models'], ['data - to - text models', 'to ensure', 'robust encoding'], ['robust encoding', 'of', 'each element / entities'], ['each element / entities', 'in comparison to', 'all others'], ['two - level architecture', 'integrate', 'hierarchical attention mechanism'], ['hierarchical attention mechanism', 'to compute', 'hierarchical context'], ['hierarchical context', 'fed into', 'decoder']]"
[]
"[['Wiseman', 'is', 'standard encoder - decoder system'], ['standard encoder - decoder system', 'with', 'copy mechanism']]"
"[['Li', 'is', 'standard encoder - decoder'], ['standard encoder - decoder', 'with', 'delayed copy mechanism'], ['placeholders', 'replaced by', 'salient records'], ['salient records', 'extracted from', 'table'], ['table', 'by', 'pointer network']]"
"[['Puduppully - plan', 'acts in', 'two steps'], ['first standard encoder - decoder', 'generates', 'plan'], ['second standard encoder - decoder', 'generates', 'text'], ['text', 'from', 'plan']]"
[]
"[['standard encoder - decoder', 'with', 'added module'], ['added module', 'aimed at updating', 'record representations'], ['record representations', 'during', 'generation process']]"
"[['records', 'should be', 'updated']]"
"[['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['Transformer encoders', 'set to', '300']]"
"[['dropout', 'at', 'rate 0.5']]"
"[['batch size', 'of', '64']]"
"[['model', 'for', 'fixed number of 25 K updates'], ['weights', 'of', 'last 5 checkpoints'], ['last 5 checkpoints', 'to ensure', 'more stability'], ['more stability', 'across', 'runs']]"
"[['initial learning rate', 'is', '0.001'], ['initial learning rate', 'reduced by', 'half'], ['half', 'every', '10 K steps']]"
"[['beam search', 'with', 'beam size'], ['beam size', 'of', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]"
[]
[]
"[['lower results', 'obtained by', 'Flat scenario'], ['Flat scenario', 'compared to', 'other scenarios']]"
"[['scenario Hierarchical - kv and Hierarchical -k', 'omitting', 'influence'], ['influence', 'of', 'record values'], ['record values', 'in', 'attention mechanism'], ['slightly better', 'in', 'all metrics'], ['attention mechanism', 'is', 'more effective'], ['slightly better', 'in', 'all metrics'], ['slightly better', 'excepted', 'CS - R%'], ['all metrics', 'excepted', 'CS - R%']]"
"[['Our hierarchical models', 'achieve', 'significantly better scores'], ['significantly better scores', 'on', 'all metrics'], ['significantly better scores', 'compared to', 'flat architecture Wiseman']]"
"[['Flat scenario', 'obtains', 'significant higher BLEU score ('], ['Flat scenario', 'generates', 'fluent descriptions'], ['fluent descriptions', 'with', 'accurate mentions ( RG - P % )'], ['accurate mentions ( RG - P % )', 'included in', 'gold descriptions ( CS - R% )']]"
"[['Our hierarchical models', 'outperform', 'two - step decoders'], ['two - step decoders', 'of', 'Li and Puduppully - plan'], ['Li and Puduppully - plan', 'on', 'BLEU and all qualitative metrics']]"
[]
[]
"[['neural ensemble natural language generator', 'train and test on', 'three large unaligned datasets'], ['three large unaligned datasets', 'in', 'restaurant , television , and laptop domains']]"
"[['novel ways', 'to represent', 'MR inputs'], ['MR inputs', 'including', 'novel methods']]"
"[['ensemble model', 'using', 'seq2seq framework'], ['seq2seq framework', 'for', 'TensorFlow']]"
"[['individual LSTM models', 'use', 'bidirectional LSTM encoder'], ['bidirectional LSTM encoder', 'with', '512 cells per layer'], ['CNN models', 'use', 'pooling encoder']]"
"[['decoder', 'in', 'all models'], ['decoder', 'was', '4 - layer RNN decoder'], ['all models', 'was', '4 - layer RNN decoder'], ['4 - layer RNN decoder', 'with', '512 LSTM cells per layer'], ['4 - layer RNN decoder', 'with', 'attention'], ['4 - layer RNN decoder', 'with', 'attention']]"
[]
[]
"[['LSTM and the CNN models', 'benefit from', 'additional pseudo - samples'], ['additional pseudo - samples', 'in', 'training set']]"
"[['our ensemble model', 'performs', 'comparably'], ['comparably', 'to', 'baseline model'], ['comparably', 'in terms of', 'automatic metrics'], ['baseline model', 'in terms of', 'automatic metrics'], ['TGen', 'in terms of', 'automatic metrics']]"
[]
"[['our ensemble model', 'performs', 'competitively'], ['competitively', 'with', 'baseline'], ['baseline', 'on', 'TV dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'by', 'wide margin'], ['Laptop dataset', 'by', 'wide margin']]"
[]
[]
"[['text generation', 'as', 'sequenceto - sequence problem']]"
[]
[]
"[['model', 'with', 'GCN encoder'], ['LSTM encoder', 'with', '.009 BLEU points'], ['GCN encoder', 'outperforms', 'strong baseline'], ['strong baseline', 'employs', 'LSTM encoder'], ['LSTM encoder', 'with', '.009 BLEU points']]"
"[['GCN model', 'is', 'more stable'], ['more stable', 'than', 'baseline'], ['baseline', 'with', 'standard deviation']]"
"[['GCN EC model', 'outperforms', 'PKUWRITER'], ['GCN EC model', 'outperforms', 'further reinforcement learning step'], ['GCN EC model', 'outperforms', 'MELBOURNE'], ['PKUWRITER', 'uses', 'ensemble of 7 models'], ['PKUWRITER', 'uses', 'further reinforcement learning step'], ['further reinforcement learning step', 'by', '.047 BLEU points'], ['MELBOURNE', 'by', '.014 BLEU points']]"
[]
"[['neural models', 'with', 'upper bound results'], ['upper bound results', 'on', 'same dataset'], ['upper bound results', 'by', 'pipeline model'], ['same dataset', 'by', 'pipeline model'], ['STUMBA - D and TBDIL model', 'outperforming', 'GCN - based model']]"
"[['importance', 'of', 'skip connections'], ['skip connections', 'between', 'GCN layers']]"
"[['Residual and dense connections', 'lead to', 'similar results']]"
"[['Dense connections', 'produce', 'models']]"
[]
[]
[]
"[['canonical presentation', 'of', 'RSA framework'], ['RSA framework', 'grounded in', 'reference resolution']]"
[]
"[['pragmatic methods', 'obtain', 'improvements'], ['pragmatic methods', 'obtain', '0.2-1.8 METEOR'], ['improvements', 'of', '0.2-0.5'], ['improvements', 'of', '0.2-1.8 METEOR'], ['0.2-0.5', 'in', 'ROUGE scores'], ['0.2-1.8 METEOR', 'over', 'base S 0 model'], ['base S 0 model', 'with', 'distractor - based approach SD 1'], ['distractor - based approach SD 1', 'outperforming', 'reconstructorbased approach S R 1']]"
"[['SD 1', 'is', 'strong'], ['strong', 'across', 'all metrics'], ['SD 1', 'obtaining', 'results'], ['strong', 'obtaining', 'results'], ['all metrics', 'obtaining', 'results'], ['results', 'competitive to', 'best previous abstractive systems'], ['attribute type', 'for', 'base model S0'], ['Coverage ratios', 'for', 'pragmatic system SD 1'], ['pragmatic system SD 1', 'when constructing', 'distractor'], ['distractor', 'by masking', 'specified attribute']]"
[]
"[['content plan', 'from', 'input and conditions'], ['input and conditions', 'on', 'content plan'], ['content plan', 'to generate', 'output document']]"
"[['end - to - end', 'using', 'neural networks']]"
"[['one - layer pointer networks', 'during', 'content planning'], ['two - layer LSTMs', 'during', 'text generation'], ['two - layer LSTMs', 'during', 'text generation']]"
"[['Input feeding', 'employed for', 'text decoder']]"
"[['dropout', 'at', 'rate'], ['rate', 'of', '0.3']]"
"[['Models', 'trained for', '25 epochs'], ['25 epochs', 'with', 'Adagrad optimizer'], ['initial learning rate', 'was', '0.15'], ['learning rate decay', 'selected from', '{ 0.5 , 0.97 }']]"
"[['text decoding', 'made use of', 'BPTT'], ['truncation size', 'to', '100']]"
"[['beam size', 'to', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]"
[]
[]
"[['NCP', 'improves upon', 'vanilla encoderdecoder models ( ED + JC , ED + CC )']]"
"[['NCP', 'achieves', 'comparable scores'], ['comparable scores', 'with', 'joint or conditional copy mechanism']]"
"[['NCP + CC', 'achieves', 'best content selection and content ordering scores'], ['best content selection and content ordering scores', 'in terms of', 'BLEU']]"
"[['best reported system', 'achieve', 'absolute improvement'], ['absolute improvement', 'of', 'approximately 12 %'], ['absolute improvement', 'of', '12 %'], ['approximately 12 %', 'in terms of', 'relation generation'], ['12 %', 'in terms of', 'relation generation'], ['content selection precision', 'improves by', '5 %'], ['improves', 'by', '5 %'], ['recall', 'by', '15 %'], ['BLEU', 'by', '1.5 points']]"
[]
[]
"[['fluent language', 'describing', 'information']]"
"[['output', 'fed into', 'neural generation system']]"
"[['text planner', 'determines', 'information structure'], ['text planner', 'expresses it', 'unambiguously']]"
[]
[]
"[['best', 'on', 'all categories'], ['all categories', 'in', 'automatic evaluation'], ['all categories', 'in', 'UPF - FORGe'], ['all categories', 'in', 'classic grammar - based NLG system'], ['classic grammar - based NLG system', 'scored', 'best'], ['best', 'in', 'human evaluation']]"
"[['end - to - end neural baseline', 'outperforms', 'WebNLG neural systems']]"
"[['LSTM decoder', 'with', 'attention'], ['LSTM decoder', 'with', 'neural checklist model'], ['LSTM decoder', 'applying', 'entity dropout']]"
[]
"[['StrongNeural and BestPlan systems', 'outperform', 'all the WebNLG participating systems'], ['all the WebNLG participating systems', 'on', 'all automatic metrics']]"
[]
[]
"[['more general approach', 'to', 'text generation']]"
"[['character - level sequence - to - sequence model', 'with', 'attention mechanism'], ['attention mechanism', 'results in', 'completely neural end - to - end architecture']]"
[]
"[['vocabulary - free model', 'inherently', 'more general']]"
"[['character - wise copy mechanism', 'consisting in', 'soft switch'], ['soft switch', 'between', 'generation and copy mode'], ['model', 'to learn', 'rare and unhelpful self - correspondences'], ['state - of - art architecture', 'enhancing', 'recall'], ['internal representation capabilities', 'enhancing', 'recall'], ['state - of - art architecture', 'consists in', 'exchange']]"
"[['our system', 'using', 'PyTorch framework']]"
"[['negative log - likelihood loss', 'using', 'teacher forcing and Adam']]"
[]
"[['higher metric values', 'with respect to', 'TGen'], ['TGen', 'on', 'Hotel and Restaurant datasets'], ['TGen', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset']]"
"[['TGen', 'achieves', 'three out of five higher metrics values']]"
"[['approach', 'allows to obtain', 'better performance'], ['better performance', 'with respect to', 'training EDA_CS'], ['training EDA_CS', 'in', 'standard way'], ['standard way', 'on', 'Hotel and Restaurant datasets']]"
"[['EDA_CS TL', 'shows', 'bleu increment'], ['bleu increment', 'of', 'at least 14 %'], ['at least 14 %', 'with respect to', ""TGen 's score""], [""TGen 's score"", 'compared to', 'Hotel and Restaurant datasets']]"
"[['baseline model', 'largely outperformed by', 'all other examined methods'], ['EDA', 'largely outperformed by', 'all other examined methods']]"
[]
"[['novel neural network model', 'for', 'joint part - of - speech ( POS ) tagging and dependency parsing']]"
[]
[]
"[['novel neural network - based model', 'for', 'jointly learning']]"
"[['joint model', 'extends', 'well - known BIST graph - based dependency parser'], ['well - known BIST graph - based dependency parser', 'with', 'additional lower - level BiLSTM - based tagging component']]"
"[['jPTDP v 2.0', 'implemented using', 'DYNET v2.0'], ['DYNET v2.0', 'with', 'fixed random seed']]"
[]
"[['dropout', 'with', '67 % keep probability'], ['67 % keep probability', 'to', 'inputs'], ['inputs', 'of', 'BiLSTMs and MLPs']]"
"[['word dropout', 'to learn', 'embedding'], ['embedding', 'for', 'unknown words'], ['embedding', 'replace', 'each word token w'], ['each word token w', 'with', 'special "" unk "" symbol'], ['training set', 'with', 'special "" unk "" symbol'], ['special "" unk "" symbol', 'with', 'probability punk ( w )']]"
"[['objective loss', 'using', 'Adam ( Kingma and Ba , 2014 )'], ['Adam ( Kingma and Ba , 2014 )', 'with', 'initial learning rate'], ['initial learning rate', 'at', '0.001'], ['initial learning rate', 'no', 'mini-batches']]"
[]
"[['number of hidden nodes', 'in', 'MLPs'], ['number of hidden nodes', 'at', '100'], ['MLPs', 'at', '100']]"
"[['our model', 'produces', 'very competitive parsing results']]"
"[['UAS score', 'at', '94.51 %'], ['LAS score', 'at', '92.87 %'], ['LAS score', 'at', '92.87 %'], ['UAS and LAS scores', 'of', 'BIST graph - based model']]"
"[['0.9 % lower parsing scores', 'than', 'state - of - the - art dependency parser']]"
"[['state - of - the - art POS tagging accuracy', 'at', '97.97 %']]"
[]
"[['BiLSTMs', 'are', 'strong and trainable sequence models']]"
"[['each word', 'by', 'BiLSTM encoding'], ['feature function', 'passed to', 'non-linear scoring function ( multi - layer perceptron )']]"
"[['BiLSTM', 'trained with', 'rest of the parser'], ['rest of the parser', 'to learn', 'good feature representation'], ['good feature representation', 'for', 'parsing problem']]"
"[['BiLSTM feature extractor', 'in', 'two parsing architectures']]"
"[['graphbased parser', 'jointly train', 'structured - prediction model'], ['structured - prediction model', 'on top of', 'BiLSTM'], ['structured - prediction model', 'propagating', 'errors'], ['BiLSTM', 'propagating', 'errors'], ['errors', 'from', 'structured objective']]"
"[['parsers', 'implemented in', 'python'], ['parsers', 'using', 'PyCNN toolkit'], ['python', 'using', 'PyCNN toolkit'], ['PyCNN toolkit', 'for', 'neural network training']]"
[]
"[['LSTM variant', 'implemented in', 'PyCNN'], ['LSTM variant', 'optimize using', 'Adam optimizer'], ['LSTM variant', 'using', 'Adam optimizer'], ['optimize', 'using', 'Adam optimizer']]"
"[['our parsers', 'are', 'very competitive']]"
"[['first - order graph - based parser', 'with', '2 features'], ['outperforms', 'thatare not using', 'external resources'], ['all other systems', 'thatare not using', 'external resources'], ['external resources', 'including', 'third - order TurboParser']]"
"[['greedy transition based parser', 'with', '4 features'], ['beam - based transition parser', 'with', 'heavily engineered features'], ['4 features', 'matches or outperforms', 'most other parsers'], ['most other parsers', 'including', 'beam - based transition parser'], ['beam - based transition parser', 'with', 'heavily engineered features'], ['beam - based transition parser', 'with', 'Stack - LSTM parser'], ['same parser', 'trained using', 'dynamic oracle']]"
"[['simple ( 4 features )', 'to', 'extended ( 11 features ) feature set'], ['simple ( 4 features )', 'leads to', 'some gains'], ['extended ( 11 features ) feature set', 'leads to', 'some gains'], ['some gains', 'in', 'accuracy'], ['accuracy', 'for', 'English and Chinese']]"
"[['accuracy', 'of', 'graph - based parser']]"
"[['probabilistic interpretation', 'to', 'ensemble parser'], ['probabilistic interpretation', 'viewing it as', 'instance'], ['ensemble parser', 'viewing it as', 'instance'], ['instance', 'of', 'minimum Bayes risk inference']]"
"[['ensemble', 'into', 'single FOG parser'], ['single FOG parser', 'with', 'discriminative training'], ['discriminative training', 'by defining', 'new cost function']]"
"[['cost', 'of', 'each possible attachment'], ['each possible attachment', 'from', ""ensemble 's division of votes""], ['cost', 'in', 'discriminative learning']]"
[]
"[['neural FOG parser', 'trained with', 'Hamming cost']]"
[]
"[['same model', 'with', 'distillation cost'], ['distillation cost', 'gives', 'consistent improvements'], ['consistent improvements', 'for', 'all languages']]"
[]
"[['best published scores', 'For', 'German'], ['Chinese', 'achieves', 'best published scores'], ['best published scores', 'for', 'German']]"
[]
[]
[]
"[['parser choice', 'on', 'biomedical event extraction']]"
"[['Stanford - Biaffine', 'utilizes', 'pre-trained word embeddings'], ['pre-trained word embeddings', 'employ', '200 dimensional pre-trained word vectors']]"
"[['traditional feature - based models', 'use', 'original pure Java implementations'], ['NLP4J - dep', 'use', 'original pure Java implementations'], ['original pure Java implementations', 'with', 'default hyperparameter settings']]"
"[['BiLSTM - CRF - based models', 'use', 'default hyper - parameters'], ['default hyper - parameters', 'use', 'Nadam'], ['default hyper - parameters', 'run for', '50 epochs']]"
"[['Stanford - NNdep', 'select', 'word CutOff'], ['word CutOff', 'from', '{ 1 , 2 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['word CutOff', 'fix', 'other hyperparameters'], ['other hyperparameters', 'with', 'default values']]"
"[['jPTDP', 'use', '50 - dimensional character embeddings'], ['50 - dimensional character embeddings', 'fix', 'initial learning rate'], ['initial learning rate', 'at', '0.0005']]"
"[['number of BiLSTM layers', 'at', '2'], ['number of LSTM units', 'in', 'each layer'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }']]"
[]
"[['BiLSTM - CRF and Mar - MoT', 'obtain', 'lowest scores'], ['lowest scores', 'on', 'GENIA and CRAFT']]"
"[['jPTDP', 'obtains', 'similar score'], ['similar score', 'to', 'Mar - MoT'], ['similar score', 'to', 'BiLSTM - CRF'], ['Mar - MoT', 'on', 'GENIA'], ['BiLSTM - CRF', 'on', 'CRAFT'], ['similar score', 'to', 'BiLSTM - CRF'], ['BiLSTM - CRF', 'on', 'CRAFT']]"
"[['MarMoT', 'obtains', 'accuracy results'], ['accuracy results', 'at', '98.61 % and 97.07 %'], ['98.61 % and 97.07 %', 'on', 'GENIA and CRAFT']]"
"[['BiLSTM - CRF', 'obtains', 'accuracies'], ['accuracies', 'of', '98.44 %'], ['98.44 %', 'on', 'GE - NIA'], ['98.44 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT']]"
"[['CNN - based character - level word embeddings', 'provided', '0.1 % improvement'], ['0.1 % improvement', 'to', 'BiLSTM - CRF']]"
"[['BiLSTM - CRF', 'with', 'character - level word embeddings'], ['character - level word embeddings', 'obtains', 'highest accuracy scores']]"
[]
"[['GENIA', 'among', 'pre-trained models'], ['BLLIP', 'obtains', 'highest results']]"
"[['pre-trained Stanford - Biaffine ( v1 ) model', 'produces', 'lower scores'], ['lower scores', 'than', 'pre-trained Stanford - NNdep model'], ['pre-trained Stanford - NNdep model', 'on', 'GENIA']]"
"[['pre-trained NNdep and Biaffine models', 'result in', 'no significant performance differences'], ['no significant performance differences', 'irrespective of', 'source of POS tags'], ['pre-trained Stanford tagger', 'at', '98.37 %'], ['retrained NLP4J - POS model', 'at', '98.80 %']]"
[]
"[['novel neural network architecture', 'for', 'dependency parsing']]"
"[['STACKPTR', 'is', 'transition - based architecture'], ['STACKPTR', 'maintains', 'global view'], ['global view', 'of', 'sentence']]"
"[['STACKPTR parser', 'has', 'pointer network'], ['pointer network', 'as', 'backbone'], ['STACKPTR parser', 'equipped with', 'internal stack'], ['internal stack', 'to maintain', 'order'], ['order', 'of', 'head words'], ['head words', 'in', 'tree structures']]"
"[['STACKPTR parser', 'performs', 'parsing'], ['parsing', 'in', 'incremental , topdown , depth - first fashion'], ['incremental , topdown , depth - first fashion', 'at', 'each step'], ['arc', 'by assigning', 'child'], ['child', 'for', 'headword'], ['headword', 'top of', 'internal stack']]"
[]
[]
"[['BIAF', 'On', 'Chinese'], ['Full variation of STACKPTR', 'with', 'decoding beam size 10'], ['decoding beam size 10', 'outperforms', 'BIAF'], ['BIAF', 'on', 'Chinese'], ['competitive performance', 'on', 'English and German'], ['Full variation of STACKPTR', 'obtains', 'competitive performance'], ['competitive performance', 'on', 'English and German']]"
"[['Full model', 'achieves', 'best accuracy'], ['best accuracy', 'on', 'English and Chinese'], ['+ sib', 'on', 'German'], ['slightly worse', 'than', '+ sib'], ['+ sib', 'on', 'German']]"
"[['BIAF', 'On', 'all languages'], ['STACKPTR', 'significantly outperforms', 'BIAF'], ['BIAF', 'on', 'all languages'], ['all languages', 'showing', 'superiority']]"
"[['results', 'of', 'our parser'], ['our parser', 'on', 'RA'], ['results', 'slightly worse than', 'BIAF'], ['our parser', 'slightly worse than', 'BIAF']]"
"[['BIAF', 'obtains', 'better performance'], ['better performance', 'than', 'original one']]"
"[['Our model', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'UAS and LAS'], ['state - of - the - art performance', 'on', 'Chinese'], ['state - of - the - art performance', 'on', 'best UAS'], ['state - of - the - art performance', 'on', 'English'], ['UAS and LAS', 'on', 'Chinese'], ['best UAS', 'on', 'English'], ['UAS and LAS', 'on', 'Chinese'], ['best UAS', 'on', 'English'], ['best UAS', 'on', 'English']]"
"[['performance', 'competitive with', 'BIAF'], ['significantly better', 'than', 'other models']]"
[]
[]
[]
"[['sentences', 'processed in', 'linear left to right pass']]"
"[['representational power', 'of', 'neural networks'], ['neural networks', 'with', 'superior search'], ['superior search', 'enabled by', 'structured training and inference']]"
"[['neural network', 'to model', 'probability'], ['probability', 'of', 'individual parse actions']]"
"[['activations', 'from', 'all layers'], ['all layers', 'of', 'neural network'], ['activations', 'as', 'representation'], ['neural network', 'as', 'representation'], ['representation', 'in', 'structured perceptron model'], ['structured perceptron model', 'trained with', 'beam search and early updates']]"
"[['high - confidence parse trees', 'by parsing', 'unlabeled data'], ['unlabeled data', 'with', 'two different parsers'], ['high - confidence parse trees', 'selecting', 'sentences'], ['two parsers', 'produced', 'same trees']]"
"[['our neural network parser', 'than', 'other approaches'], ['significantly more', 'than', 'other approaches']]"
"[['publicly available word2vec 2 tool', 'to learn', 'CBOW embeddings']]"
[]
"[['reported accuracy', 'of', '94.22 % UAS']]"
"[['competitive', 'with', 'some of the highest reported accuries'], ['some of the highest reported accuries', 'dependencies on', 'WSJ']]"
[]
"[['neural graphbased approach', 'to achieve', 'competitive performance'], ['competitive performance', 'build', 'network'], ['network', 'uses', 'more regularization'], ['affine label classifier', 'with', 'biaffine ones']]"
"[['optimize', 'optimize with', 'Adam'], ['Adam', 'keeps', 'moving average'], ['moving average', 'of', 'L 2 norm'], ['L 2 norm', 'of', 'gradient'], ['L 2 norm', 'of', 'gradient'], ['gradient', 'for', 'each parameter'], ['each parameter', 'throughout', 'training'], ['gradient', 'for', 'each parameter'], ['gradient', 'by', 'moving average'], ['each parameter', 'by', 'moving average']]"
"[['Our model', 'gets', 'nearly the same UAS performance'], ['Our model', 'gets', 'SOTA UAS performance'], ['Our model', 'gets', 'SOTA performance'], ['nearly the same UAS performance', 'on', 'PTB - SD 3.3.0'], ['PTB - SD 3.3.0', 'as', 'current SOTA model'], ['Our model', 'gets', 'SOTA UAS performance'], ['SOTA UAS performance', 'on', 'CTB 5.1 7'], ['SOTA performance', 'on', 'all CoNLL 09 languages']]"
[]
[]
"[['classification component', 'takes into account', 'features'], ['features', 'of', 'current parser state'], ['classification component', 'predicts', 'next action'], ['next action', 'conditioned on', 'state']]"
"[['training criterion', 'to explore', 'parser states']]"
[]
"[['interpolating', 'between', 'algorithm states'], ['algorithm states', 'sampled from', 'model'], ['algorithm states', 'sampled from', 'training data'], ['more robust predictions', 'at', 'test time']]"
[]
"[['score', 'achieved by', 'dynamic oracle'], ['dynamic oracle', 'for', 'English'], ['dynamic oracle', 'is', '93.56 UAS'], ['English', 'is', '93.56 UAS']]"
"[['Chinese score', 'establishes', 'state - of - the - art']]"
[]
"[['globally normalized transition - based neural network model', 'achieves', 'state - of - the - art part - ofspeech tagging']]"
"[['simple feed - forward networks', 'without', 'any recurrence'], ['simple feed - forward networks', 'can achieve', 'comparable or better accuracies'], ['comparable or better accuracies', 'than', 'LSTMs']]"
[]
"[['beam search', 'for maintaining', 'multiple hypotheses'], ['global normalization', 'with', 'conditional random field ( CRF ) objective'], ['conditional random field ( CRF ) objective', 'to overcome', 'label bias problem']]"
"[['beam inference', 'approximate', 'partition function'], ['partition function', 'summing over', 'elements'], ['elements', 'in', 'beam'], ['beam inference', 'use', 'early updates'], ['partition function', 'use', 'early updates']]"
"[['gradients', 'based on', 'approximate global normalization'], ['gradients', 'perform', 'full backpropagation training'], ['full backpropagation training', 'of', 'all neural network parameters'], ['all neural network parameters', 'based on', 'CRF loss']]"
[]
[]
[]
"[['globally normalized model', 'significantly outperforms', 'local model']]"
"[['Beam search', 'with', 'locally normalized model'], ['locally normalized model', 'suffers from', 'severe label bias issues']]"
"[['beam search', 'with', 'locally normalized model'], ['beam search', 'with', 'global normalization'], ['locally normalized model', 'does', 'help'], ['beam search', 'with', 'global normalization'], ['global normalization', 'leads to', '7 % reduction'], ['7 % reduction', 'in', 'relative error']]"
"[['character ngrams feature', 'is', 'very important'], ['character ngrams feature', 'increasing', 'average accuracy'], ['average accuracy', 'on', ""CoNLL '09 datasets""]]"
[]
[]
"[['94.26 % LAS and 92.41 % UAS', 'with', 'tri-training']]"
[]
[]
"[['very large corpus', 'with', 'large output space']]"
"[['linear models', 'with', 'rank constraint'], ['billion words', 'within', 'ten minutes'], ['performance', 'on par with', 'state - of - the - art']]"
[]
"[['fastText', 'for', '5 epochs'], ['5 epochs', 'with', 'learning rate'], ['learning rate', 'selected on', 'validation set'], ['validation set', 'from', '{ 0.05 , 0.1 , 0.25 , 0.5 }']]"
"[['bigram information', 'improves', 'performance'], ['performance', 'by', '1 - 4 %']]"
"[['our accuracy', 'slightly better than', 'char - CNN and char - CRNN'], ['our accuracy', 'bit worse than', 'VDCNN']]"
"[['accuracy', 'by using', 'more n-grams'], ['slightly', 'by using', 'more n-grams'], ['more n-grams', 'for example with', 'trigrams'], ['performance', 'on', 'Sogou'], ['Sogou', 'goes up to', '97.1 %']]"
"[['hyperparameters', 'on', 'validation set'], ['n-grams', 'up to', '5'], ['n-grams', 'leads to', 'best performance'], ['5', 'leads to', 'best performance']]"
[]
"[['frequency - based baseline', 'predicts', 'most frequent tag']]"
"[['Tagspace', 'is', 'tag prediction model'], ['Tagspace', 'based on', 'Wsabie model']]"
[]
"[['Both models', 'achieve', 'similar performance'], ['similar performance', 'with', 'small hidden layer'], ['Both models', 'adding', 'bigrams'], ['bigrams', 'gives us', 'significant boost'], ['significant boost', 'in', 'accuracy']]"
[]
[]
"[['weakly supervised learning', 'such as', 'unsupervised pre-training'], ['weakly supervised learning', 'such as', 'unsupervised data augmentation'], ['domain gap', 'in', 'XLU']]"
[]
"[['masked language model ( MLM ) pre-training', 'using', 'unlabeled target language corpora']]"
"[['unsupervised data augmentation ( UDA ) )', 'where', 'synthetic paraphrases'], ['synthetic paraphrases', 'generated from', 'unlabeled corpus'], ['model', 'trained on', 'label consistency loss']]"
"[['pre-trained model', 'with', 'source - domain training set']]"
[]
"[['unlabeled data', 'from', 'target domain'], ['unlabeled data', 'by optimizing', 'UDA loss function']]"
"[['Self - training', 'based on', 'UDA model ( UDA + Self )']]"
"[['better one', 'as', 'teacher model']]"
"[['new XLM student', 'using', 'only unlabeled data U tgt'], ['only unlabeled data U tgt', 'in', 'target domain']]"
"[['Ft ( XLM ) results', 'without the help of', 'unlabeled data'], ['unlabeled data', 'from', 'target domain'], ['substantial gap', 'between', 'model performance'], ['substantial gap', 'between', 'monolingual baselines'], ['substantial gap', 'when using', 'state - of - the - art pre-trained cross -lingual representations']]"
"[['UDA algorithm and MLM pre-training', 'offer', 'significant improvements'], ['significant improvements', 'by utilizing', 'unlabeled data']]"
"[['sentiment classification task', 'where', 'unlabeled data size'], ['unlabeled data size', 'is', 'larger'], ['Ft ( XLM ft ) model usnig MLM pre-training', 'consistently provides', 'larger improvements'], ['larger improvements', 'compared with', 'UDA method']]"
"[['MLM method', 'is', 'relatively more resource intensive'], ['MLM method', 'takes', 'longer']]"
"[['MLdoc dataset', 'when', 'size'], ['size', 'of', 'unlabeled samples'], ['size', 'is', 'limited'], ['unlabeled samples', 'is', 'limited'], ['UDA method', 'is', 'more helpful']]"
"[['sentiment classification task', 'observe', 'self - training technique'], ['consistently improves', 'over', 'teacher model']]"
"[['best results', 'in', 'XLM and XLM ft based classifiers']]"
"[['self - training', 'achieves', 'best results']]"
"[['monolingual fine - tune baseline', 'completely close', 'performance gap'], ['performance gap', 'by utilizing', 'unlabeled data'], ['unlabeled data', 'in', 'target language']]"
"[['our framework', 'reaches', 'new state - of - the - art results'], ['our framework', 'improving over', 'vanilla XLM baselines'], ['new state - of - the - art results', 'improving over', 'vanilla XLM baselines'], ['vanilla XLM baselines', 'by', '44 %']]"
"[['unlabeled data', 'from', 'other domains'], ['unlabeled data', 'does not offer', 'consistent improvement'], ['other domains', 'does not offer', 'consistent improvement'], ['consistent improvement', 'provide', 'additional value'], ['additional value', 'in', 'isolated cases']]"
[]
[]
"[['Neural Attentive Bagof - Entities ( NABoE ) model', 'is', 'neural network model'], ['neural network model', 'addresses', 'text classification problem'], ['text classification problem', 'by modeling', 'semantics'], ['semantics', 'in', 'target documents'], ['semantics', 'using', 'entities'], ['entities', 'in', 'KB']]"
"[['each entity name', 'in', 'document'], ['entities', 'represents', 'document'], ['document', 'using', 'weighted average'], ['weighted average', 'of', 'embeddings'], ['embeddings', 'of', 'entities']]"
"[['weights', 'computed using', 'novel neural attention mechanism'], ['novel neural attention mechanism', 'enables', 'model'], ['model', 'to focus on', 'small subset'], ['small subset', 'of', 'entities'], ['entities', 'that are', 'less ambiguous'], ['less ambiguous', 'in', 'meaning'], ['novel neural attention mechanism', 'more relevant to', 'document'], ['model', 'more relevant to', 'document']]"
"[['attention mechanism', 'designed to compute', 'weights'], ['weights', 'by jointly addressing', 'entity linking and entity salience detection tasks']]"
"[['mini-batch SGD', 'with', 'learning rate'], ['learning rate', 'controlled by', 'Adam'], ['mini-batch size', 'set to', '32']]"
"[['size', 'of', 'embeddings'], ['size', 'of', 'embeddings'], ['embeddings', 'of', 'words and entities'], ['size', 'set to', 'd = 300'], ['words and entities', 'set to', 'd = 300']]"
[]
[]
"[['logistic regression classifier', 'with', 'conventional binary BoW features']]"
[]
"[['bidirectional RNN', 'with', 'gated recurrent units ( GRU )']]"
"[['NTEE', 'is', 'state - of - the - art model'], ['state - of - the - art model', 'uses', 'multi - layer perceptron classifier'], ['multi - layer perceptron classifier', 'with', 'features'], ['multi - layer perceptron classifier', 'trained on', 'Wikipedia'], ['words and entities', 'trained on', 'Wikipedia'], ['Wikipedia', 'using', 'neural network model']]"
[]
"[['our models', 'yielded', 'enhanced over all performance'], ['enhanced over all performance', 'on', 'both datasets']]"
"[['NABoE - full model', 'outperformed', 'all baseline models'], ['all baseline models', 'in terms of', 'both measures'], ['both measures', 'on', 'both datasets']]"
"[['NABoE-entity model', 'outperformed', 'all the baseline models'], ['all the baseline models', 'in terms of', 'both measures'], ['both measures', 'on', '20NG dataset'], ['F 1 score', 'on', 'R8 dataset']]"
[]
[]
"[['inherently jointed', 'to construct', 'word embeddings']]"
"[['task information', 'regularize', 'distribution'], ['distribution', 'of', 'salient words'], ['salient words', 'to have', 'clear classification boundary'], ['task information', 'adjust', 'distribution'], ['distribution', 'of', 'other words'], ['other words', 'in', 'embedding space']]"
"[['BOW method', 'employed as', 'basic baseline']]"
"[['each document', 'as', 'bag of words'], ['weighting scheme', 'is', 'TFIDF']]"
"[['Word2 Vec method', 'is', 'neural network language method'], ['neural network language method', 'which learns', 'word embeddings'], ['word embeddings', 'by maximizing', 'conditional probability'], ['conditional probability', 'leveraging', 'contextual information']]"
"[['Our method', 'performs', 'better'], ['better', 'than', 'other methods']]"
"[['ToWE - SG method', 'significantly outperforms', 'other baselines'], ['other baselines', 'on', '20 New s Group'], ['other baselines', 'on', '5 Abstract s Group'], ['other baselines', 'on', 'MR']]"
"[['word embedding methods', 'outperform', 'basic bag - of - words methods'], ['basic bag - of - words methods', 'in', 'most cases'], ['basic bag - of - words methods', 'indicating', 'superiority'], ['most cases', 'indicating', 'superiority']]"
"[['Our method', 'achieves', 'better performance'], ['better performance', 'over', 'Retrofit method']]"
"[['Our method', 'outperforms', 'TWE method'], ['TWE method', 'on', 'document - level and sentence - level tasks']]"
[]
"[['new graph neural networkbased method', 'for', 'text classification']]"
"[['single large graph', 'from', 'entire corpus'], ['entire corpus', 'contains', 'words and documents'], ['words and documents', 'as', 'nodes']]"
"[['graph', 'with', 'Graph Convolutional Network ( GCN )'], ['graph', 'with', 'simple and effective graph neural network'], ['simple and effective graph neural network', 'captures', 'high order neighborhoods information']]"
"[['edge', 'between', 'two word nodes'], ['edge', 'between', 'word node and document node'], ['word node and document node', 'built using', 'word frequency'], ['word node and document node', 'built using', ""word 's document frequency""]]"
"[['text classification problem', 'into', 'anode classification problem']]"
[]
[]
[]
"[['bag - of - words model', 'with', 'term frequencyinverse document frequency weighting']]"
"[['Logistic Regression', 'used as', 'classifier']]"
[]
"[['CNN -rand', 'uses', 'randomly initialized word embeddings'], ['CNN -rand', 'uses', 'CNN - non- static'], ['CNN - non- static', 'uses', 'pre-trained word embeddings'], ['CNN - non- static', 'uses', 'pre-trained word embeddings']]"
"[['last hidden state', 'as', 'representation'], ['representation', 'of', 'whole text']]"
[]
"[['orders of words', 'in', 'text']]"
"[['Logistic Regression', 'as', 'classifier']]"
"[['paragraph vector model', 'considers', 'word order']]"
"[['Logistic Regression', 'as', 'classifier']]"
"[['predictive text embedding', 'firstly learns', 'word embedding'], ['word embedding', 'based on', 'heterogeneous text network'], ['heterogeneous text network', 'containing', 'words , documents and labels'], ['words , documents and labels', 'as', 'nodes'], ['predictive text embedding', 'averages', 'word embeddings'], ['word embeddings', 'as', 'document embeddings'], ['document embeddings', 'for', 'text classification']]"
"[['average of word / n- grams embeddings', 'as', 'document embeddings'], ['document embeddings', 'into', 'linear classifier']]"
"[['SWEM', 'employs', 'simple pooling strategies'], ['simple word embedding models', 'employs', 'simple pooling strategies'], ['simple pooling strategies', 'operated over', 'word embeddings']]"
"[['label - embedding attentive models', 'embeds', 'words and labels'], ['label - embedding attentive models', 'in', 'same joint space'], ['words and labels', 'in', 'same joint space'], ['same joint space', 'for', 'text classification']]"
[]
"[['graph CNN model', 'operates', 'convolutions'], ['convolutions', 'over', 'word embedding similarity graphs']]"
"[['Graph - CNN - S', 'using', 'Spline filter']]"
"[['Graph - CNN - F', 'same as', 'Graph - CNN - C'], ['Graph - CNN - F', 'using', 'Fourier filter']]"
"[['Text GCN', 'set', 'embedding size'], ['embedding size', 'of', 'first convolution layer'], ['first convolution layer', 'as', '200'], ['embedding size', 'set', 'window size'], ['window size', 'as', '20']]"
"[['other parameters', 'set', 'learning rate'], ['learning rate', 'as', '0.02']]"
"[['baseline models', 'using', 'pre-trained word embeddings'], ['pre-trained word embeddings', 'used', '300 dimensional Glo Ve word embeddings']]"
"[['Text GCN', 'performs', 'best']]"
"[['pre-trained Glo Ve word embeddings', 'provided', 'CNN'], ['CNN', 'performs', 'much better'], ['much better', 'especially on', 'Ohsumed and 20 NG']]"
"[['LSTM - based models', 'rely on', 'pre-trained word embeddings'], ['LSTM - based models', 'perform', 'better'], ['better', 'when', 'documents'], ['documents', 'are', 'shorter']]"
"[['PV - DBOW', 'achieves', 'comparable results'], ['comparable results', 'to', 'strong baselines'], ['strong baselines', 'on', '20 NG and Ohsumed']]"
"[['PV - DM', 'performs', 'worse'], ['worse', 'than', 'PV - DBOW']]"
"[['Graph - CNN models', 'show', 'competitive performances']]"
[]
"[['deep pyramid CNN ( DPCNN )', 'as', 'computation time per layer']]"
"[['discrete text', 'to', 'continuous representation'], ['DPCNN architecture', 'alternates', 'convolution block'], ['DPCNN architecture', 'alternates', 'downsampling layer'], ['downsampling layer', 'over and over', '1'], ['1', 'leading to', 'deep network'], ['deep network', 'in which', 'internal data size']]"
"[['network depth', 'treated as', 'meta-parameter']]"
"[['computational complexity', 'of', 'network']]"
"[['DPCNN', 'with', '15 weight layers'], ['15 weight layers', 'outperforms', 'previous best models'], ['previous best models', 'on', 'six benchmark datasets'], ['six benchmark datasets', 'for', 'sentiment classification']]"
"[['first layer', 'performs', 'text region embedding'], ['commonly used word embedding', 'to', 'embedding'], ['embedding', 'of', 'text regions']]"
"[['pooling layers', 'with', 'stride 2'], ['stride 2', 'for', 'downsampling']]"
"[['internal data', 'for', 'each document'], ['each document', 'into', 'one vector']]"
"[['max pooling', 'for', 'all pooling layers']]"
[]
[]
"[['DPCNN', 'outperforms', 'all of the previous results']]"
[]
"[['DPCNN performances', 'with', '100 - dim unsupervised embed - dings'], ['100 - dim unsupervised embed - dings', 'as good as', '300 - dim unsupervised embeddings']]"
"[['ShallowCNN', 'rivals', 'DPCNN'], ['best linear model', 'moved up', 'worst performer'], ['worst performer', 'to', 'third best performer']]"
[]
[]
"[['general framework', 'of', 'region embedding + pooling'], ['more sophisticated region embedding', 'via', 'Long Short - Term Memory ( LSTM )']]"
"[['learning', 'of', 'dependencies'], ['dependencies', 'over', 'larger time lags']]"
"[['text regions', 'of', 'variable ( and possibly large ) sizes']]"
"[['elimination', 'of', 'word embedding layer']]"
[]
[]
"[['Optimization', 'done with', 'SGD'], ['Optimization', 'done with', 'optionally'], ['SGD', 'with', 'mini-batch size'], ['SGD', 'with', 'optionally'], ['50 or 100', 'with', 'momentum'], ['rmsprop', 'for', 'acceleration']]"
"[['our one - hot bidirectional LSTM with pooling ( oh - 2 LSTMp )', 'outperforms', 'word - vector LSTM ( wv - LSTM )'], ['word - vector LSTM ( wv - LSTM )', 'on', 'all the datasets']]"
[]
"[['oh - 2 LSTMp', 'outperforms', 'CNN']]"
"[['n-gram SVM', 'no better than', 'bag - of - word SVM'], ['bow - CNN', 'outperforms', 'seq-CNN']]"
"[['one - hot CNN', 'works', 'surprising well']]"
"[['previous best performance', 'on', '20NG'], ['20NG', 'is', '15.3'], ['pre-training wv - LSTM', 'of', '1024 units'], ['DL15', 'obtained by', 'pre-training wv - LSTM'], ['pre-training wv - LSTM', 'of', '1024 units'], ['1024 units', 'with', 'labeled training data']]"
"[['oh - 2 LSTMp', 'achieved', '13.32']]"
[]
"[['supervised wv - LSTM', 'underperformed', 'models'], ['models', 'with', 'region tv-embeddings']]"
"[['wv - 2 LSTMp', 'using', 'Google News vectors'], ['Google News vectors', 'performed', 'relatively poorly']]"
"[['performance', 'of', 'one - hot CNN'], ['one - hot CNN', 'with', 'one 200 - dim CNN tv-embedding'], ['one 200 - dim CNN tv-embedding', 'comparable with', 'our LSTM']]"
"[['LSTM', 'rivals or outperforms', 'CNN'], ['CNN', 'on', 'IMDB / Elec'], ['underperforms', 'on', 'RCV1']]"
"[['dimensionality', 'of', 'LSTM tvembeddings'], ['LSTM tvembeddings', 'from', '100 to 300'], ['100 to 300', 'on', 'RCV1'], ['LSTM tvembeddings', 'does not reach', '7.97'], ['7.97', 'of', 'CNN']]"
[]
[]
[]
[]
"[['input', 'is', 'discrete']]"
"[['perturbation', 'on', 'continuous word embeddings'], ['continuous word embeddings', 'instead of', 'discrete word inputs']]"
"[['text classifier', 'by stabilizing', 'classification function']]"
"[['TensorFlow', 'on', 'GPUs']]"
[]
[]
"[['gradient clipping', 'with', 'norm'], ['norm', 'set to', '1.0'], ['1.0', 'on', 'all the parameters'], ['all the parameters', 'except', 'word embeddings']]"
"[['regularization', 'of', 'recurrent language model'], ['regularization', 'applied', 'dropout'], ['recurrent language model', 'applied', 'dropout'], ['dropout', 'on', 'word embedding layer'], ['word embedding layer', 'with', '0.5 dropout rate']]"
"[['512 hidden units LSTM', 'For', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '512 hidden units LSTM'], ['512 hidden units LSTM', 'for', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '256 dimensional word embeddings']]"
"[['cosine distance', 'on', 'adversarial and virtual adversarial training ( 0.159-0.331 )'], ['cosine distance', 'were', 'much smaller'], ['adversarial and virtual adversarial training ( 0.159-0.331 )', 'were', 'much smaller']]"
"[['test performance', 'on', 'Elec and RCV1 datasets']]"
"[['test performance', 'on', 'baseline method'], ['state of the art performance', 'on', 'both datasets'], ['state of the art performance', 'on', 'both datasets']]"
"[['Our unidirectional LSTM model', 'improves on', 'state of the art method'], ['Our unidirectional LSTM model', 'improves on', 'our method'], ['our method', 'with', 'bidirectional LSTM'], ['results', 'on', 'RCV1']]"
"[['test performance', 'on', 'Rotten Tomatoes dataset']]"
"[['Adversarial training', 'able to', 'improve'], ['improve', 'over', 'baseline method'], ['Adversarial training', 'with', 'adversarial and virtual adversarial cost'], ['adversarial and virtual adversarial cost', 'achieved', 'almost the same performance'], ['almost the same performance', 'as', 'current state of the art method']]"
"[['test performance', 'of', 'only virtual adversarial training'], ['test performance', 'was', 'worse'], ['only virtual adversarial training', 'was', 'worse'], ['test performance', 'worse than', 'baseline'], ['only virtual adversarial training', 'worse than', 'baseline'], ['worse', 'than', 'baseline']]"
[]
"[['new architecture', 'short for', 'C - LSTM'], ['new architecture', 'by combining', 'CNN and LSTM'], ['CNN and LSTM', 'to model', 'sentences']]"
"[['simple end - to - end , unified architecture', 'by feeding', 'output'], ['output', 'of', 'one - layer CNN'], ['one - layer CNN', 'into', 'LSTM']]"
"[['CNN', 'constructed on top of', 'pre-trained word vectors'], ['pre-trained word vectors', 'from', 'massive unlabeled text data'], ['massive unlabeled text data', 'to learn', 'higher - level representions'], ['higher - level representions', 'of', 'n-grams']]"
"[['sequential correlations', 'from', 'higher - level suqence representations'], ['feature maps', 'of', 'CNN'], ['feature maps', 'organized as', 'sequential window features'], ['CNN', 'organized as', 'sequential window features'], ['sequential window features', 'to serve as', 'input'], ['input', 'of', 'LSTM']]"
"[['sequence - based input', 'relying on', 'syntactic parse trees'], ['syntactic parse trees', 'before feeding in', 'neural network']]"
"[['our model', 'based on', 'Theano'], ['our model', 'based on', 'python library'], ['python library', 'supports', 'efficient symbolic differentiation'], ['our model', 'transparent use of', 'GPU']]"
"[['model', 'on', 'GPU']]"
"[['one convolutional layer and one LSTM layer', 'for', 'both tasks']]"
"[['number of filters', 'set to be', '300'], ['memory dimension', 'set to be', '300']]"
"[['word vector layer and the LSTM layer', 'dropped outwith', 'probability'], ['probability', 'of', '0.5']]"
"[['L2 regularization', 'with', 'factor'], ['factor', 'of', '0.001'], ['0.001', 'to', 'weights'], ['weights', 'in', 'softmax layer'], ['softmax layer', 'for', 'both tasks']]"
[]
[]
"[['fourth best published result', 'for', '5 - class classification task']]"
"[['binary classification task', 'achieve', 'comparable results'], ['comparable results', 'with respect to', 'state - of - the - art ones']]"
[]
[]
"[['state - of - the - art SVM', 'depends on', 'highly engineered features']]"
"[['single convolutional layer', 'with', 'filter length 3'], ['filter length 3', 'always outperforms', 'other cases']]"
"[['single convolutional layer', 'with', 'filter length 3'], ['filter length 3', 'performs', 'best'], ['best', 'among', 'all filter configurations']]"
"[['multiple convolutional layers', 'shown that', 'filter configurations'], ['filter configurations', 'with', 'filter length 3'], ['filter configurations', 'performs', 'better'], ['better', 'without', 'tri-gram filters']]"
[]
[]
"[['deep architectures', 'of', 'many convolutional layers']]"
"[['dictionary', 'consists of', 'following characters'], ['following characters', 'plus', 'special padding'], ['abcdefghijklmnopqrstuvwxyz0123456', 'plus', 'special padding']]"
"[['input text', 'padded to', 'fixed size'], ['fixed size', 'of', '1014']]"
"[['character embedding', 'of', 'size']]"
"[['Training', 'performed with', 'SGD'], ['SGD', 'using', 'mini-batch'], ['SGD', 'using', 'momentum'], ['mini-batch', 'of size', '128'], ['initial learning rate', 'of size', '0.01'], ['initial learning rate', 'of', '0.01'], ['momentum', 'of', '0.9'], ['momentum', 'of', '0.9']]"
"[['implementation', 'done using', 'Torch'], ['implementation', 'done using', 'Torch 7']]"
[]
"[['temporal batch norm', 'without', 'dropout']]"
"[['deep architecture', 'works', 'well'], ['well', 'on', 'big data sets'], ['well', 'even for', 'small depths'], ['big data sets', 'even for', 'small depths']]"
[]
"[['most important decrease', 'in', 'classification error'], ['most important decrease', 'observed on', 'largest data set Amazon Full'], ['classification error', 'observed on', 'largest data set Amazon Full']]"
"[['temporal max - pooling', 'works', 'best'], ['best', 'on', 'all data sets']]"
[]
"[['text', 'as', 'kind of raw signal'], ['kind of raw signal', 'at', 'character level']]"
[]
[]
"[['bag - of - words model', 'constructed by selecting', '50,000 most frequent words'], ['50,000 most frequent words', 'from', 'training subset']]"
[]
"[['bag - of - ngrams models', 'constructed by selecting', '500,000 most frequent n-grams ( up to 5 - grams )'], ['500,000 most frequent n-grams ( up to 5 - grams )', 'from', 'training subset'], ['training subset', 'for', 'each dataset']]"
"[['Bag - of - means', 'on', 'word embedding']]"
"[['experimental model', 'uses', 'k-means'], ['k-means', 'on', 'word2vec'], ['word2vec', 'learnt from', 'training subset'], ['training subset', 'of', 'each dataset'], ['learnt means', 'as', 'representatives'], ['representatives', 'of', 'clustered words']]"
[]
[]
[]
"[['character - level ConvNets', 'work for', 'text classification'], ['text classification', 'need for', 'words']]"
"[['Traditional methods', 'like', 'n-grams TFIDF'], ['n-grams TFIDF', 'remain', 'strong candidates'], ['strong candidates', 'for', 'dataset'], ['of size', 'up to', 'several hundreds of thousands'], ['character - level ConvNets', 'start to do', 'better']]"
"[['Conv Nets', 'work', 'well'], ['well', 'for', 'user - generated data']]"
"[['Choice of alphabet', 'makes', 'difference']]"
[]
[]
"[['Bidirectional Long Short - Term Memory Networks with Two - Dimensional Max Pooling ( BLSTM - 2DPooling )', 'to capture', 'features'], ['features', 'on', 'time - step dimension'], ['features', 'on', 'feature vector dimension']]"
"[['Bidirectional Long Short - Term Memory Networks ( BLSTM )', 'to transform', 'text'], ['text', 'into', 'vectors']]"
"[['2D max pooling operation', 'to obtain', 'fixed - length vector']]"
"[['2D convolution ( BLSTM - 2DCNN )', 'to capture', 'more meaningful features'], ['more meaningful features', 'to represent', 'input text']]"
"[['dimension', 'of', 'word embeddings'], ['hidden units', 'of', 'LSTM'], ['dimension', 'is', '300'], ['word embeddings', 'is', '300'], ['LSTM', 'is', '300'], ['hidden units', 'of', 'LSTM'], ['hidden units', 'is', '300'], ['LSTM', 'is', '300']]"
"[['100 convolutional filters', 'for', 'window sizes'], ['window sizes', 'of', '( 3 , 3 )'], ['2D pooling size', 'of', '( 2 , 2 )'], ['2D pooling size', 'of', '( 2 , 2 )']]"
"[['mini-batch size', 'as', '10'], ['learning rate', 'of', 'AdaDelta'], ['learning rate', 'as', 'default value'], ['AdaDelta', 'as', 'default value']]"
"[['0.5', 'For', 'word embeddings'], ['0.2', 'For', 'BLSTM layer'], ['regularization', 'employ', 'Dropout operation'], ['Dropout operation', 'with', 'dropout rate'], ['dropout rate', 'of', '0.5'], ['0.5', 'for', 'word embeddings'], ['0.2', 'for', 'BLSTM layer'], ['0.2', 'for', '0.4'], ['0.4', 'for', 'penultimate layer'], ['l 2 penalty', 'with', 'coefficient 10 ? 5'], ['coefficient 10 ? 5', 'over', 'parameters']]"
[]
"[['BLSTM - 2DCNN model', 'achieves', 'excellent performance'], ['excellent performance', 'on', '4 out of 6 tasks']]"
"[['52.4 % and 89.5 % test accuracies', 'on', 'SST - 1 and SST - 2']]"
"[['BLSTM - 2DPooling', 'performs', 'worse'], ['worse', 'than', 'state - of - the - art models']]"
"[['BLSTM - CNN', 'beats', 'all baselines'], ['all baselines', 'on', 'SST - 1 , SST - 2 , and TREC datasets']]"
"[['BLSTM - 2DCNN', 'gets', 'second higher accuracies']]"
"[['BLSTM - 2DCNN', 'achieves', 'comparable result']]"
"[['external language - specific features', 'such as', 'dependency parse trees']]"
"[['BLSTM - 2DCNN', 'on', 'five datasets'], ['outperforms', 'on', 'five datasets']]"
[]
[]
"[['simple bi-directional LSTM ( BiLSTM ) architecture', 'with', 'appropriate regularization'], ['appropriate regularization', 'yields', 'accuracy and F 1'], ['accuracy and F 1', 'competitive or exceed', 'state of the art'], ['state of the art', 'on', 'four standard benchmark datasets']]"
"[['large - scale reproducibility study', 'involving', 'HAN'], ['large - scale reproducibility study', 'involving', 'XML - CNN'], ['large - scale reproducibility study', 'involving', 'KimCNN'], ['large - scale reproducibility study', 'involving', 'SGM']]"
"[['neural approaches', 'to', 'logistic regression ( LR )'], ['neural approaches', 'to', 'support vector machines ( SVMs )']]"
"[['LR model', 'trained using', 'one - vs - rest multi-label objective'], ['SVM', 'trained with', 'linear kernel']]"
"[['Nvidia GTX 1080 and RTX 2080 Ti GPUs', 'with', 'PyTorch 0.4.1'], ['PyTorch 0.4.1', 'as', 'backend framework']]"
"[['Scikitlearn 0.19.2', 'for computing', 'tf - idf vectors'], ['Scikitlearn 0.19.2', 'implementing', 'LR and SVMs']]"
"[['our simple LSTM reg model', 'achieves', 'state of the art'], ['state of the art', 'on', 'Reuters and IMDB'], ['state of the art', 'establishing', 'mean scores'], ['mean scores', 'of', '87.0 and 52.8'], ['87.0 and 52.8', 'for', 'F 1 score and accuracy'], ['F 1 score and accuracy', 'on', 'test sets'], ['test sets', 'of', 'Reuters and IMDB']]"
"[['LSTM reg', 'consistently improves upon', 'performance'], ['performance', 'of', 'LSTM base'], ['LSTM base', 'across', 'all of the tasks'], ['increases', 'of', '1.5 and 0.5 points'], ['1.5 and 0.5 points', 'for', 'F 1 score and accuracy']]"
"[['state - of - theart test F 1 scores', 'on', 'AAPD']]"
"[['non-neural LR and SVM baselines', 'perform', 'remarkably well']]"
"[['SVM', 'beats', 'many neural baselines']]"
"[['SVM', 'ties or beats', 'other models']]"
"[['LR baseline', 'better suited for', 'single - label datasets'], ['LR baseline', 'achieves', 'better accuracy']]"
[]
"[['mLSTM and Transformer language models', 'on', 'large 40 GB text dataset'], ['multidimensional emotion classification', 'based on', 'Plutchik wheel of emotions']]"
[]
[]
"[['Transformer', 'gets', 'close'], ['Transformer', 'does not exceed', 'state of the art'], ['state of the art', 'on', 'SST dataset'], ['Watson and Google Sentiment APIs', 'on', 'company tweets'], ['state of the art', 'exceeds', 'mL - STM and ELMo baseline'], ['Watson and Google Sentiment APIs', 'on', 'company tweets']]"
[]
"[['outperform', 'on', 'every emotion category'], ['Watson', 'on', 'every emotion category']]"
[]
"[['Our model', 'achieved', 'top macro-averaged F1 score'], ['top macro-averaged F1 score', 'among', 'all submission'], ['top macro-averaged F1 score', 'with', 'competitive but lower scores'], ['competitive but lower scores', 'for', 'micro -average F1']]"
"[['deep learning architectures', 'of', 'Transformer and m LSTM'], ['Transformer', 'outperforms', 'm LSTM'], ['m LSTM', 'across', 'Plutchik categories']]"
"[['Our models', 'gets', 'lower F 1 scores'], ['lower F 1 scores', 'on', 'company tweets dataset'], ['lower F 1 scores', 'than on', 'equivalent Se -m Eval categories']]"
[]
"[['modifications', 'on', 'network'], ['modifications', 'reducing', 'number of parameters'], ['network', 'reducing', 'number of parameters']]"
[]
"[['text classification model', 'requires', 'significantly fewer parameters'], ['significantly fewer parameters', 'compared to', 'stateof - the - art CNNs']]"
"[['network architecture', 'implemented in', 'PyTorch']]"
"[['SVDCNN experimental settings', 'using', 'same dictionary'], ['SVDCNN experimental settings', 'using', 'same embedding size'], ['same embedding size', 'of', '16']]"
"[['training', 'performed with', 'SGD'], ['SGD', 'utilizing', 'size batch'], ['size batch', 'of', '64'], ['size batch', 'with', 'maximum of 100 epochs'], ['64', 'with', 'maximum of 100 epochs']]"
"[['initial learning rate', 'of', '0.01'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.001'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.001'], ['weight decay', 'of', '0.001']]"
[]
"[['network reduction', 'obtained by', 'GAP'], ['GAP', 'is', 'even more representative']]"
"[['dataset', 'with', 'four target classes'], ['SVDCNN', 'with', 'VDCNN'], ['SVDCNN', 'with', 'VDCNN'], ['number of parameters', 'of', 'FC layers'], ['12.59 to 0.02 million parameters', 'representing', 'reduction'], ['reduction', 'of', '99.84 %']]"
"[['11.36 million', 'of', 'FC parameters']]"
"[['VDCNN', 'with', 'same depth'], ['same depth', 'occupies', '64. 16 MB'], ['64. 16 MB', 'of', 'storage']]"
[]
"[['performance difference', 'between', 'VDCNN and SVDCNN models'], ['performance difference', 'varies between', '0.4 and 1.3 %'], ['VDCNN and SVDCNN models', 'varies between', '0.4 and 1.3 %']]"
[]
"[['Label - Embedding Attentive Model ( LEAM )', 'to improve', 'text classification']]"
"[['proposed LEAM', 'implemented by', 'jointly embedding'], ['word and label', 'in', 'same latent space'], ['text representations', 'constructed directly using', 'text - label compatibility']]"
"[['Label - attentive text representation', 'is', 'informative'], ['informative', 'for', 'downstream classification task']]"
"[['LEAM learning procedure', 'involves', 'series of basic algebraic operations'], ['LEAM learning procedure', 'retains', 'interpretability'], ['interpretability', 'of', 'simple models']]"
"[['300 - dimensional Glo Ve word embeddings', 'as', 'initialization'], ['initialization', 'for', 'word embeddings and label embeddings'], ['word embeddings and label embeddings', 'in', 'our model']]"
"[['Out - Of - Vocabulary ( OOV ) words', 'initialized from', 'uniform distribution'], ['uniform distribution', 'with', 'range [ ? 0.01 , 0.01 ]']]"
"[['final classifier', 'implemented as', 'MLP layer'], ['MLP layer', 'followed by', 'sigmoid or softmax function'], ['sigmoid or softmax function', 'depending on', 'specific task']]"
"[['initial learning rate', 'of', '0.001'], ['minibatch size', 'of', '100']]"
"[['Dropout regularization', 'employed on', 'final MLP layer'], ['Dropout regularization', 'with', 'dropout rate 0.5'], ['final MLP layer', 'with', 'dropout rate 0.5']]"
[]
[]
"[['logistic regression model', 'with', 'bag - ofwords'], ['logistic regression model', 'with', 'single - layer 1 D convolutional network']]"
"[['multi-label classification of clinical text', 'including', 'Condensed Memory Networks ( C - MemNN )'], ['multi-label classification of clinical text', 'including', 'Attentive LSTM'], ['multi-label classification of clinical text', 'including', 'Convolutional Attention ( CAML )']]"
"[['LEAM', 'provides', 'best AUC score'], ['better F1 and P@5 values', 'than', 'all methods'], ['all methods', 'except', 'CNN']]"
"[['CNN', 'consistently outperforms', 'basic Bi - GRU architecture'], ['logistic regression baseline', 'performs', 'worse'], ['worse', 'than', 'all deep learning architectures']]"
[]
[]
"[['hierarchical classification', 'call', 'Hierarchical Deep Learning for Text classification ( HDLTex )']]"
"[['hierarchical document classification', 'call', 'Hierarchical Deep Learning for Text classification ( HDLTex )']]"
"[['HDLTex', 'combines', 'deep learning architectures'], ['deep learning architectures', 'to allow', 'over all and specialized learning']]"
[]
"[['processing', 'done on', 'Xeon E5 ? 2640 ( 2.6 GHz )'], ['processing', 'done on', 'GPU cards'], ['processing', 'done on', 'N vidia Tesla K20c'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '32 cores'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '64GB memory'], ['GPU cards', 'were', 'N vidia Quadro K620'], ['GPU cards', 'were', 'N vidia Tesla K20c']]"
"[['Python', 'using', 'Compute Unified Device Architecture ( CUDA )'], ['Compute Unified Device Architecture ( CUDA )', 'is', 'parallel computing platform']]"
"[['Keras and Tensor Flow libraries', 'for creating', 'neural networks']]"
"[['stacking SVM', 'with', 'three deep learning approaches']]"
"[['RNN', 'outperforms', 'others'], ['others', 'for', 'all three W OS data sets']]"
"[['CNN', 'performs', 'secondbest'], ['secondbest', 'for', 'three data sets']]"
"[['term weighting', 'is', 'third'], ['third', 'for', 'first two sets'], ['third place', 'for', 'third data set'], ['multi-word approach', 'in', 'third place'], ['third place', 'for', 'third data set']]"
"[['nave Bayes', 'does', 'much worse'], ['much worse', 'than', 'other methods']]"
"[['HDLTex approaches', 'with', 'stacked , deep learning architectures'], ['stacked , deep learning architectures', 'provide', 'superior performance']]"
"[['combination RNN', 'For', 'first level of classification'], ['DNN', 'For', 'second level'], ['best accuracy', 'obtained by', 'combination RNN'], ['combination RNN', 'for', 'first level of classification'], ['combination RNN', 'for', 'DNN'], ['DNN', 'for', 'second level'], ['DNN', 'for', 'second level']]"
"[['accuracies', 'of', '94 %'], ['94 %', 'for', 'first level'], ['94 %', 'for', '86 %'], ['92 %', 'for', 'second level'], ['92 %', 'for', 'second level']]"
"[['RNN', 'For', 'level one'], ['RNN', 'For', 'level 2'], ['best scores', 'achieved by', 'RNN'], ['RNN', 'for', 'level one'], ['RNN', 'for', 'level 2'], ['RNN', 'for', 'level 2']]"
[]
"[['interaction mechanism', 'capable of incorporating', 'word - level matching signals'], ['word - level matching signals', 'for', 'text classification']]"
[]
"[['proposed framework', 'consists of', 'three main components']]"
"[['word - level encoder', 'projects', 'textual contents'], ['textual contents', 'into', 'word - level representations']]"
"[['interaction layer', 'calculates', 'matching scores'], ['matching scores', 'between', 'words and classes']]"
"[['matching scores', 'into', 'predictions'], ['predictions', 'over', 'each class']]"
[]
[]
"[['multi -class task', 'chose', 'region embedding'], ['region embedding', 'as', 'Encoder'], ['Encoder', 'in', 'EXAM']]"
"[['region size', 'is', '7'], ['embedding size', 'is', '128'], ['embedding size', 'is', '128']]"
"[['adam ( Kingma and Ba 2014 )', 'as', 'optimizer'], ['adam ( Kingma and Ba 2014 )', 'with', 'initial learning rate'], ['optimizer', 'with', 'initial learning rate'], ['batch size', 'set to', '16']]"
"[['aggregation MLP', 'set', 'size'], ['size', 'of', 'hidden layer'], ['size', 'as', '2 times'], ['size', 'as', '2 times interaction feature length'], ['hidden layer', 'as', '2 times'], ['hidden layer', 'as', '2 times interaction feature length']]"
"[['MXNet ( Chen et al. )', 'with', 'single NVIDIA TITAN Xp']]"
[]
"[['baselines', 'mainly in', 'three variants']]"
"[['models', 'based on', 'feature engineering']]"
[]
"[['Models', 'based on', 'feature engineering'], ['Models', 'get', 'worst results'], ['feature engineering', 'get', 'worst results'], ['worst results', 'on', 'all the five datasets'], ['worst results', 'compared to', 'other methods'], ['all the five datasets', 'compared to', 'other methods']]"
"[['Char - based models', 'get', 'highest over all scores'], ['highest over all scores', 'on', 'two Amazon datasets']]"
"[['Word - based baselines', 'exceed', 'other variants'], ['other variants', 'on', 'three datasets'], ['lose', 'on', 'two Amazon datasets']]"
"[['W.C Region Emb', 'performs', 'best']]"
"[['EXAM', 'achieves', 'best performance'], ['best performance', 'over', 'three datasets']]"
"[['EXAM', 'improves', 'best performance'], ['best performance', 'by', '1.1 %']]"
[]
"[['EXAM', 'by', 'MXNet']]"
"[['matrix', 'trained by', 'word2vec'], ['word2vec', 'to initialize', 'embedding layer'], ['embedding size', 'is', '256']]"
"[['GRU', 'as', 'Encoder'], ['each GRU Cell', 'has', '1,024 hidden states']]"
"[['accumulated MLP', 'has', '60 hidden units']]"
"[['Adam', 'to optimize', 'models'], ['models', 'on', 'one NVIDIA TITAN Xp'], ['one NVIDIA TITAN Xp', 'with', 'batch size'], ['batch size', 'of', '1000'], ['initial learning rate', 'is', '0.001']]"
"[['validation set', 'applied for', 'early - stopping'], ['early - stopping', 'to avoid', 'overfitting']]"
"[['Word - based models', 'better than', 'char - based models'], ['char - based models', 'in', 'Kanshan - Cup dataset']]"
"[['Our models', 'achieve', 'state - of - the - art performance'], ['state - of - the - art performance', 'over', 'two different datasets']]"
[]
[]
[]
"[['each language', 'define', 'train , development and test corpus']]"
[]
"[['classifiers', 'based on', 'MultiCCA embeddings'], ['classifiers', 'perform', 'very well'], ['MultiCCA embeddings', 'perform', 'very well'], ['very well', 'on', 'development corpus']]"
"[['system', 'trained on', 'English'], ['system', 'achieves', 'excellent results'], ['English', 'achieves', 'excellent results'], ['excellent results', 'transfered to', 'different languages']]"
"[['transfer accuracies', 'are', 'quite low'], ['quite low', 'when training', 'classifiers'], ['classifiers', 'on', 'other languages'], ['other languages', 'than', 'English']]"
"[['systems', 'using', 'multilingual sentence embeddings']]"
"[['German or French', 'leads to', 'better transfer performance'], ['better transfer performance', 'training on', 'English']]"
"[['Crosslingual transfer', 'between', 'very different languages'], ['very different languages', 'like', 'Chinese and Russian'], ['Crosslingual transfer', 'achieves', 'remarkable results']]"
[]
"[['important improvement', 'for', 'all languages'], ['important improvement', 'in comparison to', 'zero - shot or targeted transfer learning'], ['all languages', 'in comparison to', 'zero - shot or targeted transfer learning']]"
[]
"[['positioninvariance', 'into', 'RNN'], ['novel model', 'named', 'Disconnected Recurrent Neural Network ( DRNN )']]"
"[['position - invariance', 'utilize', 'max pooling'], ['max pooling', 'to extract', 'important information']]"
"[['special 1D CNN', 'where', 'convolution kernels'], ['convolution kernels', 'replaced with', 'recurrent units']]"
"[['300D Glo Ve 840B vectors', 'as', 'pre-trained word embeddings']]"
"[['Adadelta ( Zeiler , 2012 )', 'to optimize', 'all the trainable parameters']]"
"[['hyperparameter', 'of', 'Adadelta']]"
"[['gradient explosion problem', 'apply', 'gradient norm clipping']]"
"[['batch size', 'set to', '128'], ['all the dimensions', 'of', 'input vectors and hidden'], ['input vectors and hidden', 'shows', 'our proposed model'], ['all the other models', 'in', '7 datasets']]"
"[['very deep CNN ( VDCNN )', 'performs', 'well'], ['well', 'in', 'large datasets']]"
"[['our model', 'achieves', '10 - 50 % relative error reduction'], ['10 - 50 % relative error reduction', 'compared with', 'char - CRNN']]"
"[['DRNN', 'performs', 'far better'], ['far better', 'than', 'CNN']]"
"[['Our model DRNN', 'achieves', 'much better performance'], ['much better performance', 'than', 'GRU and LSTM']]"
[]
[]
[]
"[['iterative routing process', 'to decide', 'credit attribution'], ['credit attribution', 'between', 'nodes'], ['credit attribution', 'from', 'lower and higher layers']]"
"[['Three strategies', 'to stabilize', 'dynamic routing process'], ['dynamic routing process', 'to alleviate', 'disturbance'], ['disturbance', 'of', 'some noise capsules'], ['"" background "" information', 'such as', 'stop words']]"
"[['300 - dimensional word2vec vectors', 'to initialize', 'embedding vectors']]"
"[['mini-batch', 'with', 'size'], ['50', 'for', ""AG 's news""], ['25', 'for', 'other datasets'], ['25', 'for', 'other datasets']]"
"[['Adam optimization algorithm', 'with', '1e - 3 learning rate'], ['1e - 3 learning rate', 'to train', 'model']]"
[]
[]
"[['capsule networks', 'achieve', 'best results'], ['best results', 'on', '4 out of 6 benchmarks'], ['best results', 'verifies', 'effectiveness'], ['4 out of 6 benchmarks', 'verifies', 'effectiveness'], ['effectiveness', 'of', 'capsule networks']]"
[]
"[['capability', 'of', 'capsule network'], ['capsule network', 'on', 'multi-label text classification'], ['multi-label text classification', 'by using', 'single - label samples'], ['single - label samples', 'as', 'training data']]"
"[['capsule networks', 'have', 'substantial and significant improvement'], ['substantial and significant improvement', 'in terms of', 'all four evaluation metrics'], ['all four evaluation metrics', 'over', 'strong baseline methods'], ['strong baseline methods', 'on', 'test sets'], ['test sets', 'in', 'Reuters - Full datasets']]"
"[['larger improvement', 'achieved on', 'Reuters - Multi - label dataset'], ['multi-label documents', 'in', 'test set']]"
"[['much stronger transferring capability', 'than', 'conventional deep neural networks']]"
"[['good results', 'on', 'Reuters - Full'], ['competitors', 'on', 'single - label documents'], ['good results', 'indicate', 'capsule network'], ['Reuters - Full', 'indicate', 'capsule network'], ['robust superiority', 'over', 'competitors'], ['competitors', 'on', 'single - label documents']]"
[]
"[['capsule networks', 'correctly recognize and cluster', 'important phrases'], ['important phrases', 'with respect to', 'text categories']]"
[]
[]
"[['local information', 'based on', 'words'], ['context window', 'around', 'global information'], ['global information', 'exploiting', 'document - level coherence']]"
"[['deep learning', 'to learn', 'basic features and their combinations']]"
[]
"[['Wikipedia ( Feb 2014 ) corpus', 'For', 'training'], ['entity embeddings only', 'use', 'Wikipedia ( Feb 2014 ) corpus'], ['Wikipedia ( Feb 2014 ) corpus', 'for', 'training']]"
"[['0 mean normal distribution', 'with', 'standard deviation 1']]"
"[['each entity vector', 'on', ""entity 's Wikipedia canonical description page""], [""entity 's Wikipedia canonical description page"", 'for', '400 iterations']]"
"[['Adagrad', 'with', 'learning rate'], ['learning rate', 'of', '0.3']]"
"[['embedding size d', '=', '300'], ['window size', 'of', '20'], ['20', 'for', 'hyperlinks']]"
"[['Training', 'takes', '20 hours'], ['20 hours', 'on', 'single TitanX GPU'], ['single TitanX GPU', 'with', '12 GB']]"
"[['Our local and global ED models', 'trained on', 'AIDA - train ( multiple epochs )'], ['AIDA - train ( multiple epochs )', 'validated on', 'AIDA - A']]"
"[['Adam', 'with', 'learning rate'], ['learning rate', 'of', '1e - 4'], ['1e - 4', 'until', 'validation accuracy'], ['validation accuracy', 'exceeds', '90 %'], ['validation accuracy', 'setting it to', '1e - 5'], ['90 %', 'setting it to', '1e - 5']]"
"[['regularize', 'use', 'early stopping'], ['early stopping', 'stop', 'learning'], ['learning', 'if', 'validation accuracy'], ['does not increase', 'after', '500 epochs']]"
"[['single GPU', 'takes', '2 ms'], ['single GPU', 'takes', '16 hours'], ['single GPU', 'on average', '2 ms'], ['2 ms', 'per', 'mention'], ['16 hours', 'for', '1250 epochs'], ['1250 epochs', 'over', 'AIDA - train']]"
"[['state of the art accuracy', 'on', 'AIDA'], ['AIDA', 'is', 'largest and hardest']]"
"[['accuracy', 'on', 'AIDA - B dataset'], ['gold entities', 'have', 'low frequency or mention prior']]"
"[['our method', 'performs', 'well'], ['well', 'in', 'harder cases']]"
[]
[]
"[['words and entities', 'for', 'named entity disambiguation ( NED )']]"
"[['NED', 'using', 'simple NED model'], ['simple NED model', 'based on', 'trained contextualized embeddings']]"
"[['new contextualized embedding model', 'for', 'words and entities'], ['words and entities', 'for', 'NED'], ['new contextualized embedding model', 'for', 'NED'], ['words and entities', 'for', 'NED']]"
[]
"[['sequence of words and entities', 'in', 'input text'], ['contextualized embedding', 'for', 'each word and entity']]"
[]
"[['model', 'using', 'texts and their entity annotations'], ['texts and their entity annotations', 'retrieved from', 'Wikipedia']]"
"[['our models', 'outperformed', 'all previously proposed models']]"
"[['pseudo entity annotations', 'boosted', 'accuracy'], ['accuracy', 'by', '0.3 %']]"
"[['new state - of - the - art results', 'on', 'four of the five datasets'], ['four of the five datasets', 'namely', 'MSNBC'], ['four of the five datasets', 'namely', 'AQUAINT'], ['four of the five datasets', 'namely', 'ACE2004'], ['four of the five datasets', 'namely', 'WNED - WIKI'], ['four of the five datasets', 'performed', 'competitive'], ['competitive', 'on', 'WNED - CLUEWEB dataset']]"
"[['pseudo entity annotations', 'improved', 'performance'], ['performance', 'on', 'AQUAINT and ACE2004 datasets']]"
[]
[]
[]
[]
"[['each token', 'assigned', 'representation'], ['representation', 'function of', 'entire input sentence']]"
"[['vectors', 'derived from', 'bidirectional LSTM'], ['bidirectional LSTM', 'trained with', 'coupled lan - guage model ( LM ) objective'], ['coupled lan - guage model ( LM ) objective', 'on', 'large text corpus']]"
[]
"[['ELMo representations', 'are', 'deep']]"
"[['linear combination of the vectors', 'stacked above', 'each input word'], ['vectors', 'stacked above', 'each input word'], ['each input word', 'for', 'each end task'], ['each input word', 'markedly improves', 'performance'], ['performance', 'over', 'top LSTM layer']]"
"[['intrinsic evaluations', 'show', 'higher - level LSTM states'], ['higher - level LSTM states', 'capture', 'context - dependent aspects'], ['context - dependent aspects', 'of', 'word meaning'], ['lowerlevel states', 'model', 'aspects']]"
[]
"[['ELMo', 'to', 'baseline model'], ['4.7 %', 'from', '81.1 % to 85.8 %'], ['24.9 % relative error reduction', 'over', 'baseline'], ['test set F 1', 'improving', 'overall single model state - of - the - art'], ['overall single model state - of - the - art', 'by', '1.4 %']]"
"[['increase', 'of', '4.7 %'], ['4.7 %', 'with', 'ELMo'], ['significantly larger', 'then', '1.8 % improvement'], ['1.8 % improvement', 'from adding', 'CoVe'], ['1.8 % improvement', 'to', 'baseline model'], ['CoVe', 'to', 'baseline model']]"
[]
"[['ELMo', 'to', 'ESIM model'], ['ELMo', 'improves', 'accuracy'], ['ESIM model', 'improves', 'accuracy'], ['accuracy', 'by', 'average of 0.7 %'], ['average of 0.7 %', 'across', 'five random seeds']]"
[]
"[['OntoNotes coreference annotations', 'from', 'CoNLL 2012 shared task'], ['OntoNotes coreference annotations', 'adding', 'ELMo'], ['ELMo', 'improved', 'average F 1'], ['average F 1', 'by', '3.2 %'], ['3.2 %', 'from', '67.2 to 70.4']]"
[]
"[['ELMo enhanced biLSTM - CRF', 'achieves', '92. 22 % F 1'], ['92. 22 % F 1', 'averaged over', 'five runs']]"
[]
"[['size', 'of', 'neural WSD models'], ['coverage', 'without', 'additional training data'], ['two different methods', 'without impacting', 'precision']]"
"[['WSD system', 'relies on', 'pre-trained BERT word vectors'], ['state of the art', 'on', 'all WSD evaluation tasks']]"
[]
"[['semantic relationships', 'between', 'senses'], ['senses', 'included in', 'WordNet'], ['senses', 'such as', 'hypernymy'], ['senses', 'such as', 'hyponymy'], ['senses', 'such as', 'meronymy'], ['senses', 'such as', 'antonymy'], ['WordNet', 'such as', 'hypernymy']]"
[]
"[['BERT', 'used', 'model'], ['model', 'named', 'bert - largecased'], ['bert - largecased', 'of', 'PyTorch implementation'], ['bert - largecased', 'consists of', 'vectors'], ['PyTorch implementation', 'consists of', 'vectors']]"
"[['Transformer encoder layers', 'used', 'same parameters'], ['same parameters', 'as', '"" base "" model'], ['6 layers', 'with', '8 attention heads'], ['6 layers', 'with', 'dropout'], ['hidden size', 'of', '2048'], ['dropout', 'of', '0.1']]"
"[['our systems', 'that use', 'sense vocabulary compression'], ['sense vocabulary compression', 'through', 'all relations'], ['all relations', 'obtain', 'scores'], ['overall equivalent', 'to', 'systems']]"
"[['Princeton WordNet Gloss Corpus', 'use of', 'BERT'], ['BERT', 'as', 'input embeddings'], ['state of the art', 'on', 'every task']]"
"[['BERT', 'as', 'input embeddings'], ['scores', 'above', 'state of the art']]"
"[['BERT', 'instead of', 'ELMo or Glo Ve'], ['BERT', 'improves', 'score'], ['ELMo or Glo Ve', 'improves', 'score'], ['score', 'by', 'approximately 3 and 5 points'], ['improves', 'by', 'approximately 2 points'], ['BERT', 'adding', 'WNGC'], ['ELMo or Glo Ve', 'adding', 'WNGC'], ['WNGC', 'to', 'training data'], ['improves', 'by', 'approximately 2 points']]"
"[['ensembles', 'adds', 'roughly another 1 point'], ['roughly another 1 point', 'to', 'final F1 score']]"
"[['compression method', 'through', 'all relations'], ['compression method', 'negatively impact', 'results'], ['all relations', 'negatively impact', 'results'], ['results', 'in', 'some cases'], ['results', 'when using', 'ELMo or GloVe'], ['some cases', 'when using', 'ELMo or GloVe']]"
[]
[]
"[['Lexical resources', 'like', 'WordNet']]"
"[['gloss - augmented WSD neural network', 'variant of', 'memory network']]"
"[['GAS', 'jointly encodes', 'context and glosses'], ['context and glosses', 'of', 'target word'], ['GAS', 'models', 'semantic relationship'], ['semantic relationship', 'between', 'context and glosses'], ['context and glosses', 'in', 'memory module']]"
"[['inner relationship', 'between', 'glosses and context'], ['inner relationship', 'employ', 'multiple passes operation'], ['multiple passes operation', 'within', 'memory'], ['memory', 'as', 're-reading process'], ['multiple passes operation', 'adopt', 'two memory updating mechanisms']]"
[]
"[['pre-trained word embeddings', 'with', '300 dimensions']]"
"[['256 hidden units', 'in', 'context module']]"
"[['Orthogonal initialization', 'used for', 'weights'], ['weights', 'in', 'LSTM'], ['random uniform initialization', 'with', 'range [ - 0.1 , 0.1 ]'], ['Orthogonal initialization', 'used for', 'others'], ['random uniform initialization', 'used for', 'others'], ['range [ - 0.1 , 0.1 ]', 'used for', 'others']]"
[]
"[['number of passes | T M |', 'from', '1 to 5'], ['1 to 5', 'in', 'our framework'], ['finding', 'performs', 'best']]"
"[['Adam optimizer', 'in', 'training process'], ['Adam optimizer', 'with', '0.001 initial learning rate'], ['training process', 'with', '0.001 initial learning rate']]"
"[['overfitting', 'use', 'dropout regularization'], ['drop rate', 'to', '0.5']]"
"[['up to 100 epochs', 'with', 'early stopping'], ['early stopping', 'if', 'validation loss'], [""does n't improve"", 'within', 'last 10 epochs']]"
[]
"[['Babelfy', 'exploits', 'semantic network structure'], ['semantic network structure', 'from', 'BabelNet'], ['Babelfy', 'builds', 'unified graph - based architecture'], ['unified graph - based architecture', 'for', 'WSD and Entity Linking']]"
[]
"[['IMS', 'selects', 'linear Support Vector Machine ( SVM )'], ['linear Support Vector Machine ( SVM )', 'as', 'classifier'], ['linear Support Vector Machine ( SVM )', 'makes use of', 'set of features'], ['set of features', 'surrounding', 'target word'], ['target word', 'within', 'limited window'], ['limited window', 'such as', 'POS tags'], ['limited window', 'such as', 'local words'], ['limited window', 'such as', 'local collocations']]"
"[['IMS +emb', 'selects', 'IMS'], ['IMS', 'as', 'underlying framework'], ['IMS +emb', 'makes use of', 'word embeddings'], ['word embeddings', 'as', 'features']]"
[]
"[['Bi- LSTM', 'leverages', 'bidirectional LSTM network'], ['bidirectional LSTM network', 'shares', 'model parameters'], ['model parameters', 'among', 'all words']]"
"[['WSD', 'into', 'sequence learning task'], ['multi - task learning framework', 'for', 'WSD'], ['multi - task learning framework', 'for', 'coarse - grained semantic labels ( LEX )']]"
[]
"[['GAS and GAS ext', 'achieves', 'state - of - theart performance'], ['state - of - theart performance', 'concatenation of', 'all test datasets']]"
"[['GAS ext', 'with', 'concatenation memory updating strategy'], ['concatenation memory updating strategy', 'achieves', 'best results'], ['70.6', 'concatenation of', 'four test datasets']]"
"[['appropriate number of passes', 'boost', 'performance'], ['appropriate number of passes', 'avoid', 'over - fitting'], ['over - fitting', 'of', 'model']]"
[]
"[['multiple passes operation', 'performs', 'better'], ['better', 'than', 'one pass']]"
[]
"[['number of passes', 'larger than', '3'], ['F1- score', 'stops', 'increasing or even decreases'], ['increasing or even decreases', 'due to', 'over-fitting']]"
[]
[]
[]
"[['sequence of words', 'surrounding', 'target word'], ['words', 'using', 'real valued vector representation']]"
[]
"[['freely available 2 Glo Ve vectors', 'trained on', 'Wikipedia and Gigaword']]"
"[['Words', 'initialized from', 'N ( 0 , 0.1 )']]"
"[['Our proposed model', 'achieves', 'top score'], ['top score', 'on', 'SE2'], ['IMS + adapted CW', 'on', 'SE3'], ['Our proposed model', 'tied with', 'IMS + adapted CW'], ['IMS + adapted CW', 'on', 'SE3']]"
"[['dropword', 'consistently improves', 'results'], ['results', 'on', 'SE2 and SE3']]"
"[['input words', 'yields', 'substantially worse result']]"
"[['system', 'effectively makes use of', 'information'], ['information', 'in', 'pre-trained word embeddings']]"
[]
[]
"[['target word', 'as', 'context'], ['context', 'for', 'disambiguation']]"
[]
"[['novel knowledge - based WSD algorithm', 'for', 'all - word WSD task'], ['all - word WSD task', 'utilizes', 'whole document'], ['whole document', 'as', 'context'], ['context', 'for', 'word']]"
"[['formalism', 'of', 'topic models'], ['topic models', 'especially', 'Latent Dirichlet Allocation ( LDA )']]"
"[['variant of LDA', 'in which', 'topic proportions'], ['topic proportions', 'for', 'document'], ['synset proportions', 'for', 'document'], ['topic proportions', 'replaced by', 'synset proportions'], ['synset proportions', 'for', 'document']]"
"[['non-uniform prior', 'for', 'synset distribution'], ['synset distribution', 'over', 'words'], ['words', 'to model', 'frequency of words'], ['frequency of words', 'within', 'synset']]"
"[['relationships', 'between', 'synsets'], ['synsets', 'by using', 'logisticnormal prior'], ['logisticnormal prior', 'for drawing', 'synset proportions'], ['synset proportions', 'of', 'document']]"
"[['proposed method', 'outperforms', 'state - of - the - art WSD system'], ['state - of - the - art WSD system', 'by', 'significant margin ( pvalue < 0.01 )'], ['state - of - the - art WSD system', 'by achieving', 'overall F1 - score'], ['significant margin ( pvalue < 0.01 )', 'by achieving', 'overall F1 - score'], ['overall F1 - score', 'of', '66.9'], [""Moro14 's score"", 'of', '65.5'], [""Moro14 's score"", 'of', '65.5']]"
"[['performance', 'of', 'proposed model'], ['performance', 'is', 'not much worse'], ['proposed model', 'is', 'not much worse'], ['not much worse', 'than', 'best supervised system']]"
"[['proposed system', 'outperforms', 'all previous knowledgebased systems']]"
[]
[]
[]
"[['jointly', 'in', 'single neural model'], ['single neural model', 'makes', 'whole process']]"
"[['noise', 'automatically learn', 'features'], ['features', 'over', 'set of contexts'], ['set of contexts', 'of', 'different granularity levels']]"
"[['Each level of granularity', 'handled by', 'separate component'], ['separate component', 'of', 'model']]"
"[['token - level component', 'extracts', 'higher - level features'], ['higher - level features', 'from', 'whole question context'], ['character - level component', 'builds', 'lower - level features'], ['lower - level features', 'for', 'candidate n-gram']]"
"[['features', 'from', 'knowledge base context'], ['knowledge base context', 'of', 'candidate entity'], ['character - level features', 'extracted for', 'entity label'], ['entities', 'surrounding', 'candidate entity'], ['candidate entity', 'in', 'knowledge graph']]"
"[['n-gram', 'is', 'entity mention']]"
[]
[]
[]
[]
"[['heuristics baseline', 'ranks', 'candidate entities'], ['candidate entities', 'according to', 'frequency'], ['frequency', 'in', 'Wikipedia']]"
[]
"[['frequency', 'of', 'entity'], ['labels', 'of', 'connected entities and relations'], ['entity', 'in', 'Wikipedia'], ['edit distance', 'between', 'label'], ['edit distance', 'between', 'token n-gram'], ['label', 'of', 'token n-gram'], ['number of entities and relations', 'immediately connected to', 'entity'], ['entity', 'in', 'KB'], ['word overlap', 'between', 'input question'], ['word overlap', 'between', 'length'], ['labels', 'of', 'connected entities and relations'], ['length', 'of', 'n-gram']]"
"[['VCG model', 'shows', 'overall F- score result'], ['overall F- score result', 'better than', 'DBPedia Spotlight baseline'], ['DBPedia Spotlight baseline', 'by', 'wide margin']]"
"[['our model', 'achieves', 'higher precision values'], ['higher precision values', 'compared to', 'other approaches'], ['our model', 'manages to keep', 'satisfactory level of recall']]"
[]
[]
[]
"[['supervised WSD model', 'leverages', 'Bidirectional Long Short - Term Memory ( BLSTM ) network']]"
"[['neural sense vectors ( i.e. sense embeddings )', 'learned during', 'model training'], ['neural word vectors ( i.e. word embeddings )', 'learned through', 'unsupervised deep learning approach']]"
[]
[]
"[['results', 'of', 'top - performing and low - performing supervised algorithms']]"
[]
"[['sequential follow', 'of', 'information'], ['order', 'of', 'context words'], ['information', 'into', 'our Bidirectional LSTM'], ['our Bidirectional LSTM', 'shuffle', 'order'], ['order', 'of', 'context words'], ['our Bidirectional LSTMs', 'with', 'two different fully - connected networks'], ['two different fully - connected networks', 'of', 'same size 50']]"
[]
[]
[]
[]
"[['sense - annotated text', 'to', 'sense labels'], ['single all - words model', 'from', 'training data']]"
"[['English uk WaC corpus', 'as', 'initialization']]"
"[['all architectures', 'employed', '2 layers'], ['2 layers', 'of', 'bidirectional LSTM'], ['bidirectional LSTM', 'with', '2048 hidden units']]"
"[['F1 - score', 'on', 'each in - dividual test set'], ['F1- score', 'on', 'concatenation'], ['F1- score', 'obtained on', 'concatenation'], ['concatenation', 'of', 'all four test sets'], ['F1- score', 'divided by', 'part - of - speech tag']]"
"[['supervised systems', 'considered', 'Context2 Vec'], ['word embeddings', 'using', 'exponential decay']]"
"[['BLSTM and Seq2Seq', 'achieved', 'results'], ['performing', 'on par with', 'word experts'], ['word experts', 'tuned over', 'explicitly engineered features']]"
"[['BLSTM models', 'to outperform', 'Seq2Seq counterparts']]"
[]
"[['RNN - based architectures', 'outperformed', 'classical supervised approaches'], ['classical supervised approaches', 'when dealing with', 'verbs']]"
"[['BLSTM and Seq2Seq', 'outperformed', 'UKB and IMS'], ['UKB and IMS', 'trained on', 'SemCor']]"
[]
"[['bilingual and multilingual models', 'consistently outperformed', 'MFS baseline']]"
[]
[]
[]
"[['WSD', 'using', 'nearest neighbor classification'], ['nearest neighbor classification', 'on', 'CWEs']]"
"[['CWEs', 'to approach', 'WSD task'], ['utilized directly', 'to approach', 'WSD task']]"
"[['semantic capabilities', 'of', 'CWEs'], ['semantic capabilities', 'employ', 'simple , yet interpretable approach'], ['simple , yet interpretable approach', 'to', 'WSD'], ['WSD', 'using', 'k -nearest neighbor classification ( kNN ) approach']]"
[]
"[['ELMo', 'as well as', 'BERT embeddings'], ['BERT embeddings', 'beats', 'state of the art'], ['state of the art', 'of', 'lexical sample task SE - 2']]"
"[['outperforms', 'on', 'SE - 3 task'], ['all others', 'on', 'SE - 3 task']]"
"[['major performance drop', 'of', 'our approach'], ['major performance drop', 'for', 'two all - words WSD tasks'], ['our approach', 'for', 'two all - words WSD tasks']]"
"[['semantically and structurally similar sentence contexts', 'of', 'polysemic target words']]"
"[['SE - 2 and SE - 3 training datasets', 'provide', 'more CWEs'], ['more CWEs', 'for', 'each word and sense'], ['our approach', 'performs', 'better'], ['better', 'with', 'growing number of CWEs']]"
"[['CWEs', 'do not organize', 'well'], ['well', 'in', 'spherically shaped form'], ['spherically shaped form', 'in', 'embedding space'], ['spherically shaped form', 'in', 'embedding space']]"
[]
[]
"[['SensEval - 2 and SensEval - 3', 'achieve', 'new state - of - the - art result']]"
"[['S7 - T *', 'achieve', 'minor improvements'], ['minor improvements', 'with', 'higher k']]"
[]
"[['different CWE models', 'encode', 'information'], ['information', 'such as', 'distinguishable senses'], ['distinguishable senses', 'in', 'vector space']]"
"[['Flair embeddings', 'hardly allow to distinguish', 'any clusters'], ['most senses', 'scattered across', 'entire plot']]"
"[['slightly more separated', 'In', 'different regions'], ['major senses', 'are', 'slightly more separated'], ['slightly more separated', 'in', 'different regions'], ['different regions', 'of', 'point cloud']]"
[]
"[['neural network model', 'to jointly learn', 'distributed representations'], ['distributed representations', 'of', 'KB entities']]"
"[['every text', 'in', 'KB'], ['each other', 'in', 'continuous vector space'], ['text and the relevant entities', 'close to', 'each other'], ['each other', 'in', 'continuous vector space']]"
"[['humanedited entity annotations', 'obtained from', 'Wikipedia'], ['humanedited entity annotations', 'as', 'supervised data'], ['supervised data', 'of', 'relevant entities'], ['relevant entities', 'to', 'texts']]"
[]
"[['Explicit Semantic Analysis ( ESA )', 'represents', 'semantics']]"
"[['ESA', 'shows', 'text']]"
"[['placing', 'into', 'same vector space'], ['texts and entities', 'into', 'same vector space'], ['placing', 'easily compute', 'similarity'], ['texts and entities', 'easily compute', 'similarity'], ['similarity', 'between', 'texts and entities']]"
[]
"[['conventional approach', 'using', 'logistic regression ( LR ) classifier'], ['logistic regression ( LR ) classifier', 'trained with', 'binary BOW features'], ['binary BOW features', 'to predict', 'correct answer']]"
"[['BOW - DT', 'based on', 'BOW baseline'], ['BOW baseline', 'augmented with', 'feature set'], ['feature set', 'with', 'dependency relation indicators']]"
"[['QANTA', 'based on', 'recursive neural network'], ['recursive neural network', 'to derive', 'distributed representations']]"
"[['FTS - BRNN', 'based on', 'bidirectional recurrent neural network ( RNN )'], ['bidirectional recurrent neural network ( RNN )', 'with', 'gated recurrent units ( GRU )']]"
[]
"[['our method', 'mostly performed', 'perfect']]"
[]
[]
"[['state of the art results', 'on', 'most WSD evaluation tasks'], ['coverage', 'of', 'supervised systems']]"
"[['method', 'reducing', 'vocabulary of senses'], ['vocabulary of senses', 'of', 'Word Net'], ['meaning', 'of', 'every word'], ['vocabulary of senses', 'by selecting', 'minimal set of senses'], ['minimal set of senses', 'required for differentiating', 'meaning']]"
[]
"[['our vocabulary reduction method', 'improves', 'coverage'], ['coverage', 'of', 'supervised systems']]"
"[['coverage improvement', 'on', 'evaluation tasks'], ['holds true', 'on', 'evaluation tasks'], ['evaluation tasks', 'for', 'both training sets']]"
"[['difference of scores', 'obtained by', 'our system'], ['difference of scores', 'using', 'sense vocabulary reduction or not'], ['difference of scores', 'using', 'sense vocabulary reduction'], ['our system', 'using', 'sense vocabulary reduction or not'], ['our system', 'using', 'sense vocabulary reduction']]"
"[['very large gap', 'on', 'SemEval 2013 task']]"
"[['WordNet Gloss Tagged', 'to', 'training data'], ['WordNet Gloss Tagged', 'obtain', 'systematically state of the art results'], ['training data', 'obtain', 'systematically state of the art results'], ['systematically state of the art results', 'on', 'all tasks'], ['all tasks', 'except on', 'SensEval']]"
"[['sense reduction method', 'does not consistently improves or decreases', 'score'], ['score', 'on', 'every task']]"
"[['ensembling', 'is', 'very efficient method'], ['very efficient method', 'in', 'WSD']]"
"[['scores', 'are', 'significantly higher'], ['significantly higher', 'when applying', 'vocabulary reduction algorithm']]"
[]
[]
"[['Lexical resources', 'like', 'WordNet']]"
"[['gloss - augmented WSD neural network', 'variant of', 'memory network']]"
"[['GAS', 'jointly encodes', 'context and glosses'], ['context and glosses', 'of', 'target word'], ['GAS', 'models', 'semantic relationship'], ['semantic relationship', 'between', 'context and glosses'], ['context and glosses', 'in', 'memory module']]"
"[['inner relationship', 'between', 'glosses and context'], ['inner relationship', 'employ', 'multiple passes operation'], ['multiple passes operation', 'within', 'memory'], ['memory', 'as', 're-reading process'], ['multiple passes operation', 'adopt', 'two memory updating mechanisms']]"
"[['pre-trained word embeddings', 'with', '300 dimensions']]"
"[['256 hidden units', 'in', 'context module']]"
"[['Orthogonal initialization', 'used for', 'weights'], ['weights', 'in', 'LSTM'], ['random uniform initialization', 'with', 'range [ - 0.1 , 0.1 ]'], ['Orthogonal initialization', 'used for', 'others'], ['random uniform initialization', 'used for', 'others'], ['range [ - 0.1 , 0.1 ]', 'used for', 'others']]"
[]
"[['number of passes | T M |', 'from', '1 to 5'], ['1 to 5', 'in', 'our framework'], ['finding', 'performs', 'best']]"
"[['Adam optimizer', 'in', 'training process'], ['Adam optimizer', 'with', '0.001 initial learning rate'], ['training process', 'with', '0.001 initial learning rate']]"
"[['overfitting', 'use', 'dropout regularization'], ['drop rate', 'to', '0.5']]"
"[['up to 100 epochs', 'with', 'early stopping'], ['early stopping', 'if', 'validation loss'], [""does n't improve"", 'within', 'last 10 epochs']]"
[]
"[['GAS and GAS ext', 'achieves', 'state - of - theart performance'], ['state - of - theart performance', 'concatenation of', 'all test datasets']]"
"[['best', 'on', 'all the test sets'], ['best', 'find that', 'GAS ext'], ['all the test sets', 'find that', 'GAS ext'], ['GAS ext', 'with', 'concatenation memory updating strategy'], ['concatenation memory updating strategy', 'achieves', 'best results'], ['70.6', 'concatenation of', 'four test datasets']]"
"[['other three neural - based methods', 'find that', 'our best model'], ['our best model', 'outperforms', 'previous best neural network models'], ['previous best neural network models', 'on', 'every individual test set']]"
"[['IMS + emb', 'on', 'SE3 , SE13 and SE15 test sets']]"
"[['glosses', 'into', 'neural WSD'], ['glosses', 'greatly improve', 'performance'], ['neural WSD', 'greatly improve', 'performance'], ['glosses', 'extending', 'original gloss'], ['original gloss', 'further boost', 'results']]"
"[['our proposed model', 'greatly improves', 'WSD task'], ['WSD task', 'by', '2.2 % F1 - score'], ['2.2 % F1 - score', 'with the help of', 'gloss knowledge']]"
"[['original gloss', 'as', 'background knowledge'], ['GAS', 'further improve', 'performance'], ['performance', 'with the help of', 'extended glosses'], ['extended glosses', 'through', 'semantic relations']]"
[]
[]
[]
[]
[]
"[['significantly better', 'than', 'algorithm'], ['algorithm', 'based on', 'continuous bag of words model ( Word2 vec )'], ['continuous bag of words model ( Word2 vec )', 'especially on', 'verbs']]"
"[['semi-supervised algorithm', 'uses', 'label propagation'], ['label propagation', 'to label', 'unlabeled sentences'], ['unlabeled sentences', 'based on', 'similarity'], ['similarity', 'to', 'labeled ones']]"
[]
"[['Our proposed algorithms', 'achieve', 'highest all - words F 1 scores'], ['highest all - words F 1 scores', 'except for', 'Sem - Eval 2013']]"
"[['highest F 1 score', 'on', 'Nouns ( Sem - Eval - 7 Coarse )'], ['Unified WSD', 'on', 'other part - of - speech tags'], ['our algorithms', 'outperform', 'Unified WSD'], ['Unified WSD', 'on', 'other part - of - speech tags']]"
[]
[]
"[['LSTM classifier', 'outperforms', 'Word2 Vec classifier']]"
[]
"[['LSTM classifier', 'trained with', 'OMSTI'], ['LSTM classifier', 'performs', 'worse'], ['OMSTI', 'performs', 'worse'], ['worse', 'trained with', 'SemCor']]"
"[['our naive nearest neighbor classifiers', 'do not have', 'learned model']]"
[]
[]
[]
"[['LSTM', 'outperforms', 'Word2Vec'], ['Word2Vec', 'by', 'more than 10 % overall words']]"
[]
"[['SemCor ( or MASC ) trained classifier', 'on a par with', 'NOAD trained classifier'], ['NOAD trained classifier', 'on', 'F1 score']]"
[]
"[['accuracy and resource usage', 'use', 'second best LSTM model ( h = 2048 and p = 512 )']]"
[]
"[['LP', 'did not yield', 'clear benefits'], ['clear benefits', 'when using', 'Word2 Vec language model']]"
"[['6.3 % increase', 'on', 'SemCor'], ['7.3 % increase', 'on', 'MASC'], ['7.3 % increase', 'on', 'MASC'], ['7.3 % increase', 'using', 'LP'], ['MASC', 'using', 'LP'], ['LP', 'with', 'LSTM language model']]"
[]
"[['substantially improves', 'when', 'training datasets'], ['classifier F1', 'when', 'training datasets'], ['training datasets', 'are', 'SemCor + NOAD'], ['training datasets', 'are', 'MASC + NOAD']]"
[]
"[['LP graph', 'by connecting', 'two nodes'], ['two nodes', 'if', 'affinity'], ['affinity', 'above', '95 % percentile']]"
"[['F1 scores', 'are', 'relatively stable'], ['relatively stable', 'when', 'percentile'], ['ranges', 'between', '85 to 98'], ['decrease', 'when', 'percentile'], ['percentile', 'drops to', '80']]"
[]
"[['independent entity embeddings', 'trained to match', 'fixed length vector representations'], ['fixed length vector representations', 'of', 'textual context']]"
"[['RELIC', 'to', 'entity typing']]"
"[['RELIC', 'obtain', 'data'], ['data', 'from', '2018 - 10 - 22 dump'], ['2018 - 10 - 22 dump', 'of', 'English Wikipedia']]"
"[['each context sentence', 'to', '128 tokens']]"
"[['entity embedding size', 'to', 'd = 300']]"
"[['model', 'using', 'Tensor Flow']]"
[]
"[['RELIC', 'matches', 'state of the art']]"
"[['entity linking performance', 'could be', 'boosted even higher'], ['boosted even higher', 'through', 'adoption of']]"
"[['RELIC', 'outperforms', 'prior work']]"
[]
"[['significantly outperforms', 'on', 'both datasets'], ['prior results', 'on', 'both datasets']]"
"[['TypeNet', 'train with', 'structured loss'], ['structured loss', 'based on', 'TypeNet hierarchy'], ['our flat classifier', 'of', 'binary labels']]"
[]
"[['masking mentions', 'during', 'training'], ['masking mentions', 'beneficial for', 'entity typing tasks'], ['masking mentions', 'detrimental for', 'entity linking']]"
"[['higher mask rate', 'leads to', 'better performance']]"
"[['mask rate', 'of', '10 %'], ['RELIC', 'nears', 'optimum performance'], ['optimum performance', 'on', 'most tasks']]"
[]
"[[""RELIC 's performance"", 'approaching', 'upper bound'], ['upper bound', 'on', 'supervised tasks']]"
[]
"[['retrieve - then - read approach', 'taken by', 'ORQA'], ['retrieve - then - read approach', 'outperforms', 'direct answer retrieval approach'], ['ORQA', 'outperforms', 'direct answer retrieval approach'], ['direct answer retrieval approach', 'taken by', 'RELIC']]"
"[['ORQA', 'runs', 'BERT based reading comprehension model'], ['BERT based reading comprehension model', 'over', 'multiple evidence passages']]"
"[['reading comprehension baseline', 'by', '20 points']]"
[]
[]
"[['novel embedding method', 'specifically designed for', 'NED']]"
"[['method', 'to construct', 'novel embedding'], ['novel embedding', 'jointly maps', 'words and entities'], ['words and entities', 'into', 'same continuous vector space']]"
"[['similar words and entities', 'close to', 'one another'], ['one another', 'in', 'vector space']]"
"[['similarity', 'between', 'any pair of items']]"
"[['each context word', 'given', 'target word']]"
[]
"[['conventional skip - gram model', 'learns to predict', 'neighboring words'], ['neighboring words', 'given', 'target word'], ['neighboring entities', 'given', 'target entity'], ['target word', 'in', 'text corpora'], ['KB graph model', 'learns to estimate', 'neighboring entities'], ['neighboring entities', 'given', 'target entity'], ['target entity', 'in', 'link graph'], ['link graph', 'of', 'KB'], ['anchor context model', 'learns to predict', 'neighboring words'], ['neighboring words', 'given', 'target entity'], ['target entity', 'using', 'anchors and their context words'], ['anchors and their context words', 'in', 'KB']]"
"[['straightforward NED method', 'computes', 'two contexts'], ['two contexts', 'using', 'proposed embedding']]"
"[['NED method', 'combines', 'contexts'], ['contexts', 'with', 'several standard features'], ['several standard features', 'using', 'supervised machine learning']]"
"[['Our method', 'successfully achieved', 'enhanced performance'], ['enhanced performance', 'on', 'CoNLL and the TAC 2010 datasets']]"
"[['performance', 'on', 'CoNLL dataset']]"
"[['Our method', 'outperformed', 'all the state - of - the - art methods'], ['all the state - of - the - art methods', 'on', 'both datasets']]"
[]
[]
"[['methodology', 'for learning', 'statistical texture model'], ['statistical texture model', 'from', '"" in - the -wild "" facial images']]"
"[['featurebased texture models', 'for', '3 DMMs']]"
"[['advantage', 'of using', '"" in - the -wild "" feature - based texture model'], ['"" in - the -wild "" feature - based texture model', 'is', 'fitting strategy'], ['fitting strategy', 'gets', 'simplified']]"
[]
"[['"" in - the -wild "" conditions', 'present in', 'test set'], ['Classic model', 'performs', 'worst']]"
"[['texture - free Linear model', 'does', 'better'], ['ITW model', 'most able to recover', 'facial shapes'], ['facial shapes', 'due to', 'ideal feature basis'], ['ideal feature basis', 'for', '"" in - the -wild "" conditions']]"
[]
[]
[]
[]
[]
"[['3D face reconstruction', 'by using', 'novel volumetric representation'], ['3D face reconstruction', 'by using', 'appropriate CNN architecture'], ['appropriate CNN architecture', 'trained to', 'regress'], ['regress', 'directly from', '2 D facial image'], ['2 D facial image', 'to', 'corresponding 3D volume']]"
"[['end - to - end', 'using', 'RMSProp'], ['RMSProp', 'with', 'initial learning rate'], ['initial learning rate', 'of', '10 ? 4'], ['lowered', 'after', '40 epochs'], ['40 epochs', 'to', '10 ?5']]"
"[['random augmentation', 'applied to', 'each input sample ( face image )']]"
"[['input and target', 'flipped', 'horizontally']]"
"[['input samples', 'adjusted with', 'some colour scaling'], ['some colour scaling', 'on', 'each RGB channel']]"
"[['landmark detection module', 'trained to regress', 'Gaussians'], ['Gaussians', 'with', 'standard deviation']]"
[]
"[['3DDFA and EOS', 'on', 'all datasets']]"
"[['All VRNs', 'perform', 'well'], ['well', 'across', 'whole spectrum of facial poses , expressions and occlusions']]"
[]
"[['particularly better', 'than', 'plain VRN']]"
[]
"[['performance', 'of', 'our method'], ['decreases', 'as', 'pose']]"
[]
[]
"[['Effect of Gaussian size', 'for', 'guidance']]"
"[['performance', 'of', '3D reconstruction'], ['performance', 'dropped by', 'negligible amount'], ['3D reconstruction', 'dropped by', 'negligible amount']]"
[]
[]
"[['novel loss function', 'namely', 'Wing loss'], ['novel loss function', 'designed to improve', 'deep neural network training capability'], ['deep neural network training capability', 'for', 'small and medium range errors']]"
"[['data augmentation strategy', 'i.e.', 'pose - based data balancing'], ['data augmentation strategy', 'compensates', 'low frequency of occurrence'], ['low frequency of occurrence', 'of', 'samples'], ['low frequency of occurrence', 'with', 'large out - of - plane head rotations'], ['samples', 'with', 'large out - of - plane head rotations'], ['large out - of - plane head rotations', 'in', 'training set']]"
"[['two - stage facial landmark localisation framework', 'for', 'performance boosting']]"
[]
"[['training and testing', 'of', 'our networks'], ['training and testing', 'conducted on', 'server'], ['training and testing', 'conducted on', '4 NVIDIA GeForce GTX Titan X ( Pascal ) cards'], ['our networks', 'conducted on', 'server'], ['our networks', 'conducted on', '4 NVIDIA GeForce GTX Titan X ( Pascal ) cards'], ['server', 'running', 'Ubuntu 16.04'], ['server', 'running', '4 NVIDIA GeForce GTX Titan X ( Pascal ) cards'], ['Ubuntu 16.04', 'with', '2 Intel Xeon E5-2667 v4 CPU'], ['Ubuntu 16.04', 'with', '4 NVIDIA GeForce GTX Titan X ( Pascal ) cards']]"
"[['one GPU card', 'for measuring', 'run time']]"
"[['weight decay', 'to', '5 10 ? 4'], ['momentum', 'to', '0.9'], ['batch size', 'to', '8'], ['momentum', 'to', '0.9'], ['batch size', 'to', '8'], ['batch size', 'to', '8'], ['8', 'for', 'network training']]"
[]
"[['standard ReLu function', 'used for', 'nonlinear activation'], ['Max pooling', 'stride of', '2']]"
"[['convolutional layer', 'used', '3 3 kernels'], ['3 3 kernels', 'with', 'stride'], ['stride', 'of', '1']]"
"[['17', 'For', 'AFLW'], ['17', 'For', '300W'], ['9', 'For', '300W'], ['number of bins K', 'set to', '17'], ['17', 'for', 'AFLW'], ['17', 'for', '9'], ['9', 'for', '300W'], ['9', 'for', '300W']]"
"[['3 10 ?5 to 3 10 ? 7', 'For', 'other loss functions'], ['input image size', 'is', '64 64 3'], ['input image size', 'reduced', 'learning rate'], ['learning rate', 'from', '3 10 ? 6'], ['learning rate', 'from', '3 10 ?5 to 3 10 ? 7'], ['3 10 ? 6', 'to', '3 10 ?8'], ['3 10 ?8', 'for', 'L2 loss'], ['learning rate', 'from', '3 10 ?5 to 3 10 ? 7'], ['3 10 ?5 to 3 10 ? 7', 'for', 'other loss functions']]"
"[['parameters', 'of', 'Wing loss'], ['1 10 ? 5 to 1 10 ? 7', 'For', 'other loss functions'], ['input image size', 'is', '128 128 3'], ['learning rate', 'from', '1 10 ? 6 to 1 10 ?8'], ['1 10 ? 6 to 1 10 ?8', 'for', 'L2 loss'], ['learning rate', 'from', '1 10 ? 5 to 1 10 ? 7'], ['1 10 ? 5 to 1 10 ? 7', 'for', 'other loss functions']]"
"[['data augmentation', 'randomly rotated', 'each training image'], ['data augmentation', 'between', 'each training image'], ['each training image', 'between', '[ ? 30 , 30 ] degrees'], ['each training image', 'between', '[ ? 10 , 10 ] degrees'], ['[ ? 30 , 30 ] degrees', 'for', 'CNN - 6'], ['each training image', 'between', '[ ? 30 , 30 ] degrees'], ['each training image', 'between', '[ ? 10 , 10 ] degrees'], ['[ ? 10 , 10 ] degrees', 'for', 'CNN - 7']]"
"[['bounding box perturbation', 'applied', 'random translations'], ['random translations', 'to', 'upper-left and bottom - right corners'], ['upper-left and bottom - right corners', 'of', 'face bounding box'], ['face bounding box', 'within', '5 %'], ['upper-left and bottom - right corners', 'of', 'face bounding box'], ['5 %', 'of', 'bounding']]"
[]
"[['Gaussian blur (? = 1 )', 'to', 'each training image'], ['each training image', 'with', 'probability'], ['probability', 'of', '50 %']]"
[]
"[['CNN - 6/7 network', 'outperforms', 'all the other approaches'], ['all the other approaches', 'trained with', 'commonly used L2 loss function']]"
"[['loss function', 'from', 'L2'], ['L2', 'to', 'L1'], ['performance', 'of', 'our method']]"
"[['newly proposed Wing loss function', 'further improves', 'accuracy']]"
[]
"[['two - stage landmark localisation framework', 'with', 'PDB strategy'], ['newly proposed Wing loss function', 'outperforms', 'all the other stateof - the - art algorithms'], ['all the other stateof - the - art algorithms', 'on', '300 W dataset inaccuracy']]"
"[['error', 'reduced by', 'almost 20 %'], ['almost 20 %', 'compared to', 'current best result'], ['current best result', 'reported by', 'RAR algorithm']]"
[]
"[['regression network', 'reliance on', 'inverse rendering'], ['inverse rendering', 'to reproduce', 'image pixels']]"
"[['loss', 'based on', 'facial identity features'], ['facial identity features', 'produced by', 'face recognition network'], ['face recognition network', 'such as', 'VGG - Face'], ['face recognition network', 'such as', ""Google 's FaceNet""]]"
"[['invariance', 'to apply', 'loss'], ['loss', 'matches', 'identity features'], ['identity features', 'between', 'input photograph'], ['identity features', 'between', 'synthetic rendering'], ['synthetic rendering', 'of', 'predicted face']]"
"[['fooling problem', 'by applying', 'three novel losses'], ['batch distribution loss', 'to match', 'statistics'], ['statistics', 'of', 'each training batch'], ['each training batch', 'to', 'statistics'], ['statistics', 'of', 'morphable model'], ['multiple , independent views', 'of', 'predicted shape'], ['loopback loss', 'to ensure', 'regression network'], ['regression network', 'correctly reinterpret', 'own output'], ['features', 'from', 'multiple , independent views'], ['multiple , independent views', 'of', 'predicted shape']]"
"[['3D shape and texture regression network', 'using', 'face recognition network'], ['3D shape and texture regression network', 'using', 'morphable face model']]"
"[['3D face results', 'improve on', 'accuracy'], ['accuracy', 'of', 'previous work']]"
[]
"[['absolute error', 'to', 'ground truth'], ['ground truth', 'by', '20 - 25 %']]"
"[['more stable', 'across', 'changing environments']]"
[]
"[['Our method', 'achieves', 'average similarity'], ['average similarity', 'between', 'rendering and photo'], ['rendering and photo', 'of', '0.403'], ['0.403', 'on', 'MoFA test']]"
"[[""Our method 's results"", 'closer to', 'same - person distribution'], ['same - person distribution', 'than', 'differentperson distribution'], ['differentperson distribution', 'in', 'all cases']]"
"[['distance', 'between', 'GT distribution and the same - person LFW distribution'], ['GT distribution and the same - person LFW distribution', 'is', 'very low'], ['very low', 'with', 'almost the same mean ( 0.51 vs 0.50 )']]"
[]
[]
"[['CNN', 'to fit', '3 D face model'], ['3 D face model', 'to', 'face image']]"
[]
"[['contour constraint', 'where', 'contour'], ['contour constraint', 'where', 'SIFT constraint'], ['SIFT constraint', 'where', 'SIFT key points'], ['contour', 'of', 'predicted shape'], ['predicted shape', 'should match', 'detected 2 D face boundary'], ['predicted shape', 'should match', 'SIFT constraint'], ['SIFT constraint', 'where', 'SIFT key points'], ['same vertexes', 'on', '3D face model']]"
"[['CNN training', 'as', 'additional loss function terms'], ['end - to - end training', 'results in', 'enhanced CNN'], ['enhanced CNN', 'for', '3 D face model fitting']]"
"[['inherent advantage', 'in handling', 'multiple training databases']]"
[]
"[['network', 'use', '20 , 10 , and 10 epochs'], ['20 , 10 , and 10 epochs', 'for', 'stage 1 to 3']]"
"[['initial global learning rate', 'as', '1 e ? 3'], ['learning rate', 'by', 'factor of 10'], ['factor of 10', 'when', 'training error'], ['training error', 'approaches', 'plateau']]"
"[['minibatch size', 'is', '32'], ['Leaky ReLU', 'is', '0.01'], ['weight decay', 'is', '0.005'], ['leak factor', 'for', 'Leaky ReLU'], ['Leaky ReLU', 'is', '0.01']]"
"[['our method', 'outperforms', 'best methods'], ['best methods', 'with', 'large margin'], ['large margin', 'of', '17.8 % improvement']]"
"[['our method', 'shows', 'large improvement']]"
"[['images', 'with', 'yaw angle'], ['yaw angle', 'in', '[ 60 , 90 ]'], ['yaw angle', 'in', 'our method'], ['our method', 'improves', 'performance'], ['performance', 'by', '28 %'], ['28 %', 'from', '7.93 to 5.68']]"
"[['our method', 'reaches', 'higher accuracy']]"
[]
"[['Our method', 'is', 'second best method'], ['second best method', 'on', 'challenging set']]"
"[['performance', 'of', 'our method'], ['performance', 'comparable to', 'other methods'], ['our method', 'comparable to', 'other methods'], ['other methods', 'designed for', 'near - frontal datasets']]"
"[['accuracy', 'of', 'our method'], ['accuracy', 'on', 'AFLW2000 - 3D'], ['our method', 'on', 'AFLW2000 - 3D'], ['consistently improves', 'adding', 'more datasets']]"
"[['our method', 'achieves', '9.5 % and 20 % relative improvement'], ['9.5 % and 20 % relative improvement', 'by utilizing', 'datasets'], ['datasets', 'in', 'stage 2 and stage 3'], ['stage 2 and stage 3', 'over', 'first stage']]"
"[['datasets', 'from', 'second and third stages'], ['26 % relative improvement', 'achieve', 'NME'], ['NME', 'of', '3.86 %']]"
"[['LFC + SPC and LFC + CFC performances', 'shows', 'CFC'], ['CFC', 'is', 'more helpful'], ['more helpful', 'than', 'SPC']]"
"[['all constraints', 'achieves', 'best performance']]"
"[['images', 'with', 'NME - lp'], ['NME - lp', 'between', '5 % and 15 %'], ['5 % and 15 %', 'is', 'helpful'], ['SPC', 'is', 'helpful']]"
"[['superior representation power', 'of', 'nonlinear 3 DMM'], ['nonlinear 3 DMM', 'over', 'linear counterpart'], ['contribution', 'to', 'face alignment and 3D reconstruction']]"
"[['two network decoders', 'instead of', 'two PCA spaces'], ['two PCA spaces', 'as', 'shape and texture model components']]"
"[['different networks', 'for', 'shape and texture'], ['multi - layer perceptron ( MLP )', 'for', 'shape'], ['multi - layer perceptron ( MLP )', 'for', 'texture'], ['convolutional neural network ( CNN )', 'for', 'texture'], ['multi - layer perceptron ( MLP )', 'for', 'shape'], ['convolutional neural network ( CNN )', 'for', 'texture']]"
"[['Each decoder', 'take', 'shape or texture representation'], ['shape or texture representation', 'as', 'input'], ['Each decoder', 'output', 'dense 3 D face or a face texture'], ['Each decoder', 'output', 'face texture']]"
"[['fitting algorithm', 'to', 'nonlinear 3 DMM'], ['nonlinear 3 DMM', 'formulated as', 'CNN encoder']]"
"[['encoder', 'takes', '2 D face image'], ['2 D face image', 'as', 'input'], ['encoder', 'generates', 'shape and texture parameters'], ['shape and texture parameters', 'from', 'two decoders'], ['two decoders', 'estimate', '3D face and texture']]"
"[['3 D face and texture', 'perfectly reconstruct', 'input face'], ['input face', 'if', 'fitting algorithm']]"
"[['differentiable rendering layer', 'to generate', 'reconstructed face'], ['reconstructed face', 'by fusing', '3D face , texture , and the camera projection parameters'], ['3D face , texture , and the camera projection parameters', 'estimated by', 'encoder']]"
"[['endto - end learning scheme', 'where', 'encoder and two decoders'], ['encoder and two decoders', 'to minimize', 'difference'], ['learnt jointly', 'to minimize', 'difference'], ['difference', 'between', 'reconstructed face and the input face']]"
"[['large collection of unconstrained 2D images', 'without relying on', '3D scans']]"
"[['shape and texture representation power', 'over', 'linear 3 DMM']]"
"[['model', 'optimized using', 'Adam optimizer'], ['model', 'with', '0.0002'], ['Adam optimizer', 'with', 'initial learning rate'], ['Adam optimizer', 'with', '0.0002'], ['initial learning rate', 'of', '0.001'], ['initial learning rate', 'of', '0.0002'], ['0.001', 'when minimizing', 'L 0'], ['0.0002', 'when minimizing', 'L.']]"
"[['losses', 'to have', 'similar magnitudes']]"
[]
"[['reconstruction error', 'in', 'image space'], ['reconstruction error', 'through', 'rendering layer'], ['rendering layer', 'with', 'groundtruth S and m']]"
"[['nonlinear texture', 'closer to', 'groundtruth'], ['groundtruth', 'than', 'linear model'], ['linear model', 'especially for', 'in - the - wild images']]"
"[['significantly lower L 1 reconstruction error', 'than', 'lin'], ['significantly lower L 1 reconstruction error', 'compare', 'power'], ['nonlinear and linear 3 DMM', 'in representing', 'real - world 3D scans']]"
"[['significantly smaller reconstruction error', 'than', 'linear model']]"
[]
"[['low error', 'comparable to', 'optimization - based methods']]"
[]
"[['on - par results', 'with', 'Garrido et al.'], ['on - par results', 'with', 'offline optimization method'], ['on - par results', 'surpassing', 'all other regression methods']]"
"[['global image - based discriminator', 'is', 'redundant'], ['global structure', 'guaranteed by', 'rendering layer']]"
"[['global image - based discriminator', 'can cause', 'severe artifacts'], ['severe artifacts', 'in', 'resultant texture']]"
"[['patchGAN', 'offers', 'higher realism'], ['patchGAN', 'offers', 'fewer artifacts']]"
[]
[]
"[['fairly accurate 3 D models', 'generated by using', 'simple mean shape'], ['simple mean shape', 'deformed to', 'input image'], ['input image', 'at', 'relatively low computational cost'], ['relatively low computational cost', 'compared to', 'other approaches']]"
"[['Our network', 'implemented in', 'Caffe framework']]"
"[['new layer', 'created', 'bilinear sampler module'], ['new layer', 'consisting of', '3D TPS transformation module'], ['new layer', 'consisting of', 'bilinear sampler module']]"
"[['two architectures', 'as', 'pre-trained models'], ['pre-trained models', 'for', 'shared feature extraction networks']]"
"[['AlexNet architecture', 'freeze', 'first layer']]"
"[['2D landmark regression', 'implemented by', 'attaching'], ['additional layers', 'on top of', 'last convolution layer']]"
[]
[]
"[['3D dense face model', 'rather than', 'sparse landmark shape model'], ['sparse landmark shape model', 'to', 'image']]"
[]
"[['fitting process', 'in', '3 DDFA'], ['3 DDFA', 'propose', 'cascaded convolutional neutral network ( CNN ) based regression method']]"
"[['CNN', 'to fit', '3D face model'], ['3D face model', 'with', 'specifically designed feature'], ['specifically designed feature', 'namely', 'Projected Normalized Coordinate Code ( PNCC )']]"
[]
"[['first attempt', 'to solve', '3D face alignment'], ['3D face alignment', 'with', 'CNN']]"
"[['training', 'of', '3DDFA'], ['pairs', 'of', '2D face images and 3D face models'], ['3DDFA', 'construct', 'face database'], ['face database', 'containing', 'pairs'], ['pairs', 'of', '2D face images and 3D face models']]"
"[['face profiling algorithm', 'to synthesize', '60 k + training samples'], ['60 k + training samples', 'across', 'large poses']]"
"[['synthesized samples', 'well simulate', 'face appearances'], ['face appearances', 'in', 'large poses'], ['synthesized samples', 'boost', 'performance'], ['performance', 'of', 'prior and our proposed face alignment algorithms']]"
[]
[]
"[['reduced', 'due to', 'initialization regeneration']]"
"[['training and testing errors', 'converge', 'fast'], ['fast', 'after', '2 iterations']]"
"[['updated', 'at', 'beginning of'], ['testing error', 'continues to', 'descend']]"
[]
"[['PDC', 'can not well model', 'fitting error'], ['PDC', 'converges to', 'unsatisfied result']]"
"[['WPDC', 'explicitly models', 'priority'], ['WPDC', 'explicitly models', 'adaptively optimizes'], ['priority', 'of', 'each parameter'], ['adaptively optimizes', 'with', 'parameter weights'], ['WPDC', 'leading to', 'best result'], ['adaptively optimizes', 'leading to', 'best result'], ['parameter weights', 'leading to', 'best result']]"
[]
"[['all the methods', 'benefits substantially from', 'face profiling'], ['face profiling', 'when dealing with', 'large poses']]"
"[['3DDFA', 'reaches', 'state of the art'], ['state of the art', 'above', 'all the 2D methods'], ['all the 2D methods', 'beyond', 'medium poses']]"
"[['minimum standard deviation', 'of', '3DDFA'], ['minimum standard deviation', 'demonstrates', 'robustness'], ['3DDFA', 'demonstrates', 'robustness'], ['robustness', 'to', 'pose variations']]"
"[['performance', 'of', '3DDFA']]"
[]
"[['performance', 'in', '[ 60 , 90 ]'], ['performance', 'in', 'standard deviation'], ['reduced', 'when considering', 'all the landmarks']]"
[]
"[['3 DDFA', 'demonstrates', 'competitive performance'], ['competitive performance', 'on', 'common set'], ['competitive performance', 'on', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'challenging set'], ['state - of - the - art performance', 'on', 'challenging set']]"
[]
[]
"[['novel deep learning framework', 'named', 'Multi - Center Learning ( MCL )'], ['novel deep learning framework', 'to exploit', 'strong correlations'], ['strong correlations', 'among', 'landmarks']]"
"[['multiple shape prediction layers', 'to predict', 'locations'], ['locations', 'of', 'landmarks'], ['each shape prediction layer', 'emphasizes on', 'detection'], ['detection', 'of', 'certain cluster of landmarks']]"
"[['loss', 'of', 'each landmark'], ['challenging landmarks', 'are', 'focused']]"
"[['model complexity', 'propose', 'model assembling method'], ['model assembling method', 'to integrate', 'multiple shape prediction layers'], ['multiple shape prediction layers', 'into', 'one shape prediction layer']]"
"[['entire framework', 'reinforces', 'learning process'], ['learning process', 'of', 'each landmark'], ['each landmark', 'with', 'low model complexity']]"
"[['Uniform scaling and translation', 'with', 'different extents'], ['different extents', 'on', 'face bounding boxes']]"
"[['training samples', 'augmented through', 'horizontal flip and JPEG compression']]"
"[['MCL', 'using', 'open source deep learning framework Caffe']]"
"[['input face patch', 'is', '50 50 grayscale image'], ['each pixel value', 'normalized to', '[ ?1 , 1 )'], ['each pixel value', 'normalized to', 'multiplying'], ['[ ?1 , 1 )', 'subtracting', '128']]"
"[['more complex model', 'needed for', 'labeling pattern'], ['labeling pattern', 'with', 'more facial landmarks'], ['512/512/1 , 024', 'for', '5/29/68 facial landmarks']]"
"[['type of solver', 'is', 'SGD'], ['SGD', 'with', 'mini-batch size'], ['mini-batch size', 'of', '64'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.0005'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.0005']]"
"[['maximum learning iterations', 'of', 'pre-training and each finetuning step'], ['initial learning rates', 'of', 'pre-training and each fine - tuning step'], ['pre-training and each finetuning step', 'are', '1810 4 and 610 4'], ['initial learning rates', 'of', 'pre-training and each fine - tuning step'], ['pre-training and each fine - tuning step', 'are', '0.02 and 0.001']]"
"[['learning rate', 'multiplied by', 'factor'], ['factor', 'of', '0.3'], ['0.3', 'at', 'every 3 10 4 iterations']]"
"[['MCL', 'against', 'state - of - the - art methods'], ['MCL', 'against', 'RecNet'], ['MCL', 'against', 'RAR'], ['MCL', 'against', 'FLD + PDE'], ['state - of - the - art methods', 'including', 'ESR'], ['state - of - the - art methods', 'including', 'SDM'], ['state - of - the - art methods', 'including', 'Cascaded CNN'], ['state - of - the - art methods', 'including', 'RCPR'], ['state - of - the - art methods', 'including', 'CFAN'], ['state - of - the - art methods', 'including', 'LBF'], ['state - of - the - art methods', 'including', 'c GPRT'], ['state - of - the - art methods', 'including', 'CFSS'], ['state - of - the - art methods', 'including', 'TCDCN'], ['state - of - the - art methods', 'including', 'ALR'], ['state - of - the - art methods', 'including', 'CFT'], ['state - of - the - art methods', 'including', 'RFLD'], ['state - of - the - art methods', 'including', 'RecNet'], ['state - of - the - art methods', 'including', 'RAR'], ['state - of - the - art methods', 'including', 'FLD + PDE']]"
"[['MCL', 'outperforms', 'most of the state - of - the - art methods'], ['most of the state - of - the - art methods', 'on', 'AFLW dataset']]"
"[['several challenging images', 'from', 'AFLW and COFW']]"
"[['MCL', 'demonstrates', 'superior capability']]"
"[['MCL', 'achieves', 'competitive performance'], ['competitive performance', 'on', 'all three benchmarks']]"
"[['average running speed', 'of', 'deep learning methods'], ['deep learning methods', 'for detecting', '68 facial landmarks']]"
[]
"[['BM', 'worse on', 'AFLW'], ['AFLW', 'than', 'pre-BM']]"
"[['Global Average Pooling', 'is', 'more advantageous'], ['more advantageous', 'for', 'more complex problems'], ['more complex problems', 'with', 'more facial landmarks']]"
[]
[]
[]
"[['left eye model and the right eye model', 'reduce', 'alignment errors'], ['alignment errors', 'of', 'corresponding clusters']]"
"[['assembled AM', 'improve', 'detection accuracy'], ['detection accuracy', 'of', 'landmarks'], ['landmarks', 'of', 'left eye and the right eye'], ['detection accuracy', 'of', 'landmarks'], ['landmarks', 'of', 'left eye and the right eye'], ['left eye and the right eye', 'on the basis of', 'WM']]"
"[['two models', 'improve', 'localization precision'], ['localization precision', 'of', 'other clusters']]"
[]
"[['accuracy', 'of', 'AM'], ['accuracy', 'superior to', 'Simplified AM'], ['AM', 'superior to', 'Simplified AM'], ['Simplified AM', 'especially on', 'challenging IBUG']]"
"[['improves slightly', 'on', 'COFW'], ['better solution', 'on', 'IBUG'], ['Weighting Simplified AM', 'fails to search', 'better solution'], ['better solution', 'on', 'IBUG']]"
"[['stronger robustness', 'than', 'BM and WM']]"
"[['localization accuracy', 'of', 'facial landmarks'], ['facial landmarks', 'from', 'each cluster']]"
[]
"[['correlations', 'among', 'different facial parts'], ['face alignment', 'especially for', 'partially occluded faces']]"
"[['testing faces', 'with', 'occlusions'], ['mean error results', 'of', 'WM and AM']]"
"[['results', 'of', 'landmarks'], ['results', 'of', 'remaining landmarks'], ['landmarks', 'from', 'left eye cluster'], ['remaining landmarks', 'from', 'other clusters'], ['results', 'of', 'remaining landmarks'], ['remaining landmarks', 'from', 'other clusters'], ['remaining landmarks', 'become', 'worse slightly'], ['other clusters', 'become', 'worse slightly']]"
"[['WM and AM', 'perform', 'well'], ['well', 'on', 'occluded left eyes'], ['occluded left eyes', 'with', 'mean error'], ['mean error', 'of', '6.60 and 6.50']]"
[]
"[['mean error', 'of', 're -DAN'], ['mean error', 'reduced from', '7.97 to 7.81'], ['7.97 to 7.81', 'after using', 'our proposed weighting fine - tuning']]"
[]
[]
"[['new framework', 'to augment', 'training'], ['training', 'for', 'facial landmark detection'], ['facial landmark detection', 'without using', 'extra knowledge']]"
"[['face images', 'into', 'space'], ['space', 'of', 'structure and style']]"
"[['conditional variational auto - encoder model', 'in which', 'Kullback - Leiber ( KL ) divergence loss and skip connections'], ['Kullback - Leiber ( KL ) divergence loss and skip connections', 'incorporated for', 'compact representation'], ['compact representation', 'of', 'style and structure']]"
"[['visual style translation', 'between', 'existing facial geometry']]"
"[['glasses', 'of', 'poor quality'], ['poor quality', 'under', 'blur or strong lighting'], ['blur or strong lighting', 'rerendered from', 'corresponding style'], ['facial landmark detectors', 'for', 'rather general and robust system'], ['rather general and robust system', 'to recognize', 'facial geometry']]"
"[['all images', 'cropped and resized to', '256 256'], ['256 256', 'using', 'provided bounding boxes']]"
"[['6 residual encoder blocks', 'for', 'downsampling'], ['6 residual encoder blocks', 'for downsampling', 'input feature maps'], ['input feature maps', 'where', 'batch normalization']]"
"[['training', 'of', 'disentangling step'], ['initial learning rate', 'of', '0.01'], ['disentangling step', 'use', 'Adam'], ['Adam', 'with', 'initial learning rate'], ['0.0001', 'with', 'no augmentation'], ['initial learning rate', 'of', '0.01'], ['0.01', 'descends', 'linearly'], ['linearly', 'to', '0.0001'], ['0.0001', 'with', 'no augmentation']]"
"[['detectors', 'augment', 'each landmark map'], ['each landmark map', 'with', 'k random styles'], ['k random styles', 'sampled from', 'other face images']]"
"[['simple baseline network', 'based on', 'ResNet - 18'], ['simple baseline network', 'chosen by changing', 'output dimension'], ['ResNet - 18', 'chosen by changing', 'output dimension'], ['output dimension', 'of', 'last FC layers'], ['increase', 'brought by', 'style translation']]"
[]
"[['light - weight Res - 18', 'improved by', '13.8 %']]"
"[['stronger baseline', 'achieves', '4.39 % NME'], ['our model', 'achieves', '4.39 % NME'], ['4.39 % NME', 'under', 'style - augmented training'], ['state - of the - art entries', 'by', 'large margin']]"
"[['our method', 'brings', '15.9 % improvement'], ['our method', 'brings', '9 % boost'], ['15.9 % improvement', 'to', 'SAN model'], ['9 % boost', 'to', 'LAB'], ['5.27 % NME', 'to', '4.76 %'], ['9 % boost', 'to', 'LAB'], ['9 % boost', 'from', '5.27 % NME'], ['LAB', 'from', '5.27 % NME'], ['5.27 % NME', 'to', '4.76 %']]"
"[['our model', 'based on', 'simple backbone']]"
[]
"[['our model', 'yields', '1.8 % and 3.1 % improvement'], ['1.8 % and 3.1 % improvement', 'on', 'LAB and SAN'], ['1.8 % and 3.1 % improvement', 'manifest', 'consistent benefit'], ['consistent benefit', 'when using', '"" style - augmented "" strategy']]"
[]
"[['Our model', 'performs', 'best'], ['Our model', 'performs', '2.82 % failure rate'], ['best', 'with', '4.43 % mean error'], ['best', 'with', '2.82 % failure rate']]"
[]
"[['style information', 'boosts', 'landmark detectors'], ['landmark detectors', 'with', 'large - scale training set']]"
"[['our method', 'improves', 'SAN baseline'], ['SAN baseline', 'in terms of', 'NME'], ['NME', 'on', 'Full set'], ['Full set', 'from', '6.94 % to 6.01 %']]"
"[['hidden face part', 'better modeled with', 'our strategy']]"
"[['style and structure', 'influences', 'quality']]"
"[['Style - augmented synthetic images', 'improve', ""detectors ' performance""], [""detectors ' performance"", 'by', 'large margin'], ['even larger', 'when', 'number of training images'], ['number of training images', 'is', 'quite small']]"
"[['number of random sampled styles k', 'of', 'each annotated landmarks'], ['each annotated landmarks', 'on', 'ResNet - 50 baseline']]"
[]
[]
[]
"[['novel face alignment method', 'dub', 'Deep Alignment Network ( DAN )']]"
"[['multistage neural network', 'where', 'each stage'], ['each stage', 'refines', 'landmark positions'], ['landmark positions', 'estimated at', 'previous stage'], ['landmark positions', 'iteratively improving', 'landmark locations']]"
"[['each stage', 'of', 'our algorithm'], ['dense layer', 'of', 'previous stage'], ['our algorithm', 'area', 'face image'], ['face image', 'normalized to', 'canonical pose'], ['face image', 'normalized to', 'image'], ['image', 'learned from', 'dense layer']]"
"[['entire face image', 'during', 'process'], ['process', 'of', 'face alignment']]"
"[['total of 10 images', 'created from', 'each input image'], ['each input image', 'in', 'training set']]"
"[['Training', 'performed using', 'Theano 0.9.0'], ['Training', 'performed using', 'Lasagne 0.2']]"
"[['optimization', 'use', 'Adam stochastic optimization'], ['Adam stochastic optimization', 'with', 'initial step size'], ['Adam stochastic optimization', 'with', 'mini batch size'], ['initial step size', 'of', '0.001'], ['mini batch size', 'of', '64'], ['mini batch size', 'of', '64']]"
"[['validation', 'use', 'random subset'], ['random subset', 'of', '100 images'], ['100 images', 'from', 'training set']]"
"[['Python implementation', 'runs at', '73 fps'], ['Python implementation', 'runs at', '45 fps'], ['73 fps', 'for', 'images'], ['45 fps', 'for', 'images'], ['images', 'processed in', 'parallel'], ['45 fps', 'for', 'images']]"
"[['failure rate reduction', 'of', '60 %'], ['60 %', 'on', '300 W private test set']]"
"[['failure rate reduction', 'of', '72 %'], ['72 %', 'on', '300W public test set']]"
"[['9 % improvement', 'of', 'mean error'], ['mean error', 'on', 'challenging subset']]"
[]
[]
[]
"[['DeCaFA', 'composed of', 'several stages'], ['landmark - wise attention maps', 'relatively to', 'heterogeneous annotation markups']]"
"[['refined', 'through', 'successive stages'], ['different prediction tasks', 'benefit from', 'each other']]"
"[['DeCaFA models', 'use', '1 to 4 stages'], ['12 3 3 convolutional layers', 'with', '64 ? 64 ? 128 ? 128 ? 256 ? 256 channels'], ['64 ? 64 ? 128 ? 128 ? 256 ? 256 channels', 'for', 'downsampling portion']]"
"[['input images', 'resized to', '128 128 grayscale images'], ['128 128 grayscale images', 'processed by', 'network']]"
"[['Each convolution', 'followed by', 'batch normalization layer'], ['batch normalization layer', 'with', 'ReLU activation']]"
"[['smooth feature maps', 'do not use', 'transposed convolution'], ['bilinear image upsampling', 'followed with', '3 3 convolutional layers']]"
"[['whole architecture', 'trained using', 'ADAM optimizer'], ['ADAM optimizer', 'with', '5e ? 4 learning rate'], ['ADAM optimizer', 'with', 'learning rate'], ['ADAM optimizer', 'with', 'learning rate annealing'], ['5e ? 4 learning rate', 'with', 'momentum 0.9'], ['learning rate annealing', 'with', 'power 0.9'], ['annealing', 'with', 'power 0.9'], ['5e ? 4 learning rate', 'with', 'momentum 0.9'], ['5e ? 4 learning rate', 'with', 'learning rate'], ['5e ? 4 learning rate', 'with', 'learning rate annealing'], ['learning rate annealing', 'with', 'power 0.9'], ['annealing', 'with', 'power 0.9']]"
"[['400000 updates', 'with', 'batch size'], ['400000 updates', 'with', 'batch size 8'], ['400000 updates', 'with', 'alternating updates'], ['batch size', 'for', 'each database'], ['batch size 8', 'for', 'each database'], ['8', 'for', 'each database'], ['400000 updates', 'with', 'alternating updates'], ['alternating updates', 'between', 'databases']]"
"[['accuracy', 'add', 'more stages'], ['steadily increases', 'add', 'more stages'], ['saturates', 'after', 'third'], ['third', 'on', 'LFPW and HELEN']]"
"[['Coarsely annotated data ( 5 landmarks )', 'significantly helps', 'fine - grained landmark localization']]"
"[['whole input image ( F 3 - Equation vs F 2 - Equation )', 'significantly improves', 'accuracy'], ['accuracy', 'on', 'challenging data'], ['challenging data', 'such as', '300 W - challenging'], ['challenging data', 'such as', 'WFLW - pose']]"
[]
"[['F 5 - Equation fusion', 'uses', 'local and global cues'], ['local and global cues', 'is', 'best'], ['best', 'by', 'significant margin']]"
"[['transfer layers', 'better than using', 'independant transfer layers'], ['first transfer layer', 'benefits from', 'gradients'], ['gradients', 'from', 'subsequents layer'], ['subsequents layer', 'at', 'train time']]"
[]
"[['DeCaFA', 'sets', 'new state - of - the - art'], ['new state - of - the - art', 'on', 'three databases']]"
[]
[]
[]
"[['Adaptive Wing loss', 'able to', 'significantly improve']]"
"[['convolution operation', 'in', 'bottom - up and top - down CNN structures'], ['bottom - up and top - down CNN structures', 'such as', 'stacked Hourglass ( HG )']]"
"[['boundaries', 'predicted from', 'previous HG module'], ['boundaries', 'into', 'our model']]"
"[['boundary coordinates', 'add', 'sub-task'], ['sub-task', 'of', 'boundary prediction'], ['boundary prediction', 'by concatenating', 'additional boundary channel'], ['additional boundary channel', 'into', 'ground truth heatmap'], ['ground truth heatmap', 'jointly trained with', 'other channels']]"
"[['training', 'use', 'RM - SProp'], ['RM - SProp', 'with', 'initial learning rate'], ['initial learning rate', 'of', '1 10 ?4']]"
"[['momentum', 'to be', '0'], ['weight decay', 'to be', '1 10 ?5']]"
"[['learning rate', 'reduced to', '1 10 ?5 and 1 10 ? 6'], ['1 10 ?5 and 1 10 ? 6', 'after', '80 and 160 epoches']]"
"[['Data augmentation', 'performed with', 'random rotation'], ['Data augmentation', 'performed with', 'translation'], ['Data augmentation', 'performed with', 'flipping'], ['Data augmentation', 'performed with', 'rescaling']]"
[]
[]
"[['Our method', 'able to achieve', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', '300W testing dataset']]"
"[['challenge subset ( iBug dataset )', 'able to', 'outperform']]"
"[['significant margin', 'proves', 'robustness'], ['robustness', 'of', 'our approach'], ['robustness', 'against', 'occlusion and large pose variation'], ['our approach', 'against', 'occlusion and large pose variation']]"
"[['previous state - of - theart', 'on', 'variant metrics'], ['300 W private test dataset', 'outperform', 'previous state - of - theart'], ['previous state - of - theart', 'on', 'variant metrics'], ['variant metrics', 'including', 'NME']]"
[]
"[['Our method', 'achieves', 'best results'], ['best results', 'on', 'WFLW dataset'], ['significantly more difficult', 'than', 'COFW and 300W']]"
"[['every subset', 'outperform', 'previous state - of - the - art']]"
"[['fails', 'on', '2.84 %'], ['2.84 %', 'of', 'all images'], ['two times improvement', 'compared with', '7.6']]"
[]
[]
"[['powerful representation', 'of', 'Convolutional Neural Network ( CNN )'], ['one regressor', 'to learn', 'descent directions'], ['descent directions', 'in', 'coarse and fine stages']]"
"[['discriminative landmarks features', 'proposed', 'Landmarks - Attention Network ( LAN )'], ['Landmarks - Attention Network ( LAN )', 'focuses on', 'appearance'], ['appearance', 'around', 'landmarks']]"
"[['holistic increment', 'significantly reduces', 'dimension'], ['holistic increment', 'significantly reduces', 'number of model parameters'], ['dimension', 'of', 'final feature layer'], ['dimension', 'of', 'number of model parameters']]"
"[['machine', 'with', 'Core i7 - 5930 k CPU'], ['machine', 'with', 'GTX 1080 GPU'], ['GTX 1080 GPU', 'with', '8G video memory'], ['GTX 1080 GPU', 'with', '8G video memory']]"
"[['detected faces', 'resized into', '256 256'], ['location patch size', 'is', '57 57']]"
"[['Rectified Linear Unit ( ReLU )', 'adopted as', 'activation function'], ['optimizer', 'is', 'Adadelta ( Zeiler 2012 ) approach'], ['learning rate', 'set to', '0.1'], ['weight decay', 'set to', '1']]"
"[['CNN', 'requires', 'around 2 days']]"
"[['NME results', 'shows', 'SIR'], ['SIR', 'comparatively with', 'RAR'], ['SIR', 'outperform', 'other existing methods']]"
"[['robust performance', 'In', 'large pose , expression and illumination environment'], ['our method', 'achieves', 'robust performance'], ['robust performance', 'in', 'large pose , expression and illumination environment']]"
"[['SIR method', 'outperform', 'state - of - the - art methods'], ['state - of - the - art methods', 'according to', 'CED curve']]"
[]
[]
[]
"[['well - defined facial boundaries', 'to represent', 'geometric structure'], ['geometric structure', 'of', 'human face']]"
"[['facial structure', 'using', '13 boundary lines']]"
"[['boundary - aware face alignment algorithm', 'contains', 'two stages']]"
[]
"[['adversarial learning ideas', 'by using', 'landmark - based boundary effectiveness discriminator']]"
"[['jointly learned', 'in', 'end - to - end manner']]"
"[['stacked hourglass structure', 'to estimate', 'facial boundary heatmap'], ['stacked hourglass structure', 'model', 'structure'], ['structure', 'between', 'facial boundaries'], ['facial boundaries', 'through', 'message passing'], ['message passing', 'to increase', 'robustness'], ['robustness', 'to', 'occlusion']]"
"[['boundary heatmaps', 'serve as', 'structure cue'], ['structure cue', 'to guide', 'feature learning'], ['feature learning', 'for', 'landmark regressor']]"
[]
[]
"[['Our method', 'performs', 'best'], ['best', 'among', 'all of the state - of - the - art methods']]"
[]
"[['improvement', 'for', 'extreme diversity of samples'], ['extreme diversity of samples', 'on', 'WFLW']]"
[]
"[['Our model', 'outperforms', 'previous results'], ['previous results', 'with', 'large margin']]"
"[['4.62 % mean error', 'with', '2.17 % failure rate']]"
"[['failure rate', 'significantly reduced by', '3.75 %']]"
"[['our method', 'uses', 'boundary information'], ['boundary information', 'achieves', '29 % , 32 % and 29 % relative performance improve- ment'], ['29 % , 32 % and 29 % relative performance improve- ment', 'over', 'baseline method']]"
"[['boundary map ( "" BM "" )', 'is', 'most effective one']]"
[]
"[['boundary information', 'in', 'all four levels'], ['boundary information', 'improves', 'mean error'], ['all four levels', 'improves', 'mean error'], ['mean error', 'from', '7.12 %']]"
"[['improved consistently', 'by fusing', 'boundary heatmaps'], ['boundary heatmaps', 'at', 'more levels']]"
"[['effectiveness', 'of', 'boundary information fusion'], ['boundary information fusion', 'rather than', 'network structure changes']]"
"[['effectiveness', 'of', 'using hourglass structure design']]"
[]
"[['Adversarial learning', 'improves', 'quality and effectiveness'], ['quality and effectiveness', 'of', 'boundary heatmaps']]"
[]
"[['robust and efficient face alignment algorithm', 'based on', 'coarse - to - fine cascade of ERTs']]"
"[['3 D face model', 'to', 'probability maps'], ['probability maps', 'produced by', 'CNN']]"
"[['ERT', 'implicitly imposes', 'prior face shape'], ['prior face shape', 'on', 'solution'], ['prior face shape', 'addressing', 'shortcomings'], ['shortcomings', 'of', 'deep models']]"
"[['coarse - to - fine structure', 'tackles', 'combinatorial explosion'], ['combinatorial explosion', 'of', 'parts deformation']]"
"[['initialization', 'by using', 'RANSAC - like procedure'], ['RANSAC - like procedure', 'increases', 'robustness']]"
"[['early stopping and better data augmentation techniques', 'for increasing', 'regularization'], ['regularization', 'when training', 'ERT and the CNN']]"
"[['Adam stochastic optimization', 'with', '? 1 = 0.9 , ? 2 = 0.999 and = 1 e ? 8 parameters']]"
"[['until convergence', 'with', 'initial learning rate ? = 0.001'], ['convergence', 'with', 'initial learning rate ? = 0.001']]"
"[['validation error', 'levels out for', '10 epochs'], ['validation error', 'multiply', 'learning rate'], ['10 epochs', 'multiply', 'learning rate'], ['learning rate', 'by', 'decay = 0.05']]"
"[['batch normalization', 'after', 'each convolution']]"
"[['All layers', 'contain', '68 filters'], ['68 filters', 'to describe', 'required landmark features']]"
"[['Gaussian filter', 'with', '? = 33'], ['Gaussian filter', 'to', 'output probability maps'], ['? = 33', 'to', 'output probability maps'], ['output probability maps', 'to stabilize', 'initialization'], ['output probability maps', 'to stabilize', 'initialization , g 0']]"
"[['coarse - to - fine ERT', 'with', 'Gradient Boosting algorithm']]"
"[['maximum of T = 20 stages', 'of', 'K = 50 regression trees per stage']]"
"[['depth', 'of', 'trees'], ['depth', 'set to', '4'], ['trees', 'set to', '4']]"
"[['number of tests', 'to choose', 'best split parameters'], ['best split parameters', 'set to', '200']]"
"[['each image', 'to set', 'face size'], ['face size', 'to set', '160160 pixels'], ['face size', 'to', '160160 pixels']]"
"[['Z = 25 initializations', 'in', 'robust soft POSIT scheme'], ['robust soft POSIT scheme', 'of', 'g 0']]"
"[['shapes', 'of', 'each face training image'], ['SA', 'of', 'at least N A = 60000 samples'], ['shapes', 'to create', 'set'], ['each face training image', 'to create', 'set'], ['shapes', 'of', 'each face training image'], ['set', 'of', 'at least N A = 60000 samples'], ['SA', 'of', 'at least N A = 60000 samples'], ['at least N A = 60000 samples', 'to train', 'cascade']]"
"[['overfitting', 'use', 'subsampling factor ? = 0.5'], ['subsampling factor ? = 0.5', 'in', 'ERT']]"
"[['CNN and the coarse - to - fine ensemble of trees', 'takes', '48 hours'], ['CNN and the coarse - to - fine ensemble of trees', 'using', 'dual Intel Xeon Silver 4114 CPU'], ['48 hours', 'using', 'NVidia GeForce GTX 1080 Ti ( 11 GB ) GPU'], ['48 hours', 'using', 'dual Intel Xeon Silver 4114 CPU'], ['dual Intel Xeon Silver 4114 CPU', 'at', '2.20 GHz'], ['2.20 GHz', 'with', 'batch size'], ['batch size', 'of', '32 images']]"
"[['3 DDE', 'better than', 'any other'], ['any other', 'providing', 'public implementation']]"
"[['improve', 'by', 'large margin'], ['other ERT methods', 'as', 'RCPR'], ['other ERT methods', 'as', 'ERT'], ['other ERT methods', 'as', 'c GPRT']]"
[]
"[['DAN and LAB', 'implement', 'cascade of CNN regressors'], ['regularization', 'obtained by using', 'cascade of ERT'], ['cascade of ERT', 'in', '3 DDE']]"
"[['Our approach', 'obtains', 'best overall performance'], ['best overall performance', 'in', 'indoor and outdoor subsets'], ['best overall performance', 'in', 'full subset'], ['indoor and outdoor subsets', 'of', 'private competition'], ['full subset', 'of', '300W public test set'], ['best overall performance', 'in', 'full subset'], ['full subset', 'of', '300W public test set']]"
"[['challenging subset', 'of', '300W public competition'], ['SHN', 'gets', 'better results'], ['better results', 'than', '3DDE']]"
"[['3D initialization', 'to achieve', 'top overall performance'], ['key', 'to achieve', 'top overall performance'], ['top overall performance', 'see', 'CNN + MS + DE'], ['CNN + 3D + DE', 'in', 'full subset']]"
"[['good performance', 'in presence of', 'large face rotations']]"
"[['large receptive fields', 'of', 'CNNs'], ['specially helpful', 'in', 'challenging situations']]"
"[['significative local improvements', 'in', 'difficult cases'], ['coarse - to - fine strategy', 'provides', 'significative local improvements'], ['significative local improvements', 'in', 'difficult cases'], ['significative local improvements', 'with', 'rare facial part combinations']]"
[]
[]
[]
"[['end - to - end method', 'called', 'Position map Regression Network ( PRN )'], ['Position map Regression Network ( PRN )', 'to jointly predict', 'dense alignment']]"
"[['UV position map', 'is', '2D image'], ['2D image', 'recording', '3D coordinates'], ['3D coordinates', 'of', 'complete facial point cloud'], ['UV position map', 'keeping', 'semantic meaning'], ['semantic meaning', 'at', 'each UV place']]"
"[['simple encoder - decoder network', 'with', 'weighted loss'], ['weighted loss', 'focuses more on', 'discriminative region'], ['focuses', 'more on', 'discriminative region'], ['discriminative region', 'to regress', 'UV position map'], ['UV position map', 'from', 'single 2 D facial image']]"
"[['optimization', 'use', 'Adam optimizer'], ['Adam optimizer', 'with', 'learning rate'], ['learning rate', 'begins at', '0.0001'], ['half', 'after', 'each 5 epochs']]"
"[['batch size', 'set as', '16']]"
"[['training codes', 'implemented with', 'TensorFlow']]"
[]
"[['state - of - the - art method 3D - FAN', 'when calculating', 'per distance'], ['per distance', 'with', '2D coordinates']]"
"[['performance discrepancy', 'between', 'our method and 3D - FAN']]"
"[['our method', 'robust to', 'change of pose and datasets']]"
"[['AFLW2000 - 3 D dataset', 'show', 'our predictions'], ['our predictions', 'are', 'more accurate'], ['more accurate', 'than', 'ground truth'], ['ground truth', 'in', 'some cases']]"
"[['our method', 'outperforms', 'best methods'], ['best methods', 'with', 'large margin'], ['large margin', 'of', 'more than 27 %'], ['more than 27 %', 'on', '2 D and 3D coordinates'], ['more than 27 %', 'on', 'AFLW2000 - 3D']]"
"[['Network', 'Network trained without using', 'weight mask'], ['Network', 'trained without using', 'weight mask'], ['worst performance', 'compared with', 'other two settings']]"
"[['weights', 'to', 'specific regions'], ['specific regions', 'such as', '68 facial landmarks'], ['specific regions', 'such as', 'central face region'], ['specific regions', 'such as', 'weight ratio'], ['weight ratio', 'shows', 'considerable improvement'], ['considerable improvement', 'on', '68 points datasets'], ['68 points datasets', 'over', 'weight ratio']]"
[]
[]
[]
[]
"[['novel learning method', 'leverages', '2D "" in - the - wild "" face images'], ['2D "" in - the - wild "" face images', 'to effectively supervise and facilitate', '3D face model learning']]"
"[['novel self - supervised learning method', 'able to train', '3 D face model'], ['3 D face model', 'with', 'weak supervision'], ['weak supervision', 'from', '2D images']]"
"[['2D landmarks', 'from', 'predicted 3D ones'], ['predicted 3D ones', 'via', 'direct 3D - to - 2D projection']]"
"[['cycle - consistency', 'over', '2D landmark predictions'], ['2D landmark predictions', 'taking', 'recovered 2D landmarks'], ['small difference', 'with', 'annotated ones']]"
[]
"[['proposed 2 DASL', 'implemented with', 'Pytorch']]"
"[['SGD optimizer', 'for', 'CNN regressor'], ['CNN regressor', 'with', 'learning rate'], ['Adam as optimizer', 'with', 'fixed learning rate 1 10 ?4'], ['learning rate', 'beginning at', '5 10 ?5'], ['SGD optimizer', 'decays', 'exponentially'], ['discriminator', 'uses', 'Adam as optimizer'], ['Adam as optimizer', 'with', 'fixed learning rate 1 10 ?4']]"
"[['two - stage strategy', 'to train', 'our model']]"
"[['first stage', 'train', 'model'], ['model', 'using', 'overall loss L.']]"
"[['our model', 'using', 'Vertex Distance Cost']]"
[]
"[['our 2 DASL', 'achieves', 'lowest NME ( % )'], ['2 D and 3D coordinates', 'among', 'all the methods']]"
"[['outperforms', 'by', 'large margin'], ['large margin', 'on', '68 spare landmarks'], ['large margin', 'on', 'dense coordinates']]"
"[['our method', 'achieves', 'lowest mean NME'], ['our method', 'achieves', 'lowest NME'], ['lowest mean NME', 'on', 'both of the two datasets'], ['all poses', 'on', 'AFLW2000 - 3D'], ['lowest NME', 'across', 'all poses'], ['all poses', 'on', 'AFLW2000 - 3D']]"
"[['Our 2DASL', 'performs', 'better'], ['better', 'than', 'PRNet'], ['Our 2DASL', 'reducing', 'NME'], ['NME', 'by', '0.09 and 0.08'], ['0.09 and 0.08', 'on', 'AFLW2000 - 3D and AFLW - LFPA']]"
"[['2 DASL', 'achieves', '0.2 lower NME'], ['0.2 lower NME', 'than', 'PRNet']]"
[]
"[['3D reconstruction results', 'of', '2 DASL'], ['2 DASL', 'outperforms', '3 DDFA'], ['3 DDFA', 'by', '0.39']]"
"[['weights', 'to', 'central points'], ['0.09', 'to', '0.23'], ['central points', 'of', 'facial landmarks'], ['facial landmarks', 'reduces', 'NME'], ['NME', 'by', '0.09'], ['0.23', 'on', 'two stages']]"
"[['self - critic learning', 'not used', 'NME'], ['increases', 'by', '0.04/0.18'], ['0.04/0.18', 'for', 'with / without weight mask']]"
"[['self - supervision scheme', 'reduce', 'NME'], ['NME', 'by', '0.1'], ['0.1', 'when', 'weight mask'], ['0.1', 'when', '0.23'], ['weight mask', 'used', '0.23'], ['0.23', 'if', 'weight mask']]"
"[['FLMs', 'as', 'input'], ['FLMs', 'accelerate', 'convergence'], ['input', 'accelerate', 'convergence'], ['convergence', 'of', 'training process']]"
[]
"[['novel Semantic Alignment method', 'reduces', ""' semantic ambiguity ' intrinsi-cally""]]"
"[[""' real ' ground - truth"", 'as', 'latent variable'], ['latent variable', 'to', 'optimize'], [""optimized ' real ' ground - truth"", 'supervises', 'landmark detection network training']]"
"[['probabilistic model', 'simultaneously search', ""' real ' ground - truth""], ['probabilistic model', 'train', 'landmark detection network'], ['landmark detection network', 'in', 'end - to - end way']]"
"[['prior model', 'to constrain', 'latent variable'], ['latent variable', 'close to', 'observations'], ['observations', 'of', ""' real ' ground truth""]]"
"[['likelihood model', 'to reduce', 'Pearson Chi-square distance'], ['Pearson Chi-square distance', 'between', 'expected and the predicted distributions'], ['expected and the predicted distributions', 'of', ""' real ' ground - truth""]]"
"[['heatmap', 'generated by', 'hourglass architecture'], ['hourglass architecture', 'represents', 'confidence'], ['confidence', 'of', 'each pixel']]"
"[['global heatmap correction unit ( GHCU )', 'maintains', 'global face shape constraint'], ['global heatmap correction unit ( GHCU )', 'recovers', 'unconfidently predicted landmarks'], ['unconfidently predicted landmarks', 'caused by', 'challenging factors'], ['challenging factors', 'such as', 'occlusions']]"
"[['data augmentation', 'randomly sample', 'angle of rotation and the bounding box scale'], ['angle of rotation and the bounding box scale', 'from', 'Gaussian distribution']]"
"[['four - stage stacked hourglass network', 'as', 'our backbone'], ['our backbone', 'trained by', 'optimizer RMSprop']]"
"[['roughly converged model', 'with', 'human annotations'], ['initial learning rate', 'is', '2.5 10 ?4'], ['initial learning rate', 'decayed to', '2.5 10 ? 6'], ['2.5 10 ?4', 'decayed to', '2.5 10 ? 6'], ['2.5 10 ? 6', 'after', '120 epochs']]"
"[['Semantic Alignment', 'from', 'beginning'], ['initial learning rate', 'is', '2.5 10 ? 6'], ['initial learning rate', 'divided by', '5 , 2 and 2'], ['5 , 2 and 2', 'at', 'epoch 30 , 60 and 90']]"
"[['batch size', 'to', '10'], ['10', 'for', 'network training']]"
"[['PyTorch', 'on', '2 Titan X GPUs']]"
[]
"[['HGs', 'with', 'our Semantic Alignment ( HGs + SA )'], ['4.37 % vs 5.04 %', 'in terms of', 'NME'], ['NME', 'on', 'Full set']]"
"[['GHCU', 'see that', 'HGs + SA + GHCU'], ['HGs + SA + GHCU', 'slightly outperforms', 'HGs + SA']]"
"[['in - plane - rotation', 'by training', 'preprocessing network'], ['state of the art performance', 'on', 'Challenge set and Full set']]"
"[['Challenge set', 'significantly outperform', 'state of the art method']]"
"[['68 facial points', 'contain', 'many weak semantic landmarks']]"
[]
[]
[]
[]
[]
"[['HGs + SA + GHCU', 'reduce', 'error rate ( RMSE )'], ['error rate ( RMSE )', 'by', '18 %'], ['18 %', 'on', 'Category 3 test set']]"
[]
"[['Semantic alignment', 'consistently improve', 'performance'], ['performance', 'on', 'all subset sets']]"
"[['GHCU', 'is', 'more effective'], ['more effective', 'on', 'challenge data set']]"
[]
"[['popular one - stage RetinaNet method', 'to perform', 'face detection']]"
"[['high performance face detector', 'namely', 'AInnoFace']]"
"[['two - step classification and regression', 'for', 'detection'], ['Intersection over Union ( IoU ) loss function', 'for', 'regression'], ['multi-scale testing strategy', 'for', 'inference'], ['Intersection over Union ( IoU ) loss function', 'for', 'regression'], ['data augmentation', 'based on', 'data - anchor - sampling'], ['data - anchor - sampling', 'for', 'training'], ['max - out operation', 'for', 'robuster classification'], ['multi-scale testing strategy', 'for', 'inference']]"
"[['backbone network', 'in', 'proposed AInnoFace detector'], ['proposed AInnoFace detector', 'initialized by', 'pretrained model'], ['pretrained model', 'on', 'ImageNet dataset']]"
"[['"" xavier "" method', 'to randomly initialize', 'parameters'], ['parameters', 'in', 'newly added convolutional layers']]"
"[['stochastic gradient descent ( SGD ) algorithm', 'to', 'batch size'], ['stochastic gradient descent ( SGD ) algorithm', 'fine - tune', 'model'], ['model', 'with', '0.9 momentum'], ['model', 'with', 'batch size']]"
"[['warmup strategy', 'applied to', 'gradually ramp up'], ['learning rate', 'from', '0.0003125'], ['0.0003125', 'to', '0.01'], ['0.01', 'at', 'first 5 epochs']]"
"[['regular learning rate schedule', 'dividing by', '10'], ['10', 'at', '100 and 120 epochs'], ['regular learning rate schedule', 'ending at', '130 epochs']]"
"[['full training and testing codes', 'built on', 'PyTorch library']]"
"[['some new state - of - the - art results', 'based on', 'AP score'], ['AP score', 'across', 'three subsets'], ['three subsets', 'on', 'validation and testing subsets'], ['96.5 % ( Easy ) , 95.7 % ( Medium ) and 91.2 % ( Hard )', 'for', 'testing subset']]"
"[['superiority', 'of', 'our AInnoFace detector']]"
[]
[]
"[['new multi-scale face detector', 'with', 'extremely tiny size ( EXTD )']]"
"[['network', 'in generating', 'each feature - map']]"
"[['backbone network', 'reduces', 'size'], ['size', 'of', 'feature map'], ['feature map', 'by', 'half'], ['backbone network', 'get', 'other feature maps'], ['other feature maps', 'with', 'recurrently passing']]"
"[['sharing', 'significantly reduce', 'number of parameters'], ['more layers', 'to generate', 'low - level feature maps'], ['low - level feature maps', 'used for detecting', 'small faces']]"
"[['proposed iterative architecture', 'makes', 'network'], ['network', 'to observe', 'features'], ['features', 'from', 'various scale of faces'], ['features', 'from', 'various layer locations'], ['proposed iterative architecture', 'offer', 'abundant semantic information'], ['abundant semantic information', 'to', 'network']]"
"[['baseline framework', 'follows', 'FPN - like structures'], ['baseline framework', 'applied to', 'SSD - like architecture']]"
[]
[]
"[['negative slope', 'of', 'Leaky - ReLU'], ['initial negative slope', 'of', 'PReLU'], ['Leaky - ReLU', 'set to', '0.25'], ['0.25', 'identical to', 'initial negative slope'], ['initial negative slope', 'of', 'PReLU']]"
"[['results', 'in', '138 times lighter'], ['138 times lighter', 'in', 'model size'], ['28.3 , 19.2 , and 11 times lighter', 'in', 'Madds'], ['results', 'are', '28.3 , 19.2 , and 11 times lighter'], ['138 times lighter', 'are', '28.3 , 19.2 , and 11 times lighter'], ['28.3 , 19.2 , and 11 times lighter', 'in', 'Madds']]"
"[['SOTA face detectors', 'such as', 'Pyra - midBox'], ['SOTA face detectors', 'such as', 'DSFD'], ['our best model EXTD - FPN - 64 - PReLU', 'achieved', 'lower results']]"
"[['margin', 'between', 'PyramidBox and the proposed model'], ['PyramidBox and the proposed model', 'on', 'WIDER FACE hard case'], ['WIDER FACE hard case', 'was', '3.4 %']]"
"[['m AP gap', 'to', 'DSFD']]"
"[['our SSD - based variations', 'got', 'lower mAP results'], ['lower mAP results', 'than', 'FPN - based variants']]"
"[['S3FD version', 'trained with', 'Mo - bile FaceNet backbone network'], ['proposed SSD variants', 'achieved', 'comparable or better detection performance']]"
"[['our method', 'achieved', 'higher performance'], ['higher performance', 'in', 'WIDER FACE hard dataset'], ['higher performance', 'than', 'other cases'], ['WIDER FACE hard dataset', 'than', 'other cases']]"
"[['FPN based architecture', 'achieved', 'better detection performance'], ['better detection performance', 'compared to', 'SSD based architecture'], ['better detection performance', 'especially for detecting', 'small faces'], ['SSD based architecture', 'especially for detecting', 'small faces']]"
"[['PReLU', 'outperformed', 'Leaky - ReLU'], ['Leaky - ReLU', 'with', 'larger margin']]"
"[['novel face detection network', 'with', 'three novel contributions']]"
[]
"[['Feature Enhance Module ( FEM )', 'to enhance', 'discriminability and robustness'], ['discriminability and robustness', 'of', 'features'], ['advantages', 'of', 'FPN'], ['discriminability and robustness', 'of', 'features'], ['advantages', 'of', 'FPN'], ['advantages', 'of', 'Receptive Field Block ( RFB )'], ['FPN', 'in', 'PyramidBox'], ['FPN', 'in', 'RFBNet'], ['Receptive Field Block ( RFB )', 'in', 'RFBNet'], ['FPN', 'in', 'RFBNet'], ['Receptive Field Block ( RFB )', 'in', 'RFBNet']]"
"[['Progressive Anchor Loss ( PAL )', 'uses', 'progressive anchor sizes'], ['progressive anchor sizes', 'for', 'different levels'], ['progressive anchor sizes', 'for', 'different shots']]"
"[['smaller anchor sizes', 'in', 'first shot'], ['larger sizes', 'in', 'second shot'], ['larger sizes', 'in', 'second shot']]"
"[['Improved Anchor Matching ( IAM )', 'integrates', 'anchor partition strategy'], ['anchor-based data augmentation', 'to better match', 'anchors and ground truth faces'], ['Improved Anchor Matching ( IAM )', 'provides', 'better initialization'], ['better initialization', 'for', 'regressor']]"
"[['proposed network', 'as', 'Dual Shot Face Detector ( DSFD )']]"
"[['backbone networks', 'initialized by', 'pretrained VGG / ResNet'], ['pretrained VGG / ResNet', 'on', 'Image Net']]"
"[[""newly added convolution layers ' parameters"", 'initialized by', ""' xavier ' method""]]"
"[['SGD', 'with', '0.9 momentum , 0.0005 weight decay'], ['0.9 momentum , 0.0005 weight decay', 'to fine - tune', 'DSFD model']]"
"[['batch size', 'set to', '16']]"
"[['learning rate', 'set to', '10 ?3'], ['10 ?3', 'for', 'first 40 k steps'], ['10 ? 4 and 10 ? 5', 'for', 'two 10 k steps'], ['learning rate', 'decay it to', '10 ? 4 and 10 ? 5'], ['10 ? 4 and 10 ? 5', 'for', 'two 10 k steps']]"
"[[""first shot 's outputs"", 'are', 'ignored'], ['second shot', 'predicts', 'top 5 k high confident detections']]"
"[['Non-maximum suppression', 'applied with', 'jaccard overlap'], ['jaccard overlap', 'of', '0.3'], ['0.3', 'to produce', 'top 750 high confident bounding boxes']]"
"[['4 bounding box coordinates', 'round down', 'top left coordinates'], ['4 bounding box coordinates', 'round down', 'roundup width and height'], ['roundup width and height', 'to expand', 'detection bounding box']]"
[]
[]
[]
"[['VGG16 - based FSSD', 'from', '92.6 % , 90.2 % , 79.1 %'], ['92.6 % , 90.2 % , 79.1 %', 'to', '93.0 % , 91.4 % , 84.6 %']]"
"[['Progressive Anchor Loss', 'use', 'Res50 - based FSSD'], ['Res50 - based FSSD', 'as', 'baseline'], ['Res50 - based FSSD', 'to add', 'progressive anchor loss'], ['baseline', 'to add', 'progressive anchor loss']]"
"[['progressive anchor loss', 'improve', 'Res50 - based FSSD'], ['Res50 - based FSSD', 'using', 'FEM'], ['FEM', 'from', '95.0 % , 94.1 % , 88.0 %'], ['95.0 % , 94.1 % , 88.0 %', 'to', '95.3 % , 94.4 % , 88.6 %']]"
[]
"[['Res101 based FSSD', 'using', 'FEM'], ['FEM', 'from', '95.8 % , 95.1 % , 89.7 %'], ['95.8 % , 95.1 % , 89.7 %', 'to', '96.1 % , 95.2 % , 90.0 %']]"
[]
"[['best performance', 'among', 'all of the state - of - the - art face detectors'], ['all of the state - of - the - art face detectors', 'based on', 'average precision ( AP )'], ['average precision ( AP )', 'across', 'three subsets'], ['96.0 % ( Easy ) , 95.3 % ( Medium ) and 90.0 % ( Hard )', 'on', 'test set']]"
[]
"[['DSFD', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'discontinuous and continuous ROC curves'], ['discontinuous and continuous ROC curves', 'i.e.', '99.1 % and 86.2 %'], ['99.1 % and 86.2 %', 'when', 'number of false positives'], ['number of false positives', 'equals to', '1 , 000']]"
"[['additional annotations', 'to', 'unlabeled faces'], ['false positives', 'of', 'our model']]"
[]
"[['unified deep neural network', 'denoted', 'multi -scale CNN ( MS - CNN )']]"
[]
"[['unified multi-scale deep CNN', 'denoted', 'multi -scale CNN ( MS - CNN )'], ['unified multi-scale deep CNN', 'for', 'fast object detection'], ['multi -scale CNN ( MS - CNN )', 'for', 'fast object detection']]"
[]
[]
"[['object detection', 'performed with', 'multiple output layers'], ['multiple output layers', 'focusing on', 'objects'], ['objects', 'within', 'certain scale ranges']]"
"[['complimentary detectors', 'at', 'different output layers'], ['complimentary detectors', 'to form', 'strong multi-scale detector']]"
"[['performance', 'of', 'MS - CNN detector'], ['MS - CNN detector', 'evaluated on', 'KITTI and Caltech Pedestrian benchmarks']]"
"[['detector', 'implemented in', 'C ++'], ['C ++', 'within', 'Caffe toolbox']]"
"[['implementation', 'on', 'single CPU core ( 2.40 GHz )'], ['single CPU core ( 2.40 GHz )', 'of', 'Intel Xeon E5 - 2630 server'], ['Intel Xeon E5 - 2630 server', 'with', '64 GB of RAM']]"
"[['NVIDIA Titan GPU', 'used for', 'CNN computations']]"
"[['MS - CNN', 'set', 'new record'], ['new record', 'detection of', 'pedestrians and cyclists']]"
"[['nontrivial margin', 'over', 'very recent SDP + RPN'], ['very recent SDP + RPN', 'used', 'scale depen - dent pooling']]"
[]
"[['MS - CNN', 'performs', 'very well'], ['very well', 'for', 'small and occluded objects'], ['very well', 'outperforming', 'DeepParts'], ['DeepParts', 'explicitly addresses', 'occlusion']]"
[]
[]
"[['weakly supervised multimodal annotation segmentation ( WSMA - Seg ) approach', 'uses', 'segmentation models'], ['segmentation models', 'to achieve', 'accurate and robust object detection'], ['accurate and robust object detection', 'without', 'NMS']]"
"[['weakly supervised bounding box annotations', 'In', 'detection tasks'], ['WSMA - Seg', 'converts', 'weakly supervised bounding box annotations'], ['weakly supervised bounding box annotations', 'in', 'detection tasks'], ['detection tasks', 'to', 'multi-channel segmentation - like masks'], ['multi-channel segmentation - like masks', 'called', 'multimodal annotations'], ['segmentation model', 'trained using', 'multimodal annotations'], ['multimodal annotations', 'as', 'labels'], ['labels', 'to learn', 'multimodal heatmaps'], ['multimodal heatmaps', 'for', 'training images']]"
"[['contours', 'In', 'objects'], ['resulting heatmaps', 'of', 'given test image'], ['circumscribed quadrilaterals', 'of', 'corresponding contours'], ['resulting heatmaps', 'converted into', 'instance - aware segmentation map'], ['instance - aware segmentation map', 'based on', 'pixel - level logic operation'], ['contour tracing operation', 'to generate', 'contours'], ['conducted', 'to generate', 'contours'], ['contours', 'for', 'objects'], ['objects', 'using', 'segmentation map'], ['bounding boxes', 'of', 'objects'], ['circumscribed quadrilaterals', 'of', 'corresponding contours'], ['bounding boxes', 'created as', 'circumscribed quadrilaterals'], ['circumscribed quadrilaterals', 'of', 'corresponding contours']]"
[]
"[['our proposed method', 'with', 'Stack = 2 , Base = 40 , Depth = 5'], ['Stack = 2 , Base = 40 , Depth = 5', 'achieved', 'best performance'], ['best performance', 'among', 'all solutions'], ['all solutions', 'in terms of', 'F1 Score']]"
"[['state - of - the - art baselines', 'is', 'much simpler'], ['WSMA - Seg', 'is', 'much simpler'], ['WSMA - Seg', 'is', 'more efficient']]"
[]
"[['WIDER Face', 'results in', 'much lower detection accuracy'], ['much lower detection accuracy', 'compared to', 'other face detection datasets']]"
"[['proposed WSMA - Seg', 'outperforms', 'state - of - the - art baselines'], ['state - of - the - art baselines', 'in', 'all three categories'], ['state - of - the - art baselines', 'reaching', '94.70 , 93.41 , and 87.23'], ['94.70 , 93.41 , and 87.23', 'in', 'Easy , Medium , and Hard categories']]"
[]
"[['WSMA - Seg approach', 'outperforms', 'all state - of - the - art baselines'], ['all state - of - the - art baselines', 'in terms of', 'most metrics'], ['most metrics', 'including', 'most challenging metrics'], ['most metrics', 'including', 'AP']]"
"[['performance', 'of', 'our proposed approach']]"
"[['proposed WSMA - Seg approach', 'achieves', 'more accurate and robust object detection'], ['more accurate and robust object detection', 'than', 'state - of - the - art approaches'], ['state - of - the - art approaches', 'without', 'NMS']]"
[]
[]
[]
"[['novel pixel - wise face localisation method', 'named', 'Reti- naFace'], ['novel pixel - wise face localisation method', 'employs', 'multi-task learning strategy'], ['multi-task learning strategy', 'to simultaneously predict', 'face score'], ['multi-task learning strategy', 'to simultaneously predict', 'face box'], ['multi-task learning strategy', 'to simultaneously predict', 'five facial landmarks'], ['multi-task learning strategy', 'to simultaneously predict', '3D position and correspondence'], ['3D position and correspondence', 'of', 'each facial pixel']]"
[]
"[['RetinaFace', 'using', 'SGD optimiser'], ['momentum', 'at', '0.9'], ['weight decay', 'at', '0.0005'], ['weight decay', 'at', '0.0005'], ['batch size', 'of', '8 4']]"
"[['learning rate', 'starts from', '10 ? 3'], ['learning rate', 'rising to', '10 ? 2'], ['10 ? 3', 'rising to', '10 ? 2'], ['10 ? 2', 'after', '5 epochs'], ['learning rate', 'divided by', '10'], ['5 epochs', 'divided by', '10'], ['10', 'at', '55 and 68 epochs']]"
"[['training process', 'terminates at', '80 epochs']]"
[]
"[['WIDER FACE', 'follow', 'standard practices'], ['WIDER FACE', 'employ', 'flip']]"
"[['Box voting', 'applied on', 'union set'], ['union set', 'of', 'predicted face boxes'], ['predicted face boxes', 'using', 'IoU threshold'], ['IoU threshold', 'at', '0.4']]"
"[['face box AP ( 0.408 % ) and mAP ( 0.775 % )', 'on', 'Hard subset']]"
"[['dense regression branch', 'increases', 'face box AP'], ['face box AP', 'on', 'Easy and Medium subsets'], ['results', 'on', 'Hard subset'], ['results', 'on', 'Hard subset']]"
"[['landmark and dense regression', 'enables', 'further improvement'], ['jointly', 'enables', 'further improvement']]"
[]
"[['RetinaFace', 'produces', 'best AP'], ['best AP', 'in', 'all subsets']]"
"[['Reti - na Face', 'sets up', 'new impressive record ('], ['new impressive record (', 'on', 'Hard subset'], ['91.4 % v.s. 90.3 % )', 'on', 'Hard subset'], ['Hard subset', 'which contains', 'large number of tiny faces']]"
"[['RetinaFace', 'successfully finds', 'about 900 faces ( threshold at 0.5 )'], ['about 900 faces ( threshold at 0.5 )', 'out of', 'reported 1 , 151 faces']]"
[]
"[['RetinaFace', 'significantly decreases', 'normalised mean errors ( NME )'], ['normalised mean errors ( NME )', 'from', '2.72 % to 2.21 %'], ['normalised mean errors ( NME )', 'compared to', 'MTCNN'], ['2.72 % to 2.21 %', 'compared to', 'MTCNN']]"
"[['RetinaFace', 'significantly decreases', 'failure rate'], ['failure rate', 'from', '26.31 %']]"
[]
"[['dense regression results', 'of', 'RetinaFace'], ['dense regression results', 'comparable with', 'state - of - the - art methods']]"
"[['five facial landmarks regression', 'alleviate', 'training difficulty'], ['training difficulty', 'of', 'dense regression branch'], ['five facial landmarks regression', 'significantly improve', 'dense regression results']]"
"[['single - stage features', 'to predict', 'dense correspondence parameters'], ['dense correspondence parameters', 'is', 'much harder'], ['much harder', 'than', 'employing'], ['much harder', 'than', '( Region of Interest ) RoI features']]"
[]
"[['CFP - FP', 'demonstrate', 'Reti - na Face'], ['Reti - na Face', 'boost', ""ArcFace 's verification accuracy""], [""ArcFace 's verification accuracy"", 'from', '98.37 %']]"
[]
"[['large - scale face detection dataset', 'called', 'WIDER FACE']]"
"[['32 , 203 images', 'with', '393 , 703 labeled faces'], ['10 times larger', 'than', 'current largest face detection dataset']]"
"[['faces', 'vary largely in', 'appearance , pose , and scale']]"
[]
"[['VJ , ACF , DPM , and Faceness', 'as', 'baselines']]"
[]
"[['Faceness', 'outperforms', 'other methods'], ['other methods', 'on', 'three subsets'], ['other methods', 'with', 'DPM and ACF'], ['three subsets', 'with', 'DPM and ACF']]"
"[['average precision ( AP )', 'of', 'most methods'], ['most methods', 'are', 'over 60 %']]"
"[['10 %', 'for', 'all methods'], ['drops', 'on', 'medium set'], ['10 %', 'on', 'medium set'], ['all methods', 'on', 'medium set']]"
"[['hard set', 'is', 'even more challenging']]"
[]
"[['results', 'of', 'small scale'], ['small scale', 'are', 'abysmal']]"
[]
[]
"[['maximum AP', 'is', 'only 26.5 %'], ['maximum AP', 'is', '26.5 %'], ['only 26.5 %', 'achieved by', 'Faceness'], ['26.5 %', 'achieved by', 'Faceness']]"
[]
"[['best performance', 'achieved by', 'Faceness'], ['Faceness', 'with', 'recall'], ['recall', 'below', '20 %']]"
[]
[]
"[['state - of - the - art face detector', 'with', 'real - time speed'], ['real - time speed', 'on', 'CPU']]"
"[['novel face detector', 'named', 'FaceBoxes'], ['novel face detector', 'trained', 'end - to - end']]"
"[['lightweight yet powerful network structure', 'consists of', 'Rapidly Digested Convolutional Layers ( RDCL )'], ['lightweight yet powerful network structure', 'consists of', 'Multiple Scale Convolutional Layers ( MSCL )']]"
"[['RDCL', 'designed to enable', 'FaceBoxes'], ['FaceBoxes', 'to achieve', 'real - time speed'], ['real - time speed', 'on', 'CPU'], ['MSCL', 'aims at', 'enriching'], ['MSCL', 'discretizing', 'anchors'], ['anchors', 'over', 'different layers'], ['different layers', 'to handle', 'various scales']]"
"[['new anchor densification strategy', 'to make', 'different types of anchors'], ['different types of anchors', 'have', 'same density'], ['same density', 'on', 'input image'], ['same density', 'significantly improves', 'recall rate'], ['recall rate', 'of', 'small faces']]"
"[['most boxes', 'by', 'confidence threshold'], ['confidence threshold', 'of', '0.05'], ['jaccard overlap', 'of', '0.3'], ['top 400 boxes', 'before applying', 'NMS'], ['NMS', 'with', 'jaccard overlap'], ['jaccard overlap', 'of', '0.3'], ['NMS', 'keep', 'top 200 boxes']]"
"[['speed', 'using', 'Titan X ( Pascal )'], ['speed', 'using', 'cuDNN v 5.1'], ['cuDNN v 5.1', 'with', 'Intel Xeon E5-2660v3@2.60 GHz']]"
[]
"[['density', 'of', 'small anchors ( i.e. , 32 32 and 64 64 )'], ['small anchors ( i.e. , 32 32 and 64 64 )', 'to improve', 'recall rate'], ['recall rate', 'of', 'small faces']]"
"[['m AP', 'on', 'FDDB'], ['m AP', 'reduced from', '96.0 %'], ['96.0 %', 'to', '94.9 %'], ['94.9 %', 'after ablating', 'anchor densification strategy']]"
"[['RDCL', 'is', 'efficient and accuracy - preserving']]"
[]
"[['our FaceBoxes', 'outperforms', 'all others'], ['all others', 'by', 'large margin']]"
[]
"[['Our method', 'significantly outperforms', 'all other methods'], ['Our method', 'significantly outperforms', 'commercial face detectors']]"
[]
"[['Our FaceBoxes', 'achieves', 'state - of - the - art performance'], ['Our FaceBoxes', 'achieves', 'outperforms'], ['outperforms', 'by', 'large margin'], ['all others', 'by', 'large margin'], ['large margin', 'on', 'discontinuous and continuous ROC curves']]"
[]
"[['novel framework', 'based on', 'CNNs'], ['CNNs', 'for', 'simultaneous face detection'], ['CNNs', 'for', 'head pose estimation'], ['CNNs', 'for', 'gender recognition']]"
"[['CNN architecture', 'to learn', 'common features'], ['CNN architecture', 'exploit', 'synergy']]"
"[['intermediate layer features', 'as', 'hyperfeatures']]"
"[['separate fusion - CNN', 'to fuse', 'hyperfeatures']]"
"[['tasks', 'train them', 'simultaneously'], ['simultaneously', 'using', 'multiple loss functions']]"
"[['deep CNN', 'combined with', 'fusion - CNN']]"
[]
"[['both HyperFace and HF - ResNet', 'outperform', 'all the reported academic and commercial detectors'], ['all the reported academic and commercial detectors', 'on', 'AFW and PASCAL datasets']]"
"[['HyperFace', 'achieves', 'high mean average precision ( m AP )'], ['high mean average precision ( m AP )', 'of', '97.9 % and 92.46 %'], ['97.9 % and 92.46 %', 'for', 'AFW and PASCAL datasets']]"
"[['HF - ResNet', 'improves', 'm AP'], ['m AP', 'to', '99.4 % and 96.2 %']]"
"[['HyperFace performance', 'comparable to', 'recently published deep learning - based face detection methods'], ['Faceness', 'on', 'FDDB dataset'], ['m AP', 'of', '90.1 %']]"
"[['multitask CNNs ( Multitask Face and HyperFace )', 'outperform', 'R - CNN Face'], ['R - CNN Face', 'by', 'wide margin']]"
[]
"[['HyperFace', 'performs', 'consistently accurate']]"
"[['R - CNN Fiducial and Multitask Face', 'attain', 'similar performance']]"
"[['HF - ResNet', 'significantly improves', 'performance'], ['performance', 'over', 'HyperFace'], ['HyperFace', 'for', 'AFW and AFLW datasets']]"
"[['HyperFace', 'achieves', 'comparable NME'], ['comparable NME', 'of', '10.88'], ['NME', 'of', '8.18'], ['HF - ResNet', 'achieves', 'state - of - theart result'], ['state - of - theart result', 'on', 'IBUG'], ['IBUG', 'with', 'NME'], ['NME', 'of', '8.18']]"
[]
"[['both HyperFace and HF - ResNet', 'outperform', 'existing methods'], ['existing methods', 'by', 'large margin']]"
"[['HF - ResNet', 'further improves', 'performance'], ['performance', 'for', 'roll , pitch'], ['performance', 'for', 'yaw'], ['performance', 'as well as', 'yaw']]"
[]
"[['our method', 'outperforms', 'PANDA and FaceTracer']]"
"[['HF - ResNet', 'achieves', 'state - of - the - art results'], ['state - of - the - art results', 'on', 'CelebA and LFWA datasets']]"
"[['HyperFace', 'with', 'linear bounding box regression'], ['traditional NMS', 'achieves', 'm AP'], ['m AP', 'of', '94 %']]"
[]
[]
"[['semi-supervised solution', 'to generate', 'approximate labels'], ['approximate labels', 'for', 'contextual parts'], ['contextual parts', 'related to', 'faces'], ['series of anchors', 'called', 'PyramidAnchors']]"
"[['performance', 'of', 'Feature Pyramid Networks ( FPN )'], ['Low - level Feature Pyramid Network ( LFPN )', 'to join', 'mutually helpful features']]"
"[['Context - sensitive prediction module ( CPM )', 'to incorporate', 'context information'], ['context information', 'around', 'target face'], ['context information', 'with', 'wider and deeper network'], ['target face', 'with', 'wider and deeper network']]"
"[['max - in - out layer', 'for', 'prediction module'], ['max - in - out layer', 'to further improve', 'capability'], ['prediction module', 'to further improve', 'capability'], ['capability', 'of', 'classification network']]"
"[['training strategy', 'named as', 'Data - anchor - sampling'], ['Data - anchor - sampling', 'to make', 'adjustment'], ['adjustment', 'on', 'distribution'], ['distribution', 'of', 'training dataset']]"
[]
"[['PyramidBox', 'achieves', 'state - ofart performance']]"
[]
"[['outperforms', 'across', 'all three subsets'], ['others', 'across', 'all three subsets'], ['outperforms', 'i.e.', '0.961 ( easy )'], ['all three subsets', 'i.e.', '0.961 ( easy )'], ['outperforms', 'for', 'testing set']]"
[]
[]
[]
[]
"[['designed region - based CNN architecture', 'allows', 'network'], ['network', 'simultaneously look at', 'multi-scale features'], ['designed region - based CNN architecture', 'explicitly look outside', 'facial regions'], ['facial regions', 'as', 'potential body regions']]"
"[['global semantic features', 'in', 'high level layers'], ['localization features', 'in', 'low level layers'], ['localization features', 'in', 'low level layers'], ['localization features', 'for', 'facial representation'], ['low level layers', 'for', 'facial representation']]"
"[['CMS - RCNN method', 'introduces', 'Multi - Scale Region Proposal Network ( MS - RPN )'], ['CMS - RCNN method', 'introduces', 'Contextual Multi - Scale Convolution Neural Network ( CMS - CNN )'], ['Multi - Scale Region Proposal Network ( MS - RPN )', 'to generate', 'Contextual Multi - Scale Convolution Neural Network ( CMS - CNN )'], ['Contextual Multi - Scale Convolution Neural Network ( CMS - CNN )', 'to do', 'inference'], ['inference', 'on', 'region candidates'], ['region candidates', 'of', 'facial regions']]"
"[['CMS - RCNN', 'implemented in', 'Caffe deep learning framework']]"
"[['first 5 sets of convolution layers', 'have', 'same architecture'], ['same architecture', 'as', 'deep VGG - 16 model'], ['first 5 sets of convolution layers', 'during', 'training'], ['parameters', 'initialized from', 'pre-trained VGG - 16']]"
"[['MS - RPN', 'want', ""' conv3 ' , ' conv4 ' , and ' conv5 '""], [""' conv3 ' , ' conv4 ' , and ' conv5 '"", 'to be', 'synchronized'], ['synchronized', 'to', 'same size']]"
"[['conv3', 'followed by', 'pooling layer'], ['pooling layer', 'to perform', 'down - sampling']]"
"[['normalized', 'along', 'channel axis'], ['normalized', 'to', 'concatenated together'], ['channel axis', 'to', 'learnable re-weighting scale'], ['channel axis', 'to', 'concatenated together']]"
"[['initial re-weighting scale', 'needs to be', 'carefully set']]"
"[['initial scale', 'of', ""' conv3 ' , ' conv4 ' , and ' conv5 '""], [""' conv3 ' , ' conv4 ' , and ' conv5 '"", 'to be', '66.84 , 94.52 , and 94.52']]"
"[['RoI pooling layer', 'ensure that', 'pooled feature maps'], ['pooled feature maps', 'have', 'same size']]"
"[['features', 'pooled from', ""' conv3 ' , ' conv4 ' , and ' conv5 '""], [""' conv3 ' , ' conv4 ' , and ' conv5 '"", 'initialized with', 'scale'], ['scale', 'to be', '57.75 , 81.67 , and 81.67'], ['57.75 , 81.67 , and 81.67', 'for', 'face and body pipelines']]"
"[['MS - RPN and the CMS - CNN', 'share', 'same parameters'], ['same parameters', 'for', 'all convolution layers'], ['computation', 'resulting in', 'higher efficiency'], ['once', 'resulting in', 'higher efficiency']]"
"[['channel size', 'of', 'concatenated feature map']]"
[]
"[['best average precision', 'in', 'all level faces'], ['best average precision', 'outperforms', 'second best baseline'], ['second best baseline', 'by', '26.0 % ( Easy )']]"
[]
"[['Our method', 'achieves', 'best recall rate']]"
"[['proposed CMS - RCNN approach', 'outperforms', 'most of the published face detection methods'], ['proposed CMS - RCNN approach', 'achieves', 'very high recall rate'], ['very high recall rate', 'comparing against', 'all other methods']]"
[]
"[['detailed design Faster RCNN method', 'named', 'FDNet1.0'], ['detailed design Faster RCNN method', 'for', 'face detection'], ['FDNet1.0', 'for', 'face detection'], ['detailed design Faster RCNN method', 'achieves', 'more decent performance'], ['more decent performance', 'than', 'previous methods']]"
"[['deformable layer', 'with', 'fewer channels'], ['fewer channels', 'attached to', 'backbone network'], ['backbone network', 'to produce', '"" thin "" feature map'], ['"" thin "" feature map', 'fed to', 'full connected layer'], ['full connected layer', 'building', 'efficient yet accurate two - stage detector']]"
"[['NMS', 'in', 'RPN stage'], ['RPN stage', 'over', 'WIDER FACE dataset']]"
[]
"[['Single NVIDIA Tesla K80', 'used for', 'training and testing']]"
"[['Mini batch size', 'set to', '1'], ['1', 'considering', 'memory consumption']]"
"[['ResNet_v1_101', 'trained on', 'ImageNet - 128w'], ['ImageNet - 128w', 'used for', 'Faster RCNN feature extraction']]"
"[['carefully designed', 'to capture', 'better locations'], ['faces', 'in', 'RPN stage'], ['number of filters', 'for', 'RPN layer']]"
"[['batch size', 'of', 'RPN and R - CNN'], ['RPN and R - CNN', 'assigned as', '256 and 128']]"
"[['initial learning rate', 'set to', '1e - 3'], ['initial learning rate', 'decrease to', '1e - 4'], ['1e - 4', 'after', '20w iterations']]"
"[['momentum', 'set to', '1e - 4 and 0.9']]"
"[['FDNet1.0', 'wins', 'one 2nd place ( hard set = 87.9 % )'], ['one 2nd place ( hard set = 87.9 % )', 'on', 'validation set']]"
[]
[]
"[['effects', 'of', 'two - step classification and regression'], ['two - step classification and regression', 'propose', 'novel face detection framework'], ['novel face detection framework', 'named', 'Selective Refinement Network ( SRN )'], ['Selective Refinement Network ( SRN )', 'selectively applies', 'two - step classification and regression'], ['two - step classification and regression', 'to', 'specific levels of detection layers']]"
"[['SRN', 'consists of', 'two key modules'], ['two key modules', 'named as', 'Selective Two - step Classification ( STC ) module'], ['two key modules', 'named as', 'Selective Two - step Regression ( STR ) module']]"
"[['STC', 'applied to', 'filter out'], ['detection layers', 'contains', '88.9 % samples']]"
"[['Receptive Field Enhancement ( RFE )', 'to provide', 'more diverse receptive fields'], ['more diverse receptive fields', 'to better capture', 'extreme - pose faces']]"
"[['loss function', 'for', 'SRN'], ['loss function', 'sum of', 'STC loss and the STR loss'], ['SRN', 'sum of', 'STC loss and the STR loss'], ['SRN', 'sum of', 'STR loss']]"
"[['backbone network', 'initialized by', 'pretrained ResNet - 50 model'], ['all the parameters', 'in', 'newly added convolution layers'], ['newly added convolution layers', 'initialized by', '"" xavier "" method']]"
"[['SRN model', 'using', 'SGD'], ['SRN model', 'using', 'batch size'], ['SGD', 'with', '0.9 momentum'], ['SGD', 'with', 'batch size']]"
"[['learning rate', 'to', '10 ?2'], ['10 ?2', 'for', 'first 100 epochs'], ['10 ? 3 and 10 ? 4', 'for', 'another 20 and 10 epochs'], ['10 ? 3 and 10 ? 4', 'for', 'another 20 and 10 epochs']]"
"[['SRN', 'using', 'Py - Torch library']]"
[]
"[['state - of - the - art methods', 'with', 'top AP score ( 99.87 % )']]"
[]
"[['SRN', 'achieves', 'state - of - the - art results'], ['state - of - the - art results', 'by improving', '4.99 % AP score'], ['4.99 % AP score', 'compared to', 'second best method STN']]"
[]
"[['our SRN', 'sets', 'new state - of - the - art performance'], ['new state - of - the - art performance', 'i.e.', '98.8 % true positive rate'], ['98.8 % true positive rate', 'when', 'number of false positives'], ['number of false positives', 'equal to', '1000']]"
[]
"[['SRN', 'performs', 'favourably'], ['favourably', 'against', 'state - of - the - art'], ['state - of - the - art', 'based on', 'average precision ( AP )'], ['average precision ( AP )', 'across', 'three subsets']]"
[]
[]
[]
"[['variant of channel features', 'called', 'aggregate channel features'], ['aggregate channel features', 'extracted directly as', 'pixel values'], ['pixel values', 'on', 'subsampled channels']]"
"[['aggregate channel features', 'breakthrough', 'bottleneck'], ['bottleneck', 'in', 'VJ framework'], ['great advance', 'in', 'face detection'], ['great advance', 'in', 'face detection']]"
"[['deep and all - round investigation', 'into', 'specific feature parameters'], ['specific feature parameters', 'concerning', 'channel types'], ['specific feature parameters', 'concerning', 'subsampling method'], ['specific feature parameters', 'concerning', 'feature scale']]"
"[['feature representation', 'enriches', 'representation capacity'], ['different combinations of channel types', 'impact', 'performance'], ['color channel', 'in', 'LUV space'], ['RGB space', 'show', 'best result']]"
"[['our multi-scale detector', 'achieves', 'ap value'], ['ap value', 'of', '96.8 %'], ['ap value', 'outperforming', 'other academic methods'], ['other academic methods', 'by', 'large margin']]"
"[['commercial systems', 'better than', 'Face.com'], ['ours', 'better than', 'Face.com'], ['commercial systems', 'almost equal to', 'Face ++ and Google Picasa'], ['ours', 'almost equal to', 'Face ++ and Google Picasa']]"
"[['discrete score', 'where', 'evaluation metric'], ['our detector', 'achieves', '83.7 %']]"
"[['continuous score', 'takes', 'overlap ratio'], ['overlap ratio', 'as', 'score'], ['continuous score', 'gets', '61.9 % true positive rate'], ['our method', 'gets', '61.9 % true positive rate'], ['61.9 % true positive rate', 'at', '1 FPPI'], ['1 FPPI', 'for', 'multiscale version'], ['61.9 % true positive rate', 'surpassing', 'other methods'], ['other methods', 'which output', 'rectangular detections'], ['rectangular detections', 'by', 'notable margin']]"
"[['Our detector', 'using', 'single - scale features'], ['single - scale features', 'performs', 'little worse'], ['little worse', 'benefit of', 'faster detection speed']]"
[]
[]
"[['new cascade Convolutional Neural Network', 'trained', 'end - to - end']]"
"[['first stage', 'is', 'multi-task Region Proposal Network ( RPN )'], ['multi-task Region Proposal Network ( RPN )', 'simultaneously proposes', 'candidate face regions'], ['candidate face regions', 'along with', 'associated facial landmarks']]"
[]
"[['network', 'calculated on', 'original resolution'], ['original resolution', 'to better leverage', 'more discriminative information']]"
"[['aligned candidate face region', 'fed into', 'second - stage network'], ['second - stage network', 'for', 'further verification'], ['RCNN', 'for', 'further verification']]"
"[['K face candidate regions', 'with', 'top responses'], ['top responses', 'in', 'local neighborhood'], ['local neighborhood', 'from', 'RPN']]"
"[['feature maps', 'from', 'two cascaded networks'], ['two cascaded networks', 'to form', 'architecture'], ['architecture', 'trained', 'end - to - end']]"
"[['canonical positions', 'of', 'facial landmarks'], ['facial landmarks', 'in', 'aligned face image'], ['predicted facial landmarks', 'in', 'candidate face region'], ['predicted facial landmarks', 'in', 'candidate face region'], ['predicted facial landmarks', 'jointly defines', 'transform'], ['candidate face region', 'jointly defines', 'transform'], ['transform', 'from', 'candidate face region']]"
"[['annotated facial landmarks', 'In', 'each true face regions'], ['training', 'of', 'first - stage RPN'], ['first - stage RPN', 'to predict', 'facial landmarks'], ['facial landmarks', 'supervised by', 'annotated facial landmarks'], ['annotated facial landmarks', 'in', 'each true face regions']]"
[]
"[['region - of - interest ( ROI ) convolution scheme', 'to make', 'run-time'], ['run-time', 'of', 'Supervised Transformer Network'], ['run-time', 'to be', 'more efficient'], ['Supervised Transformer Network', 'to be', 'more efficient']]"
"[['conventional boosting cascade', 'to obtain', 'set of face candidate areas']]"
"[['regions', 'into', 'irregular binary ROI mask']]"
"[['DNN operations', 'processed inside', 'ROI mask'], ['DNN operations', 'significantly reduce', 'computation']]"
"[['feature combination', 'bring about', '1 % , 1 % , and 2 % recall improvement']]"
"[['anyone part', 'will cause', 'recall drop']]"
"[['NMS', 'tend to include', 'too much noisy low confidence candidates']]"
"[['very close', 'using', 'all candidates'], ['Our non - top K suppression', 'achieved', 'consistently better results'], ['consistently better results', 'than', 'NMS'], ['consistently better results', 'under', 'same number of candidates'], ['NMS', 'under', 'same number of candidates']]"
"[['FDDB dataset', 'compare with', 'all public methods']]"
[]
[]
[]
[]
"[['face detection with arbitrary facial variations', 'as', 'unconstrained face detection problem']]"
"[['simple pixel - level feature', 'called', 'Normalized Pixel Difference ( NPD )']]"
"[['NPD', 'computed as', 'ratio'], ['ratio', 'of', 'difference'], ['difference', 'between', 'any two pixel intensity values']]"
"[['several desirable properties', 'such as', 'scale invariance'], ['several desirable properties', 'such as', 'boundedness'], ['several desirable properties', 'such as', 'ability'], ['ability', 'to reconstruct', 'original image']]"
"[['NPD features', 'obtained from', 'lookup table'], ['face detection template', 'easily scaled for', 'multiscale face detection']]"
"[['deep quadratic tree learning method', 'construct', 'single soft - cascade AdaBoost classifier'], ['single soft - cascade AdaBoost classifier', 'to handle', 'complex face manifolds'], ['single soft - cascade AdaBoost classifier', 'to handle', 'arbitrary pose and occlusion conditions']]"
"[['different types of faces', 'automatically divided into', 'different leaves'], ['different leaves', 'of', 'tree classifier'], ['complex face manifold', 'in', 'high dimensional space'], ['high dimensional space', 'partitioned in', 'learning process']]"
"[['divide and conquer "" strategy', 'to tackle', 'unconstrained face detection'], ['unconstrained face detection', 'in', 'single classifier'], ['views', 'in', 'training set of face images'], ['unconstrained face detection', 'without', 'pre-labeling'], ['single classifier', 'without', 'pre-labeling'], ['pre-labeling', 'of', 'views'], ['views', 'in', 'training set of face images']]"
"[['resulting face detector', 'robust to', 'blur and low image resolution']]"
[]
"[['detection template', 'of', '24 24 pixels']]"
"[['maximum depth', 'of', 'tree classifiers']]"
"[['soft cascade training', 'set', 'threshold'], ['threshold', 'of', 'each exit'], ['minimal score', 'of', 'positive samples'], ['threshold', 'as', 'minimal score'], ['each exit', 'as', 'minimal score'], ['minimal score', 'of', 'positive samples']]"
"[['final detector', 'contains', '1,226 deep quadratic trees'], ['final detector', 'contains', '46,401 NPD features']]"
"[['near frontal face detector', 'using', 'proposed NPD features'], ['near frontal face detector', 'using', 'classic cascade of regression trees ( CART )'], ['classic cascade of regression trees ( CART )', 'with', 'depth of four']]"
"[['subset', 'of', 'training data'], ['training data', 'including', '12,102 face images'], ['training data', 'including', '12,315 nonface images']]"
"[['detection template', 'is', '20 20 pixels']]"
"[['detector cascade', 'contains', '15 stages'], ['detector cascade', 'for', 'each stage'], ['target false accept rate', 'was', '0.5'], ['0.5', 'with', 'detection rate'], ['detection rate', 'of', '0.999']]"
[]
"[['proposed method', 'outperforms', 'most of the baseline methods']]"
"[['proposed NPD face detector', 'is', 'second best one'], ['proposed NPD face detector', 'is', 'third best one'], ['second best one', 'at', 'FP = 0'], ['FP = 0', 'for', 'discrete metric'], ['third best one', 'for', 'continuous metric'], ['third best one', 'for', 'continuous metric']]"
"[['proposed NPD detector', 'among', 'top performers'], ['top performers', 'for', 'discrete metric']]"
"[['Joint Cascade algorithm', 'is', 'most competitive one'], ['most competitive one', 'in terms of', 'accuracy and speed']]"
[]
"[['proposed NPD face detector', 'significantly outperforms', 'Viola - Jones and PittPatt face detectors']]"
[]
"[['NPD detector', 'performs', 'better'], ['slightly worse', 'than', 'Viola - Jones'], ['Viola - Jones', 'at', 'higher FPs']]"
[]
"[['Light and Fast Face Detector ( LFFD )', 'for', 'edge devices']]"
[]
"[['pre-defined anchor boxes', 'manually designed for', 'each detection branch']]"
"[['all parameters', 'with', 'xavier method'], ['network', 'from', 'scratch']]"
"[['optimization method', 'is', 'SGD'], ['SGD', 'with', '0.9 momentum'], ['SGD', 'with', 'batch size']]"
"[['initial learning rate', 'is', '0.1']]"
"[['1,500,000 iterations', 'reduce', 'learning rate'], ['learning rate', 'by multiplying', '0.1'], ['0.1', 'at', 'iteration 600,000 , 1,000,000 , 1,200,000 and 1,400,000']]"
"[['training time', 'is', 'about 5 days'], ['about 5 days', 'with', 'two NVIDIA GTX 1080 TI']]"
"[['Our method', 'implemented using', 'MXNet']]"
[]
[]
"[['high accuracy', 'with', 'marginal gaps']]"
"[['proposed LFFD', 'gains', 'slightly lower accuracy'], ['slightly lower accuracy', 'than', 'first four methods'], ['proposed LFFD', 'outperforms', 'FaceBoxes']]"
"[['LFFD', 'is', 'superior'], ['superior', 'for detecting', 'unconstrained faces']]"
[]
[]
"[['Pyramid Box', 'obtains', 'best results'], ['best results', 'on', 'Hard parts'], ['SSH', 'on', 'Hard parts'], ['performance', 'of', 'SSH'], ['SSH', 'on', 'Hard parts']]"
"[['FaceBoxes', 'does not get', 'desirable results'], ['desirable results', 'on', 'Medium and Hard parts']]"
"[['proposed method LFFD', 'consistently outperforms', 'Face - Boxes']]"
"[['LFFD', 'better than', 'SSH'], ['SSH', 'that uses', 'VGG16'], ['VGG16', 'as', 'backbone'], ['backbone', 'on', 'Hard parts']]"
[]
[]
"[['new framework', 'to integrate', 'two tasks'], ['two tasks', 'using', 'unified cascaded CNNs'], ['unified cascaded CNNs', 'by', 'multi-task learning']]"
"[['proposed CNNs', 'consist of', 'three stages']]"
"[['first stage', 'produces', 'candidate windows'], ['candidate windows', 'through', 'shallow CNN'], ['quickly', 'through', 'shallow CNN']]"
"[['windows', 'to reject', 'large number of non-faces windows'], ['large number of non-faces windows', 'through', 'more complex CNN']]"
"[['more powerful CNN', 'to refine', 'result'], ['more powerful CNN', 'output', 'facial landmarks positions']]"
"[['face detector and alignment', 'against', 'state - of - the - art methods'], ['state - of - the - art methods', 'in', 'Face Detection Data Set and Benchmark ( FDDB )']]"
[]
"[['hard sample mining', 'beneficial to', 'performance improvement']]"
[]
"[['performance', 'of', 'bounding box regression']]"
[]
"[['our method', 'consistently outperforms', 'all the previous approaches'], ['all the previous approaches', 'by', 'large margin'], ['large margin', 'in', 'both the benchmarks']]"
[]
"[['outperforms', 'with', 'margin'], ['all the state - of - the - art methods', 'with', 'margin']]"
[]
[]
"[['hard examples', 'at', 'image level'], ['hard examples', 'in parallel with', 'anchor level']]"
"[['difficulty scores', 'to', 'training images'], ['training images', 'during', 'learning process']]"
"[['not perfectly detected', 'to better facilitate', 'following learning process']]"
"[['detection quality', 'by exclusively exploiting', 'small faces']]"
"[['our detector', 'is', 'more efficient']]"
"[['ImageNet pretrained VGG16 model', 'to initialize', 'our network backbone'], ['randomly initialized', 'with', 'Gaussian initialization']]"
"[['model', 'with', 'itersize'], ['model', 'with', 'learning rate'], ['46 k iterations', 'with', 'learning rate'], ['another 14 k iterations', 'with', 'smaller learning rate'], ['itersize', 'to be', '2'], ['itersize', 'for', '46 k iterations'], ['46 k iterations', 'with', 'learning rate'], ['another 14 k iterations', 'with', 'smaller learning rate'], ['learning rate', 'of', '0.004'], ['smaller learning rate', 'of', '0.0004'], ['another 14 k iterations', 'with', 'smaller learning rate'], ['smaller learning rate', 'of', '0.0004']]"
"[['training', 'use', '4 GPUs'], ['4 GPUs', 'to simultaneously to compute', 'gradient'], ['4 GPUs', 'update', 'weight'], ['weight', 'by', 'synchronized SGD'], ['synchronized SGD', 'with', 'Momentum']]"
"[['first two blocks', 'of', 'VGG16'], ['rest layers', 'of', 'VGG16'], ['first two blocks', 'frozen during', 'training'], ['VGG16', 'frozen during', 'training'], ['rest layers', 'of', 'VGG16'], ['rest layers', 'set to have', 'double learning rate']]"
"[['testing image', 'so that', 'short side'], ['short side', 'contains', '100 , 300 , 600 , 1000 and 1400 pixels']]"
"[['testing strategies', 'used in', 'Pyra - midBox'], ['Pyra - midBox', 'such as', 'horizontal flip'], ['Pyra - midBox', 'such as', 'bounding - box voting']]"
"[['average precision ( AP )', 'for', 'our model']]"
"[['our method', 'achieves', 'best performance'], ['best performance', 'on', 'hard subset'], ['our method', 'outperforms', 'current state - of - the - art'], ['current state - of - the - art', 'by', 'large margin']]"
"[['performance', 'on', 'easy subset'], ['easy subset', 'is', 'bit worse'], ['medium subset', 'comparable to', 'most recent state - of - the - art'], ['performance', 'on', 'easy subset'], ['performance', 'is', 'bit worse'], ['easy subset', 'is', 'bit worse']]"
"[['our method', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'of', 'TPR = 98.7 %'], ['TPR = 98.7 %', 'given', '1000 false positives']]"
"[['our method', 'achieves', 'new']]"
"[['our method', 'achieves', 'state - of - the - art and almost perfect performance'], ['state - of - the - art and almost perfect performance', 'with', 'AP'], ['AP', 'of', '99.60']]"
"[['Our model', 'with', 'single detection feature map'], ['single detection feature map', 'performs', 'better'], ['better', 'than', 'one with three detection feature maps']]"
"[['HIM', 'improve', 'performance'], ['performance', 'on', 'hard subset'], ['performance', 'without involving', 'more complex network architecture'], ['hard subset', 'without involving', 'more complex network architecture'], ['significantly', 'without involving', 'more complex network architecture']]"
"[['DH', 'boost', 'performance'], ['performance', 'shows', 'effectiveness'], ['effectiveness', 'of designing', 'larger convolution'], ['larger convolution', 'for', 'larger anchors']]"
[]
"[['photometric distortion and cropping', 'contribute to', 'more robust face detector']]"
[]
[]
"[['multiple times', 'for', 'multiscale object detection']]"
[]
[]
"[['RSA unit', 'plugged at', 'some specific depths'], ['some specific depths', 'in', 'network'], ['RSA unit', 'fed with', 'initial feature map'], ['initial feature map', 'at', 'largest scale']]"
"[['unit', 'convolves', 'input'], ['input', 'in', 'recurrent manner'], ['unit', 'to generate', 'prediction'], ['recurrent manner', 'to generate', 'prediction'], ['prediction', 'of', 'feature map'], ['half the size', 'of', 'input'], ['feature map', 'that is', 'half the size'], ['half the size', 'of', 'input']]"
"[['network', 'with', 'input'], ['input', 'at', 'one scale only'], ['rest features', 'at', 'smaller scales'], ['rest features', 'at', 'smaller scales'], ['smaller scales', 'through', 'learnable RSA unit']]"
"[['scale - forecast network', 'to globally predict', 'potential scales'], ['potential scales', 'for', 'novel image'], ['feature pyramids', 'for', 'certain set of scales'], ['certain set of scales', 'based on', 'prediction']]"
"[['landmark retracing network', 'retraces', 'location'], ['location', 'of', 'regressed landmarks'], ['regressed landmarks', 'in', 'preceding layers'], ['landmark retracing network', 'generates', 'confidence score'], ['confidence score', 'for', 'each landmark'], ['each landmark', 'based on', 'landmark feature set']]"
"[['final score', 'of', 'identifying'], ['face', 'within', 'anchor'], ['identifying', 'revised by', 'LRN network']]"
"[['three components', 'incorporated into', 'unified CNN framework'], ['three components', 'incorporated into', 'trained end - to - end']]"
"[['shallow version', 'of', 'ResNet'], ['structure', 'is', 'shallow version'], ['shallow version', 'of', 'ResNet'], ['ResNet', 'where', 'first seven ResNet blocks']]"
[]
"[['All numbers of channels', 'set to', 'half'], ['half', 'of', 'original ResNet model']]"
"[['output', 'of', 'predicted scales'], ['predicted scales', 'to launch', 'RSA unit']]"
"[['ratio', 'of', 'positive and the negative'], ['positive and the negative', 'is', '1 : 1'], ['1 : 1', 'in', 'all experiments']]"
"[['batch size', 'is', '4'], ['base learning rate', 'set to', '0.001'], ['0.001', 'with', 'decrease'], ['decrease', 'of', '6 %'], ['6 %', 'every', '10,000 iterations']]"
"[['maximum training iteration', 'is', '1,000,000']]"
"[['stochastic gradient descent', 'as', 'optimizer']]"
[]
"[['our trained scale network', 'recalls', 'almost 99 %'], ['almost 99 %', 'at', 'x = 1']]"
"[['feature approximation', 'at', 'smaller scales']]"
"[['features', 'in', 'deep CNN model']]"
"[['minimum operation', 'in', 'each component'], ['minimum operation', 'means', 'scaleforecast network'], ['scaleforecast network', 'used where', 'no face'], ['no face', 'appears in', 'image'], ['maximum operation', 'indicates', 'amount'], ['amount', 'when', 'faces'], ['faces', 'appear at', 'all scales']]"
"[['computation', 'happens before', 'layer res2 b'], ['acceptable error rate', 'of', '3.44 %']]"
"[['times', 'of', 'recurrent operation'], ['cumulative effect', 'of rolling out', 'predictions']]"
[]
[]
"[['face detector', 'on the top of', 'R - FCN'], ['face detector', 'achieves', 'more decent performance'], ['more decent performance', 'than', 'R - CNN face detectors']]"
"[['size', 'of', 'general face'], ['size', 'of', 'anchors and RoIs'], ['size', 'carefully design', 'size'], ['size', 'of', 'anchors and RoIs']]"
"[['position - sensitive average pooling', 'to generate', 'embedding features'], ['embedding features', 'for enhancing', 'discrimination'], ['position - sensitive average pooling', 'eliminate', 'effect'], ['non-uniformed contribution', 'in', 'each facial part']]"
[]
"[['on - line hard example mining ( OHEM ) technique', 'integrated into', 'our network'], ['on - line hard example mining ( OHEM ) technique', 'for boosting', 'learning'], ['learning', 'on', 'hard examples']]"
"[['training hyper - parameters', 'similar to', 'Face R - CNN']]"
"[['our network', 'with', 'pre-trained weights'], ['pre-trained weights', 'of', '101 - layer ResNet'], ['101 - layer ResNet', 'trained on', 'Image Net']]"
"[['pre-trained model', 'throughout', 'entire training process'], ['pre-trained model', 'to keep', 'essential feature extractor'], ['entire training process', 'to keep', 'essential feature extractor'], ['essential feature extractor', 'trained on', 'ImageNet']]"
"[['Face R - FCN', 'enumerates', 'multiple configurations'], ['multiple configurations', 'of', 'anchor'], ['multiple configurations', 'to accurately search for', 'faces']]"
"[['range of multiple scales and aspect ratios', 'to construct', 'multi-scale anchors']]"
"[['RPN and R - FCN', 'learned jointly with', 'softmax loss'], ['RPN and R - FCN', 'learned jointly with', 'smooth L1 loss']]"
"[['anchors', 'with', 'certain IoU scores']]"
"[['256', 'for', 'size'], ['256', 'for', '128'], ['256', 'for', 'R - FCN'], ['128', 'for', 'R - FCN'], ['size', 'of', 'RPN mini-batch'], ['128', 'for', 'R - FCN']]"
"[['multi-scale training', 'where', 'input image'], ['input image', 'resized with', 'bilinear interpolation'], ['bilinear interpolation', 'to', 'various scales ( say , 1024 or 1200 )']]"
"[['multi-scale testing', 'performed by', 'scale image'], ['scale image', 'into', 'image pyramid'], ['image pyramid', 'for', 'better detecting'], ['better detecting', 'on', 'tiny and general faces']]"
"[['1st place', 'across', 'three subsets'], ['three subsets', 'on', 'validation set and test set'], ['validation set and test set', 'of', 'WIDER FACE']]"
"[['our approach', 'superior to', 'prior best - performing one'], ['prior best - performing one', 'by', 'clear margin']]"
[]
"[['Face R - FCN', 'consistently achieves', 'impressive performance'], ['impressive performance', 'in terms of', 'continuous ROC curve']]"
"[['discrete ROC curve', 'superior to', 'prior best - performing method']]"
"[['best true positive rate', 'of', 'discrete ROC curve'], ['discrete ROC curve', 'at', '1000/2000 false positives ( 98.49%/99.07 % )']]"
"[['Face R - FCN', 'shows', 'superior performance'], ['superior performance', 'over', 'prior methods'], ['prior methods', 'across', 'three subsets ( easy , medium and hard )'], ['three subsets ( easy , medium and hard )', 'in', 'validation and test sets']]"
"[['98. 99 %', 'of', 'discrete ROC curve'], ['98. 99 %', 'of', '99. 42 %'], ['discrete ROC curve', 'at', '1000 false positives'], ['99. 42 %', 'at', '2000 false positives'], ['discrete ROC curve', 'at', '1000 false positives'], ['99. 42 %', 'at', '2000 false positives']]"
[]
[]
[]
[]
"[['separate detectors', 'tuned for', 'different scales ( and aspect ratios )']]"
"[['scale - specific detectors', 'in', 'multitask fashion'], ['scale - specific detectors', 'make use of', 'features'], ['multitask fashion', 'make use of', 'features'], ['features', 'defined over', 'multiple layers'], ['multiple layers', 'of', 'single ( deep ) feature hierarchy']]"
"[['simply strategy', 'resize', 'images'], ['images', 'at', 'test - time'], ['test - time', 'by', 'interpolation and decimation']]"
[]
"[['final approach', 'is', 'delicate mixture'], ['delicate mixture', 'of', 'scale - specific detectors'], ['scale - specific detectors', 'used in', 'scale - invariant fashion']]"
"[['convolutional deep features', 'extracted from', 'multiple layers'], ['convolutional deep features', 'are', 'effective "" foveal "" descriptors'], ['multiple layers', 'are', 'effective "" foveal "" descriptors'], ['effective "" foveal "" descriptors', 'that capture', 'high - resolution detail'], ['effective "" foveal "" descriptors', 'that capture', 'coarse low - resolution cues'], ['coarse low - resolution cues', 'across', 'large receptive field']]"
"[['highresolution components', 'of', 'our foveal descriptors'], ['our foveal descriptors', 'extracted from', 'lower convolutional layers'], ['our foveal descriptors', 'crucial for', 'accurate localization']]"
[]
"[['hybrid - resolution model ( HR )', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'all difficulty levels']]"
[]
"[['out - of - the - box detector ( HR )', 'outperforms', 'all published results'], ['all published results', 'on', 'discrete score'], ['discrete score', 'uses', 'standard 50 % intersection - over - union threshold'], ['standard 50 % intersection - over - union threshold', 'to define', 'correctness']]"
"[['our detector', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'continuous score']]"
"[['regressor', 'trained with', '10 - fold cross validation']]"
[]
[]
"[['ADAPT', 'focused on', 'two specialised domain English subtasks'], ['two specialised domain English subtasks', 'by developing', 'unsupervised system'], ['word embeddings', 'from', 'supplied reference corpora']]"
[]
[]
"[['eleven out of eighteen', 'on', 'medical domain subtask'], ['medical domain subtask', 'with', 'Mean Average Precision ( MAP )'], ['Mean Average Precision ( MAP )', 'of', '8.13']]"
"[['first place', 'among', 'all the unsupervised systems']]"
"[['our system', 'ranked', '13th'], ['MAP', 'of', '1.88'], ['4th', 'among', 'unsupervised systems']]"
[]
[]
[]
"[['neural network architecture', 'for', 'concerned task'], ['distributed representations', 'for', 'words and phrases'], ['various neural networks', 'to model', 'distributed representations'], ['distributed representations', 'for', 'words and phrases']]"
"[['unambiguous vector representation', 'via', 'term embedding'], ['deep neural networks', 'to discover', 'hypernym relationships'], ['hypernym relationships', 'between', 'terms']]"
[]
"[['diagonal variant', 'of', 'Ada - Grad'], ['Ada - Grad', 'used for', 'neural network training']]"
[]
[]
"[['hidden dimension', 'of', 'all neural models'], ['all neural models', 'are', '200']]"
"[['batch size', 'set to', '20'], ['word embedding and sense embedding sizes', 'set to', '300']]"
"[['single GPU ( NVIDIA GTX 980 Ti )', 'with', 'roughly 1.5h'], ['roughly 1.5h', 'for', 'general - purpose subtask'], ['roughly 1.5h', 'for', '0.5h'], ['general - purpose subtask', 'for', 'English'], ['domain - specific domain - specific ones', 'for', 'medical and music']]"
"[['Convolution or recurrent gated mechanisms', 'in', 'CNN - based ( CNN , RCNN )'], ['Convolution or recurrent gated mechanisms', 'in', 'RNN ( GRU , LSTM ) based neural networks'], ['words', 'in', 'phrase'], ['semantic connections', 'between', 'words'], ['words', 'in', 'phrase'], ['semantic connections', 'guide', 'networks'], ['networks', 'to discover', 'hypernym relationships']]"
"[['CNN - based network performance', 'better than', 'RNN - based']]"
[]
"[['term embedding averaging', 'in terms of', 'all the metrics'], ['CNN - based network', 'performs', 'better'], ['better', 'than', 'RNN - based ones'], ['RNN - based ones', 'in', 'most of the metrics'], ['RNN - based ones', 'using', 'word embedding'], ['most of the metrics', 'using', 'word embedding']]"
"[['sense embedding', 'shows', 'much poorer result']]"
[]
[]
[]
"[['performance', 'of', 'measures'], ['principled way', 'to select', 'suitable measure'], ['suitable measure', 'yielding', 'consistent performance'], ['consistent performance', 'across', 'datasets']]"
"[['unsupervised measures', 'to', 'state - of - the - art supervised methods']]"
[]
[]
"[['preference', 'to', 'syntactic context - types ( dep and joint )']]"
"[['successful', 'In', 'hypernymy detection'], ['raw frequency', 'appears to be', 'successful'], ['successful', 'in', 'hypernymy detection']]"
"[['new SLQS variants', 'on top of', 'list']]"
"[['well', 'in discriminating', 'hypernyms'], ['hypernyms', 'from', 'symmetric relations']]"
[]
"[['over all performance', 'of', 'embeddingbased classifiers'], ['embeddingbased classifiers', 'is', 'almost perfect'], ['best performance', 'achieved using', 'concatenation method'], ['best performance', 'achieved using', 'dependency - based embeddings'], ['concatenation method', 'with', 'GloVe'], ['concatenation method', 'with', 'dependency - based embeddings']]"
"[['unsupervised measures', 'perform', 'worse'], ['worse', 'than', 'embedding - based classifiers']]"
[]
[]
"[['hypernym detection algorithm', 'based on', 'sense embeddings']]"
"[['hypernymic relations', 'by exploiting', 'linear transformations'], ['linear transformations', 'in', 'embedding spaces'], ['specific semanticallyaware transformation matrix', 'for', 'each domain of knowledge']]"
"[['best configuration', 'considers', 'two training sources']]"
"[['Manually curated pairs', 'from', 'Wikidata'], ['Hypernymy relations', 'from', 'KB'], ['Hypernymy relations', 'from', 'KB'], ['Hypernymy relations', 'integrates', 'several Open Information Extraction ( OIE ) systems']]"
[]
[]
"[['taxonomy learning and Information Extraction systems', 'namely', 'WiBi'], ['taxonomy learning and Information Extraction systems', 'namely', 'DefIE']]"
"[['DefIE', 'is', 'automaic OIE system'], ['automaic OIE system', 'relying on', 'syntactic structure'], ['syntactic structure', 'of', 'pre-dis ambiguated definitions']]"
[]
"[['Yago and WiBi', 'achieve', 'best over all results']]"
"[['TAXOEM - BED', 'based solely on', 'distributional information'], ['TAXOEM - BED', 'performed', 'competitively'], ['competitively', 'in detecting', 'new hypernyms'], ['new hypernyms', 'compared to', 'DefIE'], ['new hypernyms', 'improving', 'recall'], ['DefIE', 'improving', 'recall'], ['recall', 'in', 'most domains']]"
"[['particularly well', 'on', 'media and physics']]"
[]
[]
"[['Word2vec', 'to produce', 'word embeddings']]"
"[['skip - gram model ( - cbow 0 )', 'used with', 'embedding dimension'], ['embedding dimension', 'set to', '300 ( - size 300 )']]"
[]
"[['best F - value', 'on', 'validation set'], ['best F - value', 'is', '0.68'], ['0.68', 'when', 'best cluster number'], ['best cluster number', 'is', '2']]"
"[['projection learning method', 'performs', 'not very well'], ['not very well', 'on', 'task9']]"
[]
"[['performance', 'evaluated using', 'cross validation or the test data'], ['performance', 'is', 'much worse'], ['cross validation or the test data', 'is', 'much worse'], ['much worse', 'than', 'typical hypernym prediction task']]"
"[['1st', 'on', 'Spanish'], ['6th', 'on', 'English'], ['2nd', 'on', 'Italian'], ['6th', 'on', 'English'], ['1st', 'ranked by', 'metric'], ['6th', 'ranked by', 'metric']]"
"[['dropped', 'on', 'English'], ['significantly', 'on', 'English'], ['dropped', 'dropped by', '4 %'], ['MAP', 'dropped by', '4 %'], ['performance', 'increased by', 'margin'], ['dropped', 'increased by', 'margin'], ['margin', 'on', 'Spanish']]"
[]
[]
"[['ranked 1st', 'on', 'all three sub - tasks']]"
"[['scores', 'are', 'much higher'], ['much higher', 'than', 'strongest baselines']]"
[]
"[['data augmentation', 'improved', 'our scores'], ['our scores', 'on', '1A and 2B'], ['slightly', 'on', '1A and 2B'], ['data augmentation', 'increased them by', 'several points'], ['several points', 'on', '2A']]"
"[['cross-evaluation results', 'better than', 'supervised baseline'], ['domain - specific test set', 'better than', 'strong , supervised baseline'], ['supervised baseline', 'computed using', 'normal evaluation setup'], ['general - purpose data', 'produced', 'better results'], ['better results', 'on', 'domain - specific test set'], ['domain - specific test set', 'than', 'strong , supervised baseline']]"
"[['unsupervised system', 'outperformed', 'all other unsupervised systems'], ['unsupervised system', 'outperformed', 'supervised baseline']]"
"[['run 1', 'is', 'best'], ['best', 'on', 'all 3 test sets'], ['best', 'when', 'hybrid system']]"
[]
[]
"[['word embeddings', 'during', 'training']]"
"[['supervised model', 'prone to', 'overfitting']]"
[]
"[['distributional technique', 'concatenating', 'two feature vectors'], ['feature vector', 'constructed using', 'dependency parser output'], ['feature vector', 'obtained using', 'term embeddings']]"
"[['concatenated vector', 'create', 'binary supervised classifier model'], ['binary supervised classifier model', 'based on', 'support vector machine ( SVM ) algorithm']]"
"[['term and its candidate hypernym', 'are', 'hypernym related or not']]"
[]
"[['our system', 'performs', 'better'], ['better', 'than', 'STJU system'], ['our system', 'performs', 'better'], ['better', 'than', 'MFH system'], ['better', 'on', 'English corpora'], ['MFH system', 'on', 'English corpora']]"
"[['our system', 'performs', 'well'], ['well', 'in discovering', 'new hypernyms'], ['new hypernyms', 'not defined in', 'gold hypernyms'], ['new hypernyms', 'yields', 'good False Positive values'], ['good False Positive values', 'in', 'three corpora']]"
"[['candidate hypernym extraction ( CHE ) coverage', 'for', 'English testing terms'], ['English testing terms', 'is', '950 ( 63 % )']]"
"[['system', 'based on', 'sparse coding'], ['system', 'based on', 'formal concept hierarchy'], ['formal concept hierarchy', 'obtained from', 'word embeddings']]"
"[['sparse feature pairs', 'to', 'hypernym extraction']]"
[]
[]
"[['hierarchical sparse coding', 'where', 'trees']]"
"[['correspondence', 'between', 'variable tree and the hypernym hierarchy']]"
"[['attribute pairs', 'achieved', 'first place'], ['first place', 'in', 'categories']]"
[]
[]
"[['rule - based system', 'exploits', 'syntactic dependency paths'], ['syntactic dependency paths', 'that generalize', 'Hearst - style lexical patterns']]"
[]
"[['very productive', 'generating', 'tens of thousands relations']]"
"[['main objective', 'to outperform', 'random strategy']]"
"[['lower scores', 'obtained for', 'multiword expressions']]"
[]
[]
"[['input sequence and coreference clusters', 'extracted from', 'external system'], ['input sequence and coreference clusters', 'introduce', 'term'], ['term', 'in', 'update equations'], ['update equations', 'for', 'Gated Recurrent Units ( GRU )'], ['Gated Recurrent Units ( GRU )', 'depends on', 'hidden state'], ['hidden state', 'of', 'coreferent antecedent'], ['coreferent antecedent', 'of', 'current token']]"
"[['hidden states', 'propagated along', 'coreference chains']]"
"[['Coref - GRU layer', 'with', 'regular GRU layer'], ['recent model', 'for', 'reading comprehension']]"
[]
"[['clear improvements', 'of using', 'C - GRU layers'], ['C - GRU layers', 'over', 'GRU layers']]"
"[['QRN baseline', 'found that', 'C - GRU'], ['C - GRU', 'was', 'significantly worse'], ['significantly worse', 'on', 'task 15 ( basic deduction )']]"
"[['C - GRU', 'significantly better than', 'QRN'], ['significantly better', 'than', 'QRN'], ['significantly better', 'on', 'task 16 ( basic induction )'], ['QRN', 'on', 'task 16 ( basic induction )']]"
[]
"[['higher performance', 'for', 'C - GRU model'], ['C - GRU model', 'in', 'low data regime'], ['better generalization', 'throughout', 'training curve']]"
[]
[]
[]
"[['novel context zoom - in network ( ConZNet )', 'for', 'RC tasks'], ['novel context zoom - in network ( ConZNet )', 'skip through', 'irrelevant parts'], ['irrelevant parts', 'of', 'document'], ['novel context zoom - in network ( ConZNet )', 'generate', 'answer'], ['answer', 'using', 'relevant regions'], ['relevant regions', 'of', 'text']]"
"[['ConZNet architecture', 'consists of', 'two phases']]"
"[['first phase', 'identify', 'relevant regions'], ['relevant regions', 'of', 'text'], ['relevant regions', 'by employing', 'reinforcement learning algorithm']]"
"[['second phase', 'based on', 'encoder - decoder architecture'], ['encoder - decoder architecture', 'comprehends', 'identified regions'], ['identified regions', 'of', 'text'], ['encoder - decoder architecture', 'generates', 'answer'], ['answer', 'by using', 'residual self - attention network'], ['answer', 'by using', 'RNNbased sequence generator'], ['residual self - attention network', 'as', 'encoder'], ['residual self - attention network', 'as', 'RNNbased sequence generator'], ['RNNbased sequence generator', 'along with', 'pointer network'], ['pointer network', 'as', 'decoder']]"
"[['relevant regions', 'of', 'text'], ['text', 'based on', 'question']]"
[]
"[['decoder', 'to copy', 'words'], ['decoder', 'copy', 'words'], ['words', 'from', 'relevant regions'], ['words', 'from', 'fixed vocabulary'], ['relevant regions', 'of', 'text'], ['decoder', 'to generate', 'words'], ['words', 'from', 'fixed vocabulary']]"
[]
"[['two baseline models', 'with', 'Context Zoom layer']]"
[]
"[['weights', 'of', 'model'], ['weights', 'initialized by', 'Glorot Initialization'], ['model', 'initialized by', 'Glorot Initialization'], ['biases', 'initialized with', 'zeros']]"
"[['300 dimensional word vectors', 'from', 'GloVe'], ['GloVe', 'with', '840 billion pre-trained vectors'], ['300 dimensional word vectors', 'to initialize', 'word embeddings']]"
"[['words', 'initialized by', 'sampling'], ['sampling', 'from', 'uniform random distribution']]"
"[['dropout', 'between', 'layers'], ['dropout', 'with', 'keep probability'], ['keep probability', 'of', '0.8']]"
"[['number of hidden units', 'set to', '100']]"
"[['our model', 'with', 'AdaDelta ( Zeiler , 2012 ) optimizer'], ['our model', 'with', 'minibatch size'], ['AdaDelta ( Zeiler , 2012 ) optimizer', 'for', '50 epochs'], ['initial learning rate', 'of', '0.1'], ['minibatch size', 'of', '32']]"
"[['performance', 'of', 'our model'], ['gradually dropped', 'from', 'sample size 7 onwards']]"
"[['few relevant sentences', 'are', 'sufficient']]"
"[['performance', 'of', 'model'], ['sample size', 'of', '1'], ['improved dramatically', 'with', 'sample sizes'], ['3 and 5', 'compared to', 'sample size']]"
"[['self - attention mechanism', 'in', 'Context zoom layer'], ['Context zoom layer', 'is', 'important component'], ['important component', 'to identify', 'related relevant sentences']]"
[]
"[['high accuracy', 'with', 'fully neural approach'], ['fully neural approach', 'involving', 'single feedforward network'], ['fully neural approach', 'involving', 'pre-trained skip - thought embeddings']]"
"[['models', 'considering', 'full context'], ['last sentence', 'of', 'context'], ['models', 'that consider', 'full context']]"
"[['sentences', 'in', 'story'], ['sentences', 'in', 'feed - forward neural network'], ['story', 'in', 'feed - forward neural network'], ['last sentence', 'in', 'prompt'], ['three strategies', 'using', 'skip - thought embeddings'], ['skip - thought embeddings', 'for', 'sentences'], ['sentences', 'in', 'story'], ['story', 'in', 'feed - forward neural network'], ['three strategies', 'training', 'model'], ['model', 'on', 'provided validation set'], ['three strategies', 'considering', 'two endings'], ['two endings', 'with', 'last sentence'], ['last sentence', 'in', 'prompt']]"
"[['SGD', 'with', 'learning rate'], ['learning rate', 'of', '0.01']]"
"[['training', 'save', 'model'], ['model', 'every', '3000 iterations']]"
"[['3 - layer feed - forward neural network', 'trained on', 'validation set'], ['validation set', 'by summing', 'skip - thought embeddings'], ['skip - thought embeddings', 'of', 'last sentence ( LS )'], ['skip - thought embeddings', 'of', 'last sentence ( LS )'], ['last sentence ( LS )', 'of', 'story prompt and the ending'], ['story prompt and the ending', 'gives', 'best accuracy ( 76.5 % )']]"
[]
"[['model', 'trained using', 'last sentence ( LS )'], ['last sentence ( LS )', 'of', 'story context'], ['story context', 'has', 'higher accuracy'], ['higher accuracy', 'compared to', 'model'], ['model', 'that uses', 'GRU'], ['GRU', 'to encode', 'full context ( FC )']]"
[]
[]
[]
"[['end - to - end neural network', 'for', 'question answering']]"
"[['coattentive encoder', 'captures', 'interactions'], ['interactions', 'between', 'question and the document'], ['dynamic pointing decoder', 'alternates between', 'estimating'], ['estimating', 'start and end of', 'answer span']]"
"[['corpus', 'use', 'tokenizer'], ['tokenizer', 'from', 'Stanford CoreNLP']]"
"[['Glo Ve word vectors', 'pretrained on', '840B Common Crawl corpus']]"
"[['vocabulary', 'to', 'words'], ['out - of - vocabulary words', 'to', 'zero'], ['words', 'present in', 'Common Crawl corpus'], ['embeddings', 'for', 'out - of - vocabulary words'], ['out - of - vocabulary words', 'to', 'zero']]"
"[['max sequence length', 'of', '600'], ['hidden state size', 'of', '200'], ['600', 'during', 'training'], ['hidden state size', 'of', '200'], ['200', 'for', 'linear layers']]"
"[['initial state', 'of', 'zero']]"
"[['Sentinel vectors', 'are', 'randomly initialized and optimized'], ['randomly initialized and optimized', 'during', 'training']]"
"[['dynamic decoder', 'set', 'maximum number of iterations'], ['maximum number of iterations', 'to', '4'], ['dynamic decoder', 'use', 'maxout pool size'], ['maxout pool size', 'of', '16']]"
"[['dropout', 'to regularize', 'our network'], ['our network', 'during', 'training'], ['dropout', 'optimize', 'model'], ['model', 'using', 'ADAM']]"
[]
"[['performance', 'of', 'Dynamic Coattention Network'], ['start and end points', 'of', 'answer span'], ['Dynamic Coattention Network', 'on', 'SQuAD dataset'], ['Dynamic Coattention Network', 'compared to', 'other submitted models'], ['capability', 'to estimate', 'start and end points'], ['start and end points', 'of', 'answer span']]"
"[['model', 'able to explore', 'local maxima'], ['local maxima', 'corresponding to', 'multiple plausible answers']]"
[]
[]
[]
"[['Relation Memory Network "" ( RMN )', 'able to find', 'complex relation']]"
"[['MLP', 'to find out', 'relevant information'], ['relevant information', 'with', 'new generalization']]"
"[['RMN', 'inherits', ""RN 's MLP - based output feature map""], [""RN 's MLP - based output feature map"", 'on', 'Memory Network architecture']]"
[]
"[['Embedding component', 'where', 'story and question'], ['story and question', 'embedded through', 'different LSTMs'], ['32 unit LSTM', 'for', 'story and question']]"
[]
"[['batch normalization', 'For', 'all MLPs'], ['regularization', 'use', 'batch normalization'], ['batch normalization', 'for', 'all MLPs']]"
"[['softmax output', 'optimized with', 'cross - entropy loss function'], ['cross - entropy loss function', 'using', 'Adam optimizer'], ['cross - entropy loss function', 'with', 'learning rate'], ['Adam optimizer', 'with', 'learning rate'], ['learning rate', 'of', '2 e ?4']]"
[]
"[['full dialog scripts', 'with', 'every model response'], ['every model response', 'as', 'answer'], ['all previous dialog history', 'as', 'sentences'], ['last user utterance', 'as', 'question']]"
"[['most probable response', 'from', '4,212 candidates'], ['4,212 candidates', 'ranked from', 'set'], ['set', 'of', 'all bot utterances'], ['all bot utterances', 'appearing in', 'training , validation and test sets ( plain and OOV )'], ['training , validation and test sets ( plain and OOV )', 'for', 'all tasks']]"
[]
"[['RN and RMN', 'outperform', 'previous memory - augmented models'], ['previous memory - augmented models', 'on', 'normal and OOV tasks']]"
"[[""RMN 's attention component"", 'to', 'inner product based attention'], ['error rate', 'increased to', '11.3 %']]"
"[['number of unnecessary object pairs', 'created by', 'RN'], ['number of unnecessary object pairs', 'decreases', 'accuracy']]"
"[['all models', 'other than', 'RMN'], ['all models', 'significantly improved', 'performance'], ['performance', 'except for', 'task 3'], ['performance', 'compared to', 'plain condition']]"
"[['RMN', 'yields', 'same error rate'], ['25.1 %', 'with', 'MemN2N and GMe m N2N']]"
[]
[]
[]
[]
"[['deep , end - to - end , neural comprehension model', 'call', 'EpiReader']]"
"[['EpiReader', 'factors into', 'two components']]"
"[['first component', 'extracts', 'small set of potential answers'], ['small set of potential answers', 'based on', 'shallow comparison'], ['shallow comparison', 'of', 'question'], ['question', 'with', 'supporting text']]"
"[['second component', 'reranks', 'proposed answers'], ['proposed answers', 'based on', 'deeper semantic comparisons'], ['deeper semantic comparisons', 'with', 'text'], ['second component', 'call', 'Reasoner']]"
"[['semantic comparisons', 'implemented by', 'Reasoner'], ['semantic comparisons', 'based on', 'concept'], ['Reasoner', 'based on', 'concept']]"
"[['Extractor', 'serves', 'important function'], ['important function', 'filtering', 'large set of potential answers'], ['large set of potential answers', 'down to', 'small , tractable set of likely candidates'], ['small , tractable set of likely candidates', 'for', 'more thorough testing']]"
"[['Extractor', 'uses', 'differentiable attention mechanism'], ['differentiable attention mechanism', 'to indicate', 'words'], ['words', 'in', 'text'], ['words', 'potentially answer', 'question']]"
"[['question answering', 'with', 'Attention Sum Reader']]"
"[['Extractor', 'small set of', 'answer candidates'], ['answer candidates', 'along with', 'estimated probabilities of correctness']]"
"[['Reasoner', 'forms', 'hypotheses'], ['hypotheses', 'by inserting', 'candidate answers'], ['candidate answers', 'into', 'question'], ['Reasoner', 'estimates', 'concordance'], ['concordance', 'of', 'each hypothesis'], ['each hypothesis', 'with', 'each sentence'], ['each sentence', 'in', 'supporting text']]"
"[['estimates', 'as', 'measure'], ['measure', 'of', 'evidence'], ['evidence', 'for', 'hypothesis']]"
"[[""Reasoner 's evidence"", 'with', ""Extractor 's probability estimates""], [""Extractor 's probability estimates"", 'to produce', 'final ranking'], ['final ranking', 'of', 'answer candidates']]"
"[['our model', 'used', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', 'ADAM optimizer'], ['stochastic gradient descent', 'with', 'initial learning rate'], ['stochastic gradient descent', 'with', 'initial learning rate'], ['initial learning rate', 'of', '0.001']]"
"[['word embeddings', 'drawing from', 'uniform distribution'], ['initialized randomly', 'drawing from', 'uniform distribution'], ['initialized', 'drawing from', 'uniform distribution'], ['randomly', 'drawing from', 'uniform distribution']]"
"[['batches', 'of', '32 examples'], ['patience', 'of', '2 epochs'], ['early stopping', 'with', 'patience'], ['patience', 'of', '2 epochs']]"
"[['Theano', 'using', 'Keras framework']]"
"[['2 - regularization', 'at', '0.001 , ? = 50 , and ? = 0.04']]"
"[['EpiReader', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'across', 'board'], ['state - of - the - art performance', 'for', 'both datasets'], ['board', 'for', 'both datasets']]"
"[['2.2 % higher', 'On', 'test'], ['CNN', 'score', '2.2 % higher'], ['2.2 % higher', 'on', 'test'], ['2.2 % higher', 'than', 'best previous model']]"
[]
"[['improvement', 'on', 'CBT - NE'], ['improvement', 'is', 'more modest'], ['CBT - NE', 'is', 'more modest'], ['more modest', 'at', '1.1 %']]"
"[['CBT - NE results', 'found that', 'validation and test accuracies'], ['validation and test accuracies', 'had', 'relatively high variance'], ['relatively high variance', 'even in', 'late epochs'], ['late epochs', 'of', 'training']]"
[]
"[['novel recurrent neural network ( RNN ) architecture', 'where', 'recurrence'], ['recurrence', 'reads from', 'possibly large external memory'], ['possibly large external memory', 'before outputting', 'symbol'], ['multiple times', 'before outputting', 'symbol']]"
"[['continuous form', 'of', 'Memory Network']]"
"[['end - to - end', 'from', 'input - output pairs'], ['continuity', 'applicable to', 'more tasks']]"
"[['RNNsearch', 'with', 'multiple computational steps'], ['multiple computational steps', 'per', 'output symbol']]"
"[['2 norm', 'of', 'whole gradient'], ['whole gradient', 'of', 'all parameters'], ['whole gradient', 'of', 'all parameters'], ['2 norm', 'if', 'larger than L = 50'], ['scaled down', 'to have', 'norm L.']]"
"[['learning rate annealing schedule', 'if', 'validation cost'], ['not decreased', 'after', 'one epoch'], ['learning rate', 'scaled down by', 'factor 1.5'], ['scaled down', 'by', 'factor 1.5']]"
"[['Weights', 'initialized using', 'N ( 0 , 0.05 )'], ['batch size', 'set to', '128']]"
"[['Penn tree dataset', 'repeat', 'each training'], ['10 times', 'with', 'different random initializations']]"
[]
[]
"[['weakly supervised heuristic version', 'of', 'MemNN'], ['MemNN', 'where', 'supporting sentence labels'], ['supporting sentence labels', 'not used in', 'training']]"
"[['LSTM', 'trained using', 'question / answer pairs only'], ['standard LSTM model', 'trained using', 'question / answer pairs only']]"
[]
[]
[]
[]
"[['neural - network - based NLI models', 'benefit from', 'external knowledge']]"
[]
"[['neural - network - based NLI models', 'with', 'external knowledge'], ['external knowledge', 'in', 'coattention'], ['external knowledge', 'in', 'local inference collection'], ['external knowledge', 'in', 'inference composition components']]"
"[['proposed model', 'improves', 'state - of - the - art NLI models'], ['state - of - the - art NLI models', 'to achieve', 'better performances'], ['better performances', 'on', 'SNLI and MultiNLI datasets']]"
"[['advantage', 'of using', 'external knowledge'], ['external knowledge', 'is', 'more significant'], ['size of training data', 'is', 'restricted'], ['external knowledge', 'when', 'size of training data'], ['more significant', 'when', 'size of training data'], ['size of training data', 'is', 'restricted']]"
"[['dimension', 'of', 'hidden states'], ['hidden states', 'of', 'LSTMs and word embeddings'], ['hidden states', 'of', 'LSTMs and word embeddings'], ['hidden states', 'are', '300'], ['LSTMs and word embeddings', 'are', '300']]"
"[['word embeddings', 'initialized by', '300D GloVe 840B']]"
"[['Adam ( Kingma and Ba , 2014 )', 'used for', 'optimization'], ['Adam ( Kingma and Ba , 2014 )', 'with', 'initial learning rate'], ['optimization', 'with', 'initial learning rate'], ['initial learning rate', 'of', '0.0004']]"
"[['mini - batch size', 'set to', '32']]"
"[['Knowledge - based Inference Model ( KIM )', 'enriches', 'ESIM'], ['ESIM', 'with', 'external knowledge'], ['accuracy', 'of', '88.6 %'], ['best single - model performance', 'reported on', 'SNLI dataset']]"
"[['difference', 'between', 'ESIM and KIM'], ['difference', 'is', 'statistically significant'], ['ESIM and KIM', 'is', 'statistically significant'], ['statistically significant', 'under', 'one - tailed paired t- test'], ['one - tailed paired t- test', 'at', '99 % significance level']]"
"[['models', 'on', 'MultiNLI dataset']]"
"[['baseline ESIM', 'achieves', '76.8 % and 75.8 %'], ['76.8 % and 75.8 %', 'on', 'in - domain and cross - domain test set']]"
"[['ESIM', 'with', 'external knowledge'], ['ESIM', 'achieve', 'significant gains'], ['external knowledge', 'achieve', 'significant gains'], ['significant gains', 'to', '77.2 % and 76.4 %']]"
[]
[]
"[['answer', 'is', 'word'], ['word', 'from', 'context document']]"
"[['vector embedding', 'of', 'query']]"
"[['vector embedding', 'of', 'each individual word']]"
"[['dot product', 'between', 'question embedding and the contextual embedding'], ['question embedding and the contextual embedding', 'of', 'each occurrence'], ['each occurrence', 'of', 'candidate answer'], ['each occurrence', 'of', 'candidate answer'], ['candidate answer', 'in', 'document']]"
"[['model', 'used', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', 'ADAM update rule'], ['stochastic gradient descent', 'with', 'learning rate'], ['learning rate', 'of', '0.001 or 0.0005']]"
"[['Weights', 'in', 'GRU networks'], ['Weights', 'initialized by', 'random orthogonal matrices'], ['GRU networks', 'initialized by', 'random orthogonal matrices'], ['biases', 'initialized to', 'zero']]"
"[['gradient clipping threshold', 'of', '10'], ['batches', 'of size', '32']]"
"[['mance', 'of', 'our single model'], ['performance', 'of', 'simultaneously published models'], ['mance', 'is', 'little bit worse'], ['our single model', 'is', 'little bit worse'], ['little bit worse', 'than', 'performance'], ['performance', 'of', 'simultaneously published models']]"
[]
"[['single model', 'with', 'best validation accuracy'], ['best validation accuracy', 'achieves', 'test accuracy'], ['test accuracy', 'of', '69.5 %']]"
"[['average performance', 'of', 'top 20 % models'], ['top 20 % models', 'according to', 'validation accuracy'], ['validation accuracy', 'is', '69.9 %']]"
"[['multiple models', 'gives', 'significant further increase'], ['significant further increase', 'in', 'accuracy'], ['accuracy', 'on', 'CNN and Daily Mail datasets']]"
"[['best single model', 'with', 'accuracy'], ['MemNN', 'with', 'self supervision'], ['accuracy', 'of', '68.6 %'], ['68.6 %', 'performs', '2 % absolute better'], ['2 % absolute better', 'than', 'MemNN'], ['MemNN', 'with', 'self supervision'], ['averaging ensemble', 'performs', '4 % absolute better'], ['4 % absolute better', 'than', 'best previous result']]"
"[['0.4 % absolute better', 'than', 'Mem NN'], ['ensemble', 'improves', 'performance'], ['performance', 'to', '69 %']]"
[]
[]
[]
[]
"[['GLUE', 'does not place', 'any constraints'], ['any constraints', 'on', 'model architecture'], ['model architecture', 'beyond', 'ability'], ['ability', 'to process', 'single - sentence and sentence - pair inputs'], ['GLUE', 'to make', 'corresponding predictions']]"
"[['training data', 'is', 'plentiful']]"
"[['privately - held test data', 'to ensure', 'benchmark']]"
[]
"[['simplest baseline architecture', 'based on', 'sentence - to - vector encoders'], ['simplest baseline architecture', 'sets aside', 'GLUE'], ['models', 'with', 'more complex structures']]"
"[['multi-task training', 'yields', 'better overall scores'], ['better overall scores', 'over', 'single - task training'], ['single - task training', 'amongst', 'models'], ['models', 'using', 'attention or ELMo']]"
"[['consistent improvement', 'in using', 'ELMo embeddings'], ['ELMo embeddings', 'in place of', 'GloVe or CoVe embeddings'], ['ELMo embeddings', 'particularly for', 'single - sentence tasks'], ['GloVe or CoVe embeddings', 'particularly for', 'single - sentence tasks']]"
"[['pre-trained sentence representation models', 'observe', 'fairly consistent gains'], ['fairly consistent gains', 'moving from', 'CBoW'], ['CBoW', 'to', 'Skip - Thought']]"
"[['models', 'trained directly on', 'GLUE tasks'], ['InferSent', 'is', 'competitive']]"
"[['sentence representation models', 'substantially underperform on', 'CoLA'], ['CoLA', 'compared to', 'models'], ['models', 'directly trained on', 'task']]"
"[['models', 'trained directly on', 'task'], ['models', 'trained directly on', 'lag'], ['models', 'lag significantly behind', 'performance'], ['task', 'lag significantly behind', 'performance'], ['lag', 'lag significantly behind', 'performance'], ['lag', 'significantly behind', 'performance'], ['performance', 'of', 'best sentence representation model']]"
"[['model predictions', 'for', 'most -frequent baseline']]"
[]
[]
[]
"[['weight initialization', 'to', 'optimization dynamics'], ['optimization dynamics', 'of', 'specific learning task']]"
"[['improved weight initialization', 'starting with', 'better prior'], ['better prior', 'leads to', 'more accurate posterior']]"
"[['adaptive prior', 'implemented via', 'Markov Chain Monte Carlo ( MCMC ) methods']]"
"[['cyclical batch size schedules', 'to control', 'noise ( or temperature )'], ['noise ( or temperature )', 'of', 'SGD']]"
"[['different cyclical annealing strategies', 'for', 'wide range of problems']]"
[]
[]
"[['snapshot ensembling', 'enables', 'even greater performance']]"
"[['best performing CBS schedules', 'result in', 'significant improvements'], ['significant improvements', 'in', 'perplexity'], ['reductions', 'in', 'number of SGD training iterations'], ['significant improvements', 'over', 'baseline schedules'], ['perplexity', 'over', 'baseline schedules'], ['significant improvements', 'offer', 'reductions'], ['reductions', 'in', 'number of SGD training iterations']]"
"[['almost all CBS schedules', 'outperform', 'baseline schedule']]"
"[['CBS schedules', 'do not yield', 'large performance improvements'], ['large performance improvements', 'on', 'models'], ['smaller disparities', 'between', 'training and testing performance']]"
[]
"[['training curves', 'of', 'CBS schedules'], ['CBS schedules', 'exhibit', 'aforementioned'], ['CBS schedules', 'exhibit', 'cyclical spikes'], ['cyclical spikes', 'in', 'training loss'], ['cyclical spikes', 'in', 'testing accuracy']]"
"[['CBS', 'achieves', 'similar performance'], ['similar performance', 'to', 'baseline']]"
"[['CBS - 15', 'see', '90.71 % training accuracy'], ['CBS - 15', 'see', '56. 44 % testing accuracy']]"
"[['CBS - 15', 'on', 'C2'], ['CBS - 15', 'improves', 'accuracy'], ['accuracy', 'to', '94.82 %']]"
"[['snapshot ensembling', 'on', 'C3'], ['snapshot ensembling', 'trained with', 'CBS - 15 - 2'], ['C3', 'trained with', 'CBS - 15 - 2'], ['snapshot ensembling', 'leads to', 'improved accuracy'], ['CBS - 15 - 2', 'leads to', 'improved accuracy'], ['improved accuracy', 'of', '93. 56 %']]"
"[['ResNet50', 'on', 'Imagenet'], ['Imagenet', 'with', 'snapshots'], ['snapshots', 'from', 'last two cycles'], ['76.401 %', 'from', '75.336 %'], ['increases', 'to', '76.401 %'], ['76.401 %', 'from', '75.336 %']]"
[]
"[['TBCNNpair model', 'to recognize', 'entailment and contradiction'], ['entailment and contradiction', 'between', 'two sentences']]"
[]
[]
"[['TBCNN - pair neural model', 'to recognize', 'entailment and contradiction'], ['entailment and contradiction', 'between', 'two sentences']]"
"[['newly proposed TBCNN model', 'to capture', 'structural information'], ['structural information', 'in', 'sentences']]"
"[['TBCNN', 'is', 'more robust'], ['more robust', 'than', 'sequential convolution'], ['sequential convolution', 'in terms of', 'word order distortion']]"
"[['information', 'along', 'tree'], ['aggregates', 'serving as', 'away'], ['information', 'serving as', 'away'], ['away', 'of', 'semantic compositonality']]"
"[[""two sentences ' information"", 'combined by', 'several heuristic matching layers'], ['several heuristic matching layers', 'including', 'concatenation'], ['several heuristic matching layers', 'including', 'difference']]"
[]
"[['Word embeddings', 'pretrained ourselves by', 'word2vec'], ['word2vec', 'on', 'English Wikipedia corpus'], ['Word embeddings', 'fined tuned during', 'training']]"
"[['2 penalty', 'of', '310 ? 4'], ['granularity', 'of', '0.1'], ['dropout', 'chosen by', 'validation'], ['validation', 'with', 'granularity'], ['granularity', 'of', '0.1']]"
"[['Initial learning rate', 'set to', '1']]"
"[['stochastic gradient descent', 'with', 'batch size'], ['batch size', 'of', '50']]"
"[['TBCNN sentence pair model', 'followed by', 'simple concatenation'], ['TBCNN sentence pair model', 'outperforms', 'existing sentence encoding - based approaches'], ['simple concatenation', 'outperforms', 'existing sentence encoding - based approaches'], ['existing sentence encoding - based approaches', 'including', 'feature - rich method'], ['feature - rich method', 'using', '6 groups of humanengineered features']]"
[]
"[['element - wise product', 'is', 'significantly worse'], ['element - wise product', 'is', 'element - wise difference'], ['significantly worse', 'than', 'concatenation'], ['significantly worse', 'than', 'element - wise difference']]"
"[['different matching heuristics', 'improves', 'result'], ['TBCNN - pair model', 'with', 'concatenation'], ['element - wise product and difference', 'yields', 'highest performance'], ['highest performance', 'of', '82.1 %']]"
"[['element - wise product', 'improves', 'accuracy'], ['accuracy', 'by', 'another 0.5 %']]"
"[['full TBCNN - pair model', 'outperforms', 'all existing sentence encoding - based approaches'], ['all existing sentence encoding - based approaches', 'in - cluding', '1024d gated recurrent unit ( GRU ) - based RNN']]"
[]
[]
[]
"[['model', 'maintains', 'state']]"
[]
"[['word embedding', 'with', '300 - dimensional GloVe word vectors']]"
"[['character encoding', 'use', 'concatenation'], ['concatenation', 'of', 'multi-filter Convolutional Neural Nets'], ['multi-filter Convolutional Neural Nets', 'with', 'windows 1 , 3 , 5'], ['multi-filter Convolutional Neural Nets', 'with', 'hidden size']]"
"[['lexicon embeddings', 'are', 'd =600 - dimensions']]"
"[['embedding', 'for', 'out - of - vocabulary'], ['embedding', 'is', 'zeroed'], ['out - of - vocabulary', 'is', 'zeroed']]"
"[['hidden size', 'of', 'LSTM'], ['input size', 'of', 'output layer'], ['LSTM', 'in', 'contextual encoding layer'], ['memory generation layer', 'set to', '128'], ['input size', 'of', 'output layer'], ['output layer', 'is', '1024 ( 128 * 2 * 4 )']]"
"[['projection size', 'in', 'attention layer'], ['projection size', 'set to', '256']]"
"[['training', 'use', 'weight normalization']]"
"[['dropout rate', 'is', '0.2'], ['dropout mask', 'fixed through', 'time steps'], ['time steps', 'in', 'LSTM']]"
"[['mini - batch size', 'set to', '32']]"
"[['learning rate', 'initialized as', '0.002'], ['learning rate', 'decreased by', '0.5'], ['0.5', 'after', 'each 10 epochs']]"
"[['our multi-step model', 'consistently outperforms', 'single - step model'], ['single - step model', 'on', 'dev set'], ['dev set', 'of', 'all four datasets'], ['all four datasets', 'in terms of', 'accuracy']]"
"[['SciTail dataset', 'outperforms', 'single - step model'], ['SAN', 'outperforms', 'single - step model']]"
"[['SAN', 'outperforms', 'GPT']]"
"[['proposed model', 'obtains', '+ 2.8 improvement'], ['proposed model', 'obtains', '+ 2.1 improvement'], ['+ 2.8 improvement', 'on', '+ 2.1 improvement']]"
"[['Our model', 'outperforms', 'best system'], ['best system', 'in', 'RepEval 2017'], ['inmost cases', 'except on', 'Conditional "" and "" Tense Difference "" categories']]"
"[['SAN', 'works', 'extremely well'], ['extremely well', 'on', 'Active / Passive "" and "" Paraphrase "" categories']]"
"[['biggest improvement', 'of', 'SAN'], ['50 % vs 77 % and 58 % vs 85 %', 'on', 'Matched and Mismatched settings'], ['50 % vs 77 % and 58 % vs 85 %', 'on', '"" Antonym "" category'], ['biggest improvement', 'on', '"" Antonym "" category']]"
"[[""SAN 's result"", 'is', 'substantially better'], ['substantially better', 'than', 'previous systems']]"
[]
[]
"[['NTI', 'takes', 'sequence of tokens'], ['NTI', 'produces', 'representation'], ['representation', 'by constructing', 'full n-ary tree'], ['full n-ary tree', 'in', 'bottom - up fashion']]"
"[['Each node', 'in', 'NTI']]"
"[['different variants', 'of', 'node composition function and attention over tree'], ['node composition function and attention over tree', 'for', 'our NTI models']]"
"[['sequential leaf node transformer', 'such as', 'LSTM'], ['NTI network', 'forms', 'sequence - tree hybrid model'], ['sequence - tree hybrid model', 'taking advantage of', 'conditional and compositional powers'], ['conditional and compositional powers', 'of', 'sequential and recursive models']]"
[]
"[['best score', 'is', '87.3 % accuracy'], ['87.3 % accuracy', 'obtained with', 'full tree matching NTI model']]"
"[['NTI - SLSTM', 'improved', 'performance'], ['performance', 'of', 'sequential LSTM encoder']]"
"[['node - by - node attention models', 'improve', 'performance']]"
[]
"[['Deep LSTM and LSTM attention models', 'outperform', 'previous best result'], ['previous best result', 'by', 'large margin']]"
"[['NASM', 'improves', 'result'], ['NASM', 'sets', 'strong baseline'], ['strong baseline', 'by combining', 'variational autoencoder'], ['variational autoencoder', 'with', 'soft attention']]"
"[['NTI model', 'exceeds', 'NASM'], ['NASM', 'by', 'approximately 0.4 %'], ['approximately 0.4 %', 'on', 'MAP']]"
[]
"[['NTI - SLSTM model', 'performed', 'slightly worse']]"
"[['input', 'with', 'LSTM leaf node function'], ['input', 'achieved', 'best performance'], ['LSTM leaf node function', 'achieved', 'best performance']]"
[]
[]
[]
"[['novel neural network architecture', 'called', 'attention - over - attention model']]"
"[['another attention mechanism', 'over', 'existing document - level attention']]"
"[['"" attended attention ""', 'over', 'various document - level attentions'], ['"" attended attention ""', 'make', 'mutual look'], ['mutual look', 'not only from', 'query - to - document']]"
[]
"[['randomly initialized', 'with', 'uniformed distribution'], ['uniformed distribution', 'in', 'interval [ ? 0.05 , 0.05 ].']]"
"[['Internal weights', 'of', 'GRUs'], ['Hidden Layer', 'initialized with', 'random orthogonal matrices']]"
"[['ADAM optimizer', 'for', 'weight updating'], ['ADAM optimizer', 'with', 'initial learning rate'], ['weight updating', 'with', 'initial learning rate'], ['initial learning rate', 'of', '0.001']]"
"[['gradient clipping threshold', 'to', '5']]"
"[['batched training strategy', 'of', '32 samples']]"
"[['re-ranking step', 'generate', '5 - best list'], ['5 - best list', 'from', 'baseline neural network model']]"
"[['language model features', 'trained on', 'training proportion'], ['language model features', 'trained on', 'Kneser - Ney smoothing'], ['training proportion', 'of', 'each dataset'], ['training proportion', 'with', '8 - gram wordbased setting'], ['each dataset', 'with', '8 - gram wordbased setting'], ['Kneser - Ney smoothing', 'trained by', 'SRILM toolkit']]"
"[['Implementation', 'done with', 'Keras']]"
"[['our AoA Reader', 'outperforms', 'state - of - the - art systems'], ['state - of - the - art systems', 'by', 'large margin'], ['large margin', 'where', '2.3 % and 2.0 % absolute improvements'], ['2.3 % and 2.0 % absolute improvements', 'over', 'EpiReader'], ['EpiReader', 'in', 'CBTest NE and CN test sets']]"
"[['additional features', 'in', 're-ranking step'], ['Ao A Reader', 'in', 'CBTest NE / CN test sets'], ['another significant boost', 'over', 'Ao A Reader'], ['2.0 % to 3.7 %', 'over', 'Ao A Reader'], ['Ao A Reader', 'in', 'CBTest NE / CN test sets']]"
"[['absolute improvement', 'of', '0.9 %'], ['0.9 %', 'beyond', 'best ensemble model ( Iterative Attention )'], ['best ensemble model ( Iterative Attention )', 'in', 'CBTest NE validation set']]"
"[['our AoA Reader', 'shows', 'significant improvements'], ['significant improvements', 'over', 'previous best ensemble models'], ['significant improvements', 'by', 'large margin'], ['previous best ensemble models', 'by', 'large margin'], ['significant improvements', 'setup', 'new state - of - the - art system'], ['previous best ensemble models', 'setup', 'new state - of - the - art system']]"
"[['model', 'explicitly learn', 'weights'], ['weights', 'between', 'individual attentions'], ['weights', 'results in', 'significant boost'], ['individual attentions', 'results in', 'significant boost'], ['significant boost', 'in', 'performance'], ['significant boost', 'where', '4.1 % and 3.7 % improvements'], ['performance', 'where', '4.1 % and 3.7 % improvements'], ['4.1 % and 3.7 % improvements', 'in', 'CNN validation and test set'], ['CNN validation and test set', 'against', 'CAS Reader']]"
"[['benefit a lot', 'from', 're-ranking features']]"
"[['performance', 'boosted by', 'LM local feature']]"
[]
[]
[]
"[['connected graph', 'to depict', 'paraphrase relation'], ['paraphrase relation', 'between', 'sentences'], ['sentences', 'for', 'PI task'], ['connected graph', 'propose', 'multi-task sentence - encoding model'], ['multi-task sentence - encoding model', 'solves', 'paraphrase identification task'], ['multi-task sentence - encoding model', 'solves', 'sentence intent classification task']]"
"[['semantic retrieval framework', 'integrates', 'encoding - based sentence matching model'], ['encoding - based sentence matching model', 'with', 'approximate nearest neighbor search technology'], ['most similar question', 'from', 'all available questions'], ['very quickly', 'from', 'all available questions']]"
"[['Quora dataset', 'use', 'Glove - 840B - 300D vector'], ['Glove - 840B - 300D vector', 'as', 'pre-trained word embedding']]"
"[['character embedding', 'randomly initialized with', '150 D'], ['randomly initialized', 'with', '150 D'], ['hidden size', 'of', 'BiGRU']]"
"[['= 0.8', 'in', 'multi - task loss function']]"
"[['Dropout layer', 'applied to', 'output'], ['output', 'of', 'attentive pooling layer'], ['dropout rate', 'of', '0.1'], ['Dropout layer', 'with', 'dropout rate'], ['attentive pooling layer', 'with', 'dropout rate'], ['dropout rate', 'of', '0.1']]"
[]
"[['learning rate', 'set to', '4e - 4'], ['batch size', 'set to', '200']]"
"[['performance', 'of', 'model'], ['learning rate', 'of', '1e - 3'], ['performance', 'is', 'no longer improved'], ['model', 'is', 'no longer improved'], ['SGD optimizer', 'with', 'learning rate'], ['learning rate', 'of', '1e - 3'], ['1e - 3', 'to find', 'better local optimum']]"
"[['Enhanced Sequential Inference Model', 'is', 'interaction - based model'], ['interaction - based model', 'for', 'natural language inference']]"
"[['Bilateral Multi- Perspective Matching model', 'is', 'interaction - based sentence matching model'], ['interaction - based sentence matching model', 'with', 'superior performance']]"
"[['Shortcut - Stacked Sentence Encoder', 'is', 'encodingbased sentence - matching model'], ['encodingbased sentence - matching model', 'enhances', 'multi - layer BiLSTM'], ['multi - layer BiLSTM', 'with', 'short - cut connections']]"
[]
"[['BiMPM and ESIM models', 'without', 'any sentence interaction information'], ['Quora dataset', 'very close to', 'DIIN']]"
[]
[]
"[['BQ dataset', 'is', 'specific - domain dataset'], ['specific - domain dataset', 'with', 'low average overlap rate']]"
"[['state - of - the - art models', 'by', 'large margin'], ['state - of - the - art models', 'reaching', '83 . 62 %'], ['large margin', 'reaching', '83 . 62 %']]"
[]
[]
"[['contribution', 'of', 'ARU component']]"
"[['drop', 'to', '88.25 %']]"
"[['attentive pooling', 'better than', 'max pooling']]"
"[['drop', 'to', '88.36 %']]"
"[['drop', 'to', '88.26 %']]"
[]
[]
"[['deep fusion strategy', 'to model', 'strong interactions'], ['strong interactions', 'of', 'two sentences']]"
[]
"[['deep fusion long short - term memory neural networks ( DF - LSTMs )', 'to model', 'interactions']]"
"[['DF - LSTMs', 'consist of', 'two interconnected conditional LSTMs']]"
"[['output vector', 'of', 'DF - LSTMs'], ['DF - LSTMs', 'fed into', 'task - specific output layer'], ['task - specific output layer', 'to compute', 'match - ing score']]"
[]
"[['Each sequence', 'sum of', 'embeddings'], ['embeddings', 'of', 'words'], ['Each sequence', 'concatenated and fed to', 'MLP']]"
"[['Two sequences', 'encoded by', 'single LSTM']]"
"[['Two sequences', 'first encoded by', 'two LSTMs'], ['Two sequences', 'first encoded by', 'two LSTMs separately'], ['Parallel LSTMs', 'concatenated and fed to', 'MLP']]"
"[['Two sequences', 'encoded by', 'LSTMs'], ['LSTMs', 'with', 'attention mechanism']]"
[]
"[['proposed model', 'shows', 'superiority'], ['superiority', 'outperforms', 'stateof - the - arts methods'], ['stateof - the - arts methods', 'on', 'both metrics'], ['both metrics', 'with', 'large margin']]"
"[['weak interaction models ( NBOW , parallel LSTMs )', 'with', 'large margin']]"
[]
"[['open - domain setting', 'using', 'Wikipedia']]"
[]
"[['few relevant articles', 'among', 'more than 5 million items'], ['scan', 'to identify', 'answer'], ['carefully', 'to identify', 'answer']]"
[]
"[['Wikipedia', 'as', 'collection of articles']]"
"[['our approach', 'is', 'generic'], ['our approach', 'switched to', 'other collections of documents']]"
"[['single knowledge source', 'forces', 'model'], ['model', 'to be', 'very precise'], ['single knowledge source', 'searching for', 'answer'], ['model', 'searching for', 'answer']]"
"[['3 - layer bidirectional LSTMs', 'with', 'h = 128 hidden units'], ['h = 128 hidden units', 'for', 'paragraph and question encoding']]"
"[['Stanford CoreNLP toolkit', 'for', 'tokenization'], ['Stanford CoreNLP toolkit', 'generating', 'named entity tags']]"
"[['training examples', 'sorted by', 'length'], ['length', 'of', 'paragraph'], ['minibatches', 'of', '32 examples'], ['training examples', 'divided into', 'minibatches'], ['minibatches', 'of', '32 examples']]"
"[['Adamax', 'for', 'optimization']]"
"[['Dropout', 'with', 'p = 0.3'], ['p = 0.3', 'applied to', 'word embeddings'], ['p = 0.3', 'applied to', 'all the hidden units'], ['all the hidden units', 'of', 'LSTMs']]"
"[['79.0 % F 1 scores', 'on', 'test set'], ['79.0 % F 1 scores', 'surpasses', 'all the published results'], ['test set', 'surpasses', 'all the published results'], ['79.0 % F 1 scores', 'match', 'top performance'], ['top performance', 'on', 'SQuAD leaderboard']]"
"[['our system', 'able to achieve', 'F1'], ['F1', 'over', '77 %']]"
[]
[]
[]
[]
"[['deep cascade model', 'combines', 'advantages'], ['advantages', 'of', 'both methods'], ['advantages', 'in', 'coarse - to - fine manner'], ['both methods', 'in', 'coarse - to - fine manner']]"
"[['deep cascade model', 'designed to properly keep', 'balance'], ['balance', 'between', 'effectiveness and efficiency']]"
"[['simple features and ranking functions', 'to select', 'candidate set'], ['candidate set', 'of', 'most relevant contents'], ['candidate set', 'filtering out', 'irrelevant documents and paragraphs']]"
"[['selected paragraphs', 'passed to', 'attention - based deep MRC model'], ['attention - based deep MRC model', 'for extracting', 'actual answer span'], ['actual answer span', 'at', 'word level']]"
[]
"[['all the three tasks', 'in', 'unified deep MRC model'], ['unified deep MRC model', 'shares', 'some common bottom layers']]"
"[['cascaded structure', 'enables', 'models'], ['cascaded structure', 'to perform', 'coarse - to - fine pruning'], ['models', 'to perform', 'coarse - to - fine pruning'], ['coarse - to - fine pruning', 'at', 'different stages']]"
[]
"[['first module', 'takes', 'question'], ['collection of raw documents', 'as', 'input']]"
"[['module', 'at', 'each subsequent stage'], ['module', 'consumes', 'output'], ['each subsequent stage', 'consumes', 'output'], ['output', 'from', 'previous stage'], ['module', 'further prunes', 'documents , paragraphs and answer spans'], ['documents , paragraphs and answer spans', 'given', 'question']]"
"[['ranking function', 'used as', 'preliminary filter'], ['preliminary filter', 'to discard', 'most of the irrelevant documents or paragraphs']]"
"[['extraction function', 'designed to deal with', 'auxiliary document and paragraph extraction tasks'], ['auxiliary document and paragraph extraction tasks', 'jointly optimized with', 'final answer extraction module'], ['final answer extraction module', 'for', 'better extraction performance']]"
"[['K = 4 and N = 2', 'for', 'good performance']]"
"[['Adam optimizer', 'For', 'training'], ['multi-task deep attention framework', 'adopt', 'Adam optimizer'], ['Adam optimizer', 'for', 'training'], ['Adam optimizer', 'with', 'mini-batch size'], ['Adam optimizer', 'with', 'initial learning rate'], ['training', 'with', 'mini-batch size'], ['training', 'with', 'initial learning rate'], ['mini-batch size', 'of', '32'], ['initial learning rate', 'of', '0.0005']]"
"[['GloVe 300 dimensional word embeddings', 'in', 'TriviaQA'], ['word2 vec word embeddings', 'with', 'whole DuReader corpus'], ['whole DuReader corpus', 'for', 'DuReader']]"
"[['word embeddings', 'fixed during', 'training']]"
"[['hidden size', 'of', 'LSTM'], ['hidden size', 'set as', '150'], ['LSTM', 'set as', '150'], ['150', 'for', 'TriviaQA'], ['128', 'for', 'DuReader'], ['128', 'for', 'DuReader']]"
[]
"[['small value', 'of', '0.01']]"
"[['Nvidia Tesla M40 GPU', 'with', 'Cudnn LSTM cell'], ['Cudnn LSTM cell', 'in', 'Tensorflow 1.3']]"
"[['proposed model', 'outperforms', 'previous state - of - the - art methods'], ['previous state - of - the - art methods', 'by', 'evident margin'], ['evident margin', 'on', 'both datasets']]"
"[['shared LSTM', 'plays', 'important role'], ['important role', 'in', 'answer extraction'], ['answer extraction', 'among', 'multiple documents'], ['content probability score', 'from', 'multiple documents'], ['shared LSTM', 'keep', 'ranking order'], ['ranking order', 'from', 'document ranking component']]"
[]
"[['preliminary cascade ranking and multi-task answer extraction strategy', 'vital for', 'final performance'], ['final performance', 'serve as', 'good trade - off'], ['good trade - off', 'between', 'pure pipeline method'], ['good trade - off', 'between', 'fully joint learning method']]"
"[['three extraction tasks', 'provide', 'great benefits'], ['each other', 'with', 'shared representations'], ['shared representations', 'at', 'bottom layers']]"
[]
[]
[]
"[['problem', 'of', 'MRC']]"
"[['U - Net', 'to incorporate', 'three sub - tasks'], ['three sub - tasks', 'into', 'unified model']]"
"[['answer pointer', 'to predict', 'can - didate answer span'], ['can - didate answer span', 'for', 'question'], ['no -answer pointer', 'selecting', 'any text span'], ['any text span', 'when', 'question'], ['answer verifier', 'to determine', 'probability'], ['probability', 'of', 'question'], ['question', 'with', 'candidate answer information']]"
"[['question and its context passage', 'as', 'single contiguous sequence of tokens'], ['single contiguous sequence of tokens', 'greatly improves', 'conciseness'], ['conciseness', 'of', 'U - Net']]"
"[['universal node', 'acts on', 'question and passage'], ['question', 'is', 'answerable']]"
"[['Spacy', 'to process', 'each question and passage'], ['lemmas tags', 'of', 'each text']]"
"[['12 dimensions', 'to embed', 'POS tags'], ['POS tags', 'for', 'NER tags'], ['8', 'for', 'NER tags']]"
"[['3 binary features', 'between', 'question and passage'], ['lemma match', 'between', 'question and passage']]"
[]
"[['LSTM blocks', 'are', 'bi-directional'], ['bi-directional', 'with', 'one single layer']]"
"[['hidden layer dimension', 'as', '125'], ['hidden layer dimension', 'as', '250'], ['attention layer dimension', 'as', '250']]"
"[['dropout layer', 'overall', 'modeling layers'], ['modeling layers', 'including', 'embedding layer'], ['dropout layer', 'at', 'dropout rate'], ['dropout rate', 'of', '0.3']]"
"[['Adam optimizer', 'with', 'learning rate'], ['learning rate', 'of', '0.002']]"
"[['Our model', 'achieves', 'F 1 score'], ['Our model', 'achieves', 'EM score'], ['Our model', 'achieves', 'F 1 score'], ['Our model', 'achieves', 'EM score'], ['F 1 score', 'of', '74.0'], ['EM score', 'of', '70.3'], ['F 1 score', 'of', '72.6'], ['EM score', 'of', '70.3'], ['F 1 score', 'of', '72.6'], ['EM score', 'of', '69.2'], ['70.3', 'on', 'development set'], ['69.2', 'on', 'Test set'], ['F 1 score', 'of', '72.6'], ['EM score', 'of', '69.2'], ['EM score', 'on', 'Test set'], ['69.2', 'on', 'Test set']]"
"[['Our model', 'outperforms', 'most of the previous approaches']]"
"[['best - performing systems', 'is', 'end - to - end model']]"
"[['all the end - to - end models', 'achieve', 'best F1 scores']]"
"[['node U', 'is', 'shared'], ['information interaction', 'between', 'question and passage']]"
[]
[]
"[['performance', 'dropped', 'greatly']]"
"[['output', 'of', 'encoded presentation'], ['output', 'of', 'encoded presentation']]"
[]
[]
[]
[]
"[['inter-attention and self - attention', 'on', 'passage and question'], ['passage and question', 'to obtain', 'more effective understanding'], ['more effective understanding', 'of', 'passage and dialogue history']]"
"[['SDNet', 'leverages', 'latest breakthrough'], ['latest breakthrough', 'in', 'NLP']]"
"[['weighted sum', 'of', 'BERT layer outputs'], ['BERT layer outputs', 'with', 'locked BERT parameters']]"
"[['previous rounds of questions and answers', 'to', 'current question'], ['current question', 'to incorporate', 'contextual information']]"
"[['SDNet', 'achieves', 'significantly better results'], ['significantly better results', 'than', 'baseline models']]"
"[['single SDNet model', 'improves', 'overall F 1'], ['overall F 1', 'by', '1.6 %'], ['previous state - of - art model', 'on', 'CoQA']]"
"[['overall F 1 score', 'by', '2.7 %']]"
"[['SDNet', 'overpasses', 'all but one baseline models'], ['all but one baseline models', 'after', 'second epoch'], ['SDNet', 'achieves', 'state - of - the - art results'], ['state - of - the - art results', 'after', '8 epochs']]"
[]
[]
"[['new kind of memory - augmented neural network', 'uses', 'distributed memory and processor architecture']]"
"[['fixed number of dynamic memory cells', 'containing', 'vector key w j'], ['fixed number of dynamic memory cells', 'containing', 'vector value ( or content ) h j']]"
"[['Each cell', 'associated with', 'own "" processor ""'], ['cell value', 'given', 'input']]"
"[['EntNet', 'seen as', 'bank of gated RNNs'], ['bank of gated RNNs', 'whose', 'hidden states'], ['hidden states', 'correspond to', 'latent concepts and attributes'], ['parameters', 'describe', 'laws of the world'], ['laws of the world', 'according to which', 'attributes'], ['attributes', 'of', 'objects']]"
"[['hidden state', 'updated only when', 'new information'], ['new information', 'relevant to', 'concept']]"
"[['keys', 'used in', 'addressing / gating mechanism'], ['addressing / gating mechanism', 'correspond to', 'concepts or entities']]"
[]
"[['MemN2N', 'set', 'number of hops'], ['number of hops', 'equal to', 'T ? 2'], ['embedding dimension', 'to', 'd = 20']]"
"[['EntNet', 'had', '5 memory slots'], ['LSTM', 'had', '50 hidden units'], ['significantly more parameters', 'than', 'other two models']]"
"[['ADAM', 'with', 'initial learning rates'], ['initial learning rates', 'set by', 'grid search'], ['grid search', 'over', '{ 0.1 , 0.01 , 0.001 }'], ['grid search', 'divided by', '2']]"
"[['worst performance', 'degrades', 'quickly']]"
"[['LSTM', 'performs', 'better'], ['LSTM', 'loses', 'accuracy']]"
[]
"[['methods', 'with', 'limited memory'], ['limited memory', 'such as', 'LSTMs'], ['limited memory', 'perform', 'well'], ['well', 'on', 'more frequent , syntax based words'], ['more frequent , syntax based words', 'such as', 'prepositions and verbs']]"
[]
[]
[]
"[['multi-hops architecture', 'refines', 'results'], ['results', 'by using', 'self - attention model']]"
"[['question - passage attention models', 'for', 'machine comprehension and question answering'], ['machine comprehension and question answering', 'calculate', 'alignment matrix'], ['alignment matrix', 'corresponding to', 'all question and passage word pairs']]"
"[['EM result', 'of', 'our baseline Iterative Aligner'], ['our baseline Iterative Aligner', 'lower than', 'RNET']]"
"[['RNET', 'uses', 'different feature set']]"
"[['performance', 'with', 'different number of layers'], ['different number of layers', 'for', 'question - passage attention phase'], ['different number of layers', 'for', 'self - attention phase']]"
"[['question - passage attention phase', 'using', 'single layer'], ['single layer', ""does n't degrade"", 'performance'], ['performance', 'from', 'default setting'], ['significantly', 'from', 'default setting'], ['default setting', 'of', 'two layers']]"
"[['multiple stacking layers', 'to allow', 'evidence'], ['needed', 'to allow', 'evidence'], ['evidence', 'fully propagated through', 'passage']]"
[]
[]
"[['modeling questions', 'in', 'end - to - end neural network framework']]"
[]
"[['information', 'as', 'adaptation problem'], ['information', 'as', 'proposed']]"
[]
"[['SQuAD dataset', 'consists of', 'more than 100,000 questions'], ['more than 100,000 questions', 'annotated by', 'crowdsourcing workers']]"
"[['pre-trained 300 - D Glove 840B vectors', 'to initialize', 'our word embeddings']]"
"[['Out - of - vocabulary ( OOV ) words', 'initialized', 'randomly'], ['randomly', 'with', 'Gaussian samples']]"
"[['CharCNN filter length', 'is', '1 , 3 , 5'], ['CharCNN filter length', 'is', '50 dimensions']]"
"[['cluster number K', 'in', 'discriminative block'], ['discriminative block', 'is', '100']]"
"[['Adam method', 'used for', 'optimization']]"
"[['first momentum', 'set to be', '0.9']]"
"[['initial learning rate', 'is', '0.0004'], ['batch size', 'is', '32'], ['batch size', 'is', '32']]"
"[['hidden states', 'of', 'GRUs , and TreeLSTMs'], ['GRUs , and TreeLSTMs', 'are', '500 dimensions'], ['word - level embedding d w', 'is', '300 dimensions']]"
"[['max length', 'of', 'document'], ['document', 'to', '500'], ['question - document pairs', 'on', 'training set']]"
"[['Explicit question - type dimension d ET', 'is', '50']]"
"[['dropout', 'to', 'Encoder layer and aggregation layer'], ['Encoder layer and aggregation layer', 'with', 'dropout rate'], ['dropout rate', 'of', '0.5']]"
"[['Our model', 'achieves', '68.73 % EM score'], ['Our model', 'achieves', '77.39 % F1 score'], ['77.39 % F1 score', 'ranked among', 'state of the art single models']]"
"[['baseline model', 'using', 'no Q- code'], ['no Q- code', 'achieved', '68.00 % and 77.36 % EM and F 1 scores']]"
"[['explicit question type T - code', 'into', 'baseline model'], ['improved slightly', 'to', '68.16 % ( EM )'], ['improved slightly', 'to', '77.58 % ( F1 )']]"
"[['TreeLSTM', 'introduce', 'syntactic parses'], ['syntactic parses', 'for', 'question representation and understanding']]"
"[['78.38 % F1 score', 'on', 'whole development set'], ['78.38 % F1 score', 'separated into', 'two parts']]"
[]
[]
[]
[]
"[['internal structures', 'of', 'sentences'], ['rich patterns', 'in', 'interactions']]"
"[['deep neural network models', 'adapt', 'convolutional strategy'], ['convolutional strategy', 'to', 'natural language']]"
"[['hierarchical composition', 'for', 'sentences'], ['simple - to - comprehensive fusion', 'of', 'matching patterns'], ['matching patterns', 'with', 'same convolutional architecture']]"
"[['generic', 'requiring no', 'prior knowledge'], ['prior knowledge', 'of', 'natural language'], ['constraints', 'on', 'matching tasks']]"
[]
"[['ARC - II', 'outperforms', 'ARC - I'], ['ARC - II', 'outperforms', 'significantly']]"
"[['SENNA + MLP', 'performs', 'fairly well']]"
[]
"[['generic matching models', 'manage to perform', 'reasonably well'], ['generic matching models', 'achieving', 'accuracy and F1 score'], ['reasonably well', 'achieving', 'accuracy and F1 score'], ['accuracy and F1 score', 'close to', 'best performer'], ['best performer', 'in', '2008'], ['best performer', 'based on', 'hand - crafted features'], ['2008', 'based on', 'hand - crafted features'], ['significantly lower', 'than', 'state - of - the - art ( 76.8%/83.6 % )']]"
[]
[]
"[['MANN', 'named', 'SAM ( sparse access memory )']]"
"[['memory modifications', 'to', 'sparse subset'], ['efficient data structures', 'for', 'content - based read operations'], ['our model', 'is', 'optimal'], ['optimal', 'in', 'space and time'], ['space and time', 'with respect to', 'memory size'], ['our model', 'retaining', 'end - to - end gradient based optimization']]"
[]
"[['sparse models', 'able to', 'learn'], ['comparable efficiency', 'able to', 'dense models'], ['learn', 'with', 'comparable efficiency'], ['comparable efficiency', 'to', 'dense models'], ['sparse models', 'learn', 'more effectively'], ['more effectively', 'for', 'some tasks'], ['more effectively', 'for', 'associative recall']]"
[]
"[['SAM', 'able to', 'advance'], ['advance', 'than', 'other models'], ['further', 'than', 'other models'], ['curriculum', 'to', 'sequences']]"
[]
"[['MANNs', 'except', 'NTM'], ['MANNs', 'able to learn', 'solutions'], ['solutions', 'comparable to', 'previous best results']]"
"[['SDNC', 'manages to solve', 'all but 1 of the tasks']]"
"[['NTM', 'perform', 'poorly']]"
[]
"[['SAM', 'outperformed', 'other models']]"
"[['MANNs', 'able to perform', 'much better'], ['much better', 'than', 'chance']]"
[]
[]
"[['novel deep neural network architecture', 'to handle', 'long - range dependency'], ['long - range dependency', 'in', 'RC tasks']]"
[]
"[['two novel strategies', 'that improve', 'memory - handling capability'], ['memory - handling capability', 'while mitigating', 'information distortion']]"
"[['memory controller', 'with', 'residual connection'], ['residual connection', 'to alleviate', 'information distortion']]"
"[['gated recurrent unit ( GRU )', 'with', 'dense connection'], ['dense connection', 'conveys', 'enriched features'], ['enriched features', 'to', 'next layer'], ['next layer', 'containing', 'original as well as the transformed information']]"
"[['Sonnet', 'to implement', 'memory interface']]"
"[['NLTK', 'used for', 'tokenizing'], ['NLTK', 'used for', 'tokenizing words']]"
"[['memory controller', 'use', 'four read heads'], ['memory controller', 'use', 'one write head'], ['memory size', 'set to', '100 36']]"
"[['hidden vector dimension l', 'set to', '200']]"
"[['AdaDelta ( Zeiler , 2012 )', 'as', 'optimizer'], ['AdaDelta ( Zeiler , 2012 )', 'with', 'learning rate'], ['optimizer', 'with', 'learning rate'], ['learning rate', 'of', '0.5']]"
"[['batch size', 'set to', '20'], ['20', 'for', 'TriviaQA'], ['30', 'for', 'SQuAD and QUASAR - T'], ['30', 'for', 'SQuAD and QUASAR - T']]"
"[['exponential moving average', 'of', 'weights'], ['decaying factor', 'of', '0.001'], ['weights', 'with', 'decaying factor'], ['decaying factor', 'of', '0.001']]"
"[['more memory', 'than', 'existing methods']]"
"[['our model', 'outperforms', 'all the published results'], ['short - document case', 'such as', 'SQuAD']]"
"[['concatenation', 'of', 'layer outputs'], ['layer outputs', 'in', 'DEBS'], ['concatenation', 'helps', 'memory controller'], ['memory controller', 'store', 'contextual representations']]"
"[['DEBS', 'in', 'all the places'], ['DEBS', 'improves', 'performance most'], ['all the places', 'improves', 'performance most'], ['memory controller', 'with', 'DEBS'], ['memory controller', 'gives', 'largest performance margin'], ['DEBS', 'gives', 'largest performance margin']]"
[]
[]
"[['lexical semantics', 'over', 'sentences']]"
"[['each word', 'as', 'low -dimensional vector'], ['semantic matching vector', 'for', 'each word'], ['each word', 'based on', 'all words'], ['all words', 'in', 'other sentence']]"
"[['each word vector', 'decomposed into', 'two components']]"
"[['similar components', 'of', 'all the words'], ['similar parts', 'of', 'sentence pair'], ['dissimilar components', 'of', 'every word'], ['all the words', 'to represent', 'similar parts'], ['similar parts', 'of', 'sentence pair'], ['dissimilar components', 'of', 'every word'], ['dissimilar components', 'of', 'every word'], ['every word', 'to model', 'dissimilar parts']]"
"[['two - channel CNN operation', 'to compose', 'similar and dissimilar components'], ['similar and dissimilar components', 'into', 'feature vector']]"
"[['composed feature vector', 'to predict', 'sentence similarity']]"
[]
"[['some word overlap features', 'between', 'two sentences']]"
"[['our model', 'got', 'best MAP'], ['our model', 'got', 'comparable MRR'], ['best MAP', 'among', 'all previous work'], ['comparable MRR', 'than', 'dos']]"
[]
"[['best performance', 'acquired by', 'bigram CNN model'], ['bigram CNN model', 'combining with', 'word overlap features']]"
[]
"[['our model', 'obtained', 'comparable performance'], ['comparable performance', 'without using', 'sparse features'], ['comparable performance', 'without using', 'extra annotated resources'], ['comparable performance', 'without using', 'specific training strategies']]"
[]
"[['new self - attention mechanism', 'for', 'sentence embedding']]"
"[['DSA', 'by modifying', 'dynamic routing'], ['dynamic routing', 'in', 'capsule network']]"
"[['new self - attention mechanism', 'for', 'sentence embedding'], ['sentence embedding', 'namely', 'Dynamic Self - Attention ( DSA )']]"
"[['dynamic routing', 'functions as', 'self - attention'], ['self - attention', 'with', 'dynamic weight vector']]"
"[['DSA', 'stacked on', 'CNN'], ['DSA', 'achieves', 'new state - of - the - art results'], ['new state - of - the - art results', 'among', 'sentence encoding methods'], ['sentence encoding methods', 'in', 'Stanford Natural Language Inference ( SNLI ) dataset'], ['Stanford Natural Language Inference ( SNLI ) dataset', 'with', 'least number of parameters'], ['DSA', 'obtaining', 'comparative results'], ['new state - of - the - art results', 'obtaining', 'comparative results'], ['comparative results', 'in', 'Stanford Sentiment Treebank ( SST ) dataset']]"
"[['recent models', 'in terms of', 'time efficiency']]"
[]
[]
"[['benchmark', 'for evaluating', 'performance']]"
"[['multiple DSA', 'outperforms', 'other models'], ['other models', 'by', 'large margin ( + 1.1 % )']]"
"[['single DSA', 'shows', 'better performance'], ['better performance', 'than', 'self - attention ( + 2.2 % )']]"
"[['our implementation', 'of', 'baseline'], ['selfattention', 'stacked on', 'CNN with Dense Connection'], ['baseline', 'shows', 'better performance ( + 0.4 % )'], ['selfattention', 'shows', 'better performance ( + 0.4 % )']]"
[]
"[['Single DSA', 'outperforms', 'all the baseline models'], ['all the baseline models', 'in', 'SST - 2 dataset'], ['comparative results', 'in', 'SST - 5'], ['Single DSA', 'achieves', 'comparative results'], ['comparative results', 'in', 'SST - 5']]"
"[['marginal differences', 'in', 'performance'], ['marginal differences', 'in', 'performance'], ['marginal differences', 'in', 'performance'], ['performance', 'between', 'DSA and the previous self - attentive models']]"
[]
[]
"[['novel approach', 'to building', 'supervised reading comprehension data set']]"
"[['summary and paraphrase sentences', 'readily converted to', 'context - query - answer triples'], ['context - query - answer triples', 'using', 'simple entity detection and anonymisation algorithms']]"
"[['two new corpora', 'of', 'roughly a million news stories'], ['roughly a million news stories', 'with', 'associated queries'], ['associated queries', 'from', 'CNN and Daily Mail websites']]"
"[['efficacy', 'by building', 'novel deep learning models'], ['novel deep learning models', 'for', 'reading comprehension']]"
"[['attention - based models', 'outperform', 'pure LSTM - based approaches']]"
[]
"[['relatively strong performance', 'of', 'word distance benchmark'], ['relatively strong performance', 'relative to', 'frame - semantic benchmark'], ['word distance benchmark', 'relative to', 'frame - semantic benchmark']]"
[]
"[['clear picture', 'with', 'Impatient and the Attentive Readers'], ['Impatient and the Attentive Readers', 'outperforming', 'all other models']]"
[]
"[['Reader', 'performs', 'surprisingly well']]"
[]
"[['sentence encoding - based model', 'for recognizing', 'text entailment']]"
[]
"[['three types of relation', 'in', 'RTE']]"
"[['unified deep learning framework', 'for recognizing', 'textual entailment']]"
"[['basic model', 'based on', 'building'], ['biL - STM models', 'on', 'premises and hypothesis']]"
"[['basic mean pooling encoder', 'roughly form', 'intuition']]"
"[['simple effective input strategy', 'get ride of', 'same words'], ['same words', 'in', 'hypothesis and premise']]"
"[['training objective', 'use', 'minibatch SGD'], ['minibatch SGD', 'with', 'Rmsprop ( Tieleman and Hinton , 2012 )'], ['Rmsprop ( Tieleman and Hinton , 2012 )', 'for', 'optimization']]"
"[['batch size', 'is', '128']]"
"[['dropout layer', 'applied in', 'output'], ['output', 'of', 'network'], ['dropout layer', 'with', 'dropout rate'], ['output', 'with', 'dropout rate'], ['network', 'with', 'dropout rate'], ['dropout rate', 'set to', '0.25']]"
"[['pretrained 300D Glove 840B vectors', 'to initialize', 'word embedding']]"
"[['Out - of - vocabulary words', 'in', 'training set'], ['Out - of - vocabulary words', 'are', 'randomly initialized'], ['training set', 'are', 'randomly initialized'], ['randomly initialized', 'by', 'sampling values'], ['sampling values', 'uniformly from', '( 0.05 , 0.05 )'], ['values', 'uniformly from', '( 0.05 , 0.05 )']]"
"[['more attention', 'given to', 'Nones , Verbs and Adjectives']]"
"[['mean pooling', 'regarded', 'each word'], ['each word', 'of', 'equal importance'], ['words', 'according to', 'importance']]"
[]
"[['BERT - based model', 'for', 'Natural Questions']]"
"[['short and long answers', 'in', 'single model'], ['each document', 'into', 'multiple training instances'], ['multiple training instances', 'by using', 'overlapping windows of tokens'], ['training time', 'to create', 'balanced training set'], ['"" [ CLS ] "" token', 'at', 'training time'], ['training time', 'to predict', 'null instances']]"
"[['our model', 'from', 'BERT model'], ['our model', 'finetuned on', 'SQ u AD 1.1'], ['BERT model', 'finetuned on', 'SQ u AD 1.1']]"
"[['model', 'by minimizing', 'loss L'], ['loss L', 'with', 'Adam optimizer'], ['Adam optimizer', 'with', 'batch size'], ['batch size', 'of', '8']]"
"[['initial learning rate', 'for', 'finetuning'], ['initial learning rate', 'training for', '1 epoch'], ['1 epoch', 'with', 'initial learning rate'], ['initial learning rate', 'of', '3 10 ? 5'], ['initial learning rate', 'was', 'best setting'], ['3 10 ? 5', 'was', 'best setting']]"
"[['NQ dev and test set', 'with', 'single Tesla P100 GPU']]"
"[['BERT model', 'for', 'NQ'], ['BERT model', 'performs', 'dramatically better'], ['NQ', 'performs', 'dramatically better'], ['dramatically better', 'than', 'models']]"
"[['Our model', 'closes', 'gap'], ['gap', 'between', 'F 1 score'], ['F 1 score', 'achieved by', 'original baseline systems'], ['super - annotator upper bound', 'by', '30 %'], ['super - annotator upper bound', 'by', '50 %'], ['30 %', 'for', 'long answer NQ task'], ['super - annotator upper bound', 'by', '50 %'], ['50 %', 'for', 'short answer NQ task']]"
