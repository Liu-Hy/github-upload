2	53	73	Constituency Parsing
4	11	23	investigates
4	62	70	based on
4	71	118	general purpose sequence - to - sequence models
4	119	122	for
4	123	143	constituency parsing
5	3	14	incorporate
5	151	162	demonstrate
5	172	199	sequenceto - sequence model
7	0	36	Sequence - to - sequence ( Seq2seq )
13	25	41	Seq2seq approach
13	77	79	of
13	80	100	constituency parsing
19	0	20	Constituency Parsing
83	0	14	Model ensemble
84	0	10	Ensembling
84	11	56	several independently trained models together
84	57	79	significantly improves
87	0	31	Language model ( LM ) reranking
95	0	3	For
95	4	23	data pre-processing
95	26	45	all the parse trees
95	51	67	transformed into
95	68	84	linearized forms
95	87	92	which
95	93	100	include
95	101	125	standard UNK replacement
95	126	129	for
95	130	139	OOV words
95	144	167	POS - tag normalization
95	168	170	by
95	171	180	XX - tags
103	0	24	Ensembling and Reranking
111	6	55	Smaller mini-batch size M and gradient clipping G
111	56	64	provided
111	69	87	better performance
113	6	23	Larger layer size
113	65	69	have
113	70	83	little impact
113	84	86	on
113	91	102	performance
113	105	108	our
113	147	152	looks
113	153	161	adequate
113	162	173	in terms of
113	174	205	speed / performance trade - off
116	16	23	results
116	24	26	of
116	27	51	utilizing subword splits
119	7	12	using
119	13	32	subword information
119	33	35	as
119	36	44	features
119	45	47	is
119	52	70	promising approach
119	71	85	for leveraging
119	86	105	subword information
119	106	110	into
119	111	131	constituency parsing
126	0	20	Our Seq2seq approach
126	21	42	successfully achieved
126	47	64	competitive level
126	65	67	as
126	72	79	current
126	102	106	RNNG
