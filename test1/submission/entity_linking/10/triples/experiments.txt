(relative error reductions||ranging from||6 - 20 %)
(6 - 20 %||over||strong base models)
(ELMo||to||baseline model)
(81.1 %||to||85.8 %)
(test set F 1||improved by||4.7 %)
(4.7 %||from||81.1 %)
(81.1 %||to||85.8 %)
(test set F 1||improving||overall single model state - of - the - art)
(overall single model state - of - the - art||by||1.4 %)
(ELMo||has||baseline model)
(baseline model||has||test set F 1)
(ELMo||to||ESIM model)
(ELMo||improves||accuracy)
(ESIM model||improves||accuracy)
(accuracy||by||average of 0.7 %)
(average of 0.7 %||across||five random seeds)
(ELMo enhanced biLSTM - CRF||achieves||92. 22 % F 1)
(92. 22 % F 1||averaged over||five runs)
(our||has||ELMo enhanced biLSTM - CRF)
(all layers||instead of||last layer)
(all layers||improves||performance)
(last layer||improves||performance)
(performance||across||multiple tasks)
(all biLM layers||instead of using||last layer)
(last layer||improves||F 1)
(F 1||another||0.3 %)
(all biLM layers||allowing||task model)
(task model||to learn||individual layer weights)
(individual layer weights||improves||F 1)
(F 1||another||0.2 %)
(F 1||has||0.3 %)
(ELMo||at||output)
(output||of||biRNN)
(biRNN||in||task - specific architectures)
(task - specific architectures||improves||overall results)
(overall results||for||some tasks)
(ELMo||has||output)
(input and output layers||for||SNLI and SQuAD)
(SNLI and SQuAD||improves over||input layer)
(input and output layers||for||SRL)
(ELMo||has||input and output layers)
(SRL||has||highest)
(ELMo||improves||task performance)
(task performance||over||word vectors alone)
(ELMo||has||task performance)
(biLM top layer rep-resentations||have||F 1)
(F 1||of||69.0)
(biLM top layer rep-resentations||better at||WSD)
(WSD||then||first layer)
(biLM top layer rep-resentations||has||F 1)
(F 1||has||69.0)
(accuracies||using||first biLM layer)
(first biLM layer||higher than||top layer)
(deep biL - STMs||in||multi-task training and MT)
(Contribution||has||Experiments)
