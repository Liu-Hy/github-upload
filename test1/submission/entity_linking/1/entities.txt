2	73	100	Named Entity Disambiguation
5	19	26	propose
5	86	89	for
5	90	125	named entity disambiguation ( NED )
12	0	35	Named entity disambiguation ( NED )
18	69	74	words
18	88	91	for
18	92	95	NED
19	34	42	based on
19	47	80	bidirectional transformer encoder
20	3	8	takes
20	11	41	sequence of words and entities
20	42	44	in
20	49	59	input text
20	66	74	produces
20	77	101	contextualized embedding
20	102	105	for
20	106	126	each word and entity
21	21	28	propose
21	29	53	masked entity prediction
21	120	144	randomly masked entities
21	145	153	based on
21	154	183	words and non-masked entities
21	184	186	in
21	191	201	input text
24	4	13	NED model
24	14	23	addresses
24	28	32	task
24	33	45	by capturing
24	46	100	word - based and entity - based contextual information
24	101	106	using
24	111	144	trained contextualized embeddings
63	8	11	set
63	16	44	feed - forward / filter size
63	45	47	to
63	48	52	4096
63	59	78	dropout probability
63	79	89	applied to
63	90	100	all layers
63	101	104	was
63	105	108	0.1
63	119	138	maximum word length
63	139	141	in
63	145	159	input sequence
63	164	170	set to
63	171	174	512
66	0	16	Other parameters
66	19	25	namely
66	30	40	parameters
66	41	43	in
66	48	70	MEP and the embeddings
66	71	74	for
66	75	83	entities
66	91	111	initialized randomly
73	3	7	used
73	12	26	Adam optimizer
73	27	31	with
73	34	47	learning rate
73	48	50	of
73	51	58	2 e - 5
73	89	104	L2 weight decay
73	105	107	of
73	108	112	0.01
74	4	14	batch size
74	19	25	set to
74	26	29	252
106	3	6	set
106	11	21	batch size
106	22	24	to
106	25	27	32
106	34	38	used
106	43	57	Adam optimizer
106	58	62	with
106	65	78	learning rate
106	79	81	of
106	82	89	2 e - 5
106	92	113	?1 = 0.9 , ?2 = 0.999
106	120	135	L2 weight decay
106	136	138	of
106	139	143	0.01
113	22	34	outperformed
114	14	19	using
114	20	45	pseudo entity annotations
114	46	53	boosted
114	58	66	accuracy
114	67	69	by
114	70	75	0.3 %
