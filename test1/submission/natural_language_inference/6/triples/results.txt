(tradeoffs||in terms of||parameters and learning time per epoch)
(multiple DSA||outperforms||other models)
(other models||by||large margin ( + 1.1 % ))
(Results||With||tradeoffs)
(single DSA||shows||better performance)
(better performance||than||self - attention)
(Results||In comparison to||single DSA)
(our implementation||of||baseline)
(selfattention||stacked on||CNN)
(CNN||with||Dense Connection)
(baseline||shows||better performance ( + 0.4 % ))
(selfattention||shows||better performance ( + 0.4 % ))
(Dense Connection||shows||better performance ( + 0.4 % ))
(our implementation||name||baseline)
(baseline||name||selfattention)
(all the baseline models||in||SST - 2 dataset)
(comparative results||in||SST - 5)
(Single DSA||achieves||comparative results)
(comparative results||in||SST - 5)
(Single DSA||has||outperforms)
(outperforms||has||all the baseline models)
(SNLI dataset||in||SST dataset)
(performance||between||DSA and the previous self - attentive models)
(Results||in||SNLI dataset)
(Contribution||has||Results)
