2	25	63	Multi - Document Reading Comprehension
13	0	37	Machine reading comprehension ( MRC )
29	35	42	propose
29	45	63	deep cascade model
29	70	78	combines
29	83	93	advantages
29	110	112	in
29	115	140	coarse - to - fine manner
32	9	28	selected paragraphs
32	33	42	passed to
32	47	79	attention - based deep MRC model
32	80	94	for extracting
32	99	117	actual answer span
32	118	120	at
32	121	131	word level
33	22	39	answer extraction
33	50	59	introduce
33	64	108	document extraction and paragraph extraction
33	109	111	as
33	112	131	two auxiliary tasks
34	3	19	jointly optimize
34	20	39	all the three tasks
34	40	42	in
34	45	67	unified deep MRC model
34	76	82	shares
34	83	108	some common bottom layers
35	24	31	enables
35	36	42	models
35	43	53	to perform
35	56	82	coarse - to - fine pruning
35	83	85	at
35	86	102	different stages
35	105	118	better models
35	119	132	can be learnt
36	62	73	consists of
36	74	87	three modules
36	90	108	document retrieval
36	111	130	paragraph retrieval
36	135	152	answer extraction
38	4	10	module
38	11	13	at
38	14	35	each subsequent stage
38	36	44	consumes
38	49	55	output
38	56	60	from
38	65	79	previous stage
38	86	100	further prunes
38	105	114	documents
38	117	131	paragraphs and
38	132	144	answer spans
38	145	150	given
38	155	163	question
39	39	45	define
39	48	64	ranking function
39	72	91	extraction function
40	4	20	ranking function
40	30	37	used as
40	40	58	preliminary filter
40	59	69	to discard
40	70	116	most of the irrelevant documents or paragraphs
40	125	132	to keep
40	133	156	our framework efficient
41	4	23	extraction function
41	32	53	designed to deal with
41	58	107	auxiliary document and paragraph extraction tasks
41	119	141	jointly optimized with
41	146	176	final answer extraction module
41	177	180	for
41	181	210	better extraction performance
43	56	63	propose
43	66	97	deep cascade learning framework
43	98	108	to address
43	181	190	considers
44	3	14	incorporate
44	19	79	auxiliary document extraction and paragraph extraction tasks
44	80	82	to
44	87	114	pure answer span prediction
48	13	42	Machine Reading Comprehension
59	0	16	Cascade Learning
209	10	19	Trivia QA
209	76	87	restructure
209	92	101	documents
209	102	112	by merging
209	113	135	consecutive paragraphs
209	136	138	to
209	141	153	maximum size
209	154	156	of
209	157	166	600 words
209	167	170	for
209	171	185	each paragraph
211	0	3	For
211	8	43	multi-task deep attention framework
211	49	54	adopt
211	59	73	Adam optimizer
211	74	77	for
211	78	86	training
211	89	93	with
211	96	111	mini-batch size
211	115	117	32
211	122	143	initial learning rate
211	147	153	0.0005
212	3	6	use
212	11	48	GloVe 300 dimensional word embeddings
212	49	51	in
212	52	60	TriviaQA
212	65	70	train
212	73	98	word2 vec word embeddings
212	99	103	with
212	108	129	whole DuReader corpus
212	130	133	for
212	134	142	DuReader
213	4	19	word embeddings
213	24	36	fixed during
213	37	45	training
214	4	15	hidden size
214	16	18	of
214	19	23	LSTM
214	27	33	set as
214	34	37	150
214	38	41	for
214	42	50	TriviaQA
214	55	58	128
214	63	71	DuReader
215	66	72	set as
215	91	115	Regularization parameter
217	15	25	trained on
217	26	46	Nvidia Tesla M40 GPU
217	47	51	with
217	52	67	Cudnn LSTM cell
217	68	70	in
217	71	85	Tensorflow 1.3
221	19	27	adopting
221	32	63	deep cascade learning framework
221	70	84	proposed model
221	85	96	outperforms
221	101	140	previous state - of - the - art methods
221	141	143	by
221	147	161	evident margin
221	165	178	both datasets
221	222	237	proposed method
226	26	29	see
226	45	56	shared LSTM
226	66	75	important
226	81	83	in
226	84	101	answer extraction
226	102	107	among
226	108	126	multiple documents
226	191	216	content probability score
226	217	221	from
226	222	240	multiple documents
226	261	275	extracted from
226	330	338	can keep
226	343	356	ranking order
226	357	361	from
226	362	388	document ranking component
228	4	82	Both the preliminary cascade ranking and multi-task answer extraction strategy
228	87	92	vital
228	101	118	final performance
228	127	135	serve as
228	138	154	good trade - off
228	155	162	between
228	167	219	pure pipeline method and fully joint learning method
230	0	16	Jointly training
230	21	43	three extraction tasks
230	48	55	provide
230	56	70	great benefits
230	79	84	shows
230	94	105	three tasks
230	119	134	closely related
230	143	148	boost
230	149	159	each other
230	160	164	with
230	165	187	shared representations
230	188	190	at
230	191	204	bottom layers
231	0	41	Effectiveness v.s. Efficiency Trade - off
233	11	13	on
233	14	38	DuReader development set
234	22	33	By properly
234	41	69	more documents or paragraphs
234	70	74	into
234	75	88	consideration
234	95	106	performance
234	107	109	of
234	114	119	model
234	120	139	gradually increases
234	140	144	when
234	148	155	reaches
234	156	184	4 documents and 2 paragraphs
234	200	211	performance
234	212	230	decreases slightly
235	8	17	time cost
235	18	24	can be
235	25	40	largely reduced
235	41	52	by removing
235	53	93	more irrelevant documents and paragraphs
235	94	96	in
235	101	122	cascade ranking stage
235	143	154	performance
235	155	175	not change that much
239	4	15	performance
239	16	18	of
239	19	35	jointly training
239	40	64	answer extraction module
239	96	98	on
239	99	123	DuReader development set
240	19	32	incorporating
240	37	95	auxiliary document extraction or paragraph extraction task
240	96	98	in
240	103	127	joint learning framework
240	134	145	performance
240	146	149	can
240	150	164	always improve
241	14	30	performance gain
241	31	40	by adding
241	41	65	document extraction task
241	66	68	is
241	69	75	larger
243	11	34	E-commerce and Tax data
247	14	25	performance
247	26	41	with respect to
247	42	51	F 1 score
247	60	76	largely improved
247	86	119	proposed multi-document MRC model
248	11	37	Different Document Lengths
251	16	42	without incorporating with
251	47	69	cascade ranking module
251	76	100	answer extraction module
251	101	109	performs
251	110	123	rather poorly
251	124	131	both in
251	132	160	effectiveness and efficiency
251	161	163	as
251	168	183	document length
251	184	193	increases
