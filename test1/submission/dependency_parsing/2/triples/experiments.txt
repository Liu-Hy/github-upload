(Our ensembles of greedy , locally normalized parsers||perform||comparably)
(cost||for||its)
(cost||for||choice ( s ))
(lower||under||Hamming cost)
(ensemble is||has||confident)
(confident||has||cost)
(its||has||choice ( s ))
(per-epoch learning rate decay||of||0.05)
(0.05||to||Adam optimizer)
(per-epoch learning rate decay||has||0.05)
(Adam optimizer||automatically adjusts||global learning rate)
(global learning rate||according to||past gradient magnitudes)
(global learning rate||find||additional per-epoch decay)
(additional per-epoch decay||consistently improves||performance)
(performance||across||all settings and languages)
(Contribution||has||Experiments)
