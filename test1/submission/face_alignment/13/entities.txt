2	0	33	Nonlinear 3D Face Morphable Model
4	31	33	of
4	34	43	3D facial
4	64	92	3D Morphable Model ( 3 DMM )
4	96	110	widely used in
4	111	126	facial analysis
4	129	133	e.g.
4	136	149	model fitting
4	152	167	image synthesis
11	4	18	entire network
11	19	21	is
11	22	46	end - to - end trainable
11	47	51	with
11	52	73	only weak supervision
16	4	29	morphable model framework
16	30	38	provides
16	39	42	two
16	68	101	point - to - point correspondence
16	102	109	between
16	114	149	reconstruction and all other models
16	152	160	enabling
16	185	193	modeling
16	194	220	underlying transformations
16	221	228	between
16	229	289	types of faces ( male to female , neutral to smile , etc . )
17	0	5	3 DMM
19	3	10	propose
19	13	28	nonlinear 3 DMM
19	29	37	to model
19	38	53	shape / texture
19	54	57	via
19	58	87	deep neural networks ( DNNs )
20	10	22	trained from
20	23	50	in - the - wild face images
20	51	58	without
20	59	68	3 D scans
20	80	86	better
20	104	119	original images
20	120	126	due to
20	131	152	inherent nonlinearity
22	0	8	To model
22	9	40	highly variable 3 D face shapes
22	45	90	large amount of high - quality 3 D face scans
26	11	13	is
26	14	21	fragile
26	22	24	to
26	25	40	large variances
26	41	43	in
26	48	61	face identity
45	11	18	utilize
45	19	39	two network decoders
45	42	52	instead of
45	53	67	two PCA spaces
45	70	72	as
45	77	111	shape and texture model components
46	27	29	of
46	30	44	each component
46	50	56	design
46	57	75	different networks
46	76	79	for
46	80	97	shape and texture
46	104	136	multi - layer perceptron ( MLP )
46	137	140	for
46	141	146	shape
46	151	187	convolutional neural network ( CNN )
46	188	191	for
46	192	199	texture
48	19	22	are
48	39	54	nonlinear 3 DMM
49	13	18	learn
49	23	40	fitting algorithm
49	41	43	to
49	44	63	our nonlinear 3 DMM
49	75	88	formulated as
49	91	102	CNN encoder
50	4	11	encoder
50	12	17	takes
50	20	34	2 D face image
50	35	37	as
50	38	43	input
50	48	57	generates
50	62	90	shape and texture parameters
50	104	107	two
50	117	125	estimate
50	130	137	3D face
52	15	21	design
52	24	54	differentiable rendering layer
52	55	66	to generate
52	69	87	reconstructed face
52	88	97	by fusing
52	102	119	3D face , texture
52	159	171	estimated by
52	176	183	encoder
53	14	41	endto - end learning scheme
53	45	62	constructed where
53	67	91	encoder and two decoders
53	96	110	learnt jointly
53	111	122	to minimize
53	127	137	difference
53	138	145	between
53	150	187	reconstructed face and the input face
54	0	16	Jointly learning
54	21	56	3 DMM and the model fitting encoder
54	83	126	large collection of unconstrained 2D images
54	127	145	without relying on
54	146	154	3D scans
58	7	12	learn
58	15	36	nonlinear 3 DMM model
58	46	74	greater representation power
58	75	79	than
58	84	114	traditional linear counterpart
59	7	20	jointly learn
59	25	62	model and the model fitting algorithm
59	63	66	via
59	67	83	weak supervision
59	86	99	by leveraging
59	102	131	large collection of 2D images
59	132	139	without
59	140	148	3D scans
60	4	25	novel rendering layer
60	26	33	enables
60	38	61	end - to - end training
207	0	5	Using
207	6	37	facial mesh triangle definition
207	38	40	by
207	41	65	Basel Face Model ( BFM )
207	71	76	train
207	81	86	3 DMM
207	87	92	using
207	93	110	300W - LP dataset
208	13	28	optimized using
208	29	43	Adam optimizer
208	44	48	with
208	52	73	initial learning rate
208	74	76	of
208	77	82	0.001
208	83	98	when minimizing
208	99	102	L 0
208	109	115	0.0002
208	116	131	when minimizing
208	132	134	L.
209	34	35	Q
209	94	105	set to make
209	106	112	losses
209	113	120	to have
209	121	139	similar magnitudes
210	0	14	Expressiveness
247	0	19	Our nonlinear model
247	26	68	significantly smaller reconstruction error
247	69	73	than
247	78	90	linear model
247	93	99	0.0196
253	0	10	visualizes
253	15	36	3 DMM fitting results
253	37	39	on
253	40	54	CelebA dataset
255	7	14	recover
255	15	45	personal facial characteristic
255	46	48	in
255	49	71	both shape and texture
258	0	14	Face alignment
265	3	9	obtain
265	12	21	low error
265	30	43	comparable to
265	44	72	optimization - based methods
