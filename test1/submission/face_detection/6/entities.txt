2	7	21	Face Detection
13	0	14	Face detection
20	32	41	train set
20	42	44	of
20	45	55	WIDER FACE
20	62	88	official pre-trained SSH 1
20	95	100	fails
20	101	103	on
20	104	122	some of the images
20	123	127	with
20	128	148	extremely hard faces
24	43	50	propose
24	53	73	robust face detector
24	74	84	by putting
24	85	104	more training focus
24	105	107	on
24	114	125	hard images
27	27	37	propose to
27	38	56	mine hard examples
27	57	59	at
27	60	71	image level
27	72	88	in parallel with
27	89	101	anchor level
28	34	52	dynamically assign
28	53	70	difficulty scores
28	71	73	to
28	74	89	training images
28	90	96	during
28	101	117	learning process
28	168	183	well - detected
31	67	84	detection quality
31	85	110	by exclusively exploiting
31	111	122	small faces
37	33	40	propose
37	43	62	novel face detector
39	8	20	done without
39	21	51	any extra modules , parameters
39	55	75	computation overhead
39	76	84	added on
39	89	106	existing detector
40	3	9	design
40	12	32	single shot detector
40	33	37	with
40	38	68	only one detection feature map
40	77	87	focuses on
40	88	99	small faces
40	100	104	with
40	107	130	specific range of sizes
163	3	7	flip
163	8	18	all images
163	19	31	horizontally
163	34	43	to double
163	48	52	size
163	53	55	of
163	56	76	our training dataset
163	77	79	to
163	80	85	25760
165	3	6	use
165	10	41	ImageNet pretrained VGG16 model
165	42	55	to initialize
165	56	76	our network backbone
165	83	110	our newly introduced layers
165	115	135	randomly initialized
165	141	164	Gaussian initialization
166	3	8	train
166	13	18	model
166	19	23	with
166	28	36	itersize
166	37	42	to be
166	43	44	2
166	47	50	for
166	51	66	46 k iterations
166	69	73	with
166	76	89	learning rate
166	90	92	of
166	93	98	0.004
166	122	137	14 k iterations
166	138	142	with
166	145	166	smaller learning rate
166	170	176	0.0004
167	0	6	During
167	7	15	training
167	21	24	use
167	25	31	4 GPUs
167	32	49	to simultaneously
167	50	60	to compute
167	65	73	gradient
167	78	84	update
167	89	95	weight
167	96	98	by
167	99	115	synchronized SGD
167	116	120	with
167	121	129	Momentum
168	4	20	first two blocks
168	21	23	of
168	24	29	VGG16
168	34	40	frozen
168	41	47	during
168	52	60	training
168	71	82	rest layers
168	83	85	of
168	86	91	VGG16
168	96	107	set to have
168	110	130	double learning rate
175	16	26	our method
175	27	35	achieves
175	40	56	best performance
175	57	59	on
175	64	75	hard subset
175	82	93	outperforms
175	98	128	current state - of - the - art
175	129	131	by
175	134	146	large margin
177	0	15	Our performance
177	16	18	on
177	23	36	medium subset
177	40	53	comparable to
177	58	92	most recent state - of - the - art
177	101	112	performance
177	113	115	on
177	120	131	easy subset
177	132	134	is
177	137	146	bit worse
185	3	7	show
185	12	20	PR curve
185	44	54	our method
185	55	63	achieves
185	66	108	new the state - of - the - art performance
185	109	111	of
185	112	121	AP = 99.0
187	28	38	our method
187	39	47	achieves
187	48	74	state - of - the - art and
187	75	101	almost perfect performance
187	104	108	with
187	112	114	AP
187	115	117	of
187	118	123	99.60
191	14	22	see that
191	23	54	our single level baseline model
191	67	78	performance
191	79	92	comparable to
191	97	127	current : Ablation experiments
192	22	35	face detector
192	36	46	similar to
192	47	50	SSH
192	51	55	with
192	56	84	three detection feature maps
193	11	17	Single
193	18	20	is
193	21	42	our proposed detector
193	43	47	with
193	48	76	single detection feature map
196	0	43	Our model with single detection feature map
196	44	52	performs
196	53	59	better
196	60	64	than
196	69	106	one with three detection feature maps
201	0	9	Combining
201	10	29	HIM and DH together
201	34	41	improve
201	62	96	state - of - the - art performance
210	4	20	ablation results
210	21	33	evaluated on
210	34	56	WIDER FACE val dataset
217	20	27	resizes
217	32	37	image
217	50	60	short side
217	61	69	contains
217	70	108	100 , 300 , 600 , 1000 and 1400 pixels
217	124	132	to build
217	136	149	image pyramid
220	0	16	Without resizing
220	21	31	short side
220	32	42	to contain
220	43	61	100 and 300 pixels
220	68	79	performance
220	80	82	on
220	83	94	easy subset
220	95	97	is
220	98	107	only 78.2
225	25	28	run
225	29	40	all methods
225	41	43	on
225	48	60	same machine
225	63	67	with
225	68	95	one Titan X ( Maxwell ) GPU
225	102	107	Intel
228	12	22	except for
228	23	34	Pyramid Box
228	39	47	based on
228	48	69	Caffe1 implementation
228	81	94	compiled with
228	95	115	CUDA 9.0 and CUDNN 7
230	3	6	use
230	11	43	officially built Pad - dlePaddle
230	44	48	with
230	49	69	CUDA 9.0 and CUDNN 7
235	14	26	our detector
235	31	41	outperform
235	42	69	SSH , S 3 FD and PyramidBox
235	70	83	significantly
235	84	88	with
235	91	113	smaller inference time
