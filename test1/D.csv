triple_D
[]
[]
[]
"[['Model', 'has', 'greedy prediction']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'CNN']]"
"[['Experimental setup', 'has', 'learning rate']]"
[]
[]
[]
[]
"[['Results', 'has', 'Our CNN base model']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'Seq2seq approach']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Ensembling and Reranking']]"
"[['Results', 'has', 'Smaller mini-batch size M and gradient clipping G']]"
"[['Ablation analysis', 'has', 'Larger layer size']]"
"[['Results', 'has', 'results']]"
[]
"[['Results', 'has', 'Our Seq2seq approach']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'difference']]"
"[['Results', 'has', 'LSTM +A']]"
[]
"[['Results', 'has', 'LSTM + A']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Score combination']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'bottom - up system']]"
"[['Results', 'has', 'inorder system']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'in - order parser']]"
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Dropout']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'RNNG']]"
"[['Model', 'has', 'RNNG']]"
[]
"[['Model', 'has', 'Both inference problems']]"
"[['Hyperparameters', 'has', 'generative']]"
"[['Results', 'has', 'Do the phrasal representations']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'decisions']]"
[]
[]
"[['Model', 'has', 'which action ( a cluster merge ) available']]"
[]
"[['Hyperparameters', 'has', 'Averaged word embeddings']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'mention - ranking model']]"
"[['Results', 'has', 'cluster - ranking model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our full model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'reward - rescaled max - margin loss']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our full approach']]"
[]
"[['Results', 'has', 'improvement']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'PS BL']]"
"[['Hyperparameters', 'has', 'Embeddings']]"
"[['Hyperparameters', 'has', 'size']]"
[]
"[['Hyperparameters', 'has', 'first']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Dropout']]"
[]
[]
[]
[]
"[['Results', 'has', 'MR - LSTM']]"
[]
[]
[]
[]
"[['Model', 'has', 'manually defined cluster features']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'RNN performance']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'LSTM modules']]"
[]
"[['Hyperparameters', 'has', 'initial learning rate']]"
[]
[]
[]
"[['Results', 'has', 'Uh- huh']]"
[]
"[['Results', 'has', 'ASL']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'Our model reasons']]"
[]
[]
"[['Model', 'has', 'head - finding attention mechanism']]"
"[['Hyperparameters', 'has', 'word embeddings area fixed concatenation']]"
"[['Hyperparameters', 'has', 'hidden states']]"
[]
"[['Hyperparameters', 'has', 'features ( speaker , genre , span distance , mention width )']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'learning rate']]"
"[['Hyperparameters', 'has', 'Ensembling']]"
[]
"[['Results', 'has', 'most significant gains']]"
"[['Ablation analysis', 'has', 'distance between']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'independent variant']]"
"[['Model', 'has', 'overlap variant']]"
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'GAP']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'BERT - large']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'decoder']]"
[]
[]
[]
"[['Baselines', 'has', 'Li']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'size']]"
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'comparison']]"
"[['Ablation analysis', 'has', 'Scores of Hierarchical -k']]"
"[['Ablation analysis', 'has', 'our best model']]"
"[['Ablation analysis', 'has', 'Our hierarchical models']]"
[]
[]
"[['Ablation analysis', 'has', 'Our hierarchical models']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'decoder']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Tasks', 'has', 'Encoder ( decoder ) embeddings and hidden dimensions']]"
"[['Results', 'has', 'GCN model']]"
"[['Results', 'has', 'GCN EC model']]"
"[['Baselines', 'has', 'GCN EC']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'Residual and dense connections']]"
"[['Ablation analysis', 'has', 'Dense connections']]"
[]
[]
[]
"[['Model', 'has', 'Reconstructor - based pragmatic system']]"
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Input feeding']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'NCP']]"
"[['Results', 'has', 'NCP']]"
"[['Results', 'has', 'NCP + CC']]"
[]
[]
[]
"[['Results', 'has', '84.5 %']]"
[]
[]
"[['Results', 'has', 'CS precision']]"
"[['Results', 'has', 'NCP']]"
[]
[]
[]
[]
"[['Model', 'has', 'text planner']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'pretrained embeddings']]"
[]
[]
[]
"[['Results', 'has', 'BestPlan']]"
"[['Results', 'has', 'BestPlan']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'TGen']]"
[]
[]
[]
[]
"[['Results', 'has', 'EDA_CS TL']]"
"[['Results', 'has', 'baseline model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Word embeddings']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'BiLSTM']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'parsers']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'word and POS embeddings e ( w i ) and e ( p i )']]"
[]
[]
[]
"[['Results', 'has', 'Dynamic oracle training']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'model']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Early stopping']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'BiLSTM - CRF']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'all parsers']]"
"[['Results', 'has', 'Impact of parsing']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'STACKPTR parser']]"
"[['Model', 'has', 'STACKPTR parser']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Parameter optimization']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 're-implementation']]"
"[['Results', 'has', 'Our model']]"
"[['Results', 'has', 'STACKPTR']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'tritraining']]"
"[['Results', 'has', 'tri-training']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'resulting parser']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'error - exploring dynamic - oracle training']]"
"[['Hyperparameters', 'has', 'Flattening']]"
[]
[]
[]
"[['Model', 'has', 'outperform']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'directly optimizing']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our local model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Tasks', 'has', 'our accuracy']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Tagspace model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'first method']]"
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'Fine-tune ( Ft )']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our framework']]"
"[['Results', 'has', 'experment results']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'weights']]"
"[['Model', 'has', 'attention mechanism']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'our models']]"
"[['Results', 'has', 'NABoE - full model']]"
"[['Results', 'has', 'our models']]"
"[['Results', 'has', 'NABoE - full model']]"
[]
"[['Results', 'has', 'our attention mechanism']]"
[]
"[['Results', 'has', 'our attention mechanism']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'all word embeddings']]"
[]
[]
"[['Experimental setup', 'has', 'recommended N']]"
[]
[]
"[['Results', 'has', 'Our method']]"
[]
"[['Results', 'has', 'word embedding methods']]"
"[['Baselines', 'has', 'Retrofit method']]"
"[['Results', 'has', 'Our method']]"
[]
"[['Results', 'has', 'outperforms']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'TF - IDF + LR']]"
"[['Baselines', 'has', 'Logistic Regression']]"
"[['Baselines', 'has', 'CNN']]"
"[['Baselines', 'has', 'LSTM']]"
"[['Baselines', 'has', 'Bi- LSTM']]"
[]
"[['Baselines', 'has', 'PV - DBOW']]"
[]
"[['Baselines', 'has', 'PV - DM']]"
[]
"[['Baselines', 'has', 'PTE']]"
"[['Baselines', 'has', 'fast Text']]"
"[['Baselines', 'has', 'SWEM']]"
"[['Baselines', 'has', 'LEAM']]"
"[['Baselines', 'has', 'Graph - CNN - C']]"
"[['Baselines', 'has', 'Graph - CNN - S']]"
"[['Baselines', 'has', 'Graph - CNN - F']]"
[]
[]
"[['Results', 'has', 'Text GCN']]"
[]
[]
"[['Results', 'has', 'CNN']]"
"[['Results', 'has', 'PV - DBOW']]"
"[['Results', 'has', 'PV - DM']]"
[]
"[['Results', 'has', 'PTE and fast Text']]"
"[['Results', 'has', 'SWEM and LEAM']]"
[]
"[['Baselines', 'has', 'text graph']]"
"[['Baselines', 'has', 'label information']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'first layer']]"
[]
[]
"[['Hyperparameters', 'has', 'minibatch size']]"
"[['Hyperparameters', 'has', 'Regularization']]"
[]
"[['Hyperparameters', 'has', 'Weights']]"
"[['Hyperparameters', 'has', 'discrete input']]"
[]
"[['Ablation analysis', 'has', 'depth']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'ShallowCNN']]"
[]
[]
[]
"[['Approach', 'has', 'embedding function']]"
"[['Approach', 'has', 'document']]"
[]
"[['Approach', 'has', 'LSTM']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'LSTM']]"
[]
"[['Results', 'has', 'one - hot CNN']]"
"[['Results', 'has', 'previous best performance']]"
"[['Results', 'has', 'Our oh - 2 LSTMp']]"
[]
[]
"[['Results', 'has', 'pre-trained wv - LSTM']]"
[]
[]
[]
"[['Results', 'has', 'LSTM']]"
[]
[]
[]
"[['Results', 'has', 'best supervised results']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Batch sizes']]"
[]
[]
[]
"[['Results', 'has', 'our proposed method']]"
"[['Results', 'has', 'Our unidirectional LSTM model']]"
"[['Results', 'has', 'Adversarial training']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'CNN']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'Binary']]"
"[['Baselines', 'has', 'methods']]"
"[['Experimental setup', 'has', 'our model']]"
"[['Baselines', 'has', 'features after convolution and']]"
[]
[]
[]
"[['Experimental setup', 'has', 'word vector layer and the LSTM layer']]"
[]
"[['Experimental setup', 'has', 'word vector layer and the LSTM layer']]"
[]
[]
[]
"[['Results', 'has', 'Our result']]"
"[['Results', 'has', 'Our result']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'all processing']]"
"[['Experimental setup', 'has', 'character embedding']]"
"[['Experimental setup', 'has', 'Training']]"
[]
[]
[]
[]
"[['Results', 'has', 'Our deep architecture']]"
[]
[]
"[['Results', 'has', 'most important decrease']]"
[]
[]
[]
[]
"[['Model', 'has', 'design']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'dimension']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'BLSTM - 2DCNN model']]"
[]
"[['Results', 'has', 'BLSTM - 2DPooling']]"
"[['Results', 'has', 'BLSTM - CNN']]"
[]
[]
"[['Results', 'has', 'BLSTM-2DCNN']]"
"[['Results', 'has', 'Ada Sent']]"
"[['Results', 'has', 'DRNN']]"
"[['Baselines', 'has', 'CNN -nonstatic / MC']]"
"[['Baselines', 'has', 'Molding - CNN']]"
"[['Baselines', 'has', 'MVCNN']]"
[]
"[['Baselines', 'has', 'S- LSTM']]"
"[['Baselines', 'has', 'LSTM / BLSTM / Tree-LSTM']]"
"[['Baselines', 'has', 'LSTMN']]"
[]
[]
[]
"[['Results', 'has', 'best accuracy']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'non-neural LR and SVM baselines']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'Temporal Depthwise Separable Convolutions ( TD - SCs )']]"
"[['Model', 'has', 'Global Average Pooling ( GAP )']]"
"[['Experimental setup', 'has', 'training']]"
[]
[]
[]
"[['Results', 'has', 'network reduction']]"
"[['Results', 'has', 'performance difference']]"
"[['Results', 'has', 'base property']]"
"[['Results', 'has', 'performance']]"
[]
[]
"[['Results', 'has', 'All approaches']]"
"[['Results', 'has', 'outperforms']]"
[]
[]
"[['Ablation analysis', 'has', 'Out - Of - Vocabulary ( OOV ) words']]"
[]
"[['Ablation analysis', 'has', 'Dropout regularization']]"
[]
[]
[]
[]
"[['Results', 'has', 'LEAM']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'HDLTex']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'Stacking Support Vector Machines ( SVM )']]"
[]
"[['Results', 'has', 'CNN']]"
"[['Results', 'has', 'SVM with term weighting']]"
[]
[]
[]
"[['Results', 'has', 'Document classification']]"
[]
[]
[]
[]
"[['Model', 'has', 'fullyconnected ( FC ) layer']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'word - level encoder']]"
"[['Model', 'has', 'interaction layer']]"
[]
[]
"[['Experimental setup', 'has', 'region size']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Models']]"
"[['Results', 'has', 'Char - based models']]"
[]
[]
"[['Results', 'has', 'W.C Region Emb']]"
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'accumulated MLP']]"
[]
"[['Experimental setup', 'has', 'validation set']]"
"[['Experimental setup', 'has', 'hyperparameters']]"
"[['Results', 'has', 'Word - based models']]"
[]
"[['Results', 'has', 'Our models']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'cross - lingual document classification']]"
[]
"[['Ablation analysis', 'has', 'convolutional filters']]"
"[['Hyperparameters', 'has', 'Hyper- parameters']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'classifiers']]"
"[['Results', 'has', 'system']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'hyperparameter']]"
[]
"[['Experimental setup', 'has', 'batch size']]"
"[['Results', 'has', 'Fast - Text and region embedding methods']]"
"[['Baselines', 'has', 'D - LSTM']]"
"[['Baselines', 'has', 'Hierarchical attention network ( HAN )']]"
[]
[]
"[['Baselines', 'has', 'Char-CRNN']]"
[]
[]
[]
"[['Results', 'has', 'Our model DRNN']]"
[]
"[['Results', 'has', 'DGRU']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Variable size mini-batches']]"
"[['Tasks', 'has', 'Hyper- parameters']]"
[]
[]
[]
[]
"[['Results', 'has', 'outperforms']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'NED model']]"
[]
"[['Hyperparameters', 'has', 'Other parameters']]"
[]
"[['Hyperparameters', 'has', 'batch size']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'ELMo representations']]"
[]
[]
[]
"[['Model', 'has', 'context2vec']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'output layer weights']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', '"" all relations "" system']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'GAS']]"
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Orthogonal initialization']]"
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'IMS +emb']]"
"[['Baselines', 'has', 'Bi- LSTM']]"
[]
[]
"[['Results', 'has', 'GAS and GAS ext']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'embeddings']]"
"[['Experimental setup', 'has', 'Words']]"
[]
"[['Results', 'has', 'Our proposed model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'proposed system']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'VCG model']]"
"[['Results', 'has', 'our model']]"
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'IMS + adapted CW']]"
"[['Results', 'has', 'htsa 3']]"
"[['Baselines', 'has', 'IRST']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'both BLSTM and Seq2Seq']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'F - score figures']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'UFSAC 4 BERT']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'BOW - DT']]"
"[['Baselines', 'has', 'QANTA']]"
[]
"[['Baselines', 'has', 'FTS - BRNN']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our systems']]"
[]
"[['Results', 'has', 'sense reduction method']]"
"[['Results', 'has', 'ensembling']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'GAS']]"
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Orthogonal initialization']]"
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'IMS +emb']]"
"[['Baselines', 'has', 'Bi- LSTM']]"
[]
[]
"[['Results', 'has', 'GAS and GAS ext']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our proposed algorithms']]"
"[['Results', 'has', 'Our self - trained word embeddings']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
[]
[]
[]
[]
"[['Tasks', 'has', 'algorithm']]"
"[['Baselines', 'has', 'Word 2 Vec']]"
[]
"[['Results', 'has', 'SemCor ( or MASC ) trained classifier']]"
[]
[]
"[['Model', 'has', 'RELIC']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'conventional skip - gram model']]"
[]
[]
"[['Model', 'has', 'Our']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'classic 3 DMM']]"
"[['Baselines', 'has', 'texture - less linear model']]"
"[['Hyperparameters', 'has', 'mean mesh']]"
"[['Results', 'has', 'texture - free Linear model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Each of our architectures']]"
[]
[]
"[['Results', 'has', 'All VRNs']]"
[]
"[['Baselines', 'has', 'VRN - Guided']]"
"[['Results', 'has', 'VRN - Multitask']]"
[]
"[['Ablation analysis', 'has', 'performance']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'standard ReLu function']]"
[]
[]
[]
"[['Experimental setup', 'has', 'parameters']]"
"[['Experimental setup', 'has', 'parameters']]"
[]
[]
[]
[]
"[['Results', 'has', 'Comparison with state of the art']]"
[]
[]
"[['Results', 'has', 'our CNN - 6/7 network']]"
[]
[]
"[['Experimental setup', 'has', 'face images']]"
"[['Experimental setup', 'has', 'final size']]"
"[['Results', 'has', 'our two - stage landmark localisation framework']]"
"[['Results', 'has', 'error']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Identity prediction']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', ""Our method 's results""]]"
[]
[]
[]
[]
"[['Approach', 'has', 'DeFA']]"
[]
[]
[]
[]
"[['Approach', 'has', 'Both constraints']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'samples']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'regularization weights']]"
"[['Hyperparameters', 'has', 'lm']]"
"[['Hyperparameters', 'has', 'LFC']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', 'performance']]"
[]
"[['Ablation analysis', 'has', 'accuracy']]"
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'SPC']]"
[]
[]
"[['Model', 'has', 'entire network']]"
"[['Model', 'has', 'morphable model framework']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'encoder']]"
[]
"[['Model', 'has', 'endto - end learning scheme']]"
[]
[]
[]
"[['Model', 'has', 'novel rendering layer']]"
[]
[]
[]
[]
"[['Results', 'has', 'Our nonlinear model']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'non-visible regions']]"
[]
"[['Model', 'has', 'Landmark locations']]"
"[['Model', 'has', 'objective function']]"
[]
"[['Baselines', 'has', '3DDFA']]"
[]
[]
"[['Hyperparameters', 'has', 'Our network']]"
"[['Ablation analysis', 'has', 'new layer']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', '2D landmark regression']]"
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'initial learning rate']]"
[]
[]
"[['Hyperparameters', 'has', 'initial learning rate']]"
"[['Hyperparameters', 'has', 'landmark regression']]"
"[['Hyperparameters', 'has', 'momentum']]"
"[['Ablation analysis', 'has', 'VGG - 16 model']]"
[]
"[['Baselines', 'has', 'AFLW']]"
[]
"[['Baselines', 'has', 'methods']]"
[]
[]
"[['Baselines', 'has', 'AFLW2000 - 3D']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'Weighted Parameter Distance Cost ( WPDC )']]"
[]
[]
[]
"[['Baselines', 'has', 'Large Pose Face Alignment in']]"
"[['Hyperparameters', 'has', 'bounding boxes']]"
[]
"[['Baselines', 'has', 'CDM']]"
"[['Baselines', 'has', 'RCPR']]"
[]
[]
"[['Results', 'has', '3DDFA']]"
"[['Results', 'has', 'minimum standard deviation']]"
"[['Baselines', 'has', '3D Face Alignment']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'our']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'maximum learning iterations']]"
"[['Baselines', 'has', 'FLD + PDE']]"
"[['Results', 'has', 'Our method MCL']]"
"[['Ablation analysis', 'has', 'Global Average Pooling vs. Full Connection']]"
"[['Ablation analysis', 'has', 'Robustness of Weighting']]"
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'Simplified AM']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'features']]"
[]
[]
[]
"[['Model', 'has', 'convolutional neural network']]"
[]
[]
[]
"[['Experimental setup', 'has', 'Data augmentation']]"
[]
"[['Experimental setup', 'has', 'Training']]"
[]
"[['Experimental setup', 'has', 'Python implementation']]"
[]
[]
"[['Experimental setup', 'has', 'first']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'DeCaFA']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'DeCaFA models']]"
"[['Hyperparameters', 'has', 'Each convolution']]"
[]
"[['Hyperparameters', 'has', 'whole architecture']]"
[]
"[['Ablation analysis', 'has', 'accuracy']]"
[]
"[['Ablation analysis', 'has', 'Coarsely annotated data ( 5 landmarks )']]"
[]
[]
"[['Ablation analysis', 'has', 'F 5 - Equation fusion']]"
[]
"[['Ablation analysis', 'has', 'Our approach']]"
"[['Ablation analysis', 'has', 'DeCaFA']]"
"[['Ablation analysis', 'has', 'DeCaFA']]"
"[['Ablation analysis', 'has', 'DeCaFA']]"
[]
"[['Ablation analysis', 'has', 'Method Mean error ( % )']]"
[]
"[['Ablation analysis', 'has', 'A']]"
"[['Ablation analysis', 'has', 'DeCaFA']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'encoded coordinate information']]"
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'Difficult background pixels']]"
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Data augmentation']]"
[]
"[['Results', 'has', 'Our approach']]"
[]
[]
"[['Results', 'has', 'Our']]"
[]
"[['Results', 'has', 'Our method']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our proposed Adaptive Wing loss']]"
"[['Results', 'has', 'our approach']]"
[]
[]
[]
[]
"[['Model', 'has', 'Self - Iterative Regression']]"
[]
[]
"[['Model', 'has', 'training data']]"
[]
[]
"[['Model', 'has', 'Landmarks - Attention Network ( LAN )']]"
[]
[]
"[['Results', 'has', 'NME results']]"
[]
"[['Results', 'has', 'our method']]"
[]
[]
[]
[]
"[['Model', 'has', 'Each facial boundary line']]"
"[['Model', 'has', 'boundary - aware face alignment algorithm']]"
[]
[]
"[['Model', 'has', 'boundary heatmap estimator']]"
[]
[]
"[['Dataset', 'has', 'Each image']]"
"[['Tasks', 'has', 'AFLW dataset']]"
[]
"[['Results', 'has', 'Our method']]"
[]
[]
[]
"[['Results', 'has', 'failure rate']]"
"[['Results', 'has', 'clear boost']]"
"[['Results', 'has', 'our method']]"
"[['Ablation analysis', 'has', 'Our']]"
"[['Ablation analysis', 'has', 'our final model']]"
[]
"[['Model', 'has', 'runtime']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'ERT']]"
"[['Model', 'has', 'coarse - to - fine structure']]"
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'validation error']]"
[]
[]
[]
"[['Experimental setup', 'has', 'depth of']]"
"[['Experimental setup', 'has', 'number of tests']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Training']]"
[]
[]
[]
[]
"[['Results', 'has', 'Our approach']]"
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', '3DDE']]"
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'coarse - to - fine strategy']]"
"[['Results', 'has', 'smallest database']]"
[]
"[['Results', 'has', 'model All']]"
"[['Results', 'has', 'landmarks']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'our method']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'batch size']]"
[]
"[['Ablation analysis', 'has', 'Network trained']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'our proposed method']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', '2D facial landmarks']]"
"[['Experimental setup', 'has', 'Each face']]"
"[['Experimental setup', 'has', 'Each image']]"
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', '2DASL ( cyc )']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'best result']]"
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'our algorithm']]"
[]
"[['Experimental setup', 'has', 'training']]"
"[['Experimental setup', 'has', 'training']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'GHCU']]"
"[['Results', 'has', 'our CNN based GHCU']]"
"[['Ablation analysis', 'has', 'Semantic alignment']]"
"[['Ablation analysis', 'has', 'GHCU']]"
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'focal loss']]"
"[['Baselines', 'has', 'STR']]"
"[['Experimental setup', 'has', 'backbone network']]"
[]
"[['Experimental setup', 'has', 'stochastic gradient descent ( SGD ) algorithm']]"
"[['Experimental setup', 'has', 'warmup strategy']]"
[]
"[['Experimental setup', 'has', 'full training and testing codes']]"
"[['Results', 'has', 'our face detector']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'negative slope']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'maximum iteration number']]"
[]
[]
[]
"[['Model', 'has', 'RPN']]"
[]
"[['Hyperparameters', 'has', 'backbone networks']]"
"[['Hyperparameters', 'has', ""newly added convolution layers ' parameters""]]"
[]
"[['Hyperparameters', 'has', 'batch size']]"
"[['Hyperparameters', 'has', 'learning rate']]"
"[['Hyperparameters', 'has', 'Non-maximum suppression']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our improved anchor matching']]"
[]
[]
"[['Results', 'has', 'Our']]"
"[['Results', 'has', 'our DSFD']]"
[]
[]
[]
[]
"[['Model', 'has', 'complementary scale - specific detectors']]"
"[['Model', 'has', 'R - CNN']]"
[]
[]
"[['Model', 'has', 'complimentary detectors']]"
[]
[]
"[['Experimental setup', 'has', 'Learning']]"
"[['Experimental setup', 'has', 'learning rate']]"
"[['Experimental setup', 'has', 'Learning']]"
"[['Experimental setup', 'has', 'joint optimization']]"
"[['Experimental setup', 'has', 'parameters']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'NVIDIA Titan GPU']]"
"[['Results', 'has', 'each layer']]"
[]
"[['Results', 'has', 'effect of input size']]"
[]
[]
[]
[]
"[['Results', 'has', 'deconvoltion layer']]"
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'WSMA']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'single - stage pixel - wise face localisation method']]"
"[['Approach', 'has', 'Each positive anchor']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'learning rate']]"
"[['Experimental setup', 'has', 'training process']]"
"[['Experimental setup', 'has', 'Box voting']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'learning']]"
[]
"[['Results', 'has', 'outper']]"
"[['Results', 'has', 'RetinaFace']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'results']]"
[]
"[['Results', 'has', 'maximum AP']]"
[]
[]
"[['Results', 'has', 'best performance']]"
[]
[]
"[['Results', 'has', 'retrained models']]"
"[['Results', 'has', 'average AP improvement']]"
[]
"[['Results', 'has', 'retrained ACF detector']]"
"[['Results', 'has', 'recall rate improvement']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'parameters']]"
[]
"[['Hyperparameters', 'has', 'maximum number of iterations']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'RDCL']]"
"[['Results', 'has', 'our FaceBoxes']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'Features fusion']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'Landmarks localization']]"
"[['Model', 'has', 'former']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Fast - HyperFace']]"
[]
[]
[]
[]
"[['Model', 'has', 'Face R - FCN']]"
"[['Model', 'has', 'FAN']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'parameters']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'mAP']]"
[]
"[['Results', 'has', 'Wider and deeper context prediction module']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'CMS - RCNN method']]"
[]
[]
"[['Hyperparameters', 'has', 'CMS - RCNN']]"
"[['Hyperparameters', 'has', 'first 5 sets']]"
[]
"[['Hyperparameters', 'has', 'features']]"
[]
[]
"[['Hyperparameters', 'has', 'channel size']]"
[]
[]
"[['Results', 'has', 'Our method']]"
[]
[]
[]
"[['Results', 'has', 'context model']]"
[]
"[['Results', 'has', 'Our method']]"
"[['Results', 'has', 'proposed']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Single NVIDIA Tesla K80']]"
"[['Experimental setup', 'has', 'Mini batch size']]"
[]
"[['Experimental setup', 'has', 'Aspect ratios ( 1 , 1.5 , 2 )']]"
"[['Experimental setup', 'has', 'batch size']]"
"[['Experimental setup', 'has', 'initial learning rate']]"
"[['Experimental setup', 'has', 'Weight decay']]"
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'R - CNN - like detectors']]"
[]
[]
"[['Approach', 'has', 'Cascade']]"
"[['Approach', 'has', 'RefineDet']]"
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'backbone network']]"
[]
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'STC module']]"
"[['Ablation analysis', 'has', 'our STC']]"
[]
[]
"[['Ablation analysis', 'has', 'STR module']]"
"[['Ablation analysis', 'has', 'gap']]"
[]
"[['Ablation analysis', 'has', 'RFE']]"
[]
[]
"[['Results', 'has', 'SRN']]"
"[['Results', 'has', 'our SRN']]"
[]
[]
[]
"[['Model', 'has', 'classifier learning process']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'multi-task Region Proposal Network ( RPN )']]"
[]
[]
[]
[]
"[['Results', 'has', 'multi-task RPN , Supervised Transformer , and feature combination']]"
[]
[]
[]
[]
[]
"[['Tasks', 'has', 'Non- top K ( K = 3 ) suppression']]"
"[['Tasks', 'has', 'original']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'NPD feature']]"
[]
[]
"[['Model', 'has', 'individual NPD']]"
"[['Model', 'has', 'different types of faces']]"
[]
"[['Model', 'has', 'resulting face detector']]"
[]
"[['Model', 'has', 'deep quadratic tree learner']]"
"[['Model', 'has', 'only a single soft - cascade AdaBoost classifier']]"
"[['Model', 'has', 'unconstrained face detector']]"
[]
[]
"[['Model', 'has', 'unconstrained face variations']]"
"[['Model', 'has', 'NPD feature']]"
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'final detector']]"
"[['Hyperparameters', 'has', 'detection template']]"
"[['Hyperparameters', 'has', 'detector cascade']]"
[]
[]
[]
"[['Results', 'has', 'Joint Cascade algorithm']]"
"[['Results', 'has', 'performance']]"
[]
[]
[]
"[['Results', 'has', 'detector']]"
[]
"[['Results', 'has', 'proposed NPD method']]"
"[['Results', 'has', 'NPD detector']]"
"[['Results', 'has', 'performance improvements']]"
"[['Results', 'has', 'NPD']]"
"[['Results', 'has', 'NPD']]"
[]
"[['Results', 'has', 'DQT based detector']]"
[]
"[['Results', 'has', 'original resolution']]"
"[['Results', 'has', 'NPD detector']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'aggregate channel features ( ACF )']]"
"[['Model', 'has', 'Two - stage methods']]"
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'optimization method']]"
"[['Experimental setup', 'has', 'initial learning rate']]"
[]
"[['Experimental setup', 'has', 'training time']]"
"[['Results', 'has', 'DSFD , Pyramid Box , S3FD and SSH']]"
"[['Results', 'has', 'Pyramid Box']]"
[]
[]
"[['Results', 'has', 'FaceBoxes 3.2']]"
"[['Results', 'has', 'proposed LFFD']]"
[]
"[['Baselines', 'has', 'Bounding box regression']]"
"[['Baselines', 'has', 'Multi-source training']]"
"[['Baselines', 'has', 'Online Hard sample mining']]"
"[['Baselines', 'has', 'P- Net']]"
"[['Baselines', 'has', 'R - Net']]"
"[['Baselines', 'has', 'O - Net']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'first two blocks']]"
"[['Results', 'has', 'our method']]"
"[['Results', 'has', 'Our performance']]"
[]
"[['Results', 'has', 'our method']]"
[]
"[['Baselines', 'has', 'face detector']]"
"[['Baselines', 'has', 'Single']]"
"[['Results', 'has', 'Our model with single detection feature map']]"
[]
"[['Results', 'has', 'ablation results']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'our detector']]"
[]
[]
"[['Model', 'has', 'Most of the appearance variations']]"
"[['Model', 'has', 'location variations']]"
"[['Model', 'has', 'first']]"
[]
[]
[]
"[['Model', 'has', 'RSA unit']]"
[]
"[['Model', 'has', 'scale - forecast network']]"
"[['Model', 'has', 'landmark retracing network']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'numbers of channels']]"
[]
[]
"[['Hyperparameters', 'has', 'maximum training iteration']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Approach', 'has', 'ConvNet of R - FCN']]"
[]
[]
"[['Approach', 'has', 'on - line hard example mining ( OHEM ) technique']]"
[]
[]
"[['Hyperparameters', 'has', 'freeze']]"
[]
[]
"[['Baselines', 'has', 'RPN and R - FCN']]"
"[['Hyperparameters', 'has', 'Non- maximum suppression ( NMS )']]"
"[['Hyperparameters', 'has', 'proposals']]"
[]
[]
[]
"[['Results', 'has', 'our proposed approach']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'our hybrid - resolution model ( HR )']]"
[]
"[['Hyperparameters', 'has', 'Our regressor']]"
"[['Results', 'has', 'Resnet 101 - based detector']]"
[]
[]
[]
[]
"[['Results', 'has', 'proposed detector']]"
[]
[]
"[['Results', 'has', 'Our detector']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Our model']]"
"[['Experimental setup', 'has', 'diagonal variant']]"
"[['Experimental setup', 'has', 'hidden dimension']]"
"[['Experimental setup', 'has', 'batch size']]"
[]
[]
"[['Results', 'has', 'All the neural models']]"
[]
[]
[]
[]
"[['Results', 'has', 'inclusion hypothesis']]"
[]
[]
"[['Results', 'has', 'Hypernym vs. Synonym SLQS']]"
[]
[]
[]
"[['Results', 'has', 'over all performance']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'KB - UNIFY']]"
"[['Baselines', 'has', 'unification algorithm']]"
"[['Results', 'has', 'Yago and WiBi']]"
[]
[]
[]
"[['Hyperparameters', 'has', 'Word2vec']]"
"[['Hyperparameters', 'has', 'skip - gram model ( - cbow 0 )']]"
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our hybrid system']]"
[]
"[['Results', 'has', 'Our cross-evaluation results']]"
"[['Results', 'has', 'unsupervised system']]"
[]
[]
[]
"[['Ablation analysis', 'has', 'No subsampling']]"
"[['Baselines', 'has', 'No']]"
"[['Ablation analysis', 'has', 'Frozen embeddings']]"
[]
[]
[]
[]
[]
[]
[]
"[['Dataset', 'has', 'discovering']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'maximum number of coreference clusters']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'ConZNet architecture']]"
[]
[]
"[['Model', 'has', 'our decoder']]"
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'weights']]"
[]
[]
[]
"[['Experimental setup', 'has', 'number of hidden units']]"
[]
"[['Experimental setup', 'has', 'hyperparameter']]"
[]
[]
"[['Results', 'has', 'low performance']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'Full Context ( FC )']]"
[]
"[['Results', 'has', '3 - layer feed - forward neural network']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Sentinel vectors']]"
[]
[]
[]
"[['Results', 'has', 'performance']]"
[]
[]
"[['Ablation analysis', 'has', 'performance']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'external memory']]"
"[['Model', 'has', 'Generalization updates old memories given the new']]"
[]
"[['Model', 'has', '"" Relation Memory Network "" ( RMN )']]"
[]
"[['Model', 'has', 'Relation Memory Network ( RMN )']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'MemN2N']]"
[]
[]
"[['Model', 'has', 'softmax output']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'EpiReader']]"
[]
[]
"[['Model', 'has', 'Extractor']]"
"[['Model', 'has', 'biGRU']]"
[]
"[['Experimental setup', 'has', 'word embeddings']]"
[]
[]
[]
"[['Results', 'has', 'EpiReader']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Training']]"
"[['Hyperparameters', 'has', 'Weights']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'MemNN']]"
[]
[]
"[['Baselines', 'has', 'LSTM']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'dimension']]"
"[['Hyperparameters', 'has', 'word embeddings']]"
"[['Hyperparameters', 'has', 'word embeddings']]"
"[['Hyperparameters', 'has', 'Adam ( Kingma and Ba , 2014 )']]"
"[['Hyperparameters', 'has', 'mini - batch size']]"
[]
[]
[]
[]
"[['Results', 'has', 'baseline ESIM']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'initial weights']]"
"[['Hyperparameters', 'has', 'Weights']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'average performance']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Language modeling']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'model']]"
"[['Hyperparameters', 'has', 'Word embeddings']]"
[]
"[['Hyperparameters', 'has', 'Initial learning rate']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'full TBCNN - pair model']]"
[]
[]
[]
"[['Experimental setup', 'has', 'spaCy tool']]"
[]
[]
"[['Experimental setup', 'has', 'lexicon embeddings']]"
"[['Experimental setup', 'has', 'embedding']]"
"[['Experimental setup', 'has', 'hidden size']]"
"[['Experimental setup', 'has', 'projection size']]"
[]
"[['Experimental setup', 'has', 'dropout rate']]"
"[['Experimental setup', 'has', 'mini - batch size']]"
"[['Experimental setup', 'has', 'Our optimizer']]"
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
"[['Model', 'has', 'tree structure']]"
[]
"[['Model', 'has', 'NTI']]"
[]
"[['Hyperparameters', 'has', 'pre-trained 300 - D Glove 840B vectors']]"
"[['Hyperparameters', 'has', 'word embeddings']]"
"[['Hyperparameters', 'has', 'embeddings']]"
"[['Hyperparameters', 'has', 'size']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'attention degree']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'Embedding Layer']]"
"[['Experimental setup', 'has', 'embedding weights']]"
[]
"[['Experimental setup', 'has', 'Hidden Layer']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'language model features']]"
[]
"[['Experimental setup', 'has', 'Implementation']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'character embedding']]"
[]
"[['Hyperparameters', 'has', 'Dropout layer']]"
"[['Hyperparameters', 'has', 'Adam optimizer']]"
"[['Hyperparameters', 'has', 'learning rate']]"
[]
"[['Baselines', 'has', 'ESIM']]"
[]
[]
"[['Baselines', 'has', 'BiMPM']]"
[]
"[['Baselines', 'has', 'SSE']]"
"[['Baselines', 'has', 'Densely Interactive Inference Network']]"
[]
"[['Results', 'has', 'LCQMC dataset']]"
"[['Results', 'has', 'our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'DF - LSTMs']]"
"[['Model', 'has', 'output vector']]"
[]
[]
[]
[]
"[['Baselines', 'has', 'Neural bag - of - words ( NBOW )']]"
"[['Baselines', 'has', 'Each sequence']]"
"[['Baselines', 'has', 'Single LSTM']]"
"[['Baselines', 'has', 'Parallel LSTMs']]"
"[['Baselines', 'has', 'Attention LSTMs']]"
"[['Baselines', 'has', 'Word - by - word Attention LSTMs']]"
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'MRS']]"
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Dropout']]"
"[['Results', 'has', 'Our system ( single model )']]"
[]
[]
"[['Baselines', 'has', 'SQuAD']]"
"[['Baselines', 'has', 'Fine-tune ( DS )']]"
"[['Baselines', 'has', 'Multitask ( DS )']]"
[]
[]
[]
[]
"[['Model', 'has', 'selected paragraphs']]"
[]
[]
[]
[]
"[['Model', 'has', 'module']]"
[]
"[['Model', 'has', 'ranking function']]"
"[['Model', 'has', 'extraction function']]"
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'word embeddings']]"
"[['Experimental setup', 'has', 'hidden size']]"
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'Both the preliminary cascade ranking and multi-task answer extraction strategy']]"
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'time cost']]"
"[['Ablation analysis', 'has', 'performance']]"
[]
"[['Ablation analysis', 'has', 'performance gain']]"
[]
[]
[]
[]
[]
[]
[]
"[['Experimental setup', 'has', 'Glove embedding']]"
[]
[]
[]
[]
"[['Experimental setup', 'has', 'LSTM blocks']]"
[]
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'SDNet']]"
[]
[]
[]
[]
[]
[]
[]
"[['Ablation analysis', 'has', 'Our']]"
[]
"[['Ablation analysis', 'has', 'Variational dropout and self attention']]"
[]
"[['Model', 'has', 'basic rules']]"
[]
[]
[]
[]
"[['Results', 'has', 'MemN2N']]"
"[['Results', 'has', 'LSTM']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'our model']]"
[]
[]
[]
[]
[]
"[['Results', 'has', 'general EntNet']]"
"[['Results', 'has', 'simplified EntNet']]"
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'hidden size']]"
"[['Hyperparameters', 'has', 'Dropout']]"
[]
[]
"[['Results', 'has', 'EM result']]"
[]
[]
[]
[]
[]
"[['Dataset', 'has', 'question - answer pairs']]"
"[['Model', 'has', 'bi-directional attention flow ( BIDAF )']]"
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'Out - of - vocabulary ( OOV ) words']]"
"[['Hyperparameters', 'has', 'CharCNN filter length']]"
"[['Results', 'has', 'cluster number K']]"
"[['Hyperparameters', 'has', 'Adam method']]"
"[['Results', 'has', 'initial learning rate']]"
"[['Hyperparameters', 'has', 'hidden states']]"
[]
[]
"[['Results', 'has', 'Our model']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'WORDEMBED']]"
"[['Baselines', 'has', 'matching score']]"
[]
[]
"[['Baselines', 'has', 'SENMLP']]"
[]
"[['Results', 'has', 'two proposed']]"
"[['Results', 'has', 'ARC - II']]"
"[['Results', 'has', 'SENNA + MLP']]"
[]
[]
"[['Approach', 'has', 'External memory']]"
[]
[]
"[['Approach', 'has', 'Sparse Differentiable Neural Computer ( SDNC )']]"
[]
[]
[]
"[['Results', 'has', 'SDNC']]"
[]
"[['Results', 'has', 'Both the sparse and dense']]"
[]
"[['Results', 'has', 'SAM']]"
[]
"[['Results', 'has', 'SDNC']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'TriviaQA']]"
"[['Results', 'has', 'our model']]"
"[['Results', 'has', 'Our model with']]"
[]
[]
[]
[]
"[['Results', 'has', 'our model']]"
[]
[]
[]
[]
[]
[]
[]
"[['Model', 'has', 'vector']]"
"[['Model', 'has', 'Self - attention']]"
"[['Model', 'has', 'weight vector']]"
[]
[]
[]
[]
[]
"[['Baselines', 'has', 'DSA and self - attention']]"
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
[]
"[['Hyperparameters', 'has', 'training objective']]"
"[['Hyperparameters', 'has', 'batch size']]"
"[['Hyperparameters', 'has', 'dropout layer']]"
[]
"[['Hyperparameters', 'has', 'Out - of - vocabulary words']]"
[]
[]
[]
[]
[]
[]
"[['Results', 'has', 'Our BERT model']]"
