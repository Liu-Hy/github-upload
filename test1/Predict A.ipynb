{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the hyperparameter space with W&B sweep\n",
    "import logging\n",
    "from ast import literal_eval as load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import sklearn\n",
    "\n",
    "from simpletransformers.classification import (\n",
    "    ClassificationArgs,\n",
    "    ClassificationModel,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "available-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "df = pd.read_csv('triples.csv')\n",
    "df = df.rename(columns={'idx': 'indx'})\n",
    "df.insert(loc=0, column='idx', value=np.arange(len(df)))\n",
    "sent_num=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "operational-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(arr):\n",
    "    trip_ls = []\n",
    "    ls = []\n",
    "    for i in range(len(arr)):\n",
    "        pre_ls = literal_eval(arr[i, 3])\n",
    "        np_ls = literal_eval(arr[i, 4])\n",
    "        p_idx = [(1, *p[1]) for p in pre_ls]\n",
    "        n_idx = [(0, *n[1]) for n in np_ls]\n",
    "        for p in range(len(p_idx)):\n",
    "            for j in range(len(n_idx)-1):\n",
    "                for k in range(j+1, len(n_idx)):\n",
    "                    trip = [np_ls[j][0],pre_ls[p][0],np_ls[k][0]]\n",
    "                    trip_ls.append(trip)\n",
    "                    word_ls = arr[i, 2].split(' ')\n",
    "                    indx = sorted([p_idx[p], n_idx[j], n_idx[k]], key=lambda x:x[1])\n",
    "                    for w in range(len(indx)):\n",
    "                        if indx[w][0] == 1:\n",
    "                            word_ls.insert(indx[w][1]+2*w, '<<')\n",
    "                            word_ls.insert(indx[w][2]+2*w+1, '>>')\n",
    "                        else:\n",
    "                            word_ls.insert(indx[w][1]+2*w, '[[')\n",
    "                            word_ls.insert(indx[w][2]+2*w+1, ']]')\n",
    "                    flg = 0\n",
    "                    for tp in literal_eval(arr[i, 5]):\n",
    "                        if tp == [np_ls[j][0], pre_ls[p][0], np_ls[k][0]]:\n",
    "                            flg = 1\n",
    "                            break\n",
    "                    ls.append([int(arr[i, 0]), ' '.join(word_ls), flg])\n",
    "    dataframe = pd.DataFrame(ls)\n",
    "    dataframe.columns = ['idx', 'text', 'labels']\n",
    "    return dataframe,trip_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verbal-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.values\n",
    "df,trip_ls=convert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tamil-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.manual_seed = 1\n",
    "model_args.fp16 = False\n",
    "model_args.use_multiprocessing = True\n",
    "model_args.do_lower_case = True  # when using uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finite-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_F1(ref, pred):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lyric-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1656f7b4804aef8f4656f066b254b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443447b0f910471fa25508ced5560d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/12955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'tp': 0, 'tn': 96801, 'fp': 6835, 'fn': 0, 'F1_score': 0, 'eval_loss': 0.32792378466614797}\n"
     ]
    }
   ],
   "source": [
    "# Create a TransformerModel\n",
    "model = ClassificationModel(\n",
    "    \"bert\",\n",
    "    \"../rel/outputsA/best_model\",\n",
    "    args=model_args,\n",
    ")\n",
    "result, model_outputs, wrong_predictions = model.eval_model(df, F1_score=triple_F1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sacred-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(model_outputs.argmax(axis=1))\n",
    "df['preds']=preds\n",
    "df['cand']=trip_ls\n",
    "df.loc[df['preds']==0,'cand']=None\n",
    "data=[]\n",
    "for i in range(sent_num):\n",
    "    temp = list(df[df['idx']==i]['cand'])\n",
    "    temp = [t for t in temp if t]\n",
    "    data.append(str(temp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cooperative-nigeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[]',\n",
       " \"[['sentences', 'explicitly models', 'nested , hierarchical relationships'], ['nested , hierarchical relationships', 'among', 'words and phrases']]\",\n",
       " \"[['two variants', 'of', 'algorithm'], ['two variants', 'one for', 'parsing'], ['algorithm', 'one for', 'parsing']]\",\n",
       " \"[['greedy prediction', 'with', 'our']]\",\n",
       " \"[['simple importance sampling algorithm', 'which uses', 'samples'], ['samples', 'from', 'discriminative parser'], ['samples', 'to solve', 'inference problems'], ['discriminative parser', 'to solve', 'inference problems'], ['inference problems', 'in', 'generative model']]\",\n",
       " '[]',\n",
       " \"[['training', 'used', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', 'learning rate'], ['learning rate', 'of', '0.1']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['both directions', 'of', 'large language - model - inspired self - attention cloze model']]\",\n",
       " \"[['cloze - style training objective', 'where', 'model'], ['model', 'must predict', 'center word'], ['center word', 'given', 'left - to - right and right - to - left context representations']]\",\n",
       " '[]',\n",
       " \"[['CNN', 'use', 'adaptive softmax'], ['adaptive softmax', 'in', 'output'], ['headband', 'contains', '60K most frequent types'], ['160 K band', 'with', 'dimensionality 256'], ['160 K band', 'with', 'momentum'], ['gradients', 'if', 'norm'], ['norm', 'exceeds', '0.1']]\",\n",
       " \"[['linearly warmed up', 'from', '10 ? 7 to 1'], ['10 ? 7 to 1', 'for', '16 K steps'], ['learning rate', 'annealed using', 'cosine learning rate schedule'], ['cosine learning rate schedule', 'with', 'single phase'], ['single phase', 'to', '0.0001']]\",\n",
       " \"[['DGX - 1 machines', 'with', '8 NVIDIA V100 GPUs']]\",\n",
       " '[]',\n",
       " \"[['models', 'with', '16 bit floating point precision']]\",\n",
       " '[]',\n",
       " \"[['STILTs', 'in', 'aggregate']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['general purpose sequence - to - sequence models', 'for', 'constituency parsing']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['standard UNK replacement', 'For', 'OOV words'], ['all the parse trees', 'transformed into', 'linearized forms'], ['linearized forms', 'which', 'POS - tag normalization'], ['linearized forms', 'include', 'standard UNK replacement'], ['linearized forms', 'include', 'POS - tag normalization'], ['standard UNK replacement', 'for', 'OOV words'], ['POS - tag normalization', 'by', 'XX - tags']]\",\n",
       " '[]',\n",
       " \"[['Smaller mini-batch size M and gradient clipping G', 'provided', 'better performance']]\",\n",
       " \"[['little impact', 'on', 'performance'], ['adequate', 'in terms of', 'speed / performance trade - off']]\",\n",
       " \"[['results', 'of', 'utilizing subword splits']]\",\n",
       " \"[['subword information', 'as', 'features'], ['promising approach', 'for leveraging', 'subword information'], ['subword information', 'into', 'constituency parsing']]\",\n",
       " \"[['Our Seq2seq approach', 'successfully achieved', 'competitive level'], ['competitive level', 'as', 'current']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['single attention model', 'gets to', '88.3'], ['ensemble of 5 LSTM', 'achieves', '90.5'], ['90.5', 'matching', 'single - model BerkeleyParser']]\",\n",
       " \"[['single LSTM + A model', 'achieves', '92.5']]\",\n",
       " \"[['ensemble of 5 LSTM+ A models', 'further improves', 'score'], ['score', 'to', '92.8']]\",\n",
       " \"[['difference', 'between', 'F 1 score'], ['F 1 score', 'on', 'sentences'], ['F 1 score', 'upto', '70'], ['70', 'is', '1.3'], ['1.3', 'for', 'BerkeleyParser'], ['1.3', 'for', 'baseline LSTM'], ['1.3', 'for', '0.7']]\",\n",
       " \"[['LSTM +A', 'shows', 'less degradation'], ['less degradation', 'with', 'length'], ['length', 'than', 'BerkeleyParser']]\",\n",
       " \"[['word - vector embedding', 'with', 'pre-trained word vectors'], ['pre-trained word vectors', 'obtained from', 'word2 vec']]\",\n",
       " \"[['LSTM + A', 'trained on', 'high - confidence corpus'], ['high - confidence corpus', 'achieved', 'F 1 score'], ['F 1 score', 'of', '95.7'], ['F 1 score', 'of', '84.6'], ['95.7', 'on', 'QTB'], ['95.7', 'on', '84.6'], ['84.6', 'on', 'WEB']]\",\n",
       " \"[['Our score', 'on', 'WEB'], ['Our score', 'higher both than', 'best score'], ['in - house reimplementation', 'of', 'Berkeley Parser'], ['Berkeley Parser', 'trained on', 'human - annotated data ( 84.4 )']]\",\n",
       " \"[['slightly higher score ( 84.8 )', 'with', 'in - house Berkeley Parser'], ['in - house Berkeley Parser', 'trained on', 'large corpus']]\",\n",
       " \"[['95.7 score', 'of', 'LSTM + A'], ['best score', 'of', 'our'], ['best score', 'of', 'in - house BerkeleyParser ( 96.2 )'], ['LSTM + A', 'lower than', 'best score'], ['best score', 'of', 'our'], ['best score', 'of', 'in - house BerkeleyParser ( 96.2 )']]\",\n",
       " '[]',\n",
       " \"[['LSTM generative model ( LM )', 'use', 'pre-trained model']]\",\n",
       " \"[['actionsynchronous beam search', 'with', 'beam size K = 100'], ['actionsynchronous beam search', 'with', 'word - synchronous beam'], ['word - synchronous beam', 'with', 'K w'], ['beam size K = 100', 'for', 'RD'], ['word - synchronous beam', 'with', 'K w']]\",\n",
       " \"[['higher performance', 'for', 'LM model'], ['higher performance', 'when using', 'candidate list'], ['LM model', 'when using', 'candidate list'], ['candidate list', 'from', 'RD parser'], ['candidate list', 'versus', '92.79 F1'], ['93.66 F1', 'versus', '92.79 F1'], ['92.79 F1', 'on', 'development data']]\",\n",
       " \"[['scores', 'of', 'both models'], ['score', 'of', 'either model alone'], ['score', 'of', 'either model alone']]\",\n",
       " \"[['Score combination', 'more than compensates for', 'decrease in'], ['candidates', 'from', 'generative model']]\",\n",
       " \"[['score combination', 'improves', 'results'], ['results', 'for', 'all models'], ['results', 'with', 'candidate augmentation'], ['all models', 'with', 'candidate augmentation'], ['candidate augmentation', 'from', 'generative models']]\",\n",
       " \"[['PTB training data setting', 'using', 'all models'], ['all models', 'for', 'candidates and score combinations'], ['candidates and score combinations', 'is', 'best'], ['candidates and score combinations', 'achieving', '94.66 F1'], ['best', 'achieving', '94.66 F1']]\",\n",
       " \"[['Performance', 'using', 'only the ensembled RD models'], ['single RD model', 'with', 'score combinations'], ['score combinations', 'of', 'single models']]\",\n",
       " \"[['ensembling', 'with', 'score combination'], ['ensembling', 'achieves', 'best over all result'], ['score combination', 'achieves', 'best over all result'], ['best over all result', 'of', '94.25']]\",\n",
       " '[]',\n",
       " \"[['system', 'achieves', '93.6 F 1'], ['system', 'achieves', '94.2 F 1'], ['93.6 F 1', 'with', 'supervised reranking'], ['93.6 F 1', 'with', '94.2 F 1'], ['93.6 F 1', 'with', 'semi-supervised reranking'], ['94.2 F 1', 'with', 'semi-supervised reranking'], ['94.2 F 1', 'with', 'semi-supervised reranking']]\",\n",
       " '[]',\n",
       " \"[['novel transition system', 'for', 'constituent parsing'], ['novel transition system', 'mitigating', 'issues'], ['issues', 'of', 'bottom - up and top - down systems'], ['bottom - up and top - down systems', 'by finding', 'compromise'], ['compromise', 'between', 'bottom - up constituent information'], ['compromise', 'between', 'top - down lookahead information']]\",\n",
       " '[]',\n",
       " \"[['regularization hyperparameter (? = 10 ?6 )', 'use', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', '0.1 initialized learning rate'], ['0.1 initialized learning rate', 'with', '0.05 learning rate decay'], ['0.1 initialized learning rate', 'with', '0.05 learning rate decay']]\",\n",
       " \"[['bottom - up system', 'performs', 'slightly better'], ['slightly better', 'than', 'top - down system']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['bottom - up parser and the top - down parser', 'have', 'similar results'], ['similar results', 'under', 'greedy setting']]\",\n",
       " \"[['in - order parser', 'achieves', 'best results']]\",\n",
       " '[]',\n",
       " \"[['inorder parser', 'outperforms', 'state - of - the - art discrete parser']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['in - order parser', 'performs', 'best'], ['best', 'on', 'all constituent types']]\",\n",
       " '[]',\n",
       " \"[['trees', 'converted to', 'Stanford dependencies'], ['UAS and LAS', 'are', '95.9 % and 94.1 %']]\",\n",
       " \"[['neural - net parse reranker', 'achieves', 'very good results'], ['very good results', 'with', 'comparatively simple architecture']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Dropout', 'applied to', 'non-recurrent connections'], ['clipped', 'when', 'norm']]\",\n",
       " \"[['learning rate', 'is', '0.25 0.85 max']]\",\n",
       " '[]',\n",
       " \"[['explicit modeling', 'of', 'composition']]\",\n",
       " \"[['attention mechanism', 'find', 'headedness']]\",\n",
       " \"[['grammars', 'without', 'nonterminal labels'], ['grammars', 'find that', 'phrasal representations'], ['phrasal representations', 'depend minimally on', 'nonterminals'], ['phrasal representations', 'providing support for', 'endocentricity hypothesis']]\",\n",
       " \"[['probability distributions', 'designed to model', 'syntactic derivations'], ['syntactic derivations', 'of', 'sentences']]\",\n",
       " \"[['RNNGs', 'as', 'generative probabilistic models over']]\",\n",
       " \"[['inductive bias', 'of', 'RNNGs'], ['inductive bias', 'to test', 'linguistic hypotheses'], ['RNNGs', 'to test', 'linguistic hypotheses']]\",\n",
       " \"[['RNNG composition function', 'with', 'novel gated attention mechanism'], ['novel gated attention mechanism', 'leading to', 'GA - RNNG'], ['novel gated attention mechanism', 'to incorporate', 'more interpretability'], ['more interpretability', 'into', 'model']]\",\n",
       " \"[['information', 'passed through', 'compositions'], ['compositions', 'of', 'phrases ( in ? and the neural network architecture )']]\",\n",
       " \"[['RNNG', 'samples', 'sequence of actions'], ['sequence of actions', 'to', 'construct']]\",\n",
       " \"[['RNNG', 'uses', 'three different actions']]\",\n",
       " \"[['RNNG', 'consists of', 'stack'], ['RNNG', 'consists of', 'list of past actions'], ['buffer', 'of', 'generated words'], ['list of past actions', 'lead to', 'current configuration']]\",\n",
       " \"[['stack , buffer , and past actions', 'with', 'separate LSTM'], ['separate LSTM', 'for', 'each component'], ['each component', 'as', 'features'], ['features', 'to define', 'distribution'], ['distribution', 'over', 'next action to take'], ['distribution', 'conditioned on', 'full algorithmic state'], ['next action to take', 'conditioned on', 'full algorithmic state']]\",\n",
       " \"[['Both inference problems', 'solved using', 'importance sampling procedure']]\",\n",
       " '[]',\n",
       " \"[['Do the phrasal representations', 'learned by', 'RN - NGs'], ['Do the phrasal representations', 'depend on', 'individual lexical heads'], ['RN - NGs', 'depend on', 'individual lexical heads']]\",\n",
       " '[]',\n",
       " \"[['conversion accuracy', 'better for', 'nouns ( ? 50 % error )'], ['conversion accuracy', 'much better for', 'determiners ( 30 % ) and particles ( 6 % )'], ['determiners ( 30 % ) and particles ( 6 % )', 'with respect to', 'Collins head rules']]\",\n",
       " \"[['GA - RNNG', 'achieves', '94.2 %'], ['U - GA - RNNG', 'achieves', '93.5 %']]\",\n",
       " '[]',\n",
       " \"[['LSTM encoder', 'with', 'self - attentive architecture'], ['LSTM encoder', 'lead to', 'improvements'], ['self - attentive architecture', 'lead to', 'improvements'], ['improvements', 'to', 'state - of the - art discriminative constituency parser']]\",\n",
       " \"[['parser', 'combines', 'encoder'], ['decoder', 'customized for', 'parsing']]\",\n",
       " \"[['character LSTM', 'performs', 'better'], ['better', 'than', 'other lexical representationseven']]\",\n",
       " \"[['score', 'of', '92.67 F1'], ['92.67 F1', 'on', 'Penn Treebank WSJ development set']]\",\n",
       " \"[['same decode procedure', 'with', 'LSTM - based encoder'], ['LSTM - based encoder', 'achieves', 'development set score'], ['development set score', 'of', '92.24']]\",\n",
       " '[]',\n",
       " \"[['our model', 'learns to use', 'combination'], ['combination', 'of', 'two attention types'], ['two attention types', 'with', 'positionbased attention']]\",\n",
       " \"[['content - based attention', 'is', 'more useful'], ['more useful', 'at', 'later layers'], ['later layers', 'in', 'network']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['deep neural network', 'to build', 'distributed representations'], ['distributed representations', 'of', 'pairs'], ['pairs', 'of', 'coreference clusters'], ['pairs', 'of', 'coreference clusters']]\",\n",
       " \"[['entity - level information', 'with', 'large number of learned , continuous features'], ['large number of learned , continuous features', 'instead of', 'small number of hand - crafted categorical ones']]\",\n",
       " \"[['test time', 'builds up', 'coreference clusters'], ['coreference clusters', 'starting with', 'each mention']]\",\n",
       " \"[['decisions', 'with', 'novel easy - first cluster - ranking procedure'], ['novel easy - first cluster - ranking procedure', 'combines', 'strengths'], ['strengths', 'of', 'cluster - ranking ( Rahman and and easy - first coreference algorithms']]\",\n",
       " '[]',\n",
       " \"[['learning - to - search algorithm', 'inspired by', 'SEARN'], ['SEARN', 'to train', 'our neural network']]\",\n",
       " \"[['which action ( a cluster merge ) available', 'lead to', 'high - scoring coreference partition']]\",\n",
       " \"[['our word embeddings', 'with', '50 dimensional ones'], ['50 dimensional ones', 'produced by', 'word2vec'], ['word2vec', 'on', 'Gigaword corpus'], ['word2vec', 'on', '64 dimensional ones'], ['Gigaword corpus', 'for', 'English']]\",\n",
       " \"[['Averaged word embeddings', 'held', 'fixed'], ['fixed', 'during', 'training'], ['embeddings', 'used for', 'single words']]\",\n",
       " \"[['hidden layer sizes', 'to', 'M 1 = 1000'], ['hidden layer sizes', 'minimized', 'training objective'], ['training objective', 'using', 'RMS - Prop']]\",\n",
       " \"[['network', 'applied', 'L2 regularization'], ['L2 regularization', 'to', 'model weights'], ['dropout', 'with', 'rate'], ['rate', 'of', '0.5'], ['output', 'of', 'each hidden layer'], ['0.5', 'on', 'word embeddings'], ['output', 'of', 'each hidden layer']]\",\n",
       " '[[\\'pretraining\\', \\'crucial for\\', \"mentionranking model \\'s success\"]]',\n",
       " '[]',\n",
       " \"[['model performance', 'especially', 'distance and string matching features']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['slightly outperforms', 'using', 'left - to - right ordering'], ['left - to - right ordering', 'of', 'mentions']]\",\n",
       " \"[['mention - ranking model', 'surpasses', 'all previous systems']]\",\n",
       " \"[['cluster - ranking model', 'improves', 'results'], ['results', 'further across', 'both languages and all evaluation metrics']]\",\n",
       " \"[['much more complicated cluster - ranking model', 'brings', 'fairly modest gains'], ['fairly modest gains', 'in', 'performance']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['goal - directed endto - end deep reinforcement learning framework', 'to resolve', 'coreference']]\",\n",
       " \"[['our policy network', 'includes', 'learning span representation'], ['learning span representation', 'scoring', 'potential entity mentions'], ['our policy network', 'generating', 'probability distribution'], ['probability distribution', 'over', 'all possible coreference linking actions'], ['all possible coreference linking actions', 'from', 'current mention']]\",\n",
       " \"[['entropy regularization term', 'to encourage', 'exploration'], ['entropy regularization term', 'prevent', 'policy'], ['policy', 'from', 'prematurely converging'], ['prematurely converging', 'to', 'bad local optimum']]\",\n",
       " \"[['regularized policy network parameters', 'based on', 'rewards'], ['rewards', 'associated with', 'sequences']]\",\n",
       " \"[['learned parameters', 'for', 'initialization'], ['our model', 'use', 'learned parameters'], ['learned parameters', 'for', 'initialization']]\",\n",
       " \"[['number of sampled trajectories N s = 100', 'tune', 'regularization parameter ?'], ['regularization parameter ?', 'expr in', '{ 10 ?5 , 10 ?4 , 0.001 , 0.01 , 0.1 , 1 }'], ['regularization parameter ?', 'set it to', '10 ? 4'], ['10 ? 4', 'based on', 'development set']]\",\n",
       " \"[['significant improvement', 'on', 'OntoNotes benchmark']]\",\n",
       " \"[['our base reinforced model', 'improves', 'average F 1 score'], ['average F 1 score', 'around', '2 points']]\",\n",
       " \"[['entropy regularization', 'to encourage', 'exploration'], ['exploration', 'can improve', 'result'], ['result', 'by', '1 point']]\",\n",
       " \"[['context - dependent ELMo embedding', 'to', 'our base model'], ['context - dependent ELMo embedding', 'can further boosts', 'performance'], ['our base model', 'can further boosts', 'performance']]\",\n",
       " '[[\"our full model \\'s improvement\", \\'mainly from\\', \\'higher precision scores\\']]',\n",
       " \"[['our full model', 'achieves', 'state - of the - art performance'], ['state - of the - art performance', 'of', '73.8 % F1 - score'], ['73.8 % F1 - score', 'when using', 'ELMo and entropy regularization'], ['best F1 -score', 'of', '70.5 %'], ['70.5 %', 'when using', 'fixed word embedding']]\",\n",
       " '[]',\n",
       " \"[['two variants of reinforcement learning', 'to directly optimize', 'coreference system'], ['coreference system', 'for', 'coreference evaluation metrics']]\",\n",
       " '[[\\'max-margin coreference objective\\', \\'by incorporating\\', \\'reward\\'], [\\'reward\\', \\'associated with\\', \\'each coreference decision\\'], [\\'reward\\', \\'into\\', \"loss \\'s slack rescaling\"]]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['REINFORCE', 'does', 'slightly better'], ['slightly better', 'than', 'heuristic loss'], ['reward rescaling', 'performs', 'significantly better']]\",\n",
       " '[[\\'training\\', \\'optimizes\\', \"model \\'s performance\"], [\"model \\'s performance\", \\'in\\', \\'expectation\\'], [\\'training\\', \\'at\\', \\'test - time\\'], [\\'test - time\\', \\'takes\\', \\'most probable sequence\\'], [\\'most probable sequence\\', \\'of\\', \\'actions\\']]',\n",
       " \"[['reward - rescaled max - margin loss', 'combines', 'best of both worlds'], ['best of both worlds', 'resulting in', 'superior performance']]\",\n",
       " '[]',\n",
       " \"[['approximation', 'of', 'higher - order inference'], ['higher - order inference', 'uses', 'span - ranking architecture']]\",\n",
       " \"[['coarseto - fine approach', 'learned with', 'single endto - end objective']]\",\n",
       " \"[['maximum span width', 'from', '10 to 30 words']]\",\n",
       " '[]',\n",
       " \"[['3 highway LSTMs', 'instead of', '1']]\",\n",
       " \"[['Glo Ve word embeddings', 'with', 'window size'], ['Glo Ve word embeddings', 'with', 'window size'], ['window size', 'of', '2'], ['window size', 'of', '10'], ['2', 'for', 'headword embeddings'], ['10', 'for', 'LSTM inputs'], ['10', 'for', 'LSTM inputs']]\",\n",
       " \"[['first - order model', 'by', '0.8 F1'], ['third order model', 'provides', 'additional 0.1 F1 improvement']]\",\n",
       " \"[['span - ranking model', 'from augmented with', 'ELMo and hyperparameter tuning'], ['span - ranking model', 'achieves', '72.3 F1']]\",\n",
       " \"[['Our full approach', 'achieves', '73.0 F1'], ['73.0 F1', 'setting', 'new state of the art'], ['new state of the art', 'for', 'coreference resolution']]\",\n",
       " \"[['further improvement', 'by including', 'second - order inference']]\",\n",
       " \"[['improvement', 'largely driven by', 'over all increase'], ['over all increase', 'in', 'precision']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['mention - ranking model', 'for', 'coreference resolution'], ['Siamese Net', 'for learning', 'similarity'], ['similarity', 'between', 'sentences']]\",\n",
       " \"[['representations', 'for', 'candidate and the anaphoric sentence'], ['candidate and the anaphoric sentence', 'in', 'shared space']]\",\n",
       " \"[['joint representation', 'to calculate', 'score'], ['score', 'characterizes', 'relation']]\",\n",
       " '[]',\n",
       " \"[['PS BL', 'performs', 'worse'], ['worse', 'than', 'KZH13 model'], ['KZH13 model', 'on', 'ASN']]\",\n",
       " \"[['Embeddings', 'for', 'tags'], ['values', 'drawn from', 'uniform distribution U ? 1 ? d+t , 1 ? d+t']]\",\n",
       " \"[['size', 'of', 'LSTMs hidden states'], ['LSTMs hidden states', 'set to', '{ 100 , qlog - U ( 30 , 150 ) }']]\",\n",
       " \"[['weight matrices', 'of', 'LSTMs'], ['LSTMs', 'with', 'random orthogonal matrices']]\",\n",
       " \"[['feed - forward layer size', 'set to', 'value'], ['value', 'in', 'Optimization']]\",\n",
       " \"[['our model', 'in', 'minibatches'], ['minibatches', 'using', 'Adam ( Kingma and Ba , 2015 )'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'learning rate'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'maximal batch size']]\",\n",
       " \"[['gradients', 'by', 'global norm'], ['global norm', 'with', 'clipping value'], ['clipping value', 'in', '{ 1.0 , U ( 1 , 100 ) }']]\",\n",
       " \"[['performs', 'on', 'devset'], ['best', 'on', 'devset']]\",\n",
       " \"[['l 2 - regularization', 'with', '? ? { 10 ?5']]\",\n",
       " \"[['Dropout', 'with', 'keep probability k p ? { 0.8 , U( 0.5 , 1.0 ) }'], ['input', 'with', 'k p ? U (0.8 , 1.0 )'], ['keep probability k p ? { 0.8 , U( 0.5 , 1.0 ) }', 'applied to', 'outputs'], ['outputs', 'of', 'LSTMs']]\",\n",
       " \"[['mentionranking model ( MR - LSTM )', 'on', 'ASN corpus'], ['ASN corpus', 'using', 'default HPs']]\",\n",
       " \"[['TAG BL', 'without even necessitating', 'HP tuning']]\",\n",
       " \"[['HPs', 'tuned on', 'ARRAU - AA'], ['HPs', 'obtain', 'results'], ['all ablated model variants', 'perform', 'worse'], ['worse', 'than', 'full model'], ['large performance drop', 'when omitting', 'syntactic information ( tag , cut )']]\",\n",
       " '[]',\n",
       " \"[['more successful', 'in', 'resolving'], ['nominal', 'than', 'pronominal anaphors']]\",\n",
       " \"[['syntactic information', 'boosts', 'performance'], ['performance', 'in', 'ARRAU - AA']]\",\n",
       " \"[['MR - LSTM without context embedding ( ctx )', 'achieves', 'comparable s@ 2 score'], ['comparable s@ 2 score', 'with', 'variant']]\",\n",
       " '[]',\n",
       " \"[['representations', 'of', 'mention clusters'], ['representations', 'by embedding', 'sequentially'], ['sequentially', 'using', 'recurrent neural network']]\",\n",
       " \"[['global representation', 'from', 'individual mentions'], ['individual mentions', 'present in', 'each cluster']]\",\n",
       " '[]',\n",
       " \"[['model', 'as', 'local classifier'], ['local classifier', 'with', 'fixed context']]\",\n",
       " '[]',\n",
       " \"[['statistically significant improvement', 'of', 'over 0.8 Co NLL points'], ['over 0.8 Co NLL points', 'over', 'previous state of the art']]\",\n",
       " \"[['impact', 'of', 'global features and RNNs'], ['global features and RNNs', 'on', 'performance']]\",\n",
       " \"[['RNN', 'improves', 'performance over all']]\",\n",
       " \"[['decrease', 'for', 'both']]\",\n",
       " \"[['significantly better', 'than', 'Avg baseline'], ['barely improves', 'over', 'mention - ranking'], ['mention - ranking', 'even with', 'oracle history']]\",\n",
       " \"[['both precision and recall', 'when moving from', 'oracle history'], ['oracle history', 'upperbound to', 'greedy setting'], ['significant portion', 'of', 'possible performance improvement']]\",\n",
       " '[]',\n",
       " \"[['word embedding model', 'that learns', 'cross - sentence dependency'], ['cross - sentence dependency', 'for improving', 'end - to - end co-reference resolution ( E2E - CR )']]\",\n",
       " \"[['cross - sentence encoder', 'for', 'end - to - end co-reference ( E2E - CR )']]\",\n",
       " \"[['idea', 'of', 'external memory module'], ['external memory block', 'containing', 'syntactic and semantic information'], ['syntactic and semantic information', 'from', 'context sentences'], ['syntactic and semantic information', 'added to', 'standard LSTM model']]\",\n",
       " \"[['input sentences', 'as', 'batch'], ['proposed', 'calculate', 'representations'], ['representations', 'of', 'input words'], ['input words', 'by taking', 'target sentences and context sentences'], ['target sentences and context sentences', 'into', 'consideration']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['LSTM modules', 'applied in', 'our model'], ['LSTM modules', 'have', '200 output units'], ['our model', 'have', '200 output units']]\",\n",
       " \"[['ASL', 'calculate', 'cross - sentence dependency'], ['cross - sentence dependency', 'using', 'multilayer perceptron'], ['multilayer perceptron', 'with', 'one hidden layer'], ['one hidden layer', 'consisting of', '150 hidden units']]\",\n",
       " \"[['initial learning rate', 'set as', '0.001'], ['0.001 %', 'every', '100 steps']]\",\n",
       " '[]',\n",
       " \"[['co-reference prediction', 'select', '250 candidate antecedents'], ['250 candidate antecedents', 'as', 'our baseline model']]\",\n",
       " \"[['baseline model', 'achieved', '67.2 % F1 score'], ['ASL model', 'improved', 'performance'], ['performance', 'by', '0.6 %'], ['ASL model', 'achieved', '67.8 % average F1']]\",\n",
       " '[]',\n",
       " \"[['significantly outperform', 'encodes', 'each sentence'], ['baseline model', 'encodes', 'each sentence'], ['each sentence', 'from', 'input document']]\",\n",
       " \"[['local inputs', 'are', 'not informative enough']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['entity - level representation', 'facilitates', 'end - to - end optimization']]\",\n",
       " \"[['BERT embeddings', 'motivated by', 'impressive empirical performance'], ['impressive empirical performance', 'of', 'BERT']]\",\n",
       " \"[['BERT', 'in', 'fully convolutional manner']]\",\n",
       " \"[['BERT', 'for', 'task of coreference resolution'], ['significant improvement', 'over', 'current state - of - the - art']]\",\n",
       " '[]',\n",
       " \"[['span - ranking model', 'from with', 'ELMo input features and second - order span representations']]\",\n",
       " \"[['F1', 'Replacing', 'ELMo features'], ['ELMo features', 'with', 'BERT features'], ['ELMo features', 'achieves', '76. 25 % average F1'], ['BERT features', 'achieves', '76. 25 % average F1']]\",\n",
       " \"[['second - order span - representations', 'while using', 'BERT features'], ['BERT features', 'achieves', '76.37 % F1'], ['76.37 % F1', 'achieving', 'higher recall and lower precision'], ['higher recall and lower precision', 'on', 'all evaluation metrics']]\",\n",
       " \"[['secondorder span representations', 'achieves', '76. 64 % average F1'], ['Entity Equalization', 'achieves', '76. 64 % average F1'], ['secondorder span representations', 'consistently achieving', 'highest F 1 score']]\",\n",
       " \"[['new state of the art', 'for', 'coreference resolution'], ['new state of the art', 'improving', 'previous state of the art'], ['previous state of the art', 'by', '3.6 % average F1']]\",\n",
       " '[]',\n",
       " \"[['significantly outperforms', 'without using', 'syntactic parser or handengineered mention detector'], ['all previous work', 'without using', 'syntactic parser or handengineered mention detector']]\",\n",
       " \"[['first state - of - the - art neural coreference resolution model', 'learned', 'end - toend'], ['end - toend', 'given', 'only gold mention clusters']]\",\n",
       " \"[['improved significantly', 'by training', 'end - to - end neural model'], ['end - to - end neural model', 'jointly learns', 'which spans'], ['which spans', 'are', 'entity mentions']]\",\n",
       " \"[['Our model reasons', 'directly optimizes', 'marginal likelihood']]\",\n",
       " \"[['each span', 'which of', 'previous spans'], ['each span', 'is', 'good antecedent'], ['previous spans', 'is', 'good antecedent']]\",\n",
       " \"[['vector embeddings', 'representing', 'spans of text'], ['spans of text', 'in', 'document'], ['vector embeddings', 'combine', 'context - dependent boundary representations'], ['context - dependent boundary representations', 'with', 'head - finding attention mechanism'], ['head - finding attention mechanism', 'over', 'span']]\",\n",
       " \"[['head - finding attention mechanism', 'reveals', 'mentioninternal words'], ['mentioninternal words', 'contribute most to', 'coreference decisions']]\",\n",
       " \"[['word embeddings area fixed concatenation', 'of', '300 - dimensional GloVe embeddings'], ['word embeddings area fixed concatenation', 'of', '50 - dimensional embeddings']]\",\n",
       " \"[['hidden states', 'in', 'LSTMs'], ['hidden states', 'have', '200 dimensions'], ['LSTMs', 'have', '200 dimensions']]\",\n",
       " \"[['speaker information', 'as', 'binary feature'], ['binary feature', 'indicating whether', 'pair of spans']]\",\n",
       " \"[['features ( speaker , genre , span distance , mention width )', 'represented as', 'learned 20 - dimensional embeddings']]\",\n",
       " \"[['spans', 'such that', 'maximum span width L'], ['spans', 'such that', 'maximum number of antecedents K'], ['maximum span width L', '=', '10']]\",\n",
       " \"[['ADAM', 'for', 'learning'], ['learning', 'with', 'minibatch size'], ['minibatch size', 'of', '1']]\",\n",
       " \"[['0.2 dropout', 'to', 'all hidden layers and feature embeddings']]\",\n",
       " \"[['decayed', 'by', '0.1 %'], ['0.1 %', 'every', '100 steps']]\",\n",
       " \"[['Ensembling', 'performed for both', 'span pruning'], ['Ensembling', 'performed for both', 'antecedent decisions']]\",\n",
       " \"[['our single model', 'improves', 'state - of - the - art average F1'], ['our single model', 'improves', 'our 5 - model ensemble'], ['state - of - the - art average F1', 'by', '1.5']]\",\n",
       " \"[['most significant gains', 'come from', 'improvements'], ['improvements', 'in', 'recall']]\",\n",
       " \"[['spans and the width of spans', 'are', 'crucial signals'], ['crucial signals', 'for', 'coreference resolution']]\",\n",
       " \"[['oracle mentions', 'see', 'improvement'], ['improvement', 'of', '17.5 F1']]\",\n",
       " '[]',\n",
       " \"[['spans', 'with', '2 - 5 words'], ['75 - 90 %', 'of', 'predictions'], ['predictions', 'are', 'constituents']]\",\n",
       " '[]',\n",
       " \"[['BERT', 'to', 'coreference resolution'], ['BERT', 'achieving', 'strong improvements'], ['coreference resolution', 'achieving', 'strong improvements'], ['strong improvements', 'on', 'OntoNotes ( + 3.9 F1 ) and'], ['strong improvements', 'on', 'GAP ( + 11.5 F1 ) benchmarks']]\",\n",
       " \"[['two ways', 'of', 'extending']]\",\n",
       " \"[['independent variant', 'uses', 'non-overlapping segments'], ['non-overlapping segments', 'acts as', 'independent instance'], ['independent instance', 'for', 'BERT']]\",\n",
       " \"[['overlap variant', 'splits', 'document'], ['document', 'into', 'overlapping segments'], ['overlapping segments', 'so as to provide', 'model'], ['model', 'with', 'context'], ['context', 'beyond', '512 tokens']]\",\n",
       " '[]',\n",
       " \"[['BERT - large', 'benefits from using', 'longer context windows ( 384 word pieces )'], ['BERT - base', 'performs', 'better'], ['better', 'with', 'shorter contexts ( 128 word pieces )']]\",\n",
       " \"[['original Tensorflow implementations', 'of', 'c 2f - coref 3 and BERT']]\",\n",
       " \"[['all models', 'on', 'OntoNotes English data'], ['OntoNotes English data', 'for', '20 epochs'], ['20 epochs', 'using', 'dropout'], ['20 epochs', 'using', 'learning rates'], ['dropout', 'of', '0.3'], ['learning rates', 'of', '1 10 ?5 and 2 10 ? 4'], ['1 10 ?5 and 2 10 ? 4', 'with', 'linear decay'], ['1 10 ?5 and 2 10 ? 4', 'with', 'task parameters'], ['linear decay', 'for', 'BERT parameters']]\",\n",
       " \"[['separate models', 'with', 'max segment len'], ['max segment len', 'of', '128 , 256 , 384 , and 512'], ['128 and 384 word pieces', 'performed', 'best'], ['best', 'for', 'BERT - base']]\",\n",
       " \"[['span representations', 'using', 'attention'], ['attention', 'for', 'higher - order reasoning']]\",\n",
       " \"[['GAP', 'is', 'human - labeled corpus'], ['human - labeled corpus', 'of', 'ambiguous pronoun - name pairs'], ['ambiguous pronoun - name pairs', 'derived from', 'Wikipedia snippets']]\",\n",
       " \"[['GAP dataset', 'fit within', 'single BERT segment']]\",\n",
       " \"[['BERT - based c 2f - coref model', 'on', 'OntoNotes']]\",\n",
       " \"[['BERT', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', '9 % and 11.5 %'], ['9 % and 11.5 %', 'for', 'base and large models']]\",\n",
       " '[]',\n",
       " \"[['BERT - base', 'offers', 'improvement'], ['improvement', 'of', '0.9 %'], ['0.9 %', 'over', 'ELMo - based c2 fcoref model']]\",\n",
       " \"[['BERT - large', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', 'much larger margin'], ['much larger margin', 'of', '3.9 %']]\",\n",
       " \"[['overlap variant', 'offers', 'no improvement'], ['no improvement', 'over', 'independent']]\",\n",
       " \"[['span representations', 'achieving', 'state of the art results ( Avg. F1 79.6 )'], ['state of the art results ( Avg. F1 79.6 )', 'with', 'independent variant']]\",\n",
       " \"[['BERT - large', 'improves over', 'BERT - base']]\",\n",
       " \"[['Longer documents', 'in', 'OntoNotes'], ['Longer documents', 'contain', 'larger and more spread - out clusters'], ['OntoNotes', 'contain', 'larger and more spread - out clusters']]\",\n",
       " \"[['more effectively encoding document - level context', 'using', 'sparse representations']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['decoder', 'generates', 'words']]\",\n",
       " \"[['new structured - data encoder', 'assuming that', 'structures'], ['structures', 'should be', 'hierarchically captured']]\",\n",
       " \"[['encoding', 'of', 'data - structure'], ['decoder', 'chosen to be', 'classical module']]\",\n",
       " \"[['two - level architecture', 'first encoding', 'all entities'], ['all entities', 'on the basis of', 'their elements'], ['data structure', 'on the basis of', 'its entities'], ['Transformer encoder', 'in', 'data - to - text models'], ['data - to - text models', 'to ensure', 'robust encoding'], ['robust encoding', 'of', 'each element / entities'], ['each element / entities', 'in comparison to', 'all others'], ['two - level architecture', 'integrate', 'hierarchical attention mechanism'], ['hierarchical attention mechanism', 'to compute', 'hierarchical context'], ['hierarchical context', 'fed into', 'decoder']]\",\n",
       " \"[['Li', 'is', 'standard encoder - decoder'], ['standard encoder - decoder', 'with', 'delayed copy mechanism'], ['placeholders', 'replaced by', 'salient records'], ['salient records', 'extracted from', 'table'], ['table', 'by', 'pointer network']]\",\n",
       " \"[['standard encoder - decoder', 'with', 'added module'], ['added module', 'aimed at updating', 'record representations'], ['record representations', 'during', 'generation process']]\",\n",
       " '[]',\n",
       " \"[['two - layers multi-head self - attention', 'with', 'two heads']]\",\n",
       " \"[['small number of record keys', 'in', 'our dataset'], ['embedding size', 'fixed to', '20']]\",\n",
       " \"[['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['Transformer encoders', 'set to', '300']]\",\n",
       " \"[['dropout', 'at', 'rate 0.5']]\",\n",
       " \"[['batch size', 'of', '64']]\",\n",
       " \"[['initial learning rate', 'is', '0.001'], ['initial learning rate', 'reduced by', 'half'], ['half', 'every', '10 K steps']]\",\n",
       " \"[['beam search', 'with', 'beam size'], ['beam size', 'of', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['comparison', 'between', 'scenario Hierarchical - kv and Hierarchical -k'], ['scenario Hierarchical - kv and Hierarchical -k', 'omitting', 'entirely the influence'], ['entirely the influence', 'of', 'record values'], ['record values', 'in', 'attention mechanism'], ['attention mechanism', 'is', 'more effective']]\",\n",
       " \"[['Scores of Hierarchical -k', 'are', 'sharp'], ['scores of Hierarchical - kv', 'are', 'more'], ['sharp', 'with', 'all of the weight'], ['all of the weight', 'on', 'correct record'], ['scores of Hierarchical - kv', 'distributed over', 'all PTS QTR records'], ['more', 'distributed over', 'all PTS QTR records']]\",\n",
       " \"[['Hierarchical -k', 'reaching', '17.5 vs. 16.5'], ['17.5 vs. 16.5', 'against', 'best baseline']]\",\n",
       " \"[['Our hierarchical models', 'achieve', 'significantly better scores'], ['significantly better scores', 'on', 'all metrics']]\",\n",
       " \"[['only 75 . 62 %', 'of', 'precision']]\",\n",
       " \"[['Transformer architecture', 'is', 'promising way'], ['Transformer architecture', 'to implicitly account for', 'data structure'], ['promising way', 'to implicitly account for', 'data structure']]\",\n",
       " \"[['two - step decoders', 'of', 'Li and Puduppully - plan'], ['Li and Puduppully - plan', 'on', 'BLEU and all qualitative metrics']]\",\n",
       " \"[['precision', 'at', 'factual mentions'], ['baseline Puduppully - plan', 'reaches', '34.28 mentions']]\",\n",
       " \"[['Puduppully - updt', 'shows', 'dynamically updating'], ['encoding', 'across', 'generation process'], ['encoding', 'lead to', 'better Content Ordering ( CO )']]\",\n",
       " \"[['saliency', 'among', 'records / entities']]\",\n",
       " \"[['hierarchical encoder', 'for', 'structured data'], ['structure', 'to form', 'efficient representation'], ['efficient representation', 'of', 'its input'], ['strong synergy', 'with', 'hierarchical attention'], ['hierarchical attention', 'of', 'its associated decoder']]\",\n",
       " '[]',\n",
       " \"[['inputs', 'are', 'structured meaning representations ( MRs )']]\",\n",
       " \"[['neural ensemble natural language generator', 'train and test on', 'three large unaligned datasets'], ['three large unaligned datasets', 'in', 'restaurant , television , and laptop domains']]\",\n",
       " \"[['our ensemble model', 'using', 'seq2seq framework'], ['seq2seq framework', 'for', 'TensorFlow']]\",\n",
       " \"[['bidirectional LSTM encoder', 'with', '512 cells per layer']]\",\n",
       " \"[['decoder', 'was', '4 - layer RNN decoder'], ['4 - layer RNN decoder', 'with', '512 LSTM cells per']]\",\n",
       " \"[['different beam search parameters', 'settled on', 'beam width of 10']]\",\n",
       " \"[['length penalty', 'providing', 'best results'], ['best results', 'on', 'E2E dataset'], ['E2E dataset', 'was', '0.6'], ['TV and Laptop datasets', 'was', '0.9 and 1.0']]\",\n",
       " '[]',\n",
       " \"[['both the LSTM and the CNN models', 'benefit from', 'additional pseudo - samples'], ['additional pseudo - samples', 'in', 'training set']]\",\n",
       " \"[['ensembling approach', 'reveals', 'reranking predictions'], ['reranking predictions', 'pooled from', 'different models'], ['different models', 'produces', 'ensemble model'], ['ensemble model', 'that is', 'over all more robust'], ['over all more robust', 'than', 'individual submodels']]\",\n",
       " '[[\\'CNN model\\', \\'surpassed\\', \\'two LSTM models\\'], [\\'two LSTM models\\', \\'in the\\', \\'ability\\'], [\\'two LSTM models\\', \\'to realize\\', \\'\" fast food \" and \" pub \" values\\'], [\\'ability\\', \\'to realize\\', \\'\" fast food \" and \" pub \" values\\']]',\n",
       " \"[['hybrid ensemble model', 'manages to perform', 'best'], ['best', 'in terms of', 'error rate'], ['best', 'as well as', 'naturalness']]\",\n",
       " \"[['our ensemble model', 'performs', 'competitively'], ['competitively', 'with', 'baseline'], ['baseline', 'on', 'TV dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'by', 'wide margin'], ['Laptop dataset', 'by', 'wide margin']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['two generation scenarios', 'where', 'source data'], ['source data', 'is', 'graph structured']]\",\n",
       " \"[['multi-sentence descriptions of Knowledge Base ( KB ) entities', 'namely', 'WebNLG task']]\",\n",
       " \"[['recurrent data encoders', 'with', 'memory and gating mechanisms']]\",\n",
       " '[]',\n",
       " \"[['Graph Convolutional Network ( GCN ; )', 'as', 'our encoder']]\",\n",
       " \"[['text generation from graph - structured data', 'considering as input', 'directed'], ['V', 'is', 'set']]\",\n",
       " '[]',\n",
       " \"[['linearised version', 'of', 'source graph']]\",\n",
       " \"[['WebNLG baseline', 'use', 'linearis ation scripts']]\",\n",
       " \"[['best results', 'with', 'encoder'], ['encoder', 'with', 'four GCN layers'], ['four GCN layers', 'with', 'residual connections'], ['encoder', 'with', 'four GCN layers'], ['four GCN layers', 'with', 'residual connections'], ['four GCN layers', 'with', 'residual connections']]\",\n",
       " \"[['Encoder ( decoder ) embeddings and hidden dimensions', 'set to', '300']]\",\n",
       " \"[['GCN model', 'is', 'more stable'], ['more stable', 'than', 'baseline'], ['baseline', 'with', 'standard deviation'], ['standard deviation', 'of', '.004 vs . 010']]\",\n",
       " \"[['outperforms', 'that uses', 'further reinforcement learning step'], ['PKUWRITER', 'that uses', 'ensemble of 7 models'], ['PKUWRITER', 'that uses', 'further reinforcement learning step'], ['PKUWRITER', 'that uses', 'MELBOURNE'], ['further reinforcement learning step', 'by', '.047 BLEU points'], ['MELBOURNE', 'by', '.014 BLEU points']]\",\n",
       " \"[['GCN EC', 'behind', 'ADAPT'], ['ADAPT', 'relies on', 'sub-word encoding']]\",\n",
       " '[]',\n",
       " \"[['impact of the number of layers and the type of skip connections', 'on', 'WebNLG dataset'], ['impact of the number of layers and the type of skip connections', 'on', 'WebNLG dataset']]\",\n",
       " \"[['importance', 'of', 'skip connections'], ['skip connections', 'between', 'GCN layers']]\",\n",
       " \"[['Residual and dense connections', 'lead to', 'similar results']]\",\n",
       " \"[['Dense connections', 'produce', 'models'], ['slightly less accurate', 'than', 'residual connections']]\",\n",
       " '[]',\n",
       " \"[['informativeness', 'for', 'conditional text generation']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['concatenation', 'of', 'extracted sentences'], ['concatenation', 'used as', 'inputs'], ['extracted sentences', 'used as', 'inputs'], ['inputs', 'to', 'our models']]\",\n",
       " \"[['pragmatic methods', 'obtain', 'improvements'], ['pragmatic methods', 'obtain', '0.2-1.8 METEOR'], ['improvements', 'of', '0.2-0.5'], ['improvements', 'of', '0.2-1.8 METEOR'], ['0.2-0.5', 'in', 'ROUGE scores'], ['0.2-1.8 METEOR', 'over', 'base S 0 model'], ['base S 0 model', 'with', 'distractor - based approach'], ['SD 1', 'outperforming', 'reconstructorbased approach S R 1']]\",\n",
       " '[]',\n",
       " \"[['content selection and planning', 'within', 'neural data - to - text architecture']]\",\n",
       " \"[['each stage', 'utilize', 'beam search'], ['beam search', 'to approximately obtain', 'best results']]\",\n",
       " \"[['Input feeding', 'employed for', 'text decoder']]\",\n",
       " \"[['dropout', 'at', 'rate'], ['rate', 'of', '0.3']]\",\n",
       " \"[['25 epochs', 'with', 'Adagrad optimizer'], ['learning rate decay', 'selected from', '{ 0.5 , 0.97 }']]\",\n",
       " \"[['text decoding', 'made use of', 'BPTT'], ['truncation size', 'to', '100']]\",\n",
       " \"[['beam size', 'to', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]\",\n",
       " '[]',\n",
       " \"[['NCP', 'improves upon', 'vanilla encoderdecoder models ( ED + JC , ED + CC )']]\",\n",
       " \"[['NCP', 'achieves', 'comparable scores'], ['comparable scores', 'with', 'joint or conditional copy mechanism']]\",\n",
       " \"[['NCP + CC', 'achieves', 'best content selection and content ordering scores'], ['best content selection and content ordering scores', 'in terms of', 'BLEU']]\",\n",
       " \"[['best reported system', 'in', 'Wiseman et al.'], ['best reported system', 'achieve', 'absolute improvement'], ['absolute improvement', 'of', 'approximately 12 %'], ['approximately 12 %', 'in terms of', 'relation generation']]\",\n",
       " \"[['oracle system ( NCP + OR )', 'show', 'content selection and ordering'], ['content selection and ordering', 'correlate with', 'quality of'], ['content selection and ordering', 'correlate with', 'any improvements'], ['any improvements', 'in', 'our planning component'], ['any improvements', 'result in', 'better output'], ['our planning component', 'result in', 'better output']]\",\n",
       " \"[['template - based system', 'observe', 'low BLEU and CS precision'], ['template - based system', 'obtains', 'low BLEU and CS precision']]\",\n",
       " \"[['84.5 %', 'of', 'records'], ['records', 'in', 'NCP + CC'], ['NCP + CC', 'are', 'non-duplicates'], ['non-duplicates', 'compared to', 'obtain']]\",\n",
       " \"[['content selection and planning', 'contribute to', 'performance improvements'], ['performance improvements', 'over', 'baseline ( ED + CC )'], ['accuracy', 'further', 'increases'], ['increases', 'when', 'both components']]\",\n",
       " \"[['higher', 'by', '4.5 % and 2 %'], ['content selection precision and recall', 'as well as', 'content ordering'], ['higher', 'as well as', 'content ordering'], ['content ordering', 'by', '1.8 %']]\",\n",
       " \"[['CS precision', 'higher than', '85 %'], ['CS recall', 'higher than', '93 %'], ['CO', 'higher than', '84 %']]\",\n",
       " \"[['NCP', 'achieves', 'higher accuracy'], ['higher accuracy', 'in', 'all metrics'], ['all metrics', 'including', 'relation generation'], ['all metrics', 'including', 'content selection'], ['all metrics', 'including', 'content ordering'], ['all metrics', 'including', 'BLEU']]\",\n",
       " \"[['NCP + CC over all', 'performs', 'best']]\",\n",
       " '[]',\n",
       " \"[['set of RDF triplets', 'describing', 'facts ( entities and relations'], ['fluent text', 'faithful to', 'facts']]\",\n",
       " \"[['explicit , symbolic , text planning stage', 'whose', 'output'], ['output', 'fed into', 'neural generation system']]\",\n",
       " \"[['text planner', 'determines', 'information structure'], ['text planner', 'expresses it', 'unambiguously']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['DBPedia relations to sequences', 'of', 'tokens'], ['tokens', 'by splitting on', 'underscores'], ['tokens', 'by splitting on', 'CamelCase']]\",\n",
       " \"[['Open NMT toolkit', 'with', 'copy attn flag']]\",\n",
       " \"[['relation tokens', 'in', 'plans'], ['tokens', 'in', 'reference texts'], ['relation tokens', 'as well as', 'tokens'], ['tokens', 'in', 'reference texts']]\",\n",
       " \"[['best submissions', 'in', 'WebNLG challenge'], ['best', 'on', 'all categories']]\",\n",
       " \"[['LSTM decoder', 'with', 'attention'], ['LSTM decoder', 'with', 'neural checklist model']]\",\n",
       " '[]',\n",
       " \"[['BestPlan', 'reduces', 'all error types'], ['all error types', 'compared to', 'StrongNeural'], ['StrongNeural', 'by', '85 % , 56 % and 90 %']]\",\n",
       " \"[['BestPlan', 'performed', 'on - par'], ['on - par', 'with', 'StrongNeural'], ['BestPlan', 'surpassed', 'previous state - of - the - art UPF - FORGe']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['character - level sequence - to - sequence model', 'with', 'attention mechanism'], ['attention mechanism', 'results in', 'completely neural end - to - end architecture']]\",\n",
       " '[]',\n",
       " \"[['two important features', 'with respect to', 'state - of - art architecture'], ['character - wise copy mechanism', 'consisting in', 'soft switch'], ['soft switch', 'between', 'generation and copy mode'], ['generation and copy mode', 'disengages', 'model'], ['model', 'to learn', 'rare and unhelpful self - correspondences'], ['state - of - art architecture', 'enhancing', 'recall'], ['internal representation capabilities', 'enhancing', 'recall']]\",\n",
       " \"[['our system', 'using', 'PyTorch framework']]\",\n",
       " \"[['same dimensions', 'in terms of', 'input size'], ['same dimensions', 'in terms of', 'presence of']]\",\n",
       " '[]',\n",
       " \"[['negative log - likelihood loss', 'using', 'teacher forcing and Adam']]\",\n",
       " \"[['new formulation', 'of', 'P ( c )']]\",\n",
       " \"[['beam search mechanism and a reranker', 'over', 'top k outputs'], ['beam search mechanism and a reranker', 'to dis advantage', 'utterances'], ['utterances', 'that do not verbalize', 'all the information'], ['all the information', 'contained in', 'MR']]\",\n",
       " \"[['official code', 'provided in', 'E2E NLG Challenge website'], ['E2E NLG Challenge website', 'for', 'TGen'], ['official code', 'developed', 'our models and EDA'], ['our models and EDA', 'in', 'PyTorch'], ['our models and EDA', 'training them on', 'NVIDIA GPUs']]\",\n",
       " \"[['our model EDA_CS', 'always obtains', 'higher metric values'], ['higher metric values', 'with respect to', 'TGen'], ['TGen', 'on', 'Hotel and Restaurant datasets'], ['TGen', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset']]\",\n",
       " \"[['TGen', 'achieves', 'three out of five higher metrics values']]\",\n",
       " \"[['approach', 'allows to obtain', 'better performance'], ['better performance', 'with respect to', 'training'], ['training', 'in', 'standard way'], ['EDA_CS', 'in', 'standard way'], ['standard way', 'on', 'Hotel and Restaurant datasets']]\",\n",
       " '[[\\'EDA_CS TL\\', \\'shows\\', \\'bleu increment\\'], [\\'bleu increment\\', \\'of\\', \\'at least 14 %\\'], [\\'at least 14 %\\', \\'with respect to\\', \"TGen \\'s score\"], [\"TGen \\'s score\", \\'when compared to\\', \\'Hotel and Restaurant datasets\\']]',\n",
       " \"[['largely outperformed', 'by', 'all other examined methods']]\",\n",
       " \"[['good results', 'are', 'achieved']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['j PTDP v1.0', 'with', '2.5 + % LAS improvements'], ['2.5 + % LAS improvements', 'on', 'universal dependencies ( UD ) treebanks']]\",\n",
       " '[]',\n",
       " \"[['DYNET v2.0', 'with', 'fixed random seed']]\",\n",
       " \"[['Word embeddings', 'initialized', 'randomly'], ['character and POS tag embeddings', 'are', 'randomly initialized']]\",\n",
       " \"[['learning character - level word embeddings', 'use', 'one - layer BiLSTM seq'], ['learning character - level word embeddings', 'set', 'size'], ['size', 'of', 'LSTM hidden states'], ['LSTM hidden states', 'to be equal to', 'vector size of']]\",\n",
       " \"[['dropout', 'with', '67 % keep probability'], ['67 % keep probability', 'to', 'inputs of BiLSTMs and MLPs']]\",\n",
       " '[[\\'each word token\\', \\'apply\\', \\'appearing # ( w ) times\\'], [\\'word dropout\\', \\'to learn\\', \\'embedding\\'], [\\'embedding\\', \\'for\\', \\'unknown words\\'], [\\'embedding\\', \\'replace\\', \\'each word token\\'], [\\'appearing # ( w ) times\\', \\'in\\', \\'training set\\'], [\\'each word token\\', \\'with\\', \\'special \" unk \" symbol\\'], [\\'training set\\', \\'with\\', \\'special \" unk \" symbol\\'], [\\'special \" unk \" symbol\\', \\'with\\', \\'probability punk ( w )\\']]',\n",
       " \"[['objective loss', 'using', 'Adam ( Kingma and Ba , 2014 )'], ['Adam ( Kingma and Ba , 2014 )', 'with', 'initial learning rate'], ['initial learning rate', 'at', '0.001']]\",\n",
       " \"[['training', 'run for', '30 epochs'], ['initial learning rate', 'at', 'proportion'], ['proportion', 'of', '0.5'], ['0.5', 'every', '10 epochs']]\",\n",
       " '[]',\n",
       " \"[['number of hidden nodes', 'in', 'MLPs'], ['number of hidden nodes', 'at', '100'], ['MLPs', 'at', '100']]\",\n",
       " \"[['minimal grid search', 'of', 'hyper - parameters'], ['hyper - parameters', 'to select', 'number of BiLSTM pos and BiLSTM dep layers'], ['hyper - parameters', 'to select', 'size of LSTM hidden states'], ['number of BiLSTM pos and BiLSTM dep layers', 'from', '{ 1 , 2 }'], ['each layer', 'from', '{ 128 , 256 }'], ['size of LSTM hidden states', 'in', 'each layer'], ['each layer', 'from', '{ 128 , 256 }']]\",\n",
       " \"[['number of BiLSTM layers', 'at', '2'], ['hidden states', 'at', '128'], ['hidden states', 'at', '128']]\",\n",
       " \"[['Word embeddings', 'initialized by', '100 dimensional Glo Ve word vectors'], ['100 dimensional Glo Ve word vectors', 'pre-trained on', 'Wikipedia and Gigaword']]\",\n",
       " \"[['minimal', 'find that', 'highest mixed accuracy'], ['highest mixed accuracy', 'on', 'development set'], ['highest mixed accuracy', 'obtained when using', '2 BiLSTM layers']]\",\n",
       " \"[['our model', 'produces', 'very competitive parsing results']]\",\n",
       " \"[['UAS score', 'at', '94.51 %'], ['LAS score', 'at', '92.87 %']]\",\n",
       " \"[['Our model', 'does', 'better'], ['better', 'than', 'previous transition - based joint models'], ['similar UAS and LAS scores', 'to', 'joint model JMT']]\",\n",
       " \"[['0.9 % lower parsing scores', 'than', 'state - of - the - art dependency parser']]\",\n",
       " \"[['BiLSTM - and graph - based model', 'uses', 'more sophisticated attention mechanism'], ['more sophisticated attention mechanism', 'for better decoding', 'dependency arcs and relation types'], ['biaffine', 'for better decoding', 'dependency arcs and relation types']]\",\n",
       " \"[['our model', 'with', 'biaffine attention mechanism'], ['biaffine attention mechanism', 'to investigate', 'benefit'], ['benefit', 'for', 'our model']]\",\n",
       " \"[['POS tagging accuracy', 'at', '97.97 %'], ['POS tagging accuracy', 'on', 'test Section'], ['97.97 %', 'on', 'test Section']]\",\n",
       " '[]',\n",
       " \"[['joint model', 'For', 'universal POS tagging and dependency parsing'], ['each big or small treebank', 'train', 'joint model'], ['joint model', 'for', 'universal POS tagging and dependency parsing'], ['universal POS tagging and dependency parsing', 'using', 'fixed random seed']]\",\n",
       " \"[['tokenization , word and sentence segmentation', 'predicted by', 'UD - Pipe']]\",\n",
       " \"[['final test runs', 'carried out on', 'TIRA platform']]\",\n",
       " '[]',\n",
       " \"[['outperform', 'with', '2.5 + % higher average UAS and LAS F1 scores'], ['baseline UDPipe 1.2', 'with', '0.6 % absolute higher average UPOS F1 score'], ['baseline UDPipe 1.2', 'with', '2.5 + % higher average UAS and LAS F1 scores']]\",\n",
       " '[[\\'\" big \" category\\', \\'consisting of\\', \\'61 treebank test sets\\'], [\\'\" big \" category\\', \\'obtain\\', \\'0.8 % higher\\'], [\\'\" big \" category\\', \\'obtain\\', \\'3.1 % higher\\'], [\\'\" big \" category\\', \\'obtain\\', \\'3.6 % higher LAS\\'], [\\'3.6 % higher LAS\\', \\'than\\', \\'UDPipe 1.2\\']]',\n",
       " \"[['Our ( UniMelb ) official LAS - based rank', 'is at', '14 th place'], ['baseline UDPipe 1.2', 'is at', '18 th place'], ['baseline UDPipe 1.2', 'is at', '18 th place'], ['18 th place', 'over', 'total 26 participating systems']]\",\n",
       " '[]',\n",
       " \"[['highest F 1 scores', 'for', 'biomedical event extraction'], ['highest F 1 scores', 'for', 'opinion analysis']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['BiLSTMs', 'which are', 'strong and trainable sequence models']]\",\n",
       " \"[['elements', 'in', 'sequence ( i.e. , words )'], ['contexts', 'capturing', 'element']]\",\n",
       " \"[['concatenation', 'of', 'minimal set']]\",\n",
       " \"[['graphbased parser', 'jointly train', 'structured - prediction model'], ['structured - prediction model', 'on top of', 'BiLSTM'], ['structured - prediction model', 'propagating', 'errors'], ['BiLSTM', 'propagating', 'errors'], ['errors', 'from', 'structured objective']]\",\n",
       " \"[['Chinese', 'use', 'Penn Chinese Treebank 5.1 ( CTB5 )'], ['Penn Chinese Treebank 5.1 ( CTB5 )', 'using', 'train / test / dev splits'], ['train / test / dev splits', 'of with', 'gold partof - speech tags']]\",\n",
       " \"[['parsers', 'implemented in', 'python']]\",\n",
       " '[]',\n",
       " \"[['LSTM variant', 'implemented in', 'PyCNN'], ['LSTM variant', 'optimize using', 'Adam optimizer']]\",\n",
       " '[]',\n",
       " '[[\\'word and POS embeddings e ( w i ) and e ( p i )\\', \\'initialized to\\', \\'random values\\'], [\\'word and POS embeddings e ( w i ) and e ( p i )\\', \\'trained together with\\', \"rest of the parsers \\' networks\"]]',\n",
       " \"[['parsers', 'for', 'up to 30 iterations'], ['best model', 'according to', 'UAS accuracy'], ['UAS accuracy', 'on', 'development set']]\",\n",
       " \"[['first - order graph - based parser', 'with', '2 features'], ['outperforms', 'not using', 'external resources'], ['all other systems', 'not using', 'external resources'], ['external resources', 'including', 'third - order TurboParser']]\",\n",
       " \"[['simple ( 4 features )', 'to', 'extended ( 11 features ) feature set'], ['simple ( 4 features )', 'leads to', 'some gains in accuracy'], ['extended ( 11 features ) feature set', 'leads to', 'some gains in accuracy']]\",\n",
       " \"[['Dynamic oracle training', 'yields', 'nice gains']]\",\n",
       " '[]',\n",
       " \"[['consensus', 'among', '20 randomly - initialized stack LSTM parsers'], ['consensus', 'achieving', 'nearly the best - reported performance'], ['nearly the best - reported performance', 'on', 'standard Penn Treebank Stanford dependencies task']]\",\n",
       " \"[['ensemble', 'into', 'single FOG parser'], ['single FOG parser', 'with', 'discriminative training'], ['discriminative training', 'by defining', 'new cost function']]\",\n",
       " '[[\\'cost\\', \\'of\\', \\'each possible attachment\\'], [\\'each possible attachment\\', \\'from\\', \"ensemble \\'s division of votes\"], [\\'cost\\', \\'in\\', \\'discriminative learning\\']]',\n",
       " '[]',\n",
       " \"[['Our ensembles of greedy , locally normalized parsers', 'perform', 'comparably']]\",\n",
       " \"[['cost', 'for', 'its'], ['cost', 'for', 'choice ( s )'], ['lower', 'under', 'Hamming cost']]\",\n",
       " \"[['per-epoch learning rate decay', 'of', '0.05'], ['0.05', 'to', 'Adam optimizer']]\",\n",
       " \"[['Adam optimizer', 'automatically adjusts', 'global learning rate'], ['global learning rate', 'according to', 'past gradient magnitudes'], ['global learning rate', 'find', 'additional per-epoch decay'], ['additional per-epoch decay', 'consistently improves', 'performance'], ['performance', 'across', 'all settings and languages']]\",\n",
       " \"[['standard splits', 'for', 'all languages']]\",\n",
       " \"[['German', 'use', 'predicted tags'], ['predicted tags', 'provided by', 'CoNLL 2009 shared task organizers']]\",\n",
       " \"[['English', 'used', 'Gigaword corpus and 100 dimensions']]\",\n",
       " \"[['Adam optimizer', 'use', 'default settings'], ['default settings', 'in', 'CNN neural network library']]\",\n",
       " \"[['same model', 'with', 'distillation cost'], ['distillation cost', 'gives', 'consistent improvements'], ['consistent improvements', 'for', 'all languages']]\",\n",
       " \"[['model', 'trained with', 'Hamming cost'], ['Hamming cost', 'achieved', '93.1 UAS and 90.9 LAS'], ['93.1 UAS and 90.9 LAS', 'compared to', '93.6 UAS and 91.1 LAS'], ['93.6 UAS and 91.1 LAS', 'for', 'model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Stanford - Biaffine', 'utilizes', 'pre-trained word embeddings'], ['pre-trained word embeddings', 'employ', '200 dimensional pre-trained word vectors']]\",\n",
       " \"[['grid search', 'of', 'hyperparameters'], ['grid search', 'to select', 'number of LSTM units'], ['hyperparameters', 'to select', 'number of BiLSTM layers'], ['hyperparameters', 'to select', 'number of LSTM units'], ['number of BiLSTM layers', 'from', '{ 1 , 2 }'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }'], ['number of LSTM units', 'in', 'each layer'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }']]\",\n",
       " \"[['Early stopping', 'applied when', 'no performance improvement'], ['no performance improvement', 'on', 'development set'], ['no performance improvement', 'obtained after', '10 contiguous epochs'], ['development set', 'obtained after', '10 contiguous epochs']]\",\n",
       " \"[['Stanford - NNdep', 'select', 'word CutOff'], ['word CutOff', 'from', '{ 1 , 2 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['word CutOff', 'fix', 'other hyperparameters'], ['size of the', 'fix', 'other hyperparameters'], ['other hyperparameters', 'with', 'default values']]\",\n",
       " \"[['jPTDP', 'use', '50 - dimensional character embeddings'], ['50 - dimensional character embeddings', 'fix', 'initial learning rate'], ['initial learning rate', 'at', '0.0005']]\",\n",
       " \"[['number of BiLSTM layers', 'at', '2'], ['number of LSTM units', 'in', 'each layer'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }']]\",\n",
       " '[]',\n",
       " \"[['Corpus - level accuracy differences', 'of', 'at least 0.17 %'], ['Corpus - level accuracy differences', 'of', '0.26 %'], ['at least 0.17 %', 'in', 'GENIA'], ['0.26 %', 'in', 'CRAFT'], ['0.26 %', 'between', 'two POS tagging models'], ['CRAFT', 'between', 'two POS tagging models']]\",\n",
       " '[]',\n",
       " \"[['six retrained models', 'produce', 'competitive results']]\",\n",
       " \"[['BiLSTM - CRF', 'obtains', 'accuracies'], ['accuracies', 'of', '98.44 %'], ['98.44 %', 'on', 'GE - NIA'], ['98.44 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT']]\",\n",
       " \"[['character - level word embeddings', 'helps to produce', 'about 0.5 %'], ['accuracies', 'for', 'GENIA tagger'], ['accuracies', 'for', 'MarMoT'], ['accuracies', 'for', 'NLP4J - POS'], ['accuracies', 'for', 'BiLSTM- CRF']]\",\n",
       " \"[['CNN - based character - level word embeddings', 'provided', '0.1 % improvement'], ['0.1 % improvement', 'to', 'BiLSTM - CRF']]\",\n",
       " \"[['GENIA', 'among', 'pre-trained models'], ['BLLIP', 'obtains', 'highest results']]\",\n",
       " \"[['pre-trained NNdep and Biaffine models', 'result in', 'no significant performance differences'], ['no significant performance differences', 'irrespective of', 'source'], ['source', 'of', 'POS tags']]\",\n",
       " \"[['retrained parsing models', 'on', 'GENIA and CRAFT']]\",\n",
       " \"[['all parsers', 'produce', 'better results'], ['better results', 'for', 'shorter sentences'], ['shorter sentences', 'on', 'both corpora'], ['longer sentences', 'likely to have', 'longer dependencies']]\",\n",
       " '[]',\n",
       " \"[['parsers', 'trained with', 'GENIA treebank']]\",\n",
       " \"[['four dependency parsers', 'trained on', 'GENIA'], ['four dependency parsers', 'trained on', 'jPTDP'], ['four dependency parsers', 'produce', 'similar event extraction scores'], ['similar event extraction scores', 'on', 'development set'], ['similar event extraction scores', 'on', 'test set'], ['similar event extraction scores', 'on', 'test set'], ['jPTDP and NLP4 Jdep', 'obtain', 'lowest and highest scores']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['novel neural network architecture', 'for', 'dependency parsing']]\",\n",
       " \"[['pointer network', 'as', 'backbone'], ['STACKPTR parser', 'equipped with', 'internal stack'], ['internal stack', 'to maintain', 'order of head words'], ['order of head words', 'in', 'tree structures']]\",\n",
       " \"[['STACKPTR parser', 'performs', 'parsing'], ['parsing', 'in', 'incremental , topdown , depth - first fashion'], ['headword', 'at the top of', 'internal stack']]\",\n",
       " \"[['information', 'from', 'whole sentence and all the previously derived subtrees'], ['linear', 'in', 'sentence length']]\",\n",
       " \"[['all the parsing models', 'in', 'different languages'], ['all the parsing models', 'initialize', 'word vectors'], ['different languages', 'initialize', 'word vectors'], ['word vectors', 'with', 'pretrained word embeddings']]\",\n",
       " \"[['Chinese , Dutch , English , German and Spanish', 'use', 'structured - skipgram embeddings']]\",\n",
       " \"[['other languages', 'use', 'Polyglot embeddings']]\",\n",
       " \"[['Parameter optimization', 'performed with', 'Adam optimizer'], ['Adam optimizer', 'with', '? 1 = ? 2 = 0.9'], ['Adam optimizer', 'choose', 'initial learning rate'], ['? 1 = ? 2 = 0.9', 'choose', 'initial learning rate'], ['initial learning rate', 'of', '? 0 = 0.001']]\",\n",
       " '[]',\n",
       " '[[\\'effects\\', \\'of\\', \\'\" gradient exploding \"\\'], [\\'effects\\', \\'of\\', \\'5.0\\'], [\\'gradient clipping\\', \\'of\\', \\'5.0\\'], [\\'\" gradient exploding \"\\', \\'use\\', \\'gradient clipping\\'], [\\'gradient clipping\\', \\'of\\', \\'5.0\\']]',\n",
       " \"[['overfitting', 'apply', 'dropout']]\",\n",
       " \"[['BLSTM', 'use', 'recurrent dropout'], ['recurrent dropout', 'with', 'drop rate'], ['drop rate', 'of', '0.33'], ['0.33', 'between', 'hidden states'], ['0.33', 'between', '0.33'], ['0.33', 'between', 'layers']]\",\n",
       " \"[['embedding dropout', 'with', 'rate'], ['rate', 'of', '0.33'], ['0.33', 'on', 'all word , character , and POS embeddings']]\",\n",
       " \"[['original one', 'with', 'grandparent and sibling information'], ['different decoder inputs', 'where', 'Org model'], ['Org model', 'utilizes', 'encoder hidden states'], ['encoder hidden states', 'of', 'head words'], ['+ gpar and + sib models', 'augments', 'original one'], ['original one', 'with', 'grandparent and sibling information']]\",\n",
       " \"[['Full model', 'achieves', 'best accuracy'], ['best accuracy', 'on', 'English and Chinese'], ['+ sib', 'on', 'German'], ['slightly worse', 'than', '+ sib'], ['+ sib', 'on', 'German']]\",\n",
       " \"[['BIAF', 'On', 'all languages'], ['significantly outperforms', 'on', 'all languages'], ['BIAF', 'on', 'all languages'], ['all languages', 'showing', 'superiority']]\",\n",
       " \"[['results', 'of', 'our parser'], ['our parser', 'on', 'RA'], ['results', 'slightly worse than', 'BIAF'], ['our parser', 'slightly worse than', 'BIAF']]\",\n",
       " \"[['Our Full model', 'achieves', 'better results'], ['better results', 'than', 'most graph - based parsers']]\",\n",
       " \"[['re-implementation', 'of', 'BIAF'], ['re-implementation', 'obtains', 'better performance'], ['BIAF', 'obtains', 'better performance'], ['better performance', 'than', 'original one']]\",\n",
       " \"[['Our model', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'UAS and LAS'], ['state - of - the - art performance', 'on', 'Chinese'], ['state - of - the - art performance', 'on', 'best UAS'], ['UAS and LAS', 'on', 'Chinese'], ['UAS and LAS', 'on', 'Chinese']]\",\n",
       " \"[['STACKPTR', 'tends to perform', 'better'], ['better', 'on', 'shorter sentences'], ['shorter sentences', 'make', 'fewer parsing decisions']]\",\n",
       " '[]',\n",
       " \"[['BIAF and STACKPTR parsers', 'achieve', 'relatively high parsing accuracies'], ['relatively high parsing accuracies', 'on', 'all the 12 languages']]\",\n",
       " \"[['nine languages', 'outperforms', 'BIAF'], ['STACKPTR', 'outperforms', 'BIAF'], ['BIAF', 'for both', 'UAS and LAS']]\",\n",
       " \"[['STACKPTR', 'achieves', 'slightly better UAS'], ['LAS', 'slightly worse than', 'BIAF']]\",\n",
       " \"[['BIAF', 'obtains', 'marginally better parsing performance'], ['marginally better parsing performance', 'than', 'STACKPTR']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['sentences', 'processed in', 'linear left to right pass']]\",\n",
       " \"[['arc label similarities', 'in', 'continuous space']]\",\n",
       " \"[['representational power', 'of', 'neural networks'], ['neural networks', 'with', 'superior search'], ['superior search', 'enabled by', 'structured training and inference'], ['structured training and inference', 'making', 'our parser']]\",\n",
       " \"[['unlabeled data', 'into', 'training'], ['accuracy', 'of', 'our model'], ['accuracy', 'to', '94.26 % UAS / 92.41 % LAS'], ['our model', 'to', '94.26 % UAS / 92.41 % LAS']]\",\n",
       " \"[['basic structure', 'with', 'deeper architecture'], ['improvements', 'to', 'optimization procedure']]\",\n",
       " \"[['activations', 'from', 'all layers'], ['all layers', 'of', 'neural network'], ['activations', 'as', 'representation'], ['neural network', 'as', 'representation'], ['representation', 'in', 'structured perceptron model'], ['structured perceptron model', 'trained with', 'beam search and early updates']]\",\n",
       " \"[['large quantities', 'of', 'high - confidence parse trees'], ['high - confidence parse trees', 'by parsing', 'unlabeled data'], ['unlabeled data', 'with', 'two different parsers'], ['high - confidence parse trees', 'selecting', 'sentences'], ['two parsers', 'produced', 'same trees']]\",\n",
       " \"[['large quantities', 'of', 'high - confidence parse trees'], ['high - confidence parse trees', 'by parsing', 'unlabeled corpus'], ['large quantities', 'selecting', 'sentences'], ['high - confidence parse trees', 'selecting', 'sentences'], ['sentences', 'on', 'two different parsers'], ['two different parsers', 'produced', 'same parse trees']]\",\n",
       " \"[['neural network parsers', 'more than', 'models with']]\",\n",
       " \"[['CRF - based POS tagger', 'to generate', '5 fold jack - knifed POS tags'], ['5 fold jack - knifed POS tags', 'on', 'training set and predicted tags'], ['training set and predicted tags', 'on', 'dev , test and tune sets'], ['Stanford POS tagger', 'with', '97 . 44 %']]\",\n",
       " '[[\\'union\\', \\'of\\', \"each corpora \\'s training set\"]]',\n",
       " \"[['transition - based parser', 'with', 'beam search']]\",\n",
       " \"[['Gaussian distribution', 'with', 'variance 10 ?4']]\",\n",
       " \"[['fixed initialization', 'with', 'bi = 0.2'], ['fixed initialization', 'to ensure', 'most Relu units'], ['activated', 'during', 'initial rounds of training']]\",\n",
       " \"[['word embedding matrix E word', 'initialized', 'parameters'], ['parameters', 'using', 'pretrained word embeddings']]\",\n",
       " \"[['words', 'not appearing in', 'unsupervised data']]\",\n",
       " \"[['Section 24', 'of', 'WSJ']]\",\n",
       " \"[['tri-training', 'used', 'hyperparameters'], ['hyperparameters', 'of', '? = 0.2 , ? 0 = 0.05 , = 0.9'], ['roughly 16 hours', 'of', 'training time'], ['early stopping', 'after', 'roughly 16 hours'], ['roughly 16 hours', 'of', 'training time']]\",\n",
       " \"[['M 1 = M 2 = 1024', 'For', 'standard training set'], ['M 1 = M 2 = 1024', 'For', 'tri-training setup'], ['Treebank Union setup', 'set', 'M 1 = M 2 = 1024'], ['M 1 = M 2 = 1024', 'for', 'standard training set'], ['M 1 = M 2 = 1024', 'for', 'tri-training setup']]\",\n",
       " '[]',\n",
       " \"[['our parser', 'outperforms', 'all dependency parsers'], ['all dependency parsers', 'in', 'our comparison'], ['all dependency parsers', 'by', 'substantial margin'], ['our comparison', 'by', 'substantial margin']]\",\n",
       " \"[['Question ( QTB ) dataset', 'more sensitive to', 'smaller beam size'], ['smaller beam size', 'to train', 'models'], ['models', 'in', 'reasonable time'], ['B = 32', 'at', 'inference time only'], ['our perceptron performance', 'goes up to', '92.29 % LAS']]\",\n",
       " \"[['tritraining', 'did help', 'baseline'], ['baseline', 'on', 'dev set']]\",\n",
       " \"[['tri-training', 'helps', 'most dramatically'], ['most dramatically', 'to', 'increase'], ['accuracy', 'on', 'Treebank Union setup'], ['Treebank Union setup', 'with', 'diverse domains'], ['accuracy', 'yielding', '0.4 - 1.0 % absolute LAS improvement gains'], ['0.4 - 1.0 % absolute LAS improvement gains', 'for', 'our most accurate model']]\",\n",
       " \"[['second hidden layer', 'results in', 'large gain'], ['large gain', 'on', 'tune set']]\",\n",
       " \"[['our neural network model', 'training on', 'output'], ['our neural network model', 'training on', 'data'], ['data', 'where', 'two parsers agree'], ['two parsers agree', 'produces', 'significantly better results']]\",\n",
       " \"[['greedy models', 'after', 'tri-training'], ['greedy neural network model', 'surpasses', 'BerkeleyParser'], ['BerkeleyParser', 'in', 'accuracy']]\",\n",
       " \"[['up - training', 'improved', 'results'], ['results', 'far more than', 'tri-training'], ['tri-training', 'for', 'baseline']]\",\n",
       " \"[['structured perceptron', 'improved', 'error rates'], ['error rates', 'on', 'some of the common and difficult labels'], ['error rates', 'improved by', '> 1 %']]\",\n",
       " '[]',\n",
       " \"[['neural graphbased approach', 'to achieve', 'competitive performance'], ['competitive performance', 'build', 'network'], ['network', 'uses', 'more regularization'], ['label classifier', 'with', 'biaffine ones'], ['MLP operations', 'that reduce', 'dimensionality']]\",\n",
       " \"[['resulting parser', 'maintains', 'most of the simplicity'], ['most of the simplicity', 'of', 'neural graph - based approaches'], ['performance', 'of', 'SOTA transition - based one'], ['performance', 'of', 'SOTA transition - based one']]\",\n",
       " \"[['deep bilinear attention mechanism', 'opposed to', 'shallow bilinear attention'], ['shallow bilinear attention', 'uses', 'recurrent states']]\",\n",
       " '[]',\n",
       " \"[['dropout', 'at', 'every stage'], ['nodes', 'in', 'LSTM layers ('], ['nodes', 'applying', 'same dropout mask'], ['nodes', 'in', 'MLP layers and classifiers']]\",\n",
       " \"[['network', 'with', 'annealed Adam'], ['annealed Adam', 'for', 'about 50,000 steps'], ['about 50,000 steps', 'rounded up to', 'nearest epoch']]\",\n",
       " \"[['outperforms', 'with respect to', 'both speed and accuracy'], ['others', 'with respect to', 'both speed and accuracy']]\",\n",
       " \"[['model', 'with', 'shallow bilinear arc and label classifiers'], ['shallow bilinear arc and label classifiers', 'gets', 'same unlabeled performance'], ['same unlabeled performance', 'as', 'deep model'], ['deep model', 'with', 'same settings']]\",\n",
       " \"[['three or four layers', 'gets', 'significantly better performance'], ['significantly better performance', 'than', 'two layers'], ['three or four layers', 'increasing', 'LSTM sizes'], ['LSTM sizes', 'from', '200 to'], ['LSTM sizes', 'signficantly improves', 'performance'], ['300 or 400 dimensions', 'signficantly improves', 'performance']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['any tags at all', 'results in', 'better performance'], ['better performance', 'than', 'using'], ['better performance', 'than', 'tags']]\",\n",
       " \"[['Our model', 'gets', 'nearly the same UAS performance'], ['Our model', 'gets', 'SOTA UAS performance'], ['Our model', 'gets', 'SOTA performance'], ['nearly the same UAS performance', 'on', 'PTB - SD 3.3.0'], ['PTB - SD 3.3.0', 'as', 'current SOTA model'], ['Our model', 'gets', 'SOTA UAS performance'], ['SOTA UAS performance', 'on', 'CTB 5.1'], ['SOTA performance', 'on', 'all CoNLL 09 languages']]\",\n",
       " '[]',\n",
       " \"[['feature representation', 'able to capture', 'information'], ['information', 'from', 'entirety of the state'], ['information', 'without resorting to', 'locality assumptions']]\",\n",
       " \"[['novel stack LSTM data structure', 'allows', 'parser'], ['parser', 'to maintain', 'constant time per-state update'], ['novel stack LSTM data structure', 'retain', 'over all linear parsing time']]\",\n",
       " \"[['parser', 'makes', 'greedy decisions'], ['greedy decisions', 'according to', 'learned model']]\",\n",
       " '[]',\n",
       " \"[['algorithm states', 'sampled from', 'model'], ['algorithm states', 'sampled from', 'training data'], ['more robust predictions', 'at', 'test time']]\",\n",
       " \"[['score', 'achieved by', 'dynamic oracle'], ['dynamic oracle', 'for', 'English'], ['dynamic oracle', 'is', '93.56 UAS'], ['English', 'is', '93.56 UAS']]\",\n",
       " \"[['static oracle training controlling', 'for', 'transition system'], ['arc-standard system', 'when trained with', 'static oracle']]\",\n",
       " '[]',\n",
       " \"[['simple feed - forward networks', 'without', 'any recurrence'], ['simple feed - forward networks', 'can achieve', 'comparable or better accuracies'], ['comparable or better accuracies', 'than', 'LSTMs'], ['comparable or better accuracies', 'long as', 'globally normalized'], ['comparable or better accuracies', 'are', 'globally normalized']]\",\n",
       " \"[['beam search', 'for', 'maintaining'], ['global normalization', 'with', 'conditional random field ( CRF ) objective'], ['conditional random field ( CRF ) objective', 'to overcome', 'label bias problem']]\",\n",
       " \"[['gradients', 'based on', 'approximate global normalization'], ['gradients', 'perform', 'full backpropagation training'], ['full backpropagation training', 'of', 'all neural network parameters'], ['all neural network parameters', 'based on', 'CRF loss']]\",\n",
       " \"[['previous structured training approaches', 'used for', 'neural network transitionbased parsing']]\",\n",
       " \"[['pre-trained , state - of - the art English dependency parser', 'called', 'Parsey McParseface']]\",\n",
       " \"[['stochastic gradient descent', 'on', 'negative log - likelihood'], ['negative log - likelihood', 'of', 'data'], ['negative log - likelihood', 'under', 'model'], ['data', 'under', 'model']]\",\n",
       " '[]',\n",
       " \"[['global model', 'works', 'well'], ['model', 'in', 'two steps'], ['training', 'achieves', 'same precision'], ['model', 'achieves', 'same precision'], ['network', 'using', 'local objective'], ['global model', 'perform', 'additional training steps'], ['additional training steps', 'using', 'global objective']]\",\n",
       " \"[['averaged stochastic gradient descent', 'with', 'momentum'], ['early stopping time', 'using', 'separate held - out corpus'], ['separate held - out corpus', 'for', 'each task']]\",\n",
       " '[]',\n",
       " \"[['features', 'from', 'words'], ['features', 'from', 'history of predictions'], ['window of tokens', 'centered on', 'in - put'], ['window of tokens', 'as', 'features'], ['features', 'from', 'history of predictions']]\",\n",
       " \"[['single hidden layer', 'of size', '400']]\",\n",
       " '[]',\n",
       " \"[['sentence compression system', 'from', '3 - layer stacked LSTM'], ['3 - layer stacked LSTM', 'uses', 'dependency label information']]\",\n",
       " \"[['LSTM and our global model', 'perform', 'on par'], ['on par', 'on both', 'automatic evaluation'], ['our model', 'is', 'roughly 100 faster']]\",\n",
       " \"[['All compressions', 'kept', 'approximately 42 %'], ['approximately 42 %', 'of', 'tokens']]\",\n",
       " \"[['simple transition system', 'uses', 'SHIFT action'], ['simple transition system', 'predicts', 'POS tag'], ['POS tag', 'of', 'current word'], ['current word', 'on', 'buffer'], ['POS tag', 'shifted to', 'stack']]\",\n",
       " \"[['window 3 tokens', 'centered at', 'current focus token']]\",\n",
       " \"[['Our local model', 'compares', 'favorably']]\",\n",
       " \"[['beam search', 'with', 'locally normalized model'], ['beam search', 'with', 'global normalization'], ['locally normalized model', 'does', 'help'], ['beam search', 'with', 'global normalization'], ['global normalization', 'leads to', '7 % reduction'], ['7 % reduction', 'in', 'relative error']]\",\n",
       " '[[\\'set of character ngrams feature\\', \\'is\\', \\'very important\\'], [\\'set of character ngrams feature\\', \\'increasing\\', \\'average accuracy\\'], [\\'average accuracy\\', \\'on\\', \"CoNLL \\'09 datasets\"], [\\'average accuracy\\', \\'by\\', \\'about 0.5 % absolute\\'], [\"CoNLL \\'09 datasets\", \\'by\\', \\'about 0.5 % absolute\\']]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['bigram information', 'improves', 'performance'], ['performance', 'by', '1 - 4 %']]\",\n",
       " \"[['our accuracy', 'slightly better than', 'char - CNN and char - CRNN'], ['our accuracy', 'bit worse than', 'VDCNN']]\",\n",
       " \"[['accuracy slightly', 'by using', 'more n-grams'], ['more n-grams', 'for example with', 'trigrams'], ['trigrams', 'performance on', 'Sogou'], ['Sogou', 'goes up to', '97.1 %']]\",\n",
       " \"[['tags', 'according to', 'title and caption']]\",\n",
       " \"[['vocabulary size', 'is', '297,141']]\",\n",
       " \"[['frequency - based baseline', 'predicts', 'most frequent tag']]\",\n",
       " \"[['Tagspace ( Weston et al. , 2014 )', 'based on', 'Wsabie model']]\",\n",
       " \"[['Tagspace model', 'described using', 'convolutions'], ['convolutions', 'consider', 'linear version'], ['linear version', 'achieves', 'comparable performance'], ['Tagspace model', 'is', 'much faster']]\",\n",
       " \"[['Both', 'achieve', 'similar performance'], ['similar performance', 'with', 'small hidden layer'], ['Both', 'adding', 'bigrams'], ['bigrams', 'gives', 'significant boost'], ['significant boost', 'in', 'accuracy']]\",\n",
       " \"[['Tagspace', 'needs to compute', 'scores'], ['scores', 'for', 'all the classes'], ['all the classes', 'makes it', 'relatively slow'], ['our fast inference', 'gives', 'significant speed - up'], ['significant speed - up', 'when', 'number of classes is large ( more than 300 K here )']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['two approaches', 'for', 'domain adaptation']]\",\n",
       " \"[['first method', 'based on', 'masked language model ( MLM ) pre-training'], ['masked language model ( MLM ) pre-training', 'using', 'unlabeled target language corpora']]\",\n",
       " \"[['self - training technique', 'to do', 'domain adaptation'], ['domain adaptation', 'from', 'source language'], ['source language', 'into', 'target language']]\",\n",
       " \"[['second approach', 'as', 'basic model'], ['XLM model', 'as', 'our base model'], ['our base model', 'pre-trained by', 'large - scale parallel and monolingual data']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Train - Test Discrepancy', 'of', 'UDA Method'], ['UDA Method', 'With', 'UDA algorithm']]\",\n",
       " \"[['new classifier', 'trained only based on', 'target domain']]\",\n",
       " \"[['XLM', 'with', 'MLM loss'], ['MLM loss', 'for', 'each target domain']]\",\n",
       " \"[['pre-trained model', 'with', 'source - domain training set']]\",\n",
       " \"[['Ft ( XLM ) results', 'without the help of', 'unlabeled data'], ['unlabeled data', 'from', 'target domain'], ['substantial gap', 'between', 'model performance'], ['substantial gap', 'between', 'monolingual baselines'], ['model performance', 'of', 'cross -lingual settings'], ['substantial gap', 'when using', 'state - of - the - art pre-trained cross -lingual representations']]\",\n",
       " \"[['sentiment classification task', 'where', 'unlabeled data size'], ['unlabeled data size', 'is', 'larger'], ['Ft ( XLM ft ) model usnig MLM pre-training', 'consistently provides', 'larger improvements'], ['larger improvements', 'compared with', 'UDA method']]\",\n",
       " '[]',\n",
       " \"[['sentiment classification task', 'observe', 'self - training technique'], ['consistently improves', 'over', 'teacher model']]\",\n",
       " \"[['best results', 'in', 'both XLM and XLM ft based classifiers']]\",\n",
       " \"[['self - training', 'achieves', 'best results']]\",\n",
       " \"[['best cross - lingual results and monolingual fine - tune baseline', 'able to', 'completely close'], ['performance gap', 'by utilizing', 'unlabeled data'], ['unlabeled data', 'in', 'target language']]\",\n",
       " \"[['our framework', 'reaches', 'new state - of - the - art results'], ['our framework', 'improving over', 'vanilla XLM baselines'], ['new state - of - the - art results', 'improving over', 'vanilla XLM baselines'], ['vanilla XLM baselines', 'by', '44 %']]\",\n",
       " \"[['experment results', 'lags behind', 'ones using unlabeled data'], ['ones using unlabeled data', 'from', 'target domain']]\",\n",
       " \"[['performance', 'of', 'model'], ['improves', 'with', 'more labeled data'], ['consistently', 'with', 'more labeled data'], ['more labeled data', 'in', 'monolingual setting']]\",\n",
       " \"[['t2t', 'is', 'best performing approach']]\",\n",
       " '[]',\n",
       " \"[['our model', 'achieved', 'state - of - the - art results'], ['state - of - the - art results', 'on', 'all datasets']]\",\n",
       " \"[['text classification problem', 'by modeling', 'semantics'], ['semantics', 'in', 'target documents']]\",\n",
       " \"[['weights', 'computed using', 'novel neural attention mechanism'], ['novel neural attention mechanism', 'that enables', 'model'], ['model', 'to focus on', 'small subset'], ['small subset', 'of', 'entities'], ['entities', 'that are', 'less ambiguous'], ['less ambiguous', 'in', 'meaning']]\",\n",
       " \"[['attention mechanism', 'improves', 'interpretability'], ['interpretability', 'of', 'model']]\",\n",
       " '[]',\n",
       " \"[['embeddings', 'of', 'words ( v w ) and entities ( v e )'], ['words ( v w ) and entities ( v e )', 'using', 'pretrained embeddings'], ['pretrained embeddings', 'trained on', 'KB']]\",\n",
       " '[]',\n",
       " \"[['logistic regression classifier', 'with', 'features'], ['features', 'derived by', 'RNN']]\",\n",
       " \"[['variants', 'of', 'our NABoEentity and NABoE - full models'], ['our NABoEentity and NABoE - full models', 'based on', 'Wikifier and TAGME']]\",\n",
       " \"[['our models', 'achieved', 'enhanced performance']]\",\n",
       " \"[['NABoE-entity model', 'achieved', 'competitive performance'], ['NABoE-entity model', 'achieved', 'outperformed'], ['outperformed', 'in', 'literature category'], ['all the baseline models', 'in', 'literature category']]\",\n",
       " \"[['our models', 'yielded', 'enhanced over all performance'], ['enhanced over all performance', 'on', 'both datasets']]\",\n",
       " \"[['outperformed', 'in terms of', 'both measures'], ['all baseline models', 'in terms of', 'both measures']]\",\n",
       " \"[['all the baseline models', 'in terms of', 'both measures'], ['both measures', 'on', '20NG dataset'], ['F 1 score', 'on', 'R8 dataset']]\",\n",
       " '[]',\n",
       " \"[['dictionarybased entity detection', 'generally outperformed', 'models'], ['models', 'based on', 'entity linking systems'], ['entity linking systems', 'i.e.', 'Wikifier'], ['entity linking systems', 'i.e.', 'TAGME']]\",\n",
       " \"[['our attention mechanism', 'consistently improved', 'performance'], ['performance', 'for', 'Wikifierand TAGME - based models']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['models', 'based on', 'entity linking systems']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['AI', 'combination of', 'active learning and self learning'], ['active learning and self learning', 'for', 'named entity recognition on twitter'], ['named entity recognition on twitter', 'using', 'conditional random fields learning']]\",\n",
       " '[]',\n",
       " \"[['task - oriented word embedding method', 'denoted as', 'ToWE']]\",\n",
       " '[]',\n",
       " \"[['contextual information', 'captured following', 'context prediction task']]\",\n",
       " \"[['task information', 'regularize', 'distribution'], ['task information', 'adjust', 'distribution'], ['distribution', 'of', 'other words'], ['other words', 'in', 'embedding space']]\",\n",
       " \"[['task - oriented word embedding method', 'specially designed for', 'text classification']]\",\n",
       " '[[\"word \\'s functional attributes\", \\'in\\', \\'embedding space\\'], [\"word \\'s functional attributes\", \\'by regularizing\\', \\'distribution of words\\'], [\\'embedding space\\', \\'by regularizing\\', \\'distribution of words\\'], [\\'distribution of words\\', \\'to have\\', \\'clear classification boundary\\']]',\n",
       " \"[['each document', 'as', 'bag of words'], ['weighting scheme', 'is', 'TFIDF']]\",\n",
       " \"[['CBOW', 'predicts', 'target word'], ['target word', 'using', 'context information'], ['Skip - gram', 'predicts', 'each context word'], ['each context word', 'using', 'target word'], ['Glo Ve method', 'is', 'state - of - the - art matrix factorization method']]\",\n",
       " \"[['text classification task', 'to evaluate', 'performance'], ['performance', 'of', 'word embeddings']]\",\n",
       " \"[['document embedding', 'as', 'document feature'], ['document embedding', 'trained', 'linear classifier'], ['linear classifier', 'using', 'Liblinear']]\",\n",
       " \"[['corpus', 'with', 'Stanford Tokenizer'], ['lowercase', 'removed', 'stop words']]\",\n",
       " \"[['dimensionality', 'of', 'vectors'], ['size', 'of', 'context window'], ['vectors', 'is', '300'], ['context window', 'is', '5'], ['number of negative samples', 'is', '25']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['recommended N', 'is', '150'], ['150', 'with', 'constraint']]\",\n",
       " \"[['0 to 1', 'with', 'step size'], ['step size', 'of', '0.1']]\",\n",
       " \"[['Skip - gram and CBOW', 'reaches', 'optimal performance'], ['optimal performance', 'when', '? = 0.4 and ? = 0.3']]\",\n",
       " \"[['Our method', 'performs', 'better'], ['better', 'than', 'other methods'], ['Our method', 'proved to', 'highly reliable'], ['highly reliable', 'for', 'text classification task']]\",\n",
       " \"[['significantly outperforms', 'on', '20 New s Group'], ['significantly outperforms', 'on', '5 Abstract s Group'], ['other baselines', 'on', '20 New s Group'], ['other baselines', 'on', '5 Abstract s Group']]\",\n",
       " '[]',\n",
       " \"[['Retrofit method', 'is', 'knowledge - base enhanced word embedding method']]\",\n",
       " \"[['Our method', 'achieves', 'better performance'], ['better performance', 'over', 'Retrofit method']]\",\n",
       " \"[['TWE', 'achieves', 'relatively lower performance']]\",\n",
       " \"[['TWE method', 'on', 'document - level and sentence - level tasks']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['new graph neural networkbased method', 'for', 'text classification']]\",\n",
       " '[]',\n",
       " \"[['text classification problem', 'into', 'anode classification problem']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['bag - of - words model', 'with', 'term frequencyinverse document frequency weighting']]\",\n",
       " \"[['Logistic Regression', 'used as', 'classifier']]\",\n",
       " '[]',\n",
       " \"[['last hidden state', 'as', 'representation'], ['representation', 'of', 'whole text']]\",\n",
       " '[]',\n",
       " \"[['pre-trained word embeddings', 'to', 'Bi - LSTM']]\",\n",
       " '[]',\n",
       " \"[['Logistic Regression', 'as', 'classifier']]\",\n",
       " \"[['paragraph vector model', 'considers', 'word order']]\",\n",
       " \"[['Logistic Regression', 'as', 'classifier']]\",\n",
       " \"[['predictive text embedding', 'firstly learns', 'word embedding'], ['word embedding', 'based on', 'heterogeneous text network'], ['heterogeneous text network', 'containing', 'words , documents and labels as'], ['predictive text embedding', 'averages', 'word embeddings'], ['word embeddings', 'as', 'document embeddings'], ['document embeddings', 'for', 'text classification']]\",\n",
       " \"[['text classification', 'treats', 'average of word / n- grams embeddings'], ['average of word / n- grams embeddings', 'as', 'document embeddings'], ['document embeddings', 'into', 'linear classifier']]\",\n",
       " \"[['SWEM', 'employs', 'simple pooling strategies'], ['simple word embedding models', 'employs', 'simple pooling strategies'], ['simple pooling strategies', 'operated over', 'word embeddings']]\",\n",
       " \"[['label - embedding attentive models', 'embeds', 'words and labels'], ['label - embedding attentive models', 'in', 'same joint space'], ['words and labels', 'in', 'same joint space'], ['same joint space', 'for', 'text classification']]\",\n",
       " \"[['convolutions', 'over', 'word embedding similarity graphs']]\",\n",
       " '[]',\n",
       " \"[['Graph - CNN - F', 'using', 'Fourier filter']]\",\n",
       " \"[['Text GCN', 'set', 'embedding size'], ['embedding size', 'of', 'first convolution layer'], ['first convolution layer', 'as', '200'], ['embedding size', 'set', 'window size'], ['window size', 'as', '20']]\",\n",
       " \"[['pre-trained word embeddings', 'used', '300 dimensional Glo Ve word embeddings']]\",\n",
       " \"[['Text GCN', 'performs', 'best and significantly outperforms']]\",\n",
       " \"[['TF - IDF + LR', 'performs', 'well'], ['well', 'on', 'long text datasets'], ['long text datasets', 'like', '20 NG'], ['CNN', 'with', 'randomly initialized word embeddings']]\",\n",
       " \"[['pre-trained Glo Ve word embeddings', 'provided', 'CNN'], ['CNN', 'performs', 'much better'], ['much better', 'especially on', 'Ohsumed and 20 NG']]\",\n",
       " \"[['CNN', 'achieves', 'best results'], ['best results', 'on', 'short text dataset MR']]\",\n",
       " \"[['PV - DBOW', 'achieves', 'comparable results'], ['comparable results', 'to', 'strong baselines'], ['strong baselines', 'on', '20 NG and Ohsumed']]\",\n",
       " \"[['PV - DM', 'performs', 'worse'], ['worse', 'than', 'PV - DBOW']]\",\n",
       " \"[['PV - DBOW and PV - DM', 'indicate', 'unsupervised document embeddings'], ['unsupervised document embeddings', 'are', 'not very discriminative'], ['not very discriminative', 'in', 'text classification']]\",\n",
       " '[]',\n",
       " \"[['SWEM and LEAM', 'perform', 'quite well']]\",\n",
       " \"[['Graph - CNN models', 'show', 'competitive performances']]\",\n",
       " \"[['text graph', 'can capture', 'document - word relations'], ['GCN model', 'computes', 'new features'], ['new features', 'of', 'anode'], ['new features', 'as', 'weighted average'], ['anode', 'as', 'weighted average'], ['anode', 'as', 'second order neighbors'], ['weighted average', 'of', 'itself']]\",\n",
       " \"[['label information', 'of', 'document nodes'], ['document nodes', 'passed to', 'neighboring word nodes ( words within'], ['other word nodes and document nodes', 'thatare neighbor to', 'first step neighboring word nodes']]\",\n",
       " \"[['CNN and LSTM - based models', 'on', 'MR']]\",\n",
       " \"[['Text GCN', 'can achieve', 'higher test accuracy'], ['higher test accuracy', 'with', 'limited labeled documents']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[[\\'deep pyramid CNN ( DPCNN )\\', \\'as\\', \\'computation time\\'], [\\'computation time\\', \\'per\\', \\'layer\\'], [\\'exponentially\\', \\'in\\', \"\\' pyramid shape\"]]',\n",
       " \"[['discrete text', 'to', 'continuous representation'], ['DPCNN architecture', 'alternates', 'convolution block and a downsampling layer'], ['convolution block and a downsampling layer', 'over and', '1'], ['1', 'leading to', 'deep network'], ['deep network', 'in which', 'internal data size ( as well as per-layer computation )'], ['internal data size ( as well as per-layer computation )', 'shrinks in', 'pyramid shape']]\",\n",
       " \"[['first layer', 'performs', 'text region embedding'], ['text region embedding', 'generalizes', 'commonly used word embedding'], ['commonly used word embedding', 'to', 'embedding'], ['embedding', 'of', 'text regions'], ['text regions', 'covering', 'one or more words']]\",\n",
       " \"[['max pooling', 'for', 'all pooling layers']]\",\n",
       " \"[['log loss', 'with', 'softmax'], ['minibatch SGD', 'with', 'momentum 0.9'], ['minibatch SGD', 'with', 'momentum 0.9'], ['momentum 0.9', 'conducted for', 'n epochs']]\",\n",
       " \"[['minibatch size', 'fixed to', '100']]\",\n",
       " \"[['Regularization', 'done by', 'weight decay'], ['weight decay', 'with', 'parameter 0.0001'], ['optional dropout', 'with', '0.5'], ['Regularization', 'by', 'optional dropout'], ['optional dropout', 'with', '0.5'], ['0.5', 'applied to', 'input']]\",\n",
       " \"[['early stopping', 'after reducing', 'learning rate'], ['learning rate', 'to', '0.1']]\",\n",
       " \"[['Weights', 'initialized by', 'Gaussian distribution'], ['Gaussian distribution', 'with', 'zero mean']]\",\n",
       " \"[['discrete input', 'to', 'region embedding layer'], ['output dimensionality', 'to', '250'], ['region embedding layer', 'fixed to', 'bow input'], ['output dimensionality', 'fixed to', '250'], ['region size', 'chosen from', '{ 1 , 3 , 5 }'], ['region size', 'fixing', 'output dimensionality'], ['output dimensionality', 'to', '250']]\",\n",
       " \"[['dimensionality', 'of', 'unsupervised embeddings'], ['dimensionality', 'set to', '300'], ['unsupervised embeddings', 'set to', '300']]\",\n",
       " \"[['depth', 'of', 'DPCNN'], ['depth', 'fixed to', '15'], ['DPCNN', 'fixed to', '15']]\",\n",
       " \"[['deeper', 'did not', 'substantially improve']]\",\n",
       " '[]',\n",
       " \"[['all of the previous results', 'validates', 'effectiveness']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['ShallowCNN', 'rivals', 'DPCNN'], ['best linear model', 'moved up from', 'worst performer'], ['worst performer', 'to', 'third best performer']]\",\n",
       " \"[['improves', 'as', 'depth increases']]\",\n",
       " '[]',\n",
       " \"[['every location', 'converted to', 'low-dimensional vector'], ['low-dimensional vector', 'with', 'information'], ['information', 'relevant to', 'task being']]\",\n",
       " \"[['embedding function', 'shared among', 'all the locations']]\",\n",
       " \"[['document', 'represented as', 'sequence'], ['convolution layer', 'converts', 'small regions'], ['small regions', 'of', 'document'], ['region embedding results', 'to', 'document vector'], ['low-dimensional vectors', 'at', 'every location ( embedding of text regions )'], ['pooling layer', 'aggregates', 'region embedding results'], ['region embedding results', 'to', 'document vector'], ['document vector', 'by taking', 'componentwise maximum or average']]\",\n",
       " \"[['more sophisticated region embedding', 'via', 'Long Short - Term Memory ( LSTM )'], ['Long Short - Term Memory ( LSTM )', 'seeking to overcome', 'shortcomings'], ['shortcomings', 'in', 'supervised and semi-supervised settings']]\",\n",
       " \"[['LSTM', 'is', 'recurrent neural network']]\",\n",
       " \"[['other methods', 'including', 'previous LSTM']]\",\n",
       " \"[['best results', 'combining', 'two types of region embeddings ( LSTM embed - dings and CNN embeddings )'], ['two types of region embeddings ( LSTM embed - dings and CNN embeddings )', 'trained on', 'unlabeled data']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['vocabulary', 'reduced to', 'most frequent 30 K words'], ['most frequent 30 K words', 'of', 'training data'], ['most frequent 30 K words', 'to reduce', 'computational burden'], ['training data', 'to reduce', 'computational burden'], ['square loss', 'minimized with', 'dropout'], ['dropout', 'applied to', 'input to']]\",\n",
       " \"[['20 NG', 'for', 'topic categorization of Reuters news articles and newsgroup messages']]\",\n",
       " \"[['Optimization', 'done with', 'SGD'], ['SGD', 'with', 'mini-batch size 50 or 100'], ['mini-batch size 50 or 100', 'with', 'momentum'], ['Optimization', 'optionally', 'rmsprop'], ['SGD', 'optionally', 'rmsprop'], ['rmsprop', 'for', 'acceleration']]\",\n",
       " \"[['our one - hot bidirectional LSTM', 'with', 'pooling ( oh - 2 LSTMp )'], ['our one - hot bidirectional LSTM', 'outperforms', 'word - vector LSTM ( wv - LSTM )'], ['pooling ( oh - 2 LSTMp )', 'outperforms', 'word - vector LSTM ( wv - LSTM )'], ['word - vector LSTM ( wv - LSTM )', 'on', 'all the datasets']]\",\n",
       " \"[['region size 20', 'on', 'RCV1'], ['seq -CNN', 'with', 'regular concatenation input']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['n-gram SVM', 'is', 'no better'], ['no better', 'than', 'bag - of - word SVM']]\",\n",
       " \"[['bags of words', 'in a', 'window of 20'], ['words', 'in a', 'strict order'], ['window of 20', 'at', 'every location'], ['window of 20', 'are', 'more useful'], ['every location', 'are', 'more useful'], ['more useful', 'than', 'words'], ['words', 'in', 'strict order']]\",\n",
       " \"[['LSTM', 'loses to', 'bow - CNN']]\",\n",
       " \"[['strength', 'of', 'LSTM'], ['strength', 'to embed', 'larger regions'], ['LSTM', 'to embed', 'larger regions'], ['larger regions', 'appears not to be', 'big contributor']]\",\n",
       " \"[['one - hot CNN', 'works', 'surprising well']]\",\n",
       " \"[['previous best performance', 'on', '20NG'], ['20NG', 'is', '15.3'], ['pre-training wv - LSTM', 'of', '1024 units'], ['DL15', 'obtained by', 'pre-training wv - LSTM'], ['pre-training wv - LSTM', 'of', '1024 units'], ['1024 units', 'with', 'labeled training data']]\",\n",
       " \"[['Our oh - 2 LSTMp', 'achieved', '13.32']]\",\n",
       " \"[['obtained tv-embeddings', 'to produce', 'additional input'], ['additional input', 'to', 'supervised region embedding'], ['supervised region embedding', 'of', 'one - hot CNN'], ['supervised region embedding', 'resulting in', 'higher accuracy'], ['one - hot CNN', 'resulting in', 'higher accuracy']]\",\n",
       " \"[['clear performance improvements', 'obtained on', 'all the datasets']]\",\n",
       " \"[['models', 'with', 'region tv-embeddings']]\",\n",
       " \"[['wv - 2 LSTMp', 'using', 'Google News vectors'], ['Google News vectors', 'performed', 'relatively poorly']]\",\n",
       " \"[['word2vec', 'trained with', 'domain unlabeled data'], ['better results', 'scaled', 'word vectors']]\",\n",
       " \"[['region tv - embeddings', 'used', 'same domain unlabeled data']]\",\n",
       " \"[['LSTM', 'rivals', 'CNN'], ['LSTM', 'rivals', 'underperforms'], ['CNN', 'on', 'IMDB / Elec'], ['underperforms', 'on', 'RCV1']]\",\n",
       " \"[['dimensionality', 'of', 'LSTM tvembeddings'], ['LSTM tvembeddings', 'from', '100 to 300'], ['100 to 300', 'on', 'RCV1']]\",\n",
       " \"[['error rate', 'on', 'IMDB'], ['error rate', 'on', 'RCV1'], ['error rate', 'improved from', '6.66 to'], ['IMDB', 'improved from', '6.66 to'], ['error rate', 'on', 'RCV1'], ['RCV1', 'improved from', '7.71']]\",\n",
       " \"[['performance', 'when', 'combined']]\",\n",
       " \"[['best supervised results', 'on', 'IMDB / Elec of JZ15a'], ['best supervised results', 'obtained by integrating', 'document embedding layer'], ['IMDB / Elec of JZ15a', 'obtained by integrating', 'document embedding layer'], ['document embedding layer', 'into', 'one - hot CNN']]\",\n",
       " \"[['our new model', 'further improved it', '5.94'], ['our new model', 'on', 'Elec and RCV1'], ['our best models', 'exceeded', 'previous best results']]\",\n",
       " '[]',\n",
       " \"[['adversarial and virtual adversarial training', 'to', 'text domain'], ['perturbations', 'to', 'word embeddings'], ['adversarial and virtual adversarial training', 'by applying', 'perturbations'], ['perturbations', 'to', 'word embeddings'], ['word embeddings', 'in', 'recurrent neural network'], ['recurrent neural network', 'rather than to', 'original input itself']]\",\n",
       " \"[['robustness', 'to', 'adversarial examples'], ['generalization performance', 'for', 'original examples']]\",\n",
       " \"[['model', 'given', 'example'], ['same output distribution', 'produces on', 'adversarial perturbation'], ['adversarial perturbation', 'of', 'example']]\",\n",
       " \"[['perturbation', 'on', 'continuous word embeddings'], ['continuous word embeddings', 'instead of', 'discrete word inputs']]\",\n",
       " \"[['TensorFlow', 'on', 'GPUs']]\",\n",
       " '[]',\n",
       " \"[['gradient clipping', 'with', 'norm'], ['norm', 'set to', '1.0'], ['1.0', 'on', 'all the parameters'], ['all the parameters', 'except', 'word embeddings']]\",\n",
       " \"[['runtime', 'on', 'GPU'], ['runtime', 'used', 'truncated backpropagation'], ['GPU', 'used', 'truncated backpropagation'], ['truncated backpropagation', 'up to', '400 words'], ['400 words', 'from', 'each end of the']]\",\n",
       " \"[['regularization', 'of', 'recurrent language model'], ['regularization', 'applied', 'dropout'], ['recurrent language model', 'applied', 'dropout'], ['dropout', 'on', 'word embedding layer'], ['word embedding layer', 'with', '0.5 dropout rate']]\",\n",
       " \"[['512 hidden units LSTM', 'For', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '512 hidden units LSTM'], ['512 hidden units LSTM', 'for', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '256 dimensional word embeddings'], ['256 dimensional word embeddings', 'shared with', 'both of the LSTMs']]\",\n",
       " '[]',\n",
       " \"[['optimization', 'used', 'Adam optimizer'], ['Adam optimizer', 'with', '0.0005 initial learning rate']]\",\n",
       " \"[['Batch sizes', 'are', '64'], ['64', 'on', 'IMDB'], ['64', 'on', 'DBpedia'], ['128', 'on', 'DBpedia'], ['128', 'on', 'DBpedia']]\",\n",
       " \"[['gradient clipping', 'with', 'norm'], ['norm', 'as', '1.0'], ['1.0', 'on', 'all the parameters'], ['all the parameters', 'except', 'word embedding']]\",\n",
       " '[]',\n",
       " \"[['cosine distances', 'were', '0.361 and 0.377']]\",\n",
       " \"[['improved test performance', 'on', 'baseline method']]\",\n",
       " \"[['results', 'on', 'RCV1']]\",\n",
       " \"[['Adversarial training', 'able to', 'improve'], ['improve', 'over', 'baseline method'], ['almost the same performance', 'as', 'current state of the art method']]\",\n",
       " \"[['baseline method', 'achieved', 'nearly the current state of the art performance'], ['our proposed method', 'improves from', 'baseline method']]\",\n",
       " '[]',\n",
       " \"[['remarkable performance', 'in', 'sentence and document modeling']]\",\n",
       " \"[['C - LSTM', 'able to capture', 'both local features'], ['C - LSTM', 'able to capture', 'global and temporal sentence semantics'], ['both local features', 'of', 'phrases']]\",\n",
       " \"[['CNN and LSTM', 'to', 'model sentences']]\",\n",
       " \"[['output', 'of', 'one - layer CNN'], ['simple end - to - end , unified architecture', 'by feeding', 'output'], ['output', 'of', 'one - layer CNN'], ['one - layer CNN', 'into', 'LSTM']]\",\n",
       " \"[['CNN', 'constructed on top of', 'pre-trained word vectors'], ['pre-trained word vectors', 'from', 'massive unlabeled text data'], ['massive unlabeled text data', 'to learn', 'higher - level representions'], ['higher - level representions', 'of', 'n-grams']]\",\n",
       " \"[['sequential correlations', 'from', 'higher - level suqence representations'], ['feature maps', 'of', 'CNN'], ['feature maps', 'organized as', 'sequential window features'], ['CNN', 'organized as', 'sequential window features'], ['sequential window features', 'to serve', 'input'], ['input', 'of', 'LSTM']]\",\n",
       " \"[['LSTM', 'directly from', 'input sentence'], ['LSTM', 'first transform', 'each sentence'], ['each sentence', 'into', 'successive window ( n- gram ) features'], ['successive window ( n- gram ) features', 'to help disentangle', 'factors'], ['factors', 'of', 'variations'], ['variations', 'within', 'sentences']]\",\n",
       " '[]',\n",
       " \"[['python library', 'supports', 'efficient symbolic differentiation'], ['python library', 'supports', 'transparent use'], ['transparent use', 'of', 'GPU']]\",\n",
       " \"[['efficiency of parallel computation', 'of', 'tensors'], ['model', 'on', 'GPU']]\",\n",
       " \"[['text preprocessing', 'convert', 'all characters'], ['all characters', 'in', 'dataset'], ['all characters', 'to', 'lowercase'], ['dataset', 'to', 'lowercase']]\",\n",
       " \"[['SST', 'conduct', 'hyperparameter ( number of filters , filter length in CNN ;'], ['dropout rate and which layer to apply , etc. ) tuning', 'on', 'validation data'], ['validation data', 'in', 'standard split']]\",\n",
       " \"[['training dataset', 'For', 'hyperparameter search'], ['TREC', 'holdout', '1000 samples'], ['1000 samples', 'from', 'training dataset'], ['1000 samples', 'for', 'hyperparameter search'], ['training dataset', 'for', 'hyperparameter search'], ['TREC', 'train', 'model'], ['model', 'using', 'remaining data']]\",\n",
       " '[]',\n",
       " \"[['filter size', 'investigated', 'filter lengths'], ['filter lengths', 'of', '2 , 3 and 4'], ['2 , 3 and 4', 'in', 'two cases'], ['single convolutional layer', 'with', 'same filter length'], ['multiple convolutional layers', 'with', 'different lengths of filters in parallel']]\",\n",
       " \"[['Binary', 'is', '2 - classification task']]\",\n",
       " \"[['methods', 'related to', 'convolutional neural networks']]\",\n",
       " '[]',\n",
       " \"[['sequence', 'of', 'window representations'], ['window representations', 'fed into', 'LSTM']]\",\n",
       " \"[['different combinations', 'of', 'different filter lengths']]\",\n",
       " '[]',\n",
       " \"[['number of filters', 'of', 'length 3'], ['memory dimension', 'of', 'LSTM'], ['number of filters', 'set to', '150'], ['memory dimension', 'of', 'LSTM'], ['memory dimension', 'set to', '150'], ['LSTM', 'set to', '150']]\",\n",
       " \"[['probability', 'of', '0.5']]\",\n",
       " \"[['number of filters', 'set to', '300'], ['memory dimension', 'set to', '300']]\",\n",
       " \"[['probability', 'of', '0.5']]\",\n",
       " \"[['L2 regularization', 'with', 'factor'], ['factor', 'of', '0.001'], ['0.001', 'to', 'weights'], ['weights', 'in', 'softmax layer']]\",\n",
       " \"[['binary classification task', 'achieve', 'comparable results'], ['comparable results', 'with respect to', 'state - of - the - art ones']]\",\n",
       " \"[['single CNN and LSTM models', 'shows', 'LSTM'], ['long - term dependencies', 'across', 'sequences'], ['sequences', 'of', 'higher - level representations better']]\",\n",
       " \"[['Our result', 'consistently outperforms', 'all published neural baseline models']]\",\n",
       " \"[['Our result', 'close to', 'state - of - the - art SVM'], ['state - of - the - art SVM', 'depends on', 'highly engineered features']]\",\n",
       " \"[['impact', 'of', 'different filter configurations'], ['different filter configurations', 'in', 'convolutional layer'], ['different filter configurations', 'on', 'model performance'], ['convolutional layer', 'on', 'model performance']]\",\n",
       " \"[['multiple convolutional layers', 'shown that', 'filter configurations'], ['filter configurations', 'with', 'filter length 3'], ['filter configurations', 'performs', 'better']]\",\n",
       " '[]',\n",
       " \"[['text processing', 'operates directly at', 'character level']]\",\n",
       " '[]',\n",
       " \"[['deep architectures', 'of', 'many convolutional layers']]\",\n",
       " \"[['proposed deep convolutional network', 'shows', 'significantly better results'], ['significantly better results', 'than', 'previous ConvNets approach']]\",\n",
       " \"[['depth 9 to 17 and 29', 'for', 'Amazon Full'], ['depth 9 to 17 and 29', 'reduces', 'error rate'], ['Amazon Full', 'reduces', 'error rate'], ['error rate', 'by', '1 % absolute']]\",\n",
       " \"[['our best architecture', 'with', 'depth 29 and max - pooling'], ['test error', 'of', '37.0'], ['37.0', 'compared to', '40.43 %']]\",\n",
       " \"[['Max - pooling', 'performs', 'better'], ['better', 'than', 'other pooling types']]\",\n",
       " '[]',\n",
       " \"[['shortcut connections', 'observe', 'improved results'], ['improved results', 'when', 'network'], ['training and test errors', 'go', 'down']]\",\n",
       " \"[['all processing', 'done at', 'character level'], ['character level', 'which is', 'atomic representation'], ['atomic representation', 'of', 'sentence']]\",\n",
       " \"[['character embedding', 'of size', '16']]\",\n",
       " \"[['Training', 'performed with', 'SGD'], ['SGD', 'using', 'mini-batch'], ['SGD', 'using', 'momentum'], ['mini-batch', 'of size', '128'], ['initial learning rate', 'of size', '0.01']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['temporal batch norm', 'without', 'dropout']]\",\n",
       " \"[['Our deep architecture', 'works', 'well'], ['well', 'on', 'big data sets'], ['well', 'for', 'small depths'], ['big data sets', 'for', 'small depths']]\",\n",
       " '[[\\'our model\\', \\'performs\\', \\'better\\'], [\\'better\\', \\'than\\', \"Zhang \\'s convolutional baselines\"]]',\n",
       " '[]',\n",
       " \"[['most important decrease', 'in', 'classification error'], ['most important decrease', 'observed on', 'largest data set Amazon Full'], ['classification error', 'observed on', 'largest data set Amazon Full']]\",\n",
       " \"[['temporal max - pooling', 'works', 'best'], ['best', 'on', 'all data sets']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['raw signal', 'at', 'character level']]\",\n",
       " \"[['design', 'is', 'modular'], ['design', 'where', 'gradients'], ['modular', 'where', 'gradients'], ['gradients', 'obtained by', 'back - propagation'], ['back - propagation', 'to perform', 'optimization']]\",\n",
       " \"[['dimension', 'of', 'embedding'], ['dimension', 'is', '300'], ['embedding', 'is', '300']]\",\n",
       " \"[['number of means', 'is', '5000']]\",\n",
       " '[]',\n",
       " \"[['Bidirectional Long Short - Term Memory Networks with Two - Dimensional Max Pooling ( BLSTM - 2DPooling )', 'to capture', 'features'], ['features', 'on both', 'time - step dimension'], ['features', 'on both', 'feature vector dimension']]\",\n",
       " \"[['Bidirectional Long Short - Term Memory Networks ( BLSTM )', 'to transform', 'text'], ['text', 'into', 'vectors']]\",\n",
       " \"[['2D max pooling operation', 'utilized to obtain', 'fixed - length vector']]\",\n",
       " \"[['2D convolution ( BLSTM - 2DCNN )', 'to capture', 'more meaningful features'], ['more meaningful features', 'to represent', 'input text']]\",\n",
       " \"[['combined framework', 'utilizes', 'BLSTM'], ['BLSTM', 'to capture', 'long - term sentence dependencies'], ['combined framework', 'extracts', 'features'], ['2D convolution and 2D max pooling operation', 'for', 'sequence modeling tasks']]\",\n",
       " \"[['six text classification tasks', 'including', 'sentiment analysis'], ['six text classification tasks', 'including', 'question classification'], ['six text classification tasks', 'including', 'subjectivity classification'], ['six text classification tasks', 'including', 'newsgroups classification']]\",\n",
       " \"[['dimension', 'of', 'word embeddings'], ['hidden units', 'of', 'LSTM'], ['dimension', 'is', '300'], ['word embeddings', 'is', '300'], ['LSTM', 'is', '300'], ['hidden units', 'of', 'LSTM'], ['hidden units', 'is', '300'], ['LSTM', 'is', '300']]\",\n",
       " \"[['100 convolutional filters each', 'for', 'window sizes']]\",\n",
       " \"[['mini-batch size', 'as', '10'], ['learning rate', 'of', 'AdaDelta'], ['learning rate', 'as', 'default value 1.0'], ['AdaDelta', 'as', 'default value 1.0']]\",\n",
       " \"[['0.5', 'For', 'word embeddings'], ['0.2', 'For', 'BLSTM layer'], ['regularization', 'employ', 'Dropout operation'], ['Dropout operation', 'with', 'dropout rate'], ['dropout rate', 'of', '0.5'], ['0.5', 'for', 'word embeddings'], ['l 2 penalty', 'with', 'coefficient 10 ? 5'], ['coefficient 10 ? 5', 'over', 'parameters']]\",\n",
       " \"[['grid search', 'on', 'SST - 1 development set']]\",\n",
       " \"[['more finer tuning', 'such as using', 'different numbers of hidden units'], ['more finer tuning', 'such as using', 'wide convolution'], ['different numbers of hidden units', 'of', 'LSTM layer']]\",\n",
       " '[]',\n",
       " \"[['BLSTM - 2DCNN model', 'achieves', 'excellent performance'], ['excellent performance', 'on', '4 out of 6 tasks']]\",\n",
       " \"[['52.4 % and 89.5 % test accuracies', 'on', 'SST - 1 and SST - 2']]\",\n",
       " \"[['BLSTM - 2DPooling', 'performs', 'worse'], ['worse', 'than', 'state - of - the - art models']]\",\n",
       " \"[['BLSTM - CNN', 'beats', 'all baselines'], ['all baselines', 'on', 'SST - 1 ,'], ['all baselines', 'on', 'TREC datasets']]\",\n",
       " \"[['BLSTM - 2DCNN', 'gets', 'second higher accuracies']]\",\n",
       " \"[['BLSTM - 2DCNN', 'achieves', 'comparable result']]\",\n",
       " \"[['BLSTM-2DCNN', 'extension of', 'BLSTM - 2DPooling'], ['BLSTM -', 'capture', 'more dependencies'], ['more dependencies', 'in', 'text']]\",\n",
       " \"[['Ada Sent', 'utilizes', 'more complicated model'], ['more complicated model', 'to form', 'hierarchy'], ['BLSTM - 2DCNN', 'on', 'Subj and MR datasets']]\",\n",
       " \"[['Deep recursive neural networks', 'for', 'compositionality in language']]\",\n",
       " \"[['Convolutional neural networks', 'for', 'sentence classification']]\",\n",
       " '[]',\n",
       " \"[['Multichannel variable - size convolution', 'for', 'sentence classification']]\",\n",
       " '[]',\n",
       " \"[['Long short - term memory', 'over', 'recursive structures']]\",\n",
       " '[]',\n",
       " \"[['Long short - term memory - networks', 'for', 'machine reading']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['best accuracy', 'is', '52.6'], ['best accuracy', 'is', '2D max pooling size ( 5 , 5 )'], ['52.6', 'with', '2D filter size ( 5 , 5 )'], ['52.6', 'with', '2D max pooling size ( 5 , 5 )']]\",\n",
       " '[]',\n",
       " \"[['our simple model', 'able to achieve', 'results'], ['results', 'without', 'attention mechanisms']]\",\n",
       " '[]',\n",
       " \"[['Nvidia GTX 1080 and RTX 2080 Ti GPUs', 'with', 'PyTorch 0.4.1'], ['PyTorch 0.4.1', 'as', 'backend framework']]\",\n",
       " \"[['Scikitlearn 0.19.2', 'for computing', 'tf - idf vectors'], ['Scikitlearn 0.19.2', 'implementing', 'LR and SVMs']]\",\n",
       " \"[['HAN', 'use', 'batch size'], ['batch size', 'of', '32'], ['learning rate', 'of', '0.01'], ['32', 'across', 'all the datasets']]\",\n",
       " \"[['XML - CNN', 'select', 'dynamic pooling window length'], ['XML - CNN', 'select', '128 output channels'], ['128 output channels', 'with', 'batch sizes'], ['32 and 64', 'for', 'single - label and multilabel datasets']]\",\n",
       " \"[['KimCNN', 'use', 'batch size'], ['batch size', 'of', '64'], ['learning rate', 'of', '0.01'], ['batch size', 'with', 'learning rate'], ['64', 'with', 'learning rate'], ['learning rate', 'of', '0.01']]\",\n",
       " \"[['LSTM reg and LSTM base', 'use', 'Adam optimizer'], ['Adam optimizer', 'with', 'learning rate'], ['Adam optimizer', 'with', '0.001'], ['learning rate', 'of', '0.01'], ['batch sizes', 'of', '32 and 64'], ['0.01', 'on', 'Reuters'], ['0.001', 'using', 'batch sizes'], ['batch sizes', 'of', '32 and 64'], ['32 and 64', 'for', 'multi-label and single - label tasks']]\",\n",
       " \"[['LSTM reg', 'apply', 'temporal averaging ( TA )']]\",\n",
       " \"[['default TA exponential smoothing coefficient', 'of', '? EMA'], ['default TA exponential smoothing coefficient', 'to', '0.99']]\",\n",
       " \"[['512 hidden units', 'for', 'Bi - LSTM models'], ['Bi - LSTM models', 'whose', 'max - pooled output'], ['regularized', 'using', 'dropout rate'], ['dropout rate', 'of', '0.5']]\",\n",
       " \"[['input-hidden and hidden - hidden Bi - LSTM connections', 'using', 'embedding dropout and weight dropping'], ['embedding dropout and weight dropping', 'with', 'dropout rates'], ['dropout rates', 'of', '0.1 and 0.2']]\",\n",
       " \"[['optimization objective', 'use', 'crossentropy and binary cross - entropy loss'], ['crossentropy and binary cross - entropy loss', 'for', 'singlelabel and multi-label tasks']]\",\n",
       " \"[['300 - dimensional word vectors', 'pre-trained on', 'Google News']]\",\n",
       " \"[['all neural models', 'for', '30 epochs'], ['30 epochs', 'with', 'five random seeds'], ['five random seeds', 'reporting', 'mean']]\",\n",
       " \"[['our simple LSTM reg model', 'achieves', 'state of the art'], ['state of the art', 'on', 'Reuters and IMDB'], ['state of the art', 'establishing', 'mean scores'], ['87.0 and 52.8', 'for', 'F 1 score']]\",\n",
       " \"[['consistently improves', 'upon', 'performance'], ['performance', 'of', 'LSTM base'], ['regularization', 'yields', 'increases'], ['increases', 'of', '1.5 and 0.5 points'], ['1.5 and 0.5 points', 'for', 'F 1 score']]\",\n",
       " \"[['accuracy', 'of', 'LSTM reg and our reimplemented version of HAN'], ['LSTM reg and our reimplemented version of HAN', 'to be', 'almost two points lower'], ['almost two points lower', 'than', 'copied result'], ['copied result', 'of', 'HAN']]\",\n",
       " \"[['original result', 'by', 'nearly two points'], ['nearly two points', 'for', 'IMDB dataset']]\",\n",
       " \"[['non-neural LR and SVM baselines', 'perform', 'remarkably well']]\",\n",
       " \"[['SVM', 'beats', 'many neural baselines'], ['many neural baselines', 'including', 'our non-regularized LSTM base']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['attention - based Transformer network', 'on', '40 GB of text'], ['0.69 F1 score', 'on', 'SemEval Task 1:E - c multidimensional emotion classification problem']]\",\n",
       " '[]',\n",
       " \"[['language model', 'across', 'large text dataset']]\",\n",
       " \"[['contextualized word representation', 'based on', 'deep bidirectional language model'], ['deep bidirectional language model', 'trained on', 'large text corpus']]\",\n",
       " \"[['inclusion', 'of', 'easier , more balanced label categories'], ['easier , more balanced label categories', 'improves', 'performance'], ['performance', 'on', 'harder ones']]\",\n",
       " \"[['thresholding predictions', 'produced', 'noticeably better results'], ['noticeably better results', 'than using', 'fixed threshold value'], ['fixed threshold value', 'such as', 't * = 0.5']]\",\n",
       " \"[['outperform', 'on', 'every emotion category'], ['Watson', 'on', 'every emotion category']]\",\n",
       " '[]',\n",
       " \"[['Our model', 'achieved', 'top macro-averaged F1 score'], ['top macro-averaged F1 score', 'among', 'all submission'], ['top macro-averaged F1 score', 'with', 'competitive']]\",\n",
       " \"[['deep learning architectures', 'of', 'Transformer and m LSTM'], ['m LSTM', 'across', 'Plutchik categories']]\",\n",
       " '[]',\n",
       " \"[['significantly better', 'than', 'Watson API'], ['Watson API', 'on', 'all categories'], ['all categories', 'for', 'Watson'], ['Watson', 'supplies', 'predictions']]\",\n",
       " \"[['SemEval - trained Transformer', 'directly to', 'our company tweets dataset'], ['SemEval - trained Transformer', 'gets', 'reasonably good results'], ['our company tweets dataset', 'gets', 'reasonably good results']]\",\n",
       " \"[['rater agreement by dataset', 'see that', 'Plutchik category labels'], ['Plutchik category labels', 'contain', 'large rater dis agreement'], ['large rater dis agreement', 'among', 'vetted raters'], ['vetted raters', 'who passed', 'golden set test']]\",\n",
       " '[]',\n",
       " \"[['increases', 'with', 'depth']]\",\n",
       " \"[['text classification model', 'requires', 'significantly fewer parameters'], ['significantly fewer parameters', 'compared to', 'stateof - the - art CNNs']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['training', 'performed with', 'SGD'], ['SGD', 'utilizing', 'size batch of 64'], ['size batch of 64', 'with', 'maximum of 100 epochs']]\",\n",
       " \"[['initial learning rate', 'of', '0.01'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.001']]\",\n",
       " '[]',\n",
       " \"[['TDSCs', 'promoted', 'significant reduction'], ['significant reduction', 'in', 'convolutional parameters'], ['significant reduction', 'compared to', 'VDCNN'], ['convolutional parameters', 'compared to', 'VDCNN']]\",\n",
       " \"[['network reduction', 'obtained by', 'GAP'], ['GAP', 'is', 'even more representative']]\",\n",
       " \"[['performance difference', 'between', 'VDCNN and SVDCNN models'], ['performance difference', 'varies between', '0.4 and 1.3 %'], ['VDCNN and SVDCNN models', 'varies between', '0.4 and 1.3 %']]\",\n",
       " \"[['base property', 'of', 'VDCNN model'], ['VDCNN model', 'preserved on', 'squeezed model']]\",\n",
       " \"[['performance', 'evaluated for', 'most extensive dataset'], ['most extensive dataset', 'i.e.', 'Yelp Review'], ['accuracy', 'of', 'Char - CNN model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['All approaches', 'better than', 'traditional bag - of - words method']]\",\n",
       " \"[['state - of - the - art methods', 'on', 'two largest datasets']]\",\n",
       " \"[['other methods', 'with', 'different proportion of labeled data']]\",\n",
       " \"[['300 - dimensional Glo Ve word embeddings', 'as', 'initialization'], ['initialization', 'for', 'word embeddings and label embeddings'], ['word embeddings and label embeddings', 'in', 'our model']]\",\n",
       " \"[['Out - Of - Vocabulary ( OOV ) words', 'initialized from', 'uniform distribution'], ['uniform distribution', 'with', 'range [ ? 0.01 , 0.01 ]']]\",\n",
       " '[[\"our model \\'s parameters\", \\'with\\', \\'Adam Optimizer\\'], [\"our model \\'s parameters\", \\'with\\', \\'initial learning rate\\'], [\"our model \\'s parameters\", \\'with\\', \\'minibatch size\\']]',\n",
       " \"[['Dropout regularization', 'employed on', 'final MLP layer'], ['Dropout regularization', 'with', 'dropout rate 0.5'], ['final MLP layer', 'with', 'dropout rate 0.5']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['medical code prediction', 'on', 'Electronic Health Records dataset']]\",\n",
       " \"[['multi-label classification of clinical text', 'including', 'Condensed Memory Networks ( C - MemNN )'], ['multi-label classification of clinical text', 'including', 'Attentive LSTM'], ['multi-label classification of clinical text', 'including', 'Convolutional Attention ( CAML )']]\",\n",
       " \"[['LEAM', 'provides', 'best AUC score'], ['better F1 and P@5 values', 'than', 'all methods'], ['all methods', 'except', 'CNN']]\",\n",
       " \"[['logistic regression baseline', 'performs', 'worse'], ['worse', 'than', 'all deep learning architectures']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['HDLTex', 'combines', 'deep learning architectures'], ['deep learning architectures', 'to allow', 'over all and specialized learning'], ['over all and specialized learning', 'by', 'level of the document hierarchy']]\",\n",
       " '[]',\n",
       " \"[['document classification', 'taken from', 'deep learning']]\",\n",
       " \"[['deep learning approaches', 'to create', 'hierarchical document classification approach']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['processing', 'done on', 'Xeon E5 ? 2640 ( 2.6 GHz )'], ['processing', 'done on', 'GPU cards'], ['processing', 'done on', 'N vidia Tesla K20c'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '32 cores'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '64GB memory'], ['GPU cards', 'were', 'N vidia Quadro K620'], ['GPU cards', 'were', 'N vidia Tesla K20c']]\",\n",
       " \"[['CNN', 'performs', 'secondbest'], ['secondbest', 'for', 'three data sets']]\",\n",
       " \"[['SVM with term weighting', 'is', 'third']]\",\n",
       " \"[['combination RNN', 'For', 'first level of classification'], ['DNN', 'For', 'second level'], ['best accuracy', 'obtained by', 'combination RNN'], ['combination RNN', 'for', 'first level of classification'], ['combination RNN', 'for', 'DNN'], ['DNN', 'for', 'second level'], ['DNN', 'for', 'second level']]\",\n",
       " \"[['significantly better', 'than', 'all of the others'], ['all of the others', 'except for', 'combination of CNN and DNN']]\",\n",
       " \"[['best scores', 'achieved by', 'RNN']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['combinations', 'of', 'RNN'], ['combinations', 'of', 'DNN or CNN'], ['RNN', 'at', 'higher level'], ['RNN', 'at', 'lower level'], ['DNN or CNN', 'at', 'lower level'], ['combinations', 'at', 'lower level'], ['RNN', 'at', 'lower level'], ['DNN or CNN', 'at', 'lower level'], ['combinations', 'produced', 'accuracies'], ['lower level', 'produced', 'accuracies'], ['conventional approaches', 'using', 'nave Bayes or SVM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['fullyconnected ( FC ) layer', 'at', 'topmost of the']]\",\n",
       " \"[['parameter matrix', 'of', 'FC layer'], ['set', 'of', 'class representations'], ['parameter matrix', 'as', 'set']]\",\n",
       " \"[['interaction mechanism', 'capable of incorporating', 'word - level matching signals'], ['word - level matching signals', 'for', 'text classification']]\",\n",
       " \"[['word - level representation', 'computes', 'interaction matrix'], ['interaction matrix', 'in which', 'each entry'], ['each entry', 'is', 'matching score'], ['matching score', 'between', 'word and a class ( dot -product'], ['matching score', 'illustrating', 'word - level matching signals'], ['word and a class ( dot -product', 'illustrating', 'word - level matching signals']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['word - level encoder', 'projects', 'textual contents'], ['textual contents', 'into', 'word - level representations']]\",\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "historical-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[['sentences', 'explicitly models', 'nested , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[['two variants', 'of', 'algorithm'], ['two va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[['greedy prediction', 'with', 'our']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[['simple importance sampling algorithm', 'whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>[['short and long answers', 'in', 'single mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>[['our model', 'from', 'BERT model'], ['our mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>[['model', 'by', 'minimizing'], ['loss L', 'wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>[['Our BERT model', 'for', 'NQ'], ['Our BERT m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3149 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               triple_A\n",
       "0                                                    []\n",
       "1     [['sentences', 'explicitly models', 'nested , ...\n",
       "2     [['two variants', 'of', 'algorithm'], ['two va...\n",
       "3                [['greedy prediction', 'with', 'our']]\n",
       "4     [['simple importance sampling algorithm', 'whi...\n",
       "...                                                 ...\n",
       "3144  [['short and long answers', 'in', 'single mode...\n",
       "3145                                                 []\n",
       "3146  [['our model', 'from', 'BERT model'], ['our mo...\n",
       "3147  [['model', 'by', 'minimizing'], ['loss L', 'wi...\n",
       "3148  [['Our BERT model', 'for', 'NQ'], ['Our BERT m...\n",
       "\n",
       "[3149 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(data,columns=['triple_A'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "located-pound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[[4], 6]]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=[[[4],6]]\n",
    "str(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "separated-stanley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[['sentences', 'explicitly models', 'nested , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[['two variants', 'of', 'algorithm'], ['two va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[['greedy prediction', 'with', 'our']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[['simple importance sampling algorithm', 'whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>[['short and long answers', 'in', 'single mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>[['our model', 'from', 'BERT model'], ['our mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>[['model', 'by', 'minimizing'], ['loss L', 'wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>[['Our BERT model', 'for', 'NQ'], ['Our BERT m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3149 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               triple_A\n",
       "0                                                    []\n",
       "1     [['sentences', 'explicitly models', 'nested , ...\n",
       "2     [['two variants', 'of', 'algorithm'], ['two va...\n",
       "3                [['greedy prediction', 'with', 'our']]\n",
       "4     [['simple importance sampling algorithm', 'whi...\n",
       "...                                                 ...\n",
       "3144  [['short and long answers', 'in', 'single mode...\n",
       "3145                                                 []\n",
       "3146  [['our model', 'from', 'BERT model'], ['our mo...\n",
       "3147  [['model', 'by', 'minimizing'], ['loss L', 'wi...\n",
       "3148  [['Our BERT model', 'for', 'NQ'], ['Our BERT m...\n",
       "\n",
       "[3149 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cultural-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('A.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-jacob",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
