{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "christian-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the hyperparameter space with W&B sweep\n",
    "import logging\n",
    "from ast import literal_eval as load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import sklearn\n",
    "\n",
    "from simpletransformers.classification import (\n",
    "    ClassificationArgs,\n",
    "    ClassificationModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heated-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "df = pd.read_csv('triples.csv')\n",
    "df = df.rename(columns={'idx': 'indx'})\n",
    "df.insert(loc=0, column='idx', value=np.arange(len(df)))\n",
    "sent_num=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(arr):\n",
    "    trip_list=[]\n",
    "    ls=[]\n",
    "    for i in range(len(arr)):\n",
    "        #if arr[i,3]=='[]' or ((arr[i,3]!='[]') and (load(arr[i,3])[0][1][0]>load(arr[i,4])[0][1][0])):\n",
    "        if arr[i,4]!='[]':\n",
    "            if arr[i,3]=='[]' or ((arr[i,3]!='[]') and (load(arr[i,3])[0][1][0]>load(arr[i,4])[0][1][0])):\n",
    "                np = load(arr[i,4])[0]\n",
    "                uni_name=arr[i,1]\n",
    "                uni_name=(uni_name[0].upper()+uni_name[1:]).replace('-',' ')\n",
    "                triple=[uni_name,'has',np[0]]\n",
    "                trip_list.append(triple)\n",
    "                word_ls = arr[i,2].split(' ')\n",
    "                word_ls.insert(np[1][0], '[[')\n",
    "                word_ls.insert(np[1][1]+1, ']]')\n",
    "                unit = arr[i,1]\n",
    "                unit = (unit[0].upper()+unit[1:]).replace('-',' ')\n",
    "                unit_ls = ['[[']+(unit.split(' '))+[']]']\n",
    "                word_ls = unit_ls+[':']+word_ls\n",
    "                flg=0\n",
    "                if arr[i,8]=='[]':\n",
    "                    trip_ls = []\n",
    "                else:\n",
    "                    trip_ls = load(arr[i,8])\n",
    "                    for trip in trip_ls:\n",
    "                        if trip[1]=='has' and trip[2]==np[0]:\n",
    "                            flg=1\n",
    "                            break\n",
    "                ls.append([int(arr[i, 0]), unit, np[0], trip_ls, ' '.join(word_ls), flg])\n",
    "        #else:\n",
    "            #missed+=len(load(arr[i,8]))\n",
    "    dataframe = pd.DataFrame(ls)\n",
    "    dataframe.columns = ['idx','info_unit', 'np', 'triples', 'text', 'labels']\n",
    "    return dataframe,trip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "apparent-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.values\n",
    "df,trip_list=convert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "curious-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.manual_seed = 1\n",
    "model_args.fp16 = False\n",
    "model_args.use_multiprocessing = True\n",
    "model_args.do_lower_case = True  # when using uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cooked-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_F1(ref, pred):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "universal-custody",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1c50954f094efcb65792236d6d112f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae525cf1a60343ce8dc378f77f2a9741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'tp': 0, 'tn': 672, 'fp': 761, 'fn': 0, 'F1_score': 0, 'eval_loss': 1.573507815397655}\n"
     ]
    }
   ],
   "source": [
    "# Create a TransformerModel\n",
    "model = ClassificationModel(\n",
    "    \"bert\",\n",
    "    \"../rel/outputsD/best_model\",\n",
    "    args=model_args,\n",
    ")\n",
    "result, model_outputs, wrong_predictions = model.eval_model(df, F1_score=triple_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advisory-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(model_outputs.argmax(axis=1))\n",
    "df['preds']=preds\n",
    "df['cand']=trip_list\n",
    "df.loc[df['preds']==0,'cand']=None\n",
    "data=[]\n",
    "for i in range(sent_num):\n",
    "    temp = list(df[df['idx']==i]['cand'])\n",
    "    temp = [t for t in temp if t]\n",
    "    data.append(str(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ordinary-mills",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'greedy prediction']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'CNN']]\",\n",
       " \"[['Experimental setup', 'has', 'learning rate']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our CNN base model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'Seq2seq approach']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Ensembling and Reranking']]\",\n",
       " \"[['Results', 'has', 'Smaller mini-batch size M and gradient clipping G']]\",\n",
       " \"[['Ablation analysis', 'has', 'Larger layer size']]\",\n",
       " \"[['Results', 'has', 'results']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our Seq2seq approach']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'difference']]\",\n",
       " \"[['Results', 'has', 'LSTM +A']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'LSTM + A']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Score combination']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'bottom - up system']]\",\n",
       " \"[['Results', 'has', 'inorder system']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'in - order parser']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'Dropout']]\",\n",
       " \"[['Hyperparameters', 'has', 'learning rate']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'RNNG']]\",\n",
       " \"[['Model', 'has', 'RNNG']]\",\n",
       " '[]',\n",
       " \"[['Model', 'has', 'Both inference problems']]\",\n",
       " \"[['Hyperparameters', 'has', 'generative']]\",\n",
       " \"[['Results', 'has', 'Do the phrasal representations']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'decisions']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'which action ( a cluster merge ) available']]\",\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'Averaged word embeddings']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'mention - ranking model']]\",\n",
       " \"[['Results', 'has', 'cluster - ranking model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'our full model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'reward - rescaled max - margin loss']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our full approach']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'improvement']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'PS BL']]\",\n",
       " \"[['Hyperparameters', 'has', 'Embeddings']]\",\n",
       " \"[['Hyperparameters', 'has', 'size']]\",\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'first']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'Dropout']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'MR - LSTM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'manually defined cluster features']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'RNN performance']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'LSTM modules']]\",\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'initial learning rate']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Uh- huh']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'ASL']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'Our model reasons']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'head - finding attention mechanism']]\",\n",
       " \"[['Hyperparameters', 'has', 'word embeddings area fixed concatenation']]\",\n",
       " \"[['Hyperparameters', 'has', 'hidden states']]\",\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'features ( speaker , genre , span distance , mention width )']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'learning rate']]\",\n",
       " \"[['Hyperparameters', 'has', 'Ensembling']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'most significant gains']]\",\n",
       " \"[['Ablation analysis', 'has', 'distance between']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'independent variant']]\",\n",
       " \"[['Model', 'has', 'overlap variant']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'GAP']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'BERT - large']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'decoder']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'Li']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'size']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Ablation analysis', 'has', 'comparison']]\",\n",
       " \"[['Ablation analysis', 'has', 'Scores of Hierarchical -k']]\",\n",
       " \"[['Ablation analysis', 'has', 'our best model']]\",\n",
       " \"[['Ablation analysis', 'has', 'Our hierarchical models']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Ablation analysis', 'has', 'Our hierarchical models']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'decoder']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Tasks', 'has', 'Encoder ( decoder ) embeddings and hidden dimensions']]\",\n",
       " \"[['Results', 'has', 'GCN model']]\",\n",
       " \"[['Results', 'has', 'GCN EC model']]\",\n",
       " \"[['Baselines', 'has', 'GCN EC']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Ablation analysis', 'has', 'Residual and dense connections']]\",\n",
       " \"[['Ablation analysis', 'has', 'Dense connections']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'Reconstructor - based pragmatic system']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'Input feeding']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'NCP']]\",\n",
       " \"[['Results', 'has', 'NCP']]\",\n",
       " \"[['Results', 'has', 'NCP + CC']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', '84.5 %']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'CS precision']]\",\n",
       " \"[['Results', 'has', 'NCP']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'text planner']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'pretrained embeddings']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'BestPlan']]\",\n",
       " \"[['Results', 'has', 'BestPlan']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'TGen']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'EDA_CS TL']]\",\n",
       " \"[['Results', 'has', 'baseline model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'Word embeddings']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'BiLSTM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'parsers']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'word and POS embeddings e ( w i ) and e ( p i )']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Dynamic oracle training']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'Early stopping']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'BiLSTM - CRF']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'all parsers']]\",\n",
       " \"[['Results', 'has', 'Impact of parsing']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'STACKPTR parser']]\",\n",
       " \"[['Model', 'has', 'STACKPTR parser']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'Parameter optimization']]\",\n",
       " \"[['Hyperparameters', 'has', 'learning rate']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 're-implementation']]\",\n",
       " \"[['Results', 'has', 'Our model']]\",\n",
       " \"[['Results', 'has', 'STACKPTR']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'tritraining']]\",\n",
       " \"[['Results', 'has', 'tri-training']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'resulting parser']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'error - exploring dynamic - oracle training']]\",\n",
       " \"[['Hyperparameters', 'has', 'Flattening']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'outperform']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Ablation analysis', 'has', 'directly optimizing']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our local model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Tasks', 'has', 'our accuracy']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Tagspace model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Approach', 'has', 'first method']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'Fine-tune ( Ft )']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'our framework']]\",\n",
       " \"[['Results', 'has', 'experment results']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'weights']]\",\n",
       " \"[['Model', 'has', 'attention mechanism']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'our models']]\",\n",
       " \"[['Results', 'has', 'NABoE - full model']]\",\n",
       " \"[['Results', 'has', 'our models']]\",\n",
       " \"[['Results', 'has', 'NABoE - full model']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'our attention mechanism']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'our attention mechanism']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'all word embeddings']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'recommended N']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our method']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'word embedding methods']]\",\n",
       " \"[['Baselines', 'has', 'Retrofit method']]\",\n",
       " \"[['Results', 'has', 'Our method']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'outperforms']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'TF - IDF + LR']]\",\n",
       " \"[['Baselines', 'has', 'Logistic Regression']]\",\n",
       " \"[['Baselines', 'has', 'CNN']]\",\n",
       " \"[['Baselines', 'has', 'LSTM']]\",\n",
       " \"[['Baselines', 'has', 'Bi- LSTM']]\",\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'PV - DBOW']]\",\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'PV - DM']]\",\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'PTE']]\",\n",
       " \"[['Baselines', 'has', 'fast Text']]\",\n",
       " \"[['Baselines', 'has', 'SWEM']]\",\n",
       " \"[['Baselines', 'has', 'LEAM']]\",\n",
       " \"[['Baselines', 'has', 'Graph - CNN - C']]\",\n",
       " \"[['Baselines', 'has', 'Graph - CNN - S']]\",\n",
       " \"[['Baselines', 'has', 'Graph - CNN - F']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Text GCN']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'CNN']]\",\n",
       " \"[['Results', 'has', 'PV - DBOW']]\",\n",
       " \"[['Results', 'has', 'PV - DM']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'PTE and fast Text']]\",\n",
       " \"[['Results', 'has', 'SWEM and LEAM']]\",\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'text graph']]\",\n",
       " \"[['Baselines', 'has', 'label information']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'first layer']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'minibatch size']]\",\n",
       " \"[['Hyperparameters', 'has', 'Regularization']]\",\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'Weights']]\",\n",
       " \"[['Hyperparameters', 'has', 'discrete input']]\",\n",
       " '[]',\n",
       " \"[['Ablation analysis', 'has', 'depth']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'ShallowCNN']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Approach', 'has', 'embedding function']]\",\n",
       " \"[['Approach', 'has', 'document']]\",\n",
       " '[]',\n",
       " \"[['Approach', 'has', 'LSTM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'LSTM']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'one - hot CNN']]\",\n",
       " \"[['Results', 'has', 'previous best performance']]\",\n",
       " \"[['Results', 'has', 'Our oh - 2 LSTMp']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'pre-trained wv - LSTM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'LSTM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'best supervised results']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'Batch sizes']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'our proposed method']]\",\n",
       " \"[['Results', 'has', 'Our unidirectional LSTM model']]\",\n",
       " \"[['Results', 'has', 'Adversarial training']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'CNN']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'Binary']]\",\n",
       " \"[['Baselines', 'has', 'methods']]\",\n",
       " \"[['Experimental setup', 'has', 'our model']]\",\n",
       " \"[['Baselines', 'has', 'features after convolution and']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'word vector layer and the LSTM layer']]\",\n",
       " '[]',\n",
       " \"[['Experimental setup', 'has', 'word vector layer and the LSTM layer']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our result']]\",\n",
       " \"[['Results', 'has', 'Our result']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'all processing']]\",\n",
       " \"[['Experimental setup', 'has', 'character embedding']]\",\n",
       " \"[['Experimental setup', 'has', 'Training']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our deep architecture']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'most important decrease']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'design']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Hyperparameters', 'has', 'dimension']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'BLSTM - 2DCNN model']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'BLSTM - 2DPooling']]\",\n",
       " \"[['Results', 'has', 'BLSTM - CNN']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'BLSTM-2DCNN']]\",\n",
       " \"[['Results', 'has', 'Ada Sent']]\",\n",
       " \"[['Results', 'has', 'DRNN']]\",\n",
       " \"[['Baselines', 'has', 'CNN -nonstatic / MC']]\",\n",
       " \"[['Baselines', 'has', 'Molding - CNN']]\",\n",
       " \"[['Baselines', 'has', 'MVCNN']]\",\n",
       " '[]',\n",
       " \"[['Baselines', 'has', 'S- LSTM']]\",\n",
       " \"[['Baselines', 'has', 'LSTM / BLSTM / Tree-LSTM']]\",\n",
       " \"[['Baselines', 'has', 'LSTMN']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'best accuracy']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'non-neural LR and SVM baselines']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Our model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'Temporal Depthwise Separable Convolutions ( TD - SCs )']]\",\n",
       " \"[['Model', 'has', 'Global Average Pooling ( GAP )']]\",\n",
       " \"[['Experimental setup', 'has', 'training']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'network reduction']]\",\n",
       " \"[['Results', 'has', 'performance difference']]\",\n",
       " \"[['Results', 'has', 'base property']]\",\n",
       " \"[['Results', 'has', 'performance']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'All approaches']]\",\n",
       " \"[['Results', 'has', 'outperforms']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Ablation analysis', 'has', 'Out - Of - Vocabulary ( OOV ) words']]\",\n",
       " '[]',\n",
       " \"[['Ablation analysis', 'has', 'Dropout regularization']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'LEAM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'HDLTex']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'Stacking Support Vector Machines ( SVM )']]\",\n",
       " '[]',\n",
       " \"[['Results', 'has', 'CNN']]\",\n",
       " \"[['Results', 'has', 'SVM with term weighting']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Results', 'has', 'Document classification']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'fullyconnected ( FC ) layer']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Model', 'has', 'word - level encoder']]\",\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "middle-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(data,columns=['triple_D'])\n",
    "data.to_csv('D.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-grace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
