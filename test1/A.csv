triple_A
[]
"[['sentences', 'explicitly models', 'nested , hierarchical relationships'], ['nested , hierarchical relationships', 'among', 'words and phrases']]"
"[['two variants', 'of', 'algorithm'], ['two variants', 'one for', 'parsing'], ['algorithm', 'one for', 'parsing']]"
"[['greedy prediction', 'with', 'our']]"
"[['simple importance sampling algorithm', 'which uses', 'samples'], ['samples', 'from', 'discriminative parser'], ['samples', 'to solve', 'inference problems'], ['discriminative parser', 'to solve', 'inference problems'], ['inference problems', 'in', 'generative model']]"
[]
"[['training', 'used', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', 'learning rate'], ['learning rate', 'of', '0.1']]"
[]
[]
[]
"[['both directions', 'of', 'large language - model - inspired self - attention cloze model']]"
"[['cloze - style training objective', 'where', 'model'], ['model', 'must predict', 'center word'], ['center word', 'given', 'left - to - right and right - to - left context representations']]"
[]
"[['CNN', 'use', 'adaptive softmax'], ['adaptive softmax', 'in', 'output'], ['headband', 'contains', '60K most frequent types'], ['160 K band', 'with', 'dimensionality 256'], ['160 K band', 'with', 'momentum'], ['gradients', 'if', 'norm'], ['norm', 'exceeds', '0.1']]"
"[['linearly warmed up', 'from', '10 ? 7 to 1'], ['10 ? 7 to 1', 'for', '16 K steps'], ['learning rate', 'annealed using', 'cosine learning rate schedule'], ['cosine learning rate schedule', 'with', 'single phase'], ['single phase', 'to', '0.0001']]"
"[['DGX - 1 machines', 'with', '8 NVIDIA V100 GPUs']]"
[]
"[['models', 'with', '16 bit floating point precision']]"
[]
"[['STILTs', 'in', 'aggregate']]"
[]
[]
"[['general purpose sequence - to - sequence models', 'for', 'constituency parsing']]"
[]
[]
[]
[]
[]
[]
[]
"[['standard UNK replacement', 'For', 'OOV words'], ['all the parse trees', 'transformed into', 'linearized forms'], ['linearized forms', 'which', 'POS - tag normalization'], ['linearized forms', 'include', 'standard UNK replacement'], ['linearized forms', 'include', 'POS - tag normalization'], ['standard UNK replacement', 'for', 'OOV words'], ['POS - tag normalization', 'by', 'XX - tags']]"
[]
"[['Smaller mini-batch size M and gradient clipping G', 'provided', 'better performance']]"
"[['little impact', 'on', 'performance'], ['adequate', 'in terms of', 'speed / performance trade - off']]"
"[['results', 'of', 'utilizing subword splits']]"
"[['subword information', 'as', 'features'], ['promising approach', 'for leveraging', 'subword information'], ['subword information', 'into', 'constituency parsing']]"
"[['Our Seq2seq approach', 'successfully achieved', 'competitive level'], ['competitive level', 'as', 'current']]"
[]
[]
"[['single attention model', 'gets to', '88.3'], ['ensemble of 5 LSTM', 'achieves', '90.5'], ['90.5', 'matching', 'single - model BerkeleyParser']]"
"[['single LSTM + A model', 'achieves', '92.5']]"
"[['ensemble of 5 LSTM+ A models', 'further improves', 'score'], ['score', 'to', '92.8']]"
"[['difference', 'between', 'F 1 score'], ['F 1 score', 'on', 'sentences'], ['F 1 score', 'upto', '70'], ['70', 'is', '1.3'], ['1.3', 'for', 'BerkeleyParser'], ['1.3', 'for', 'baseline LSTM'], ['1.3', 'for', '0.7']]"
"[['LSTM +A', 'shows', 'less degradation'], ['less degradation', 'with', 'length'], ['length', 'than', 'BerkeleyParser']]"
"[['word - vector embedding', 'with', 'pre-trained word vectors'], ['pre-trained word vectors', 'obtained from', 'word2 vec']]"
"[['LSTM + A', 'trained on', 'high - confidence corpus'], ['high - confidence corpus', 'achieved', 'F 1 score'], ['F 1 score', 'of', '95.7'], ['F 1 score', 'of', '84.6'], ['95.7', 'on', 'QTB'], ['95.7', 'on', '84.6'], ['84.6', 'on', 'WEB']]"
"[['Our score', 'on', 'WEB'], ['Our score', 'higher both than', 'best score'], ['in - house reimplementation', 'of', 'Berkeley Parser'], ['Berkeley Parser', 'trained on', 'human - annotated data ( 84.4 )']]"
"[['slightly higher score ( 84.8 )', 'with', 'in - house Berkeley Parser'], ['in - house Berkeley Parser', 'trained on', 'large corpus']]"
"[['95.7 score', 'of', 'LSTM + A'], ['best score', 'of', 'our'], ['best score', 'of', 'in - house BerkeleyParser ( 96.2 )'], ['LSTM + A', 'lower than', 'best score'], ['best score', 'of', 'our'], ['best score', 'of', 'in - house BerkeleyParser ( 96.2 )']]"
[]
"[['LSTM generative model ( LM )', 'use', 'pre-trained model']]"
"[['actionsynchronous beam search', 'with', 'beam size K = 100'], ['actionsynchronous beam search', 'with', 'word - synchronous beam'], ['word - synchronous beam', 'with', 'K w'], ['beam size K = 100', 'for', 'RD'], ['word - synchronous beam', 'with', 'K w']]"
"[['higher performance', 'for', 'LM model'], ['higher performance', 'when using', 'candidate list'], ['LM model', 'when using', 'candidate list'], ['candidate list', 'from', 'RD parser'], ['candidate list', 'versus', '92.79 F1'], ['93.66 F1', 'versus', '92.79 F1'], ['92.79 F1', 'on', 'development data']]"
"[['scores', 'of', 'both models'], ['score', 'of', 'either model alone'], ['score', 'of', 'either model alone']]"
"[['Score combination', 'more than compensates for', 'decrease in'], ['candidates', 'from', 'generative model']]"
"[['score combination', 'improves', 'results'], ['results', 'for', 'all models'], ['results', 'with', 'candidate augmentation'], ['all models', 'with', 'candidate augmentation'], ['candidate augmentation', 'from', 'generative models']]"
"[['PTB training data setting', 'using', 'all models'], ['all models', 'for', 'candidates and score combinations'], ['candidates and score combinations', 'is', 'best'], ['candidates and score combinations', 'achieving', '94.66 F1'], ['best', 'achieving', '94.66 F1']]"
"[['Performance', 'using', 'only the ensembled RD models'], ['single RD model', 'with', 'score combinations'], ['score combinations', 'of', 'single models']]"
"[['ensembling', 'with', 'score combination'], ['ensembling', 'achieves', 'best over all result'], ['score combination', 'achieves', 'best over all result'], ['best over all result', 'of', '94.25']]"
[]
"[['system', 'achieves', '93.6 F 1'], ['system', 'achieves', '94.2 F 1'], ['93.6 F 1', 'with', 'supervised reranking'], ['93.6 F 1', 'with', '94.2 F 1'], ['93.6 F 1', 'with', 'semi-supervised reranking'], ['94.2 F 1', 'with', 'semi-supervised reranking'], ['94.2 F 1', 'with', 'semi-supervised reranking']]"
[]
"[['novel transition system', 'for', 'constituent parsing'], ['novel transition system', 'mitigating', 'issues'], ['issues', 'of', 'bottom - up and top - down systems'], ['bottom - up and top - down systems', 'by finding', 'compromise'], ['compromise', 'between', 'bottom - up constituent information'], ['compromise', 'between', 'top - down lookahead information']]"
[]
"[['regularization hyperparameter (? = 10 ?6 )', 'use', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', '0.1 initialized learning rate'], ['0.1 initialized learning rate', 'with', '0.05 learning rate decay'], ['0.1 initialized learning rate', 'with', '0.05 learning rate decay']]"
"[['bottom - up system', 'performs', 'slightly better'], ['slightly better', 'than', 'top - down system']]"
[]
[]
"[['bottom - up parser and the top - down parser', 'have', 'similar results'], ['similar results', 'under', 'greedy setting']]"
"[['in - order parser', 'achieves', 'best results']]"
[]
"[['inorder parser', 'outperforms', 'state - of - the - art discrete parser']]"
[]
[]
"[['in - order parser', 'performs', 'best'], ['best', 'on', 'all constituent types']]"
[]
"[['trees', 'converted to', 'Stanford dependencies'], ['UAS and LAS', 'are', '95.9 % and 94.1 %']]"
"[['neural - net parse reranker', 'achieves', 'very good results'], ['very good results', 'with', 'comparatively simple architecture']]"
[]
[]
"[['Dropout', 'applied to', 'non-recurrent connections'], ['clipped', 'when', 'norm']]"
"[['learning rate', 'is', '0.25 0.85 max']]"
[]
"[['explicit modeling', 'of', 'composition']]"
"[['attention mechanism', 'find', 'headedness']]"
"[['grammars', 'without', 'nonterminal labels'], ['grammars', 'find that', 'phrasal representations'], ['phrasal representations', 'depend minimally on', 'nonterminals'], ['phrasal representations', 'providing support for', 'endocentricity hypothesis']]"
"[['probability distributions', 'designed to model', 'syntactic derivations'], ['syntactic derivations', 'of', 'sentences']]"
"[['RNNGs', 'as', 'generative probabilistic models over']]"
"[['inductive bias', 'of', 'RNNGs'], ['inductive bias', 'to test', 'linguistic hypotheses'], ['RNNGs', 'to test', 'linguistic hypotheses']]"
"[['RNNG composition function', 'with', 'novel gated attention mechanism'], ['novel gated attention mechanism', 'leading to', 'GA - RNNG'], ['novel gated attention mechanism', 'to incorporate', 'more interpretability'], ['more interpretability', 'into', 'model']]"
"[['information', 'passed through', 'compositions'], ['compositions', 'of', 'phrases ( in ? and the neural network architecture )']]"
"[['RNNG', 'samples', 'sequence of actions'], ['sequence of actions', 'to', 'construct']]"
"[['RNNG', 'uses', 'three different actions']]"
"[['RNNG', 'consists of', 'stack'], ['RNNG', 'consists of', 'list of past actions'], ['buffer', 'of', 'generated words'], ['list of past actions', 'lead to', 'current configuration']]"
"[['stack , buffer , and past actions', 'with', 'separate LSTM'], ['separate LSTM', 'for', 'each component'], ['each component', 'as', 'features'], ['features', 'to define', 'distribution'], ['distribution', 'over', 'next action to take'], ['distribution', 'conditioned on', 'full algorithmic state'], ['next action to take', 'conditioned on', 'full algorithmic state']]"
"[['Both inference problems', 'solved using', 'importance sampling procedure']]"
[]
"[['Do the phrasal representations', 'learned by', 'RN - NGs'], ['Do the phrasal representations', 'depend on', 'individual lexical heads'], ['RN - NGs', 'depend on', 'individual lexical heads']]"
[]
"[['conversion accuracy', 'better for', 'nouns ( ? 50 % error )'], ['conversion accuracy', 'much better for', 'determiners ( 30 % ) and particles ( 6 % )'], ['determiners ( 30 % ) and particles ( 6 % )', 'with respect to', 'Collins head rules']]"
"[['GA - RNNG', 'achieves', '94.2 %'], ['U - GA - RNNG', 'achieves', '93.5 %']]"
[]
"[['LSTM encoder', 'with', 'self - attentive architecture'], ['LSTM encoder', 'lead to', 'improvements'], ['self - attentive architecture', 'lead to', 'improvements'], ['improvements', 'to', 'state - of the - art discriminative constituency parser']]"
"[['parser', 'combines', 'encoder'], ['decoder', 'customized for', 'parsing']]"
"[['character LSTM', 'performs', 'better'], ['better', 'than', 'other lexical representationseven']]"
"[['score', 'of', '92.67 F1'], ['92.67 F1', 'on', 'Penn Treebank WSJ development set']]"
"[['same decode procedure', 'with', 'LSTM - based encoder'], ['LSTM - based encoder', 'achieves', 'development set score'], ['development set score', 'of', '92.24']]"
[]
"[['our model', 'learns to use', 'combination'], ['combination', 'of', 'two attention types'], ['two attention types', 'with', 'positionbased attention']]"
"[['content - based attention', 'is', 'more useful'], ['more useful', 'at', 'later layers'], ['later layers', 'in', 'network']]"
[]
[]
[]
"[['deep neural network', 'to build', 'distributed representations'], ['distributed representations', 'of', 'pairs'], ['pairs', 'of', 'coreference clusters'], ['pairs', 'of', 'coreference clusters']]"
"[['entity - level information', 'with', 'large number of learned , continuous features'], ['large number of learned , continuous features', 'instead of', 'small number of hand - crafted categorical ones']]"
"[['test time', 'builds up', 'coreference clusters'], ['coreference clusters', 'starting with', 'each mention']]"
"[['decisions', 'with', 'novel easy - first cluster - ranking procedure'], ['novel easy - first cluster - ranking procedure', 'combines', 'strengths'], ['strengths', 'of', 'cluster - ranking ( Rahman and and easy - first coreference algorithms']]"
[]
"[['learning - to - search algorithm', 'inspired by', 'SEARN'], ['SEARN', 'to train', 'our neural network']]"
"[['which action ( a cluster merge ) available', 'lead to', 'high - scoring coreference partition']]"
"[['our word embeddings', 'with', '50 dimensional ones'], ['50 dimensional ones', 'produced by', 'word2vec'], ['word2vec', 'on', 'Gigaword corpus'], ['word2vec', 'on', '64 dimensional ones'], ['Gigaword corpus', 'for', 'English']]"
"[['Averaged word embeddings', 'held', 'fixed'], ['fixed', 'during', 'training'], ['embeddings', 'used for', 'single words']]"
"[['hidden layer sizes', 'to', 'M 1 = 1000'], ['hidden layer sizes', 'minimized', 'training objective'], ['training objective', 'using', 'RMS - Prop']]"
"[['network', 'applied', 'L2 regularization'], ['L2 regularization', 'to', 'model weights'], ['dropout', 'with', 'rate'], ['rate', 'of', '0.5'], ['output', 'of', 'each hidden layer'], ['0.5', 'on', 'word embeddings'], ['output', 'of', 'each hidden layer']]"
"[['pretraining', 'crucial for', ""mentionranking model 's success""]]"
[]
"[['model performance', 'especially', 'distance and string matching features']]"
[]
[]
"[['slightly outperforms', 'using', 'left - to - right ordering'], ['left - to - right ordering', 'of', 'mentions']]"
"[['mention - ranking model', 'surpasses', 'all previous systems']]"
"[['cluster - ranking model', 'improves', 'results'], ['results', 'further across', 'both languages and all evaluation metrics']]"
"[['much more complicated cluster - ranking model', 'brings', 'fairly modest gains'], ['fairly modest gains', 'in', 'performance']]"
[]
[]
[]
"[['goal - directed endto - end deep reinforcement learning framework', 'to resolve', 'coreference']]"
"[['our policy network', 'includes', 'learning span representation'], ['learning span representation', 'scoring', 'potential entity mentions'], ['our policy network', 'generating', 'probability distribution'], ['probability distribution', 'over', 'all possible coreference linking actions'], ['all possible coreference linking actions', 'from', 'current mention']]"
"[['entropy regularization term', 'to encourage', 'exploration'], ['entropy regularization term', 'prevent', 'policy'], ['policy', 'from', 'prematurely converging'], ['prematurely converging', 'to', 'bad local optimum']]"
"[['regularized policy network parameters', 'based on', 'rewards'], ['rewards', 'associated with', 'sequences']]"
"[['learned parameters', 'for', 'initialization'], ['our model', 'use', 'learned parameters'], ['learned parameters', 'for', 'initialization']]"
"[['number of sampled trajectories N s = 100', 'tune', 'regularization parameter ?'], ['regularization parameter ?', 'expr in', '{ 10 ?5 , 10 ?4 , 0.001 , 0.01 , 0.1 , 1 }'], ['regularization parameter ?', 'set it to', '10 ? 4'], ['10 ? 4', 'based on', 'development set']]"
"[['significant improvement', 'on', 'OntoNotes benchmark']]"
"[['our base reinforced model', 'improves', 'average F 1 score'], ['average F 1 score', 'around', '2 points']]"
"[['entropy regularization', 'to encourage', 'exploration'], ['exploration', 'can improve', 'result'], ['result', 'by', '1 point']]"
"[['context - dependent ELMo embedding', 'to', 'our base model'], ['context - dependent ELMo embedding', 'can further boosts', 'performance'], ['our base model', 'can further boosts', 'performance']]"
"[[""our full model 's improvement"", 'mainly from', 'higher precision scores']]"
"[['our full model', 'achieves', 'state - of the - art performance'], ['state - of the - art performance', 'of', '73.8 % F1 - score'], ['73.8 % F1 - score', 'when using', 'ELMo and entropy regularization'], ['best F1 -score', 'of', '70.5 %'], ['70.5 %', 'when using', 'fixed word embedding']]"
[]
"[['two variants of reinforcement learning', 'to directly optimize', 'coreference system'], ['coreference system', 'for', 'coreference evaluation metrics']]"
"[['max-margin coreference objective', 'by incorporating', 'reward'], ['reward', 'associated with', 'each coreference decision'], ['reward', 'into', ""loss 's slack rescaling""]]"
[]
[]
"[['REINFORCE', 'does', 'slightly better'], ['slightly better', 'than', 'heuristic loss'], ['reward rescaling', 'performs', 'significantly better']]"
"[['training', 'optimizes', ""model 's performance""], [""model 's performance"", 'in', 'expectation'], ['training', 'at', 'test - time'], ['test - time', 'takes', 'most probable sequence'], ['most probable sequence', 'of', 'actions']]"
"[['reward - rescaled max - margin loss', 'combines', 'best of both worlds'], ['best of both worlds', 'resulting in', 'superior performance']]"
[]
"[['approximation', 'of', 'higher - order inference'], ['higher - order inference', 'uses', 'span - ranking architecture']]"
"[['coarseto - fine approach', 'learned with', 'single endto - end objective']]"
"[['maximum span width', 'from', '10 to 30 words']]"
[]
"[['3 highway LSTMs', 'instead of', '1']]"
"[['Glo Ve word embeddings', 'with', 'window size'], ['Glo Ve word embeddings', 'with', 'window size'], ['window size', 'of', '2'], ['window size', 'of', '10'], ['2', 'for', 'headword embeddings'], ['10', 'for', 'LSTM inputs'], ['10', 'for', 'LSTM inputs']]"
"[['first - order model', 'by', '0.8 F1'], ['third order model', 'provides', 'additional 0.1 F1 improvement']]"
"[['span - ranking model', 'from augmented with', 'ELMo and hyperparameter tuning'], ['span - ranking model', 'achieves', '72.3 F1']]"
"[['Our full approach', 'achieves', '73.0 F1'], ['73.0 F1', 'setting', 'new state of the art'], ['new state of the art', 'for', 'coreference resolution']]"
"[['further improvement', 'by including', 'second - order inference']]"
"[['improvement', 'largely driven by', 'over all increase'], ['over all increase', 'in', 'precision']]"
[]
[]
"[['mention - ranking model', 'for', 'coreference resolution'], ['Siamese Net', 'for learning', 'similarity'], ['similarity', 'between', 'sentences']]"
"[['representations', 'for', 'candidate and the anaphoric sentence'], ['candidate and the anaphoric sentence', 'in', 'shared space']]"
"[['joint representation', 'to calculate', 'score'], ['score', 'characterizes', 'relation']]"
[]
"[['PS BL', 'performs', 'worse'], ['worse', 'than', 'KZH13 model'], ['KZH13 model', 'on', 'ASN']]"
"[['Embeddings', 'for', 'tags'], ['values', 'drawn from', 'uniform distribution U ? 1 ? d+t , 1 ? d+t']]"
"[['size', 'of', 'LSTMs hidden states'], ['LSTMs hidden states', 'set to', '{ 100 , qlog - U ( 30 , 150 ) }']]"
"[['weight matrices', 'of', 'LSTMs'], ['LSTMs', 'with', 'random orthogonal matrices']]"
"[['feed - forward layer size', 'set to', 'value'], ['value', 'in', 'Optimization']]"
"[['our model', 'in', 'minibatches'], ['minibatches', 'using', 'Adam ( Kingma and Ba , 2015 )'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'learning rate'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'maximal batch size']]"
"[['gradients', 'by', 'global norm'], ['global norm', 'with', 'clipping value'], ['clipping value', 'in', '{ 1.0 , U ( 1 , 100 ) }']]"
"[['performs', 'on', 'devset'], ['best', 'on', 'devset']]"
"[['l 2 - regularization', 'with', '? ? { 10 ?5']]"
"[['Dropout', 'with', 'keep probability k p ? { 0.8 , U( 0.5 , 1.0 ) }'], ['input', 'with', 'k p ? U (0.8 , 1.0 )'], ['keep probability k p ? { 0.8 , U( 0.5 , 1.0 ) }', 'applied to', 'outputs'], ['outputs', 'of', 'LSTMs']]"
"[['mentionranking model ( MR - LSTM )', 'on', 'ASN corpus'], ['ASN corpus', 'using', 'default HPs']]"
"[['TAG BL', 'without even necessitating', 'HP tuning']]"
"[['HPs', 'tuned on', 'ARRAU - AA'], ['HPs', 'obtain', 'results'], ['all ablated model variants', 'perform', 'worse'], ['worse', 'than', 'full model'], ['large performance drop', 'when omitting', 'syntactic information ( tag , cut )']]"
[]
"[['more successful', 'in', 'resolving'], ['nominal', 'than', 'pronominal anaphors']]"
"[['syntactic information', 'boosts', 'performance'], ['performance', 'in', 'ARRAU - AA']]"
"[['MR - LSTM without context embedding ( ctx )', 'achieves', 'comparable s@ 2 score'], ['comparable s@ 2 score', 'with', 'variant']]"
[]
"[['representations', 'of', 'mention clusters'], ['representations', 'by embedding', 'sequentially'], ['sequentially', 'using', 'recurrent neural network']]"
"[['global representation', 'from', 'individual mentions'], ['individual mentions', 'present in', 'each cluster']]"
[]
"[['model', 'as', 'local classifier'], ['local classifier', 'with', 'fixed context']]"
[]
"[['statistically significant improvement', 'of', 'over 0.8 Co NLL points'], ['over 0.8 Co NLL points', 'over', 'previous state of the art']]"
"[['impact', 'of', 'global features and RNNs'], ['global features and RNNs', 'on', 'performance']]"
"[['RNN', 'improves', 'performance over all']]"
"[['decrease', 'for', 'both']]"
"[['significantly better', 'than', 'Avg baseline'], ['barely improves', 'over', 'mention - ranking'], ['mention - ranking', 'even with', 'oracle history']]"
"[['both precision and recall', 'when moving from', 'oracle history'], ['oracle history', 'upperbound to', 'greedy setting'], ['significant portion', 'of', 'possible performance improvement']]"
[]
"[['word embedding model', 'that learns', 'cross - sentence dependency'], ['cross - sentence dependency', 'for improving', 'end - to - end co-reference resolution ( E2E - CR )']]"
"[['cross - sentence encoder', 'for', 'end - to - end co-reference ( E2E - CR )']]"
"[['idea', 'of', 'external memory module'], ['external memory block', 'containing', 'syntactic and semantic information'], ['syntactic and semantic information', 'from', 'context sentences'], ['syntactic and semantic information', 'added to', 'standard LSTM model']]"
"[['input sentences', 'as', 'batch'], ['proposed', 'calculate', 'representations'], ['representations', 'of', 'input words'], ['input words', 'by taking', 'target sentences and context sentences'], ['target sentences and context sentences', 'into', 'consideration']]"
[]
[]
"[['LSTM modules', 'applied in', 'our model'], ['LSTM modules', 'have', '200 output units'], ['our model', 'have', '200 output units']]"
"[['ASL', 'calculate', 'cross - sentence dependency'], ['cross - sentence dependency', 'using', 'multilayer perceptron'], ['multilayer perceptron', 'with', 'one hidden layer'], ['one hidden layer', 'consisting of', '150 hidden units']]"
"[['initial learning rate', 'set as', '0.001'], ['0.001 %', 'every', '100 steps']]"
[]
"[['co-reference prediction', 'select', '250 candidate antecedents'], ['250 candidate antecedents', 'as', 'our baseline model']]"
"[['baseline model', 'achieved', '67.2 % F1 score'], ['ASL model', 'improved', 'performance'], ['performance', 'by', '0.6 %'], ['ASL model', 'achieved', '67.8 % average F1']]"
[]
"[['significantly outperform', 'encodes', 'each sentence'], ['baseline model', 'encodes', 'each sentence'], ['each sentence', 'from', 'input document']]"
"[['local inputs', 'are', 'not informative enough']]"
[]
[]
"[['entity - level representation', 'facilitates', 'end - to - end optimization']]"
"[['BERT embeddings', 'motivated by', 'impressive empirical performance'], ['impressive empirical performance', 'of', 'BERT']]"
"[['BERT', 'in', 'fully convolutional manner']]"
"[['BERT', 'for', 'task of coreference resolution'], ['significant improvement', 'over', 'current state - of - the - art']]"
[]
"[['span - ranking model', 'from with', 'ELMo input features and second - order span representations']]"
"[['F1', 'Replacing', 'ELMo features'], ['ELMo features', 'with', 'BERT features'], ['ELMo features', 'achieves', '76. 25 % average F1'], ['BERT features', 'achieves', '76. 25 % average F1']]"
"[['second - order span - representations', 'while using', 'BERT features'], ['BERT features', 'achieves', '76.37 % F1'], ['76.37 % F1', 'achieving', 'higher recall and lower precision'], ['higher recall and lower precision', 'on', 'all evaluation metrics']]"
"[['secondorder span representations', 'achieves', '76. 64 % average F1'], ['Entity Equalization', 'achieves', '76. 64 % average F1'], ['secondorder span representations', 'consistently achieving', 'highest F 1 score']]"
"[['new state of the art', 'for', 'coreference resolution'], ['new state of the art', 'improving', 'previous state of the art'], ['previous state of the art', 'by', '3.6 % average F1']]"
[]
"[['significantly outperforms', 'without using', 'syntactic parser or handengineered mention detector'], ['all previous work', 'without using', 'syntactic parser or handengineered mention detector']]"
"[['first state - of - the - art neural coreference resolution model', 'learned', 'end - toend'], ['end - toend', 'given', 'only gold mention clusters']]"
"[['improved significantly', 'by training', 'end - to - end neural model'], ['end - to - end neural model', 'jointly learns', 'which spans'], ['which spans', 'are', 'entity mentions']]"
"[['Our model reasons', 'directly optimizes', 'marginal likelihood']]"
"[['each span', 'which of', 'previous spans'], ['each span', 'is', 'good antecedent'], ['previous spans', 'is', 'good antecedent']]"
"[['vector embeddings', 'representing', 'spans of text'], ['spans of text', 'in', 'document'], ['vector embeddings', 'combine', 'context - dependent boundary representations'], ['context - dependent boundary representations', 'with', 'head - finding attention mechanism'], ['head - finding attention mechanism', 'over', 'span']]"
"[['head - finding attention mechanism', 'reveals', 'mentioninternal words'], ['mentioninternal words', 'contribute most to', 'coreference decisions']]"
"[['word embeddings area fixed concatenation', 'of', '300 - dimensional GloVe embeddings'], ['word embeddings area fixed concatenation', 'of', '50 - dimensional embeddings']]"
"[['hidden states', 'in', 'LSTMs'], ['hidden states', 'have', '200 dimensions'], ['LSTMs', 'have', '200 dimensions']]"
"[['speaker information', 'as', 'binary feature'], ['binary feature', 'indicating whether', 'pair of spans']]"
"[['features ( speaker , genre , span distance , mention width )', 'represented as', 'learned 20 - dimensional embeddings']]"
"[['spans', 'such that', 'maximum span width L'], ['spans', 'such that', 'maximum number of antecedents K'], ['maximum span width L', '=', '10']]"
"[['ADAM', 'for', 'learning'], ['learning', 'with', 'minibatch size'], ['minibatch size', 'of', '1']]"
"[['0.2 dropout', 'to', 'all hidden layers and feature embeddings']]"
"[['decayed', 'by', '0.1 %'], ['0.1 %', 'every', '100 steps']]"
"[['Ensembling', 'performed for both', 'span pruning'], ['Ensembling', 'performed for both', 'antecedent decisions']]"
"[['our single model', 'improves', 'state - of - the - art average F1'], ['our single model', 'improves', 'our 5 - model ensemble'], ['state - of - the - art average F1', 'by', '1.5']]"
"[['most significant gains', 'come from', 'improvements'], ['improvements', 'in', 'recall']]"
"[['spans and the width of spans', 'are', 'crucial signals'], ['crucial signals', 'for', 'coreference resolution']]"
"[['oracle mentions', 'see', 'improvement'], ['improvement', 'of', '17.5 F1']]"
[]
"[['spans', 'with', '2 - 5 words'], ['75 - 90 %', 'of', 'predictions'], ['predictions', 'are', 'constituents']]"
[]
"[['BERT', 'to', 'coreference resolution'], ['BERT', 'achieving', 'strong improvements'], ['coreference resolution', 'achieving', 'strong improvements'], ['strong improvements', 'on', 'OntoNotes ( + 3.9 F1 ) and'], ['strong improvements', 'on', 'GAP ( + 11.5 F1 ) benchmarks']]"
"[['two ways', 'of', 'extending']]"
"[['independent variant', 'uses', 'non-overlapping segments'], ['non-overlapping segments', 'acts as', 'independent instance'], ['independent instance', 'for', 'BERT']]"
"[['overlap variant', 'splits', 'document'], ['document', 'into', 'overlapping segments'], ['overlapping segments', 'so as to provide', 'model'], ['model', 'with', 'context'], ['context', 'beyond', '512 tokens']]"
[]
"[['BERT - large', 'benefits from using', 'longer context windows ( 384 word pieces )'], ['BERT - base', 'performs', 'better'], ['better', 'with', 'shorter contexts ( 128 word pieces )']]"
"[['original Tensorflow implementations', 'of', 'c 2f - coref 3 and BERT']]"
"[['all models', 'on', 'OntoNotes English data'], ['OntoNotes English data', 'for', '20 epochs'], ['20 epochs', 'using', 'dropout'], ['20 epochs', 'using', 'learning rates'], ['dropout', 'of', '0.3'], ['learning rates', 'of', '1 10 ?5 and 2 10 ? 4'], ['1 10 ?5 and 2 10 ? 4', 'with', 'linear decay'], ['1 10 ?5 and 2 10 ? 4', 'with', 'task parameters'], ['linear decay', 'for', 'BERT parameters']]"
"[['separate models', 'with', 'max segment len'], ['max segment len', 'of', '128 , 256 , 384 , and 512'], ['128 and 384 word pieces', 'performed', 'best'], ['best', 'for', 'BERT - base']]"
"[['span representations', 'using', 'attention'], ['attention', 'for', 'higher - order reasoning']]"
"[['GAP', 'is', 'human - labeled corpus'], ['human - labeled corpus', 'of', 'ambiguous pronoun - name pairs'], ['ambiguous pronoun - name pairs', 'derived from', 'Wikipedia snippets']]"
"[['GAP dataset', 'fit within', 'single BERT segment']]"
"[['BERT - based c 2f - coref model', 'on', 'OntoNotes']]"
"[['BERT', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', '9 % and 11.5 %'], ['9 % and 11.5 %', 'for', 'base and large models']]"
[]
"[['BERT - base', 'offers', 'improvement'], ['improvement', 'of', '0.9 %'], ['0.9 %', 'over', 'ELMo - based c2 fcoref model']]"
"[['BERT - large', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', 'much larger margin'], ['much larger margin', 'of', '3.9 %']]"
"[['overlap variant', 'offers', 'no improvement'], ['no improvement', 'over', 'independent']]"
"[['span representations', 'achieving', 'state of the art results ( Avg. F1 79.6 )'], ['state of the art results ( Avg. F1 79.6 )', 'with', 'independent variant']]"
"[['BERT - large', 'improves over', 'BERT - base']]"
"[['Longer documents', 'in', 'OntoNotes'], ['Longer documents', 'contain', 'larger and more spread - out clusters'], ['OntoNotes', 'contain', 'larger and more spread - out clusters']]"
"[['more effectively encoding document - level context', 'using', 'sparse representations']]"
[]
[]
[]
"[['decoder', 'generates', 'words']]"
"[['new structured - data encoder', 'assuming that', 'structures'], ['structures', 'should be', 'hierarchically captured']]"
"[['encoding', 'of', 'data - structure'], ['decoder', 'chosen to be', 'classical module']]"
"[['two - level architecture', 'first encoding', 'all entities'], ['all entities', 'on the basis of', 'their elements'], ['data structure', 'on the basis of', 'its entities'], ['Transformer encoder', 'in', 'data - to - text models'], ['data - to - text models', 'to ensure', 'robust encoding'], ['robust encoding', 'of', 'each element / entities'], ['each element / entities', 'in comparison to', 'all others'], ['two - level architecture', 'integrate', 'hierarchical attention mechanism'], ['hierarchical attention mechanism', 'to compute', 'hierarchical context'], ['hierarchical context', 'fed into', 'decoder']]"
"[['Li', 'is', 'standard encoder - decoder'], ['standard encoder - decoder', 'with', 'delayed copy mechanism'], ['placeholders', 'replaced by', 'salient records'], ['salient records', 'extracted from', 'table'], ['table', 'by', 'pointer network']]"
"[['standard encoder - decoder', 'with', 'added module'], ['added module', 'aimed at updating', 'record representations'], ['record representations', 'during', 'generation process']]"
[]
"[['two - layers multi-head self - attention', 'with', 'two heads']]"
"[['small number of record keys', 'in', 'our dataset'], ['embedding size', 'fixed to', '20']]"
"[['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['Transformer encoders', 'set to', '300']]"
"[['dropout', 'at', 'rate 0.5']]"
"[['batch size', 'of', '64']]"
"[['initial learning rate', 'is', '0.001'], ['initial learning rate', 'reduced by', 'half'], ['half', 'every', '10 K steps']]"
"[['beam search', 'with', 'beam size'], ['beam size', 'of', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]"
[]
[]
"[['comparison', 'between', 'scenario Hierarchical - kv and Hierarchical -k'], ['scenario Hierarchical - kv and Hierarchical -k', 'omitting', 'entirely the influence'], ['entirely the influence', 'of', 'record values'], ['record values', 'in', 'attention mechanism'], ['attention mechanism', 'is', 'more effective']]"
"[['Scores of Hierarchical -k', 'are', 'sharp'], ['scores of Hierarchical - kv', 'are', 'more'], ['sharp', 'with', 'all of the weight'], ['all of the weight', 'on', 'correct record'], ['scores of Hierarchical - kv', 'distributed over', 'all PTS QTR records'], ['more', 'distributed over', 'all PTS QTR records']]"
"[['Hierarchical -k', 'reaching', '17.5 vs. 16.5'], ['17.5 vs. 16.5', 'against', 'best baseline']]"
"[['Our hierarchical models', 'achieve', 'significantly better scores'], ['significantly better scores', 'on', 'all metrics']]"
"[['only 75 . 62 %', 'of', 'precision']]"
"[['Transformer architecture', 'is', 'promising way'], ['Transformer architecture', 'to implicitly account for', 'data structure'], ['promising way', 'to implicitly account for', 'data structure']]"
"[['two - step decoders', 'of', 'Li and Puduppully - plan'], ['Li and Puduppully - plan', 'on', 'BLEU and all qualitative metrics']]"
"[['precision', 'at', 'factual mentions'], ['baseline Puduppully - plan', 'reaches', '34.28 mentions']]"
"[['Puduppully - updt', 'shows', 'dynamically updating'], ['encoding', 'across', 'generation process'], ['encoding', 'lead to', 'better Content Ordering ( CO )']]"
"[['saliency', 'among', 'records / entities']]"
"[['hierarchical encoder', 'for', 'structured data'], ['structure', 'to form', 'efficient representation'], ['efficient representation', 'of', 'its input'], ['strong synergy', 'with', 'hierarchical attention'], ['hierarchical attention', 'of', 'its associated decoder']]"
[]
"[['inputs', 'are', 'structured meaning representations ( MRs )']]"
"[['neural ensemble natural language generator', 'train and test on', 'three large unaligned datasets'], ['three large unaligned datasets', 'in', 'restaurant , television , and laptop domains']]"
"[['our ensemble model', 'using', 'seq2seq framework'], ['seq2seq framework', 'for', 'TensorFlow']]"
"[['bidirectional LSTM encoder', 'with', '512 cells per layer']]"
"[['decoder', 'was', '4 - layer RNN decoder'], ['4 - layer RNN decoder', 'with', '512 LSTM cells per']]"
"[['different beam search parameters', 'settled on', 'beam width of 10']]"
"[['length penalty', 'providing', 'best results'], ['best results', 'on', 'E2E dataset'], ['E2E dataset', 'was', '0.6'], ['TV and Laptop datasets', 'was', '0.9 and 1.0']]"
[]
"[['both the LSTM and the CNN models', 'benefit from', 'additional pseudo - samples'], ['additional pseudo - samples', 'in', 'training set']]"
"[['ensembling approach', 'reveals', 'reranking predictions'], ['reranking predictions', 'pooled from', 'different models'], ['different models', 'produces', 'ensemble model'], ['ensemble model', 'that is', 'over all more robust'], ['over all more robust', 'than', 'individual submodels']]"
"[['CNN model', 'surpassed', 'two LSTM models'], ['two LSTM models', 'in the', 'ability'], ['two LSTM models', 'to realize', '"" fast food "" and "" pub "" values'], ['ability', 'to realize', '"" fast food "" and "" pub "" values']]"
"[['hybrid ensemble model', 'manages to perform', 'best'], ['best', 'in terms of', 'error rate'], ['best', 'as well as', 'naturalness']]"
"[['our ensemble model', 'performs', 'competitively'], ['competitively', 'with', 'baseline'], ['baseline', 'on', 'TV dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'by', 'wide margin'], ['Laptop dataset', 'by', 'wide margin']]"
[]
[]
"[['two generation scenarios', 'where', 'source data'], ['source data', 'is', 'graph structured']]"
"[['multi-sentence descriptions of Knowledge Base ( KB ) entities', 'namely', 'WebNLG task']]"
"[['recurrent data encoders', 'with', 'memory and gating mechanisms']]"
[]
"[['Graph Convolutional Network ( GCN ; )', 'as', 'our encoder']]"
"[['text generation from graph - structured data', 'considering as input', 'directed'], ['V', 'is', 'set']]"
[]
"[['linearised version', 'of', 'source graph']]"
"[['WebNLG baseline', 'use', 'linearis ation scripts']]"
"[['best results', 'with', 'encoder'], ['encoder', 'with', 'four GCN layers'], ['four GCN layers', 'with', 'residual connections'], ['encoder', 'with', 'four GCN layers'], ['four GCN layers', 'with', 'residual connections'], ['four GCN layers', 'with', 'residual connections']]"
"[['Encoder ( decoder ) embeddings and hidden dimensions', 'set to', '300']]"
"[['GCN model', 'is', 'more stable'], ['more stable', 'than', 'baseline'], ['baseline', 'with', 'standard deviation'], ['standard deviation', 'of', '.004 vs . 010']]"
"[['outperforms', 'that uses', 'further reinforcement learning step'], ['PKUWRITER', 'that uses', 'ensemble of 7 models'], ['PKUWRITER', 'that uses', 'further reinforcement learning step'], ['PKUWRITER', 'that uses', 'MELBOURNE'], ['further reinforcement learning step', 'by', '.047 BLEU points'], ['MELBOURNE', 'by', '.014 BLEU points']]"
"[['GCN EC', 'behind', 'ADAPT'], ['ADAPT', 'relies on', 'sub-word encoding']]"
[]
"[['impact of the number of layers and the type of skip connections', 'on', 'WebNLG dataset'], ['impact of the number of layers and the type of skip connections', 'on', 'WebNLG dataset']]"
"[['importance', 'of', 'skip connections'], ['skip connections', 'between', 'GCN layers']]"
"[['Residual and dense connections', 'lead to', 'similar results']]"
"[['Dense connections', 'produce', 'models'], ['slightly less accurate', 'than', 'residual connections']]"
[]
"[['informativeness', 'for', 'conditional text generation']]"
[]
[]
"[['concatenation', 'of', 'extracted sentences'], ['concatenation', 'used as', 'inputs'], ['extracted sentences', 'used as', 'inputs'], ['inputs', 'to', 'our models']]"
"[['pragmatic methods', 'obtain', 'improvements'], ['pragmatic methods', 'obtain', '0.2-1.8 METEOR'], ['improvements', 'of', '0.2-0.5'], ['improvements', 'of', '0.2-1.8 METEOR'], ['0.2-0.5', 'in', 'ROUGE scores'], ['0.2-1.8 METEOR', 'over', 'base S 0 model'], ['base S 0 model', 'with', 'distractor - based approach'], ['SD 1', 'outperforming', 'reconstructorbased approach S R 1']]"
[]
"[['content selection and planning', 'within', 'neural data - to - text architecture']]"
"[['each stage', 'utilize', 'beam search'], ['beam search', 'to approximately obtain', 'best results']]"
"[['Input feeding', 'employed for', 'text decoder']]"
"[['dropout', 'at', 'rate'], ['rate', 'of', '0.3']]"
"[['25 epochs', 'with', 'Adagrad optimizer'], ['learning rate decay', 'selected from', '{ 0.5 , 0.97 }']]"
"[['text decoding', 'made use of', 'BPTT'], ['truncation size', 'to', '100']]"
"[['beam size', 'to', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]"
[]
"[['NCP', 'improves upon', 'vanilla encoderdecoder models ( ED + JC , ED + CC )']]"
"[['NCP', 'achieves', 'comparable scores'], ['comparable scores', 'with', 'joint or conditional copy mechanism']]"
"[['NCP + CC', 'achieves', 'best content selection and content ordering scores'], ['best content selection and content ordering scores', 'in terms of', 'BLEU']]"
"[['best reported system', 'in', 'Wiseman et al.'], ['best reported system', 'achieve', 'absolute improvement'], ['absolute improvement', 'of', 'approximately 12 %'], ['approximately 12 %', 'in terms of', 'relation generation']]"
"[['oracle system ( NCP + OR )', 'show', 'content selection and ordering'], ['content selection and ordering', 'correlate with', 'quality of'], ['content selection and ordering', 'correlate with', 'any improvements'], ['any improvements', 'in', 'our planning component'], ['any improvements', 'result in', 'better output'], ['our planning component', 'result in', 'better output']]"
"[['template - based system', 'observe', 'low BLEU and CS precision'], ['template - based system', 'obtains', 'low BLEU and CS precision']]"
"[['84.5 %', 'of', 'records'], ['records', 'in', 'NCP + CC'], ['NCP + CC', 'are', 'non-duplicates'], ['non-duplicates', 'compared to', 'obtain']]"
"[['content selection and planning', 'contribute to', 'performance improvements'], ['performance improvements', 'over', 'baseline ( ED + CC )'], ['accuracy', 'further', 'increases'], ['increases', 'when', 'both components']]"
"[['higher', 'by', '4.5 % and 2 %'], ['content selection precision and recall', 'as well as', 'content ordering'], ['higher', 'as well as', 'content ordering'], ['content ordering', 'by', '1.8 %']]"
"[['CS precision', 'higher than', '85 %'], ['CS recall', 'higher than', '93 %'], ['CO', 'higher than', '84 %']]"
"[['NCP', 'achieves', 'higher accuracy'], ['higher accuracy', 'in', 'all metrics'], ['all metrics', 'including', 'relation generation'], ['all metrics', 'including', 'content selection'], ['all metrics', 'including', 'content ordering'], ['all metrics', 'including', 'BLEU']]"
"[['NCP + CC over all', 'performs', 'best']]"
[]
"[['set of RDF triplets', 'describing', 'facts ( entities and relations'], ['fluent text', 'faithful to', 'facts']]"
"[['explicit , symbolic , text planning stage', 'whose', 'output'], ['output', 'fed into', 'neural generation system']]"
"[['text planner', 'determines', 'information structure'], ['text planner', 'expresses it', 'unambiguously']]"
[]
[]
"[['DBPedia relations to sequences', 'of', 'tokens'], ['tokens', 'by splitting on', 'underscores'], ['tokens', 'by splitting on', 'CamelCase']]"
"[['Open NMT toolkit', 'with', 'copy attn flag']]"
"[['relation tokens', 'in', 'plans'], ['tokens', 'in', 'reference texts'], ['relation tokens', 'as well as', 'tokens'], ['tokens', 'in', 'reference texts']]"
"[['best submissions', 'in', 'WebNLG challenge'], ['best', 'on', 'all categories']]"
"[['LSTM decoder', 'with', 'attention'], ['LSTM decoder', 'with', 'neural checklist model']]"
[]
"[['BestPlan', 'reduces', 'all error types'], ['all error types', 'compared to', 'StrongNeural'], ['StrongNeural', 'by', '85 % , 56 % and 90 %']]"
"[['BestPlan', 'performed', 'on - par'], ['on - par', 'with', 'StrongNeural'], ['BestPlan', 'surpassed', 'previous state - of - the - art UPF - FORGe']]"
[]
[]
[]
"[['character - level sequence - to - sequence model', 'with', 'attention mechanism'], ['attention mechanism', 'results in', 'completely neural end - to - end architecture']]"
[]
"[['two important features', 'with respect to', 'state - of - art architecture'], ['character - wise copy mechanism', 'consisting in', 'soft switch'], ['soft switch', 'between', 'generation and copy mode'], ['generation and copy mode', 'disengages', 'model'], ['model', 'to learn', 'rare and unhelpful self - correspondences'], ['state - of - art architecture', 'enhancing', 'recall'], ['internal representation capabilities', 'enhancing', 'recall']]"
"[['our system', 'using', 'PyTorch framework']]"
"[['same dimensions', 'in terms of', 'input size'], ['same dimensions', 'in terms of', 'presence of']]"
[]
"[['negative log - likelihood loss', 'using', 'teacher forcing and Adam']]"
"[['new formulation', 'of', 'P ( c )']]"
"[['beam search mechanism and a reranker', 'over', 'top k outputs'], ['beam search mechanism and a reranker', 'to dis advantage', 'utterances'], ['utterances', 'that do not verbalize', 'all the information'], ['all the information', 'contained in', 'MR']]"
"[['official code', 'provided in', 'E2E NLG Challenge website'], ['E2E NLG Challenge website', 'for', 'TGen'], ['official code', 'developed', 'our models and EDA'], ['our models and EDA', 'in', 'PyTorch'], ['our models and EDA', 'training them on', 'NVIDIA GPUs']]"
"[['our model EDA_CS', 'always obtains', 'higher metric values'], ['higher metric values', 'with respect to', 'TGen'], ['TGen', 'on', 'Hotel and Restaurant datasets'], ['TGen', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset']]"
"[['TGen', 'achieves', 'three out of five higher metrics values']]"
"[['approach', 'allows to obtain', 'better performance'], ['better performance', 'with respect to', 'training'], ['training', 'in', 'standard way'], ['EDA_CS', 'in', 'standard way'], ['standard way', 'on', 'Hotel and Restaurant datasets']]"
"[['EDA_CS TL', 'shows', 'bleu increment'], ['bleu increment', 'of', 'at least 14 %'], ['at least 14 %', 'with respect to', ""TGen 's score""], [""TGen 's score"", 'when compared to', 'Hotel and Restaurant datasets']]"
"[['largely outperformed', 'by', 'all other examined methods']]"
"[['good results', 'are', 'achieved']]"
[]
[]
[]
"[['j PTDP v1.0', 'with', '2.5 + % LAS improvements'], ['2.5 + % LAS improvements', 'on', 'universal dependencies ( UD ) treebanks']]"
[]
"[['DYNET v2.0', 'with', 'fixed random seed']]"
"[['Word embeddings', 'initialized', 'randomly'], ['character and POS tag embeddings', 'are', 'randomly initialized']]"
"[['learning character - level word embeddings', 'use', 'one - layer BiLSTM seq'], ['learning character - level word embeddings', 'set', 'size'], ['size', 'of', 'LSTM hidden states'], ['LSTM hidden states', 'to be equal to', 'vector size of']]"
"[['dropout', 'with', '67 % keep probability'], ['67 % keep probability', 'to', 'inputs of BiLSTMs and MLPs']]"
"[['each word token', 'apply', 'appearing # ( w ) times'], ['word dropout', 'to learn', 'embedding'], ['embedding', 'for', 'unknown words'], ['embedding', 'replace', 'each word token'], ['appearing # ( w ) times', 'in', 'training set'], ['each word token', 'with', 'special "" unk "" symbol'], ['training set', 'with', 'special "" unk "" symbol'], ['special "" unk "" symbol', 'with', 'probability punk ( w )']]"
"[['objective loss', 'using', 'Adam ( Kingma and Ba , 2014 )'], ['Adam ( Kingma and Ba , 2014 )', 'with', 'initial learning rate'], ['initial learning rate', 'at', '0.001']]"
"[['training', 'run for', '30 epochs'], ['initial learning rate', 'at', 'proportion'], ['proportion', 'of', '0.5'], ['0.5', 'every', '10 epochs']]"
[]
"[['number of hidden nodes', 'in', 'MLPs'], ['number of hidden nodes', 'at', '100'], ['MLPs', 'at', '100']]"
"[['minimal grid search', 'of', 'hyper - parameters'], ['hyper - parameters', 'to select', 'number of BiLSTM pos and BiLSTM dep layers'], ['hyper - parameters', 'to select', 'size of LSTM hidden states'], ['number of BiLSTM pos and BiLSTM dep layers', 'from', '{ 1 , 2 }'], ['each layer', 'from', '{ 128 , 256 }'], ['size of LSTM hidden states', 'in', 'each layer'], ['each layer', 'from', '{ 128 , 256 }']]"
"[['number of BiLSTM layers', 'at', '2'], ['hidden states', 'at', '128'], ['hidden states', 'at', '128']]"
"[['Word embeddings', 'initialized by', '100 dimensional Glo Ve word vectors'], ['100 dimensional Glo Ve word vectors', 'pre-trained on', 'Wikipedia and Gigaword']]"
"[['minimal', 'find that', 'highest mixed accuracy'], ['highest mixed accuracy', 'on', 'development set'], ['highest mixed accuracy', 'obtained when using', '2 BiLSTM layers']]"
"[['our model', 'produces', 'very competitive parsing results']]"
"[['UAS score', 'at', '94.51 %'], ['LAS score', 'at', '92.87 %']]"
"[['Our model', 'does', 'better'], ['better', 'than', 'previous transition - based joint models'], ['similar UAS and LAS scores', 'to', 'joint model JMT']]"
"[['0.9 % lower parsing scores', 'than', 'state - of - the - art dependency parser']]"
"[['BiLSTM - and graph - based model', 'uses', 'more sophisticated attention mechanism'], ['more sophisticated attention mechanism', 'for better decoding', 'dependency arcs and relation types'], ['biaffine', 'for better decoding', 'dependency arcs and relation types']]"
"[['our model', 'with', 'biaffine attention mechanism'], ['biaffine attention mechanism', 'to investigate', 'benefit'], ['benefit', 'for', 'our model']]"
"[['POS tagging accuracy', 'at', '97.97 %'], ['POS tagging accuracy', 'on', 'test Section'], ['97.97 %', 'on', 'test Section']]"
[]
"[['joint model', 'For', 'universal POS tagging and dependency parsing'], ['each big or small treebank', 'train', 'joint model'], ['joint model', 'for', 'universal POS tagging and dependency parsing'], ['universal POS tagging and dependency parsing', 'using', 'fixed random seed']]"
"[['tokenization , word and sentence segmentation', 'predicted by', 'UD - Pipe']]"
"[['final test runs', 'carried out on', 'TIRA platform']]"
[]
"[['outperform', 'with', '2.5 + % higher average UAS and LAS F1 scores'], ['baseline UDPipe 1.2', 'with', '0.6 % absolute higher average UPOS F1 score'], ['baseline UDPipe 1.2', 'with', '2.5 + % higher average UAS and LAS F1 scores']]"
"[['"" big "" category', 'consisting of', '61 treebank test sets'], ['"" big "" category', 'obtain', '0.8 % higher'], ['"" big "" category', 'obtain', '3.1 % higher'], ['"" big "" category', 'obtain', '3.6 % higher LAS'], ['3.6 % higher LAS', 'than', 'UDPipe 1.2']]"
"[['Our ( UniMelb ) official LAS - based rank', 'is at', '14 th place'], ['baseline UDPipe 1.2', 'is at', '18 th place'], ['baseline UDPipe 1.2', 'is at', '18 th place'], ['18 th place', 'over', 'total 26 participating systems']]"
[]
"[['highest F 1 scores', 'for', 'biomedical event extraction'], ['highest F 1 scores', 'for', 'opinion analysis']]"
[]
[]
[]
"[['BiLSTMs', 'which are', 'strong and trainable sequence models']]"
"[['elements', 'in', 'sequence ( i.e. , words )'], ['contexts', 'capturing', 'element']]"
"[['concatenation', 'of', 'minimal set']]"
"[['graphbased parser', 'jointly train', 'structured - prediction model'], ['structured - prediction model', 'on top of', 'BiLSTM'], ['structured - prediction model', 'propagating', 'errors'], ['BiLSTM', 'propagating', 'errors'], ['errors', 'from', 'structured objective']]"
"[['Chinese', 'use', 'Penn Chinese Treebank 5.1 ( CTB5 )'], ['Penn Chinese Treebank 5.1 ( CTB5 )', 'using', 'train / test / dev splits'], ['train / test / dev splits', 'of with', 'gold partof - speech tags']]"
"[['parsers', 'implemented in', 'python']]"
[]
"[['LSTM variant', 'implemented in', 'PyCNN'], ['LSTM variant', 'optimize using', 'Adam optimizer']]"
[]
"[['word and POS embeddings e ( w i ) and e ( p i )', 'initialized to', 'random values'], ['word and POS embeddings e ( w i ) and e ( p i )', 'trained together with', ""rest of the parsers ' networks""]]"
"[['parsers', 'for', 'up to 30 iterations'], ['best model', 'according to', 'UAS accuracy'], ['UAS accuracy', 'on', 'development set']]"
"[['first - order graph - based parser', 'with', '2 features'], ['outperforms', 'not using', 'external resources'], ['all other systems', 'not using', 'external resources'], ['external resources', 'including', 'third - order TurboParser']]"
"[['simple ( 4 features )', 'to', 'extended ( 11 features ) feature set'], ['simple ( 4 features )', 'leads to', 'some gains in accuracy'], ['extended ( 11 features ) feature set', 'leads to', 'some gains in accuracy']]"
"[['Dynamic oracle training', 'yields', 'nice gains']]"
[]
"[['consensus', 'among', '20 randomly - initialized stack LSTM parsers'], ['consensus', 'achieving', 'nearly the best - reported performance'], ['nearly the best - reported performance', 'on', 'standard Penn Treebank Stanford dependencies task']]"
"[['ensemble', 'into', 'single FOG parser'], ['single FOG parser', 'with', 'discriminative training'], ['discriminative training', 'by defining', 'new cost function']]"
"[['cost', 'of', 'each possible attachment'], ['each possible attachment', 'from', ""ensemble 's division of votes""], ['cost', 'in', 'discriminative learning']]"
[]
"[['Our ensembles of greedy , locally normalized parsers', 'perform', 'comparably']]"
"[['cost', 'for', 'its'], ['cost', 'for', 'choice ( s )'], ['lower', 'under', 'Hamming cost']]"
"[['per-epoch learning rate decay', 'of', '0.05'], ['0.05', 'to', 'Adam optimizer']]"
"[['Adam optimizer', 'automatically adjusts', 'global learning rate'], ['global learning rate', 'according to', 'past gradient magnitudes'], ['global learning rate', 'find', 'additional per-epoch decay'], ['additional per-epoch decay', 'consistently improves', 'performance'], ['performance', 'across', 'all settings and languages']]"
"[['standard splits', 'for', 'all languages']]"
"[['German', 'use', 'predicted tags'], ['predicted tags', 'provided by', 'CoNLL 2009 shared task organizers']]"
"[['English', 'used', 'Gigaword corpus and 100 dimensions']]"
"[['Adam optimizer', 'use', 'default settings'], ['default settings', 'in', 'CNN neural network library']]"
"[['same model', 'with', 'distillation cost'], ['distillation cost', 'gives', 'consistent improvements'], ['consistent improvements', 'for', 'all languages']]"
"[['model', 'trained with', 'Hamming cost'], ['Hamming cost', 'achieved', '93.1 UAS and 90.9 LAS'], ['93.1 UAS and 90.9 LAS', 'compared to', '93.6 UAS and 91.1 LAS'], ['93.6 UAS and 91.1 LAS', 'for', 'model']]"
[]
[]
"[['Stanford - Biaffine', 'utilizes', 'pre-trained word embeddings'], ['pre-trained word embeddings', 'employ', '200 dimensional pre-trained word vectors']]"
"[['grid search', 'of', 'hyperparameters'], ['grid search', 'to select', 'number of LSTM units'], ['hyperparameters', 'to select', 'number of BiLSTM layers'], ['hyperparameters', 'to select', 'number of LSTM units'], ['number of BiLSTM layers', 'from', '{ 1 , 2 }'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }'], ['number of LSTM units', 'in', 'each layer'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }']]"
"[['Early stopping', 'applied when', 'no performance improvement'], ['no performance improvement', 'on', 'development set'], ['no performance improvement', 'obtained after', '10 contiguous epochs'], ['development set', 'obtained after', '10 contiguous epochs']]"
"[['Stanford - NNdep', 'select', 'word CutOff'], ['word CutOff', 'from', '{ 1 , 2 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['word CutOff', 'fix', 'other hyperparameters'], ['size of the', 'fix', 'other hyperparameters'], ['other hyperparameters', 'with', 'default values']]"
"[['jPTDP', 'use', '50 - dimensional character embeddings'], ['50 - dimensional character embeddings', 'fix', 'initial learning rate'], ['initial learning rate', 'at', '0.0005']]"
"[['number of BiLSTM layers', 'at', '2'], ['number of LSTM units', 'in', 'each layer'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }']]"
[]
"[['Corpus - level accuracy differences', 'of', 'at least 0.17 %'], ['Corpus - level accuracy differences', 'of', '0.26 %'], ['at least 0.17 %', 'in', 'GENIA'], ['0.26 %', 'in', 'CRAFT'], ['0.26 %', 'between', 'two POS tagging models'], ['CRAFT', 'between', 'two POS tagging models']]"
[]
"[['six retrained models', 'produce', 'competitive results']]"
"[['BiLSTM - CRF', 'obtains', 'accuracies'], ['accuracies', 'of', '98.44 %'], ['98.44 %', 'on', 'GE - NIA'], ['98.44 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT']]"
"[['character - level word embeddings', 'helps to produce', 'about 0.5 %'], ['accuracies', 'for', 'GENIA tagger'], ['accuracies', 'for', 'MarMoT'], ['accuracies', 'for', 'NLP4J - POS'], ['accuracies', 'for', 'BiLSTM- CRF']]"
"[['CNN - based character - level word embeddings', 'provided', '0.1 % improvement'], ['0.1 % improvement', 'to', 'BiLSTM - CRF']]"
"[['GENIA', 'among', 'pre-trained models'], ['BLLIP', 'obtains', 'highest results']]"
"[['pre-trained NNdep and Biaffine models', 'result in', 'no significant performance differences'], ['no significant performance differences', 'irrespective of', 'source'], ['source', 'of', 'POS tags']]"
"[['retrained parsing models', 'on', 'GENIA and CRAFT']]"
"[['all parsers', 'produce', 'better results'], ['better results', 'for', 'shorter sentences'], ['shorter sentences', 'on', 'both corpora'], ['longer sentences', 'likely to have', 'longer dependencies']]"
[]
"[['parsers', 'trained with', 'GENIA treebank']]"
"[['four dependency parsers', 'trained on', 'GENIA'], ['four dependency parsers', 'trained on', 'jPTDP'], ['four dependency parsers', 'produce', 'similar event extraction scores'], ['similar event extraction scores', 'on', 'development set'], ['similar event extraction scores', 'on', 'test set'], ['similar event extraction scores', 'on', 'test set'], ['jPTDP and NLP4 Jdep', 'obtain', 'lowest and highest scores']]"
[]
[]
[]
"[['novel neural network architecture', 'for', 'dependency parsing']]"
"[['pointer network', 'as', 'backbone'], ['STACKPTR parser', 'equipped with', 'internal stack'], ['internal stack', 'to maintain', 'order of head words'], ['order of head words', 'in', 'tree structures']]"
"[['STACKPTR parser', 'performs', 'parsing'], ['parsing', 'in', 'incremental , topdown , depth - first fashion'], ['headword', 'at the top of', 'internal stack']]"
"[['information', 'from', 'whole sentence and all the previously derived subtrees'], ['linear', 'in', 'sentence length']]"
"[['all the parsing models', 'in', 'different languages'], ['all the parsing models', 'initialize', 'word vectors'], ['different languages', 'initialize', 'word vectors'], ['word vectors', 'with', 'pretrained word embeddings']]"
"[['Chinese , Dutch , English , German and Spanish', 'use', 'structured - skipgram embeddings']]"
"[['other languages', 'use', 'Polyglot embeddings']]"
"[['Parameter optimization', 'performed with', 'Adam optimizer'], ['Adam optimizer', 'with', '? 1 = ? 2 = 0.9'], ['Adam optimizer', 'choose', 'initial learning rate'], ['? 1 = ? 2 = 0.9', 'choose', 'initial learning rate'], ['initial learning rate', 'of', '? 0 = 0.001']]"
[]
"[['effects', 'of', '"" gradient exploding ""'], ['effects', 'of', '5.0'], ['gradient clipping', 'of', '5.0'], ['"" gradient exploding ""', 'use', 'gradient clipping'], ['gradient clipping', 'of', '5.0']]"
"[['overfitting', 'apply', 'dropout']]"
"[['BLSTM', 'use', 'recurrent dropout'], ['recurrent dropout', 'with', 'drop rate'], ['drop rate', 'of', '0.33'], ['0.33', 'between', 'hidden states'], ['0.33', 'between', '0.33'], ['0.33', 'between', 'layers']]"
"[['embedding dropout', 'with', 'rate'], ['rate', 'of', '0.33'], ['0.33', 'on', 'all word , character , and POS embeddings']]"
"[['original one', 'with', 'grandparent and sibling information'], ['different decoder inputs', 'where', 'Org model'], ['Org model', 'utilizes', 'encoder hidden states'], ['encoder hidden states', 'of', 'head words'], ['+ gpar and + sib models', 'augments', 'original one'], ['original one', 'with', 'grandparent and sibling information']]"
"[['Full model', 'achieves', 'best accuracy'], ['best accuracy', 'on', 'English and Chinese'], ['+ sib', 'on', 'German'], ['slightly worse', 'than', '+ sib'], ['+ sib', 'on', 'German']]"
"[['BIAF', 'On', 'all languages'], ['significantly outperforms', 'on', 'all languages'], ['BIAF', 'on', 'all languages'], ['all languages', 'showing', 'superiority']]"
"[['results', 'of', 'our parser'], ['our parser', 'on', 'RA'], ['results', 'slightly worse than', 'BIAF'], ['our parser', 'slightly worse than', 'BIAF']]"
"[['Our Full model', 'achieves', 'better results'], ['better results', 'than', 'most graph - based parsers']]"
"[['re-implementation', 'of', 'BIAF'], ['re-implementation', 'obtains', 'better performance'], ['BIAF', 'obtains', 'better performance'], ['better performance', 'than', 'original one']]"
"[['Our model', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'UAS and LAS'], ['state - of - the - art performance', 'on', 'Chinese'], ['state - of - the - art performance', 'on', 'best UAS'], ['UAS and LAS', 'on', 'Chinese'], ['UAS and LAS', 'on', 'Chinese']]"
"[['STACKPTR', 'tends to perform', 'better'], ['better', 'on', 'shorter sentences'], ['shorter sentences', 'make', 'fewer parsing decisions']]"
[]
"[['BIAF and STACKPTR parsers', 'achieve', 'relatively high parsing accuracies'], ['relatively high parsing accuracies', 'on', 'all the 12 languages']]"
"[['nine languages', 'outperforms', 'BIAF'], ['STACKPTR', 'outperforms', 'BIAF'], ['BIAF', 'for both', 'UAS and LAS']]"
"[['STACKPTR', 'achieves', 'slightly better UAS'], ['LAS', 'slightly worse than', 'BIAF']]"
"[['BIAF', 'obtains', 'marginally better parsing performance'], ['marginally better parsing performance', 'than', 'STACKPTR']]"
[]
[]
"[['sentences', 'processed in', 'linear left to right pass']]"
"[['arc label similarities', 'in', 'continuous space']]"
"[['representational power', 'of', 'neural networks'], ['neural networks', 'with', 'superior search'], ['superior search', 'enabled by', 'structured training and inference'], ['structured training and inference', 'making', 'our parser']]"
"[['unlabeled data', 'into', 'training'], ['accuracy', 'of', 'our model'], ['accuracy', 'to', '94.26 % UAS / 92.41 % LAS'], ['our model', 'to', '94.26 % UAS / 92.41 % LAS']]"
"[['basic structure', 'with', 'deeper architecture'], ['improvements', 'to', 'optimization procedure']]"
"[['activations', 'from', 'all layers'], ['all layers', 'of', 'neural network'], ['activations', 'as', 'representation'], ['neural network', 'as', 'representation'], ['representation', 'in', 'structured perceptron model'], ['structured perceptron model', 'trained with', 'beam search and early updates']]"
"[['large quantities', 'of', 'high - confidence parse trees'], ['high - confidence parse trees', 'by parsing', 'unlabeled data'], ['unlabeled data', 'with', 'two different parsers'], ['high - confidence parse trees', 'selecting', 'sentences'], ['two parsers', 'produced', 'same trees']]"
"[['large quantities', 'of', 'high - confidence parse trees'], ['high - confidence parse trees', 'by parsing', 'unlabeled corpus'], ['large quantities', 'selecting', 'sentences'], ['high - confidence parse trees', 'selecting', 'sentences'], ['sentences', 'on', 'two different parsers'], ['two different parsers', 'produced', 'same parse trees']]"
"[['neural network parsers', 'more than', 'models with']]"
"[['CRF - based POS tagger', 'to generate', '5 fold jack - knifed POS tags'], ['5 fold jack - knifed POS tags', 'on', 'training set and predicted tags'], ['training set and predicted tags', 'on', 'dev , test and tune sets'], ['Stanford POS tagger', 'with', '97 . 44 %']]"
"[['union', 'of', ""each corpora 's training set""]]"
"[['transition - based parser', 'with', 'beam search']]"
"[['Gaussian distribution', 'with', 'variance 10 ?4']]"
"[['fixed initialization', 'with', 'bi = 0.2'], ['fixed initialization', 'to ensure', 'most Relu units'], ['activated', 'during', 'initial rounds of training']]"
"[['word embedding matrix E word', 'initialized', 'parameters'], ['parameters', 'using', 'pretrained word embeddings']]"
"[['words', 'not appearing in', 'unsupervised data']]"
"[['Section 24', 'of', 'WSJ']]"
"[['tri-training', 'used', 'hyperparameters'], ['hyperparameters', 'of', '? = 0.2 , ? 0 = 0.05 , = 0.9'], ['roughly 16 hours', 'of', 'training time'], ['early stopping', 'after', 'roughly 16 hours'], ['roughly 16 hours', 'of', 'training time']]"
"[['M 1 = M 2 = 1024', 'For', 'standard training set'], ['M 1 = M 2 = 1024', 'For', 'tri-training setup'], ['Treebank Union setup', 'set', 'M 1 = M 2 = 1024'], ['M 1 = M 2 = 1024', 'for', 'standard training set'], ['M 1 = M 2 = 1024', 'for', 'tri-training setup']]"
[]
"[['our parser', 'outperforms', 'all dependency parsers'], ['all dependency parsers', 'in', 'our comparison'], ['all dependency parsers', 'by', 'substantial margin'], ['our comparison', 'by', 'substantial margin']]"
"[['Question ( QTB ) dataset', 'more sensitive to', 'smaller beam size'], ['smaller beam size', 'to train', 'models'], ['models', 'in', 'reasonable time'], ['B = 32', 'at', 'inference time only'], ['our perceptron performance', 'goes up to', '92.29 % LAS']]"
"[['tritraining', 'did help', 'baseline'], ['baseline', 'on', 'dev set']]"
"[['tri-training', 'helps', 'most dramatically'], ['most dramatically', 'to', 'increase'], ['accuracy', 'on', 'Treebank Union setup'], ['Treebank Union setup', 'with', 'diverse domains'], ['accuracy', 'yielding', '0.4 - 1.0 % absolute LAS improvement gains'], ['0.4 - 1.0 % absolute LAS improvement gains', 'for', 'our most accurate model']]"
"[['second hidden layer', 'results in', 'large gain'], ['large gain', 'on', 'tune set']]"
"[['our neural network model', 'training on', 'output'], ['our neural network model', 'training on', 'data'], ['data', 'where', 'two parsers agree'], ['two parsers agree', 'produces', 'significantly better results']]"
"[['greedy models', 'after', 'tri-training'], ['greedy neural network model', 'surpasses', 'BerkeleyParser'], ['BerkeleyParser', 'in', 'accuracy']]"
"[['up - training', 'improved', 'results'], ['results', 'far more than', 'tri-training'], ['tri-training', 'for', 'baseline']]"
"[['structured perceptron', 'improved', 'error rates'], ['error rates', 'on', 'some of the common and difficult labels'], ['error rates', 'improved by', '> 1 %']]"
[]
"[['neural graphbased approach', 'to achieve', 'competitive performance'], ['competitive performance', 'build', 'network'], ['network', 'uses', 'more regularization'], ['label classifier', 'with', 'biaffine ones'], ['MLP operations', 'that reduce', 'dimensionality']]"
"[['resulting parser', 'maintains', 'most of the simplicity'], ['most of the simplicity', 'of', 'neural graph - based approaches'], ['performance', 'of', 'SOTA transition - based one'], ['performance', 'of', 'SOTA transition - based one']]"
"[['deep bilinear attention mechanism', 'opposed to', 'shallow bilinear attention'], ['shallow bilinear attention', 'uses', 'recurrent states']]"
[]
"[['dropout', 'at', 'every stage'], ['nodes', 'in', 'LSTM layers ('], ['nodes', 'applying', 'same dropout mask'], ['nodes', 'in', 'MLP layers and classifiers']]"
"[['network', 'with', 'annealed Adam'], ['annealed Adam', 'for', 'about 50,000 steps'], ['about 50,000 steps', 'rounded up to', 'nearest epoch']]"
"[['outperforms', 'with respect to', 'both speed and accuracy'], ['others', 'with respect to', 'both speed and accuracy']]"
"[['model', 'with', 'shallow bilinear arc and label classifiers'], ['shallow bilinear arc and label classifiers', 'gets', 'same unlabeled performance'], ['same unlabeled performance', 'as', 'deep model'], ['deep model', 'with', 'same settings']]"
"[['three or four layers', 'gets', 'significantly better performance'], ['significantly better performance', 'than', 'two layers'], ['three or four layers', 'increasing', 'LSTM sizes'], ['LSTM sizes', 'from', '200 to'], ['LSTM sizes', 'signficantly improves', 'performance'], ['300 or 400 dimensions', 'signficantly improves', 'performance']]"
[]
[]
"[['any tags at all', 'results in', 'better performance'], ['better performance', 'than', 'using'], ['better performance', 'than', 'tags']]"
"[['Our model', 'gets', 'nearly the same UAS performance'], ['Our model', 'gets', 'SOTA UAS performance'], ['Our model', 'gets', 'SOTA performance'], ['nearly the same UAS performance', 'on', 'PTB - SD 3.3.0'], ['PTB - SD 3.3.0', 'as', 'current SOTA model'], ['Our model', 'gets', 'SOTA UAS performance'], ['SOTA UAS performance', 'on', 'CTB 5.1'], ['SOTA performance', 'on', 'all CoNLL 09 languages']]"
[]
"[['feature representation', 'able to capture', 'information'], ['information', 'from', 'entirety of the state'], ['information', 'without resorting to', 'locality assumptions']]"
"[['novel stack LSTM data structure', 'allows', 'parser'], ['parser', 'to maintain', 'constant time per-state update'], ['novel stack LSTM data structure', 'retain', 'over all linear parsing time']]"
"[['parser', 'makes', 'greedy decisions'], ['greedy decisions', 'according to', 'learned model']]"
[]
"[['algorithm states', 'sampled from', 'model'], ['algorithm states', 'sampled from', 'training data'], ['more robust predictions', 'at', 'test time']]"
"[['score', 'achieved by', 'dynamic oracle'], ['dynamic oracle', 'for', 'English'], ['dynamic oracle', 'is', '93.56 UAS'], ['English', 'is', '93.56 UAS']]"
"[['static oracle training controlling', 'for', 'transition system'], ['arc-standard system', 'when trained with', 'static oracle']]"
[]
"[['simple feed - forward networks', 'without', 'any recurrence'], ['simple feed - forward networks', 'can achieve', 'comparable or better accuracies'], ['comparable or better accuracies', 'than', 'LSTMs'], ['comparable or better accuracies', 'long as', 'globally normalized'], ['comparable or better accuracies', 'are', 'globally normalized']]"
"[['beam search', 'for', 'maintaining'], ['global normalization', 'with', 'conditional random field ( CRF ) objective'], ['conditional random field ( CRF ) objective', 'to overcome', 'label bias problem']]"
"[['gradients', 'based on', 'approximate global normalization'], ['gradients', 'perform', 'full backpropagation training'], ['full backpropagation training', 'of', 'all neural network parameters'], ['all neural network parameters', 'based on', 'CRF loss']]"
"[['previous structured training approaches', 'used for', 'neural network transitionbased parsing']]"
"[['pre-trained , state - of - the art English dependency parser', 'called', 'Parsey McParseface']]"
"[['stochastic gradient descent', 'on', 'negative log - likelihood'], ['negative log - likelihood', 'of', 'data'], ['negative log - likelihood', 'under', 'model'], ['data', 'under', 'model']]"
[]
"[['global model', 'works', 'well'], ['model', 'in', 'two steps'], ['training', 'achieves', 'same precision'], ['model', 'achieves', 'same precision'], ['network', 'using', 'local objective'], ['global model', 'perform', 'additional training steps'], ['additional training steps', 'using', 'global objective']]"
"[['averaged stochastic gradient descent', 'with', 'momentum'], ['early stopping time', 'using', 'separate held - out corpus'], ['separate held - out corpus', 'for', 'each task']]"
[]
"[['features', 'from', 'words'], ['features', 'from', 'history of predictions'], ['window of tokens', 'centered on', 'in - put'], ['window of tokens', 'as', 'features'], ['features', 'from', 'history of predictions']]"
"[['single hidden layer', 'of size', '400']]"
[]
"[['sentence compression system', 'from', '3 - layer stacked LSTM'], ['3 - layer stacked LSTM', 'uses', 'dependency label information']]"
"[['LSTM and our global model', 'perform', 'on par'], ['on par', 'on both', 'automatic evaluation'], ['our model', 'is', 'roughly 100 faster']]"
"[['All compressions', 'kept', 'approximately 42 %'], ['approximately 42 %', 'of', 'tokens']]"
"[['simple transition system', 'uses', 'SHIFT action'], ['simple transition system', 'predicts', 'POS tag'], ['POS tag', 'of', 'current word'], ['current word', 'on', 'buffer'], ['POS tag', 'shifted to', 'stack']]"
"[['window 3 tokens', 'centered at', 'current focus token']]"
"[['Our local model', 'compares', 'favorably']]"
"[['beam search', 'with', 'locally normalized model'], ['beam search', 'with', 'global normalization'], ['locally normalized model', 'does', 'help'], ['beam search', 'with', 'global normalization'], ['global normalization', 'leads to', '7 % reduction'], ['7 % reduction', 'in', 'relative error']]"
"[['set of character ngrams feature', 'is', 'very important'], ['set of character ngrams feature', 'increasing', 'average accuracy'], ['average accuracy', 'on', ""CoNLL '09 datasets""], ['average accuracy', 'by', 'about 0.5 % absolute'], [""CoNLL '09 datasets"", 'by', 'about 0.5 % absolute']]"
[]
[]
[]
[]
[]
[]
"[['bigram information', 'improves', 'performance'], ['performance', 'by', '1 - 4 %']]"
"[['our accuracy', 'slightly better than', 'char - CNN and char - CRNN'], ['our accuracy', 'bit worse than', 'VDCNN']]"
"[['accuracy slightly', 'by using', 'more n-grams'], ['more n-grams', 'for example with', 'trigrams'], ['trigrams', 'performance on', 'Sogou'], ['Sogou', 'goes up to', '97.1 %']]"
"[['tags', 'according to', 'title and caption']]"
"[['vocabulary size', 'is', '297,141']]"
"[['frequency - based baseline', 'predicts', 'most frequent tag']]"
"[['Tagspace ( Weston et al. , 2014 )', 'based on', 'Wsabie model']]"
"[['Tagspace model', 'described using', 'convolutions'], ['convolutions', 'consider', 'linear version'], ['linear version', 'achieves', 'comparable performance'], ['Tagspace model', 'is', 'much faster']]"
"[['Both', 'achieve', 'similar performance'], ['similar performance', 'with', 'small hidden layer'], ['Both', 'adding', 'bigrams'], ['bigrams', 'gives', 'significant boost'], ['significant boost', 'in', 'accuracy']]"
"[['Tagspace', 'needs to compute', 'scores'], ['scores', 'for', 'all the classes'], ['all the classes', 'makes it', 'relatively slow'], ['our fast inference', 'gives', 'significant speed - up'], ['significant speed - up', 'when', 'number of classes is large ( more than 300 K here )']]"
[]
[]
[]
[]
"[['two approaches', 'for', 'domain adaptation']]"
"[['first method', 'based on', 'masked language model ( MLM ) pre-training'], ['masked language model ( MLM ) pre-training', 'using', 'unlabeled target language corpora']]"
"[['self - training technique', 'to do', 'domain adaptation'], ['domain adaptation', 'from', 'source language'], ['source language', 'into', 'target language']]"
"[['second approach', 'as', 'basic model'], ['XLM model', 'as', 'our base model'], ['our base model', 'pre-trained by', 'large - scale parallel and monolingual data']]"
[]
[]
"[['Train - Test Discrepancy', 'of', 'UDA Method'], ['UDA Method', 'With', 'UDA algorithm']]"
"[['new classifier', 'trained only based on', 'target domain']]"
"[['XLM', 'with', 'MLM loss'], ['MLM loss', 'for', 'each target domain']]"
"[['pre-trained model', 'with', 'source - domain training set']]"
"[['Ft ( XLM ) results', 'without the help of', 'unlabeled data'], ['unlabeled data', 'from', 'target domain'], ['substantial gap', 'between', 'model performance'], ['substantial gap', 'between', 'monolingual baselines'], ['model performance', 'of', 'cross -lingual settings'], ['substantial gap', 'when using', 'state - of - the - art pre-trained cross -lingual representations']]"
"[['sentiment classification task', 'where', 'unlabeled data size'], ['unlabeled data size', 'is', 'larger'], ['Ft ( XLM ft ) model usnig MLM pre-training', 'consistently provides', 'larger improvements'], ['larger improvements', 'compared with', 'UDA method']]"
[]
"[['sentiment classification task', 'observe', 'self - training technique'], ['consistently improves', 'over', 'teacher model']]"
"[['best results', 'in', 'both XLM and XLM ft based classifiers']]"
"[['self - training', 'achieves', 'best results']]"
"[['best cross - lingual results and monolingual fine - tune baseline', 'able to', 'completely close'], ['performance gap', 'by utilizing', 'unlabeled data'], ['unlabeled data', 'in', 'target language']]"
"[['our framework', 'reaches', 'new state - of - the - art results'], ['our framework', 'improving over', 'vanilla XLM baselines'], ['new state - of - the - art results', 'improving over', 'vanilla XLM baselines'], ['vanilla XLM baselines', 'by', '44 %']]"
"[['experment results', 'lags behind', 'ones using unlabeled data'], ['ones using unlabeled data', 'from', 'target domain']]"
"[['performance', 'of', 'model'], ['improves', 'with', 'more labeled data'], ['consistently', 'with', 'more labeled data'], ['more labeled data', 'in', 'monolingual setting']]"
"[['t2t', 'is', 'best performing approach']]"
[]
"[['our model', 'achieved', 'state - of - the - art results'], ['state - of - the - art results', 'on', 'all datasets']]"
"[['text classification problem', 'by modeling', 'semantics'], ['semantics', 'in', 'target documents']]"
"[['weights', 'computed using', 'novel neural attention mechanism'], ['novel neural attention mechanism', 'that enables', 'model'], ['model', 'to focus on', 'small subset'], ['small subset', 'of', 'entities'], ['entities', 'that are', 'less ambiguous'], ['less ambiguous', 'in', 'meaning']]"
"[['attention mechanism', 'improves', 'interpretability'], ['interpretability', 'of', 'model']]"
[]
"[['embeddings', 'of', 'words ( v w ) and entities ( v e )'], ['words ( v w ) and entities ( v e )', 'using', 'pretrained embeddings'], ['pretrained embeddings', 'trained on', 'KB']]"
[]
"[['logistic regression classifier', 'with', 'features'], ['features', 'derived by', 'RNN']]"
"[['variants', 'of', 'our NABoEentity and NABoE - full models'], ['our NABoEentity and NABoE - full models', 'based on', 'Wikifier and TAGME']]"
"[['our models', 'achieved', 'enhanced performance']]"
"[['NABoE-entity model', 'achieved', 'competitive performance'], ['NABoE-entity model', 'achieved', 'outperformed'], ['outperformed', 'in', 'literature category'], ['all the baseline models', 'in', 'literature category']]"
"[['our models', 'yielded', 'enhanced over all performance'], ['enhanced over all performance', 'on', 'both datasets']]"
"[['outperformed', 'in terms of', 'both measures'], ['all baseline models', 'in terms of', 'both measures']]"
"[['all the baseline models', 'in terms of', 'both measures'], ['both measures', 'on', '20NG dataset'], ['F 1 score', 'on', 'R8 dataset']]"
[]
"[['dictionarybased entity detection', 'generally outperformed', 'models'], ['models', 'based on', 'entity linking systems'], ['entity linking systems', 'i.e.', 'Wikifier'], ['entity linking systems', 'i.e.', 'TAGME']]"
"[['our attention mechanism', 'consistently improved', 'performance'], ['performance', 'for', 'Wikifierand TAGME - based models']]"
[]
[]
"[['models', 'based on', 'entity linking systems']]"
[]
[]
"[['AI', 'combination of', 'active learning and self learning'], ['active learning and self learning', 'for', 'named entity recognition on twitter'], ['named entity recognition on twitter', 'using', 'conditional random fields learning']]"
[]
"[['task - oriented word embedding method', 'denoted as', 'ToWE']]"
[]
"[['contextual information', 'captured following', 'context prediction task']]"
"[['task information', 'regularize', 'distribution'], ['task information', 'adjust', 'distribution'], ['distribution', 'of', 'other words'], ['other words', 'in', 'embedding space']]"
"[['task - oriented word embedding method', 'specially designed for', 'text classification']]"
"[[""word 's functional attributes"", 'in', 'embedding space'], [""word 's functional attributes"", 'by regularizing', 'distribution of words'], ['embedding space', 'by regularizing', 'distribution of words'], ['distribution of words', 'to have', 'clear classification boundary']]"
"[['each document', 'as', 'bag of words'], ['weighting scheme', 'is', 'TFIDF']]"
"[['CBOW', 'predicts', 'target word'], ['target word', 'using', 'context information'], ['Skip - gram', 'predicts', 'each context word'], ['each context word', 'using', 'target word'], ['Glo Ve method', 'is', 'state - of - the - art matrix factorization method']]"
"[['text classification task', 'to evaluate', 'performance'], ['performance', 'of', 'word embeddings']]"
"[['document embedding', 'as', 'document feature'], ['document embedding', 'trained', 'linear classifier'], ['linear classifier', 'using', 'Liblinear']]"
"[['corpus', 'with', 'Stanford Tokenizer'], ['lowercase', 'removed', 'stop words']]"
"[['dimensionality', 'of', 'vectors'], ['size', 'of', 'context window'], ['vectors', 'is', '300'], ['context window', 'is', '5'], ['number of negative samples', 'is', '25']]"
[]
[]
"[['recommended N', 'is', '150'], ['150', 'with', 'constraint']]"
"[['0 to 1', 'with', 'step size'], ['step size', 'of', '0.1']]"
"[['Skip - gram and CBOW', 'reaches', 'optimal performance'], ['optimal performance', 'when', '? = 0.4 and ? = 0.3']]"
"[['Our method', 'performs', 'better'], ['better', 'than', 'other methods'], ['Our method', 'proved to', 'highly reliable'], ['highly reliable', 'for', 'text classification task']]"
"[['significantly outperforms', 'on', '20 New s Group'], ['significantly outperforms', 'on', '5 Abstract s Group'], ['other baselines', 'on', '20 New s Group'], ['other baselines', 'on', '5 Abstract s Group']]"
[]
"[['Retrofit method', 'is', 'knowledge - base enhanced word embedding method']]"
"[['Our method', 'achieves', 'better performance'], ['better performance', 'over', 'Retrofit method']]"
"[['TWE', 'achieves', 'relatively lower performance']]"
"[['TWE method', 'on', 'document - level and sentence - level tasks']]"
[]
[]
[]
"[['new graph neural networkbased method', 'for', 'text classification']]"
[]
"[['text classification problem', 'into', 'anode classification problem']]"
[]
[]
[]
[]
"[['bag - of - words model', 'with', 'term frequencyinverse document frequency weighting']]"
"[['Logistic Regression', 'used as', 'classifier']]"
[]
"[['last hidden state', 'as', 'representation'], ['representation', 'of', 'whole text']]"
[]
"[['pre-trained word embeddings', 'to', 'Bi - LSTM']]"
[]
"[['Logistic Regression', 'as', 'classifier']]"
"[['paragraph vector model', 'considers', 'word order']]"
"[['Logistic Regression', 'as', 'classifier']]"
"[['predictive text embedding', 'firstly learns', 'word embedding'], ['word embedding', 'based on', 'heterogeneous text network'], ['heterogeneous text network', 'containing', 'words , documents and labels as'], ['predictive text embedding', 'averages', 'word embeddings'], ['word embeddings', 'as', 'document embeddings'], ['document embeddings', 'for', 'text classification']]"
"[['text classification', 'treats', 'average of word / n- grams embeddings'], ['average of word / n- grams embeddings', 'as', 'document embeddings'], ['document embeddings', 'into', 'linear classifier']]"
"[['SWEM', 'employs', 'simple pooling strategies'], ['simple word embedding models', 'employs', 'simple pooling strategies'], ['simple pooling strategies', 'operated over', 'word embeddings']]"
"[['label - embedding attentive models', 'embeds', 'words and labels'], ['label - embedding attentive models', 'in', 'same joint space'], ['words and labels', 'in', 'same joint space'], ['same joint space', 'for', 'text classification']]"
"[['convolutions', 'over', 'word embedding similarity graphs']]"
[]
"[['Graph - CNN - F', 'using', 'Fourier filter']]"
"[['Text GCN', 'set', 'embedding size'], ['embedding size', 'of', 'first convolution layer'], ['first convolution layer', 'as', '200'], ['embedding size', 'set', 'window size'], ['window size', 'as', '20']]"
"[['pre-trained word embeddings', 'used', '300 dimensional Glo Ve word embeddings']]"
"[['Text GCN', 'performs', 'best and significantly outperforms']]"
"[['TF - IDF + LR', 'performs', 'well'], ['well', 'on', 'long text datasets'], ['long text datasets', 'like', '20 NG'], ['CNN', 'with', 'randomly initialized word embeddings']]"
"[['pre-trained Glo Ve word embeddings', 'provided', 'CNN'], ['CNN', 'performs', 'much better'], ['much better', 'especially on', 'Ohsumed and 20 NG']]"
"[['CNN', 'achieves', 'best results'], ['best results', 'on', 'short text dataset MR']]"
"[['PV - DBOW', 'achieves', 'comparable results'], ['comparable results', 'to', 'strong baselines'], ['strong baselines', 'on', '20 NG and Ohsumed']]"
"[['PV - DM', 'performs', 'worse'], ['worse', 'than', 'PV - DBOW']]"
"[['PV - DBOW and PV - DM', 'indicate', 'unsupervised document embeddings'], ['unsupervised document embeddings', 'are', 'not very discriminative'], ['not very discriminative', 'in', 'text classification']]"
[]
"[['SWEM and LEAM', 'perform', 'quite well']]"
"[['Graph - CNN models', 'show', 'competitive performances']]"
"[['text graph', 'can capture', 'document - word relations'], ['GCN model', 'computes', 'new features'], ['new features', 'of', 'anode'], ['new features', 'as', 'weighted average'], ['anode', 'as', 'weighted average'], ['anode', 'as', 'second order neighbors'], ['weighted average', 'of', 'itself']]"
"[['label information', 'of', 'document nodes'], ['document nodes', 'passed to', 'neighboring word nodes ( words within'], ['other word nodes and document nodes', 'thatare neighbor to', 'first step neighboring word nodes']]"
"[['CNN and LSTM - based models', 'on', 'MR']]"
"[['Text GCN', 'can achieve', 'higher test accuracy'], ['higher test accuracy', 'with', 'limited labeled documents']]"
[]
[]
"[['deep pyramid CNN ( DPCNN )', 'as', 'computation time'], ['computation time', 'per', 'layer'], ['exponentially', 'in', ""' pyramid shape""]]"
"[['discrete text', 'to', 'continuous representation'], ['DPCNN architecture', 'alternates', 'convolution block and a downsampling layer'], ['convolution block and a downsampling layer', 'over and', '1'], ['1', 'leading to', 'deep network'], ['deep network', 'in which', 'internal data size ( as well as per-layer computation )'], ['internal data size ( as well as per-layer computation )', 'shrinks in', 'pyramid shape']]"
"[['first layer', 'performs', 'text region embedding'], ['text region embedding', 'generalizes', 'commonly used word embedding'], ['commonly used word embedding', 'to', 'embedding'], ['embedding', 'of', 'text regions'], ['text regions', 'covering', 'one or more words']]"
"[['max pooling', 'for', 'all pooling layers']]"
"[['log loss', 'with', 'softmax'], ['minibatch SGD', 'with', 'momentum 0.9'], ['minibatch SGD', 'with', 'momentum 0.9'], ['momentum 0.9', 'conducted for', 'n epochs']]"
"[['minibatch size', 'fixed to', '100']]"
"[['Regularization', 'done by', 'weight decay'], ['weight decay', 'with', 'parameter 0.0001'], ['optional dropout', 'with', '0.5'], ['Regularization', 'by', 'optional dropout'], ['optional dropout', 'with', '0.5'], ['0.5', 'applied to', 'input']]"
"[['early stopping', 'after reducing', 'learning rate'], ['learning rate', 'to', '0.1']]"
"[['Weights', 'initialized by', 'Gaussian distribution'], ['Gaussian distribution', 'with', 'zero mean']]"
"[['discrete input', 'to', 'region embedding layer'], ['output dimensionality', 'to', '250'], ['region embedding layer', 'fixed to', 'bow input'], ['output dimensionality', 'fixed to', '250'], ['region size', 'chosen from', '{ 1 , 3 , 5 }'], ['region size', 'fixing', 'output dimensionality'], ['output dimensionality', 'to', '250']]"
"[['dimensionality', 'of', 'unsupervised embeddings'], ['dimensionality', 'set to', '300'], ['unsupervised embeddings', 'set to', '300']]"
"[['depth', 'of', 'DPCNN'], ['depth', 'fixed to', '15'], ['DPCNN', 'fixed to', '15']]"
"[['deeper', 'did not', 'substantially improve']]"
[]
"[['all of the previous results', 'validates', 'effectiveness']]"
[]
[]
"[['ShallowCNN', 'rivals', 'DPCNN'], ['best linear model', 'moved up from', 'worst performer'], ['worst performer', 'to', 'third best performer']]"
"[['improves', 'as', 'depth increases']]"
[]
"[['every location', 'converted to', 'low-dimensional vector'], ['low-dimensional vector', 'with', 'information'], ['information', 'relevant to', 'task being']]"
"[['embedding function', 'shared among', 'all the locations']]"
"[['document', 'represented as', 'sequence'], ['convolution layer', 'converts', 'small regions'], ['small regions', 'of', 'document'], ['region embedding results', 'to', 'document vector'], ['low-dimensional vectors', 'at', 'every location ( embedding of text regions )'], ['pooling layer', 'aggregates', 'region embedding results'], ['region embedding results', 'to', 'document vector'], ['document vector', 'by taking', 'componentwise maximum or average']]"
"[['more sophisticated region embedding', 'via', 'Long Short - Term Memory ( LSTM )'], ['Long Short - Term Memory ( LSTM )', 'seeking to overcome', 'shortcomings'], ['shortcomings', 'in', 'supervised and semi-supervised settings']]"
"[['LSTM', 'is', 'recurrent neural network']]"
"[['other methods', 'including', 'previous LSTM']]"
"[['best results', 'combining', 'two types of region embeddings ( LSTM embed - dings and CNN embeddings )'], ['two types of region embeddings ( LSTM embed - dings and CNN embeddings )', 'trained on', 'unlabeled data']]"
[]
[]
[]
[]
"[['vocabulary', 'reduced to', 'most frequent 30 K words'], ['most frequent 30 K words', 'of', 'training data'], ['most frequent 30 K words', 'to reduce', 'computational burden'], ['training data', 'to reduce', 'computational burden'], ['square loss', 'minimized with', 'dropout'], ['dropout', 'applied to', 'input to']]"
"[['20 NG', 'for', 'topic categorization of Reuters news articles and newsgroup messages']]"
"[['Optimization', 'done with', 'SGD'], ['SGD', 'with', 'mini-batch size 50 or 100'], ['mini-batch size 50 or 100', 'with', 'momentum'], ['Optimization', 'optionally', 'rmsprop'], ['SGD', 'optionally', 'rmsprop'], ['rmsprop', 'for', 'acceleration']]"
"[['our one - hot bidirectional LSTM', 'with', 'pooling ( oh - 2 LSTMp )'], ['our one - hot bidirectional LSTM', 'outperforms', 'word - vector LSTM ( wv - LSTM )'], ['pooling ( oh - 2 LSTMp )', 'outperforms', 'word - vector LSTM ( wv - LSTM )'], ['word - vector LSTM ( wv - LSTM )', 'on', 'all the datasets']]"
"[['region size 20', 'on', 'RCV1'], ['seq -CNN', 'with', 'regular concatenation input']]"
[]
[]
"[['n-gram SVM', 'is', 'no better'], ['no better', 'than', 'bag - of - word SVM']]"
"[['bags of words', 'in a', 'window of 20'], ['words', 'in a', 'strict order'], ['window of 20', 'at', 'every location'], ['window of 20', 'are', 'more useful'], ['every location', 'are', 'more useful'], ['more useful', 'than', 'words'], ['words', 'in', 'strict order']]"
"[['LSTM', 'loses to', 'bow - CNN']]"
"[['strength', 'of', 'LSTM'], ['strength', 'to embed', 'larger regions'], ['LSTM', 'to embed', 'larger regions'], ['larger regions', 'appears not to be', 'big contributor']]"
"[['one - hot CNN', 'works', 'surprising well']]"
"[['previous best performance', 'on', '20NG'], ['20NG', 'is', '15.3'], ['pre-training wv - LSTM', 'of', '1024 units'], ['DL15', 'obtained by', 'pre-training wv - LSTM'], ['pre-training wv - LSTM', 'of', '1024 units'], ['1024 units', 'with', 'labeled training data']]"
"[['Our oh - 2 LSTMp', 'achieved', '13.32']]"
"[['obtained tv-embeddings', 'to produce', 'additional input'], ['additional input', 'to', 'supervised region embedding'], ['supervised region embedding', 'of', 'one - hot CNN'], ['supervised region embedding', 'resulting in', 'higher accuracy'], ['one - hot CNN', 'resulting in', 'higher accuracy']]"
"[['clear performance improvements', 'obtained on', 'all the datasets']]"
"[['models', 'with', 'region tv-embeddings']]"
"[['wv - 2 LSTMp', 'using', 'Google News vectors'], ['Google News vectors', 'performed', 'relatively poorly']]"
"[['word2vec', 'trained with', 'domain unlabeled data'], ['better results', 'scaled', 'word vectors']]"
"[['region tv - embeddings', 'used', 'same domain unlabeled data']]"
"[['LSTM', 'rivals', 'CNN'], ['LSTM', 'rivals', 'underperforms'], ['CNN', 'on', 'IMDB / Elec'], ['underperforms', 'on', 'RCV1']]"
"[['dimensionality', 'of', 'LSTM tvembeddings'], ['LSTM tvembeddings', 'from', '100 to 300'], ['100 to 300', 'on', 'RCV1']]"
"[['error rate', 'on', 'IMDB'], ['error rate', 'on', 'RCV1'], ['error rate', 'improved from', '6.66 to'], ['IMDB', 'improved from', '6.66 to'], ['error rate', 'on', 'RCV1'], ['RCV1', 'improved from', '7.71']]"
"[['performance', 'when', 'combined']]"
"[['best supervised results', 'on', 'IMDB / Elec of JZ15a'], ['best supervised results', 'obtained by integrating', 'document embedding layer'], ['IMDB / Elec of JZ15a', 'obtained by integrating', 'document embedding layer'], ['document embedding layer', 'into', 'one - hot CNN']]"
"[['our new model', 'further improved it', '5.94'], ['our new model', 'on', 'Elec and RCV1'], ['our best models', 'exceeded', 'previous best results']]"
[]
"[['adversarial and virtual adversarial training', 'to', 'text domain'], ['perturbations', 'to', 'word embeddings'], ['adversarial and virtual adversarial training', 'by applying', 'perturbations'], ['perturbations', 'to', 'word embeddings'], ['word embeddings', 'in', 'recurrent neural network'], ['recurrent neural network', 'rather than to', 'original input itself']]"
"[['robustness', 'to', 'adversarial examples'], ['generalization performance', 'for', 'original examples']]"
"[['model', 'given', 'example'], ['same output distribution', 'produces on', 'adversarial perturbation'], ['adversarial perturbation', 'of', 'example']]"
"[['perturbation', 'on', 'continuous word embeddings'], ['continuous word embeddings', 'instead of', 'discrete word inputs']]"
"[['TensorFlow', 'on', 'GPUs']]"
[]
"[['gradient clipping', 'with', 'norm'], ['norm', 'set to', '1.0'], ['1.0', 'on', 'all the parameters'], ['all the parameters', 'except', 'word embeddings']]"
"[['runtime', 'on', 'GPU'], ['runtime', 'used', 'truncated backpropagation'], ['GPU', 'used', 'truncated backpropagation'], ['truncated backpropagation', 'up to', '400 words'], ['400 words', 'from', 'each end of the']]"
"[['regularization', 'of', 'recurrent language model'], ['regularization', 'applied', 'dropout'], ['recurrent language model', 'applied', 'dropout'], ['dropout', 'on', 'word embedding layer'], ['word embedding layer', 'with', '0.5 dropout rate']]"
"[['512 hidden units LSTM', 'For', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '512 hidden units LSTM'], ['512 hidden units LSTM', 'for', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '256 dimensional word embeddings'], ['256 dimensional word embeddings', 'shared with', 'both of the LSTMs']]"
[]
"[['optimization', 'used', 'Adam optimizer'], ['Adam optimizer', 'with', '0.0005 initial learning rate']]"
"[['Batch sizes', 'are', '64'], ['64', 'on', 'IMDB'], ['64', 'on', 'DBpedia'], ['128', 'on', 'DBpedia'], ['128', 'on', 'DBpedia']]"
"[['gradient clipping', 'with', 'norm'], ['norm', 'as', '1.0'], ['1.0', 'on', 'all the parameters'], ['all the parameters', 'except', 'word embedding']]"
[]
"[['cosine distances', 'were', '0.361 and 0.377']]"
"[['improved test performance', 'on', 'baseline method']]"
"[['results', 'on', 'RCV1']]"
"[['Adversarial training', 'able to', 'improve'], ['improve', 'over', 'baseline method'], ['almost the same performance', 'as', 'current state of the art method']]"
"[['baseline method', 'achieved', 'nearly the current state of the art performance'], ['our proposed method', 'improves from', 'baseline method']]"
[]
"[['remarkable performance', 'in', 'sentence and document modeling']]"
"[['C - LSTM', 'able to capture', 'both local features'], ['C - LSTM', 'able to capture', 'global and temporal sentence semantics'], ['both local features', 'of', 'phrases']]"
"[['CNN and LSTM', 'to', 'model sentences']]"
"[['output', 'of', 'one - layer CNN'], ['simple end - to - end , unified architecture', 'by feeding', 'output'], ['output', 'of', 'one - layer CNN'], ['one - layer CNN', 'into', 'LSTM']]"
"[['CNN', 'constructed on top of', 'pre-trained word vectors'], ['pre-trained word vectors', 'from', 'massive unlabeled text data'], ['massive unlabeled text data', 'to learn', 'higher - level representions'], ['higher - level representions', 'of', 'n-grams']]"
"[['sequential correlations', 'from', 'higher - level suqence representations'], ['feature maps', 'of', 'CNN'], ['feature maps', 'organized as', 'sequential window features'], ['CNN', 'organized as', 'sequential window features'], ['sequential window features', 'to serve', 'input'], ['input', 'of', 'LSTM']]"
"[['LSTM', 'directly from', 'input sentence'], ['LSTM', 'first transform', 'each sentence'], ['each sentence', 'into', 'successive window ( n- gram ) features'], ['successive window ( n- gram ) features', 'to help disentangle', 'factors'], ['factors', 'of', 'variations'], ['variations', 'within', 'sentences']]"
[]
"[['python library', 'supports', 'efficient symbolic differentiation'], ['python library', 'supports', 'transparent use'], ['transparent use', 'of', 'GPU']]"
"[['efficiency of parallel computation', 'of', 'tensors'], ['model', 'on', 'GPU']]"
"[['text preprocessing', 'convert', 'all characters'], ['all characters', 'in', 'dataset'], ['all characters', 'to', 'lowercase'], ['dataset', 'to', 'lowercase']]"
"[['SST', 'conduct', 'hyperparameter ( number of filters , filter length in CNN ;'], ['dropout rate and which layer to apply , etc. ) tuning', 'on', 'validation data'], ['validation data', 'in', 'standard split']]"
"[['training dataset', 'For', 'hyperparameter search'], ['TREC', 'holdout', '1000 samples'], ['1000 samples', 'from', 'training dataset'], ['1000 samples', 'for', 'hyperparameter search'], ['training dataset', 'for', 'hyperparameter search'], ['TREC', 'train', 'model'], ['model', 'using', 'remaining data']]"
[]
"[['filter size', 'investigated', 'filter lengths'], ['filter lengths', 'of', '2 , 3 and 4'], ['2 , 3 and 4', 'in', 'two cases'], ['single convolutional layer', 'with', 'same filter length'], ['multiple convolutional layers', 'with', 'different lengths of filters in parallel']]"
"[['Binary', 'is', '2 - classification task']]"
"[['methods', 'related to', 'convolutional neural networks']]"
[]
"[['sequence', 'of', 'window representations'], ['window representations', 'fed into', 'LSTM']]"
"[['different combinations', 'of', 'different filter lengths']]"
[]
"[['number of filters', 'of', 'length 3'], ['memory dimension', 'of', 'LSTM'], ['number of filters', 'set to', '150'], ['memory dimension', 'of', 'LSTM'], ['memory dimension', 'set to', '150'], ['LSTM', 'set to', '150']]"
"[['probability', 'of', '0.5']]"
"[['number of filters', 'set to', '300'], ['memory dimension', 'set to', '300']]"
"[['probability', 'of', '0.5']]"
"[['L2 regularization', 'with', 'factor'], ['factor', 'of', '0.001'], ['0.001', 'to', 'weights'], ['weights', 'in', 'softmax layer']]"
"[['binary classification task', 'achieve', 'comparable results'], ['comparable results', 'with respect to', 'state - of - the - art ones']]"
"[['single CNN and LSTM models', 'shows', 'LSTM'], ['long - term dependencies', 'across', 'sequences'], ['sequences', 'of', 'higher - level representations better']]"
"[['Our result', 'consistently outperforms', 'all published neural baseline models']]"
"[['Our result', 'close to', 'state - of - the - art SVM'], ['state - of - the - art SVM', 'depends on', 'highly engineered features']]"
"[['impact', 'of', 'different filter configurations'], ['different filter configurations', 'in', 'convolutional layer'], ['different filter configurations', 'on', 'model performance'], ['convolutional layer', 'on', 'model performance']]"
"[['multiple convolutional layers', 'shown that', 'filter configurations'], ['filter configurations', 'with', 'filter length 3'], ['filter configurations', 'performs', 'better']]"
[]
"[['text processing', 'operates directly at', 'character level']]"
[]
"[['deep architectures', 'of', 'many convolutional layers']]"
"[['proposed deep convolutional network', 'shows', 'significantly better results'], ['significantly better results', 'than', 'previous ConvNets approach']]"
"[['depth 9 to 17 and 29', 'for', 'Amazon Full'], ['depth 9 to 17 and 29', 'reduces', 'error rate'], ['Amazon Full', 'reduces', 'error rate'], ['error rate', 'by', '1 % absolute']]"
"[['our best architecture', 'with', 'depth 29 and max - pooling'], ['test error', 'of', '37.0'], ['37.0', 'compared to', '40.43 %']]"
"[['Max - pooling', 'performs', 'better'], ['better', 'than', 'other pooling types']]"
[]
"[['shortcut connections', 'observe', 'improved results'], ['improved results', 'when', 'network'], ['training and test errors', 'go', 'down']]"
"[['all processing', 'done at', 'character level'], ['character level', 'which is', 'atomic representation'], ['atomic representation', 'of', 'sentence']]"
"[['character embedding', 'of size', '16']]"
"[['Training', 'performed with', 'SGD'], ['SGD', 'using', 'mini-batch'], ['SGD', 'using', 'momentum'], ['mini-batch', 'of size', '128'], ['initial learning rate', 'of size', '0.01']]"
[]
[]
[]
"[['temporal batch norm', 'without', 'dropout']]"
"[['Our deep architecture', 'works', 'well'], ['well', 'on', 'big data sets'], ['well', 'for', 'small depths'], ['big data sets', 'for', 'small depths']]"
"[['our model', 'performs', 'better'], ['better', 'than', ""Zhang 's convolutional baselines""]]"
[]
"[['most important decrease', 'in', 'classification error'], ['most important decrease', 'observed on', 'largest data set Amazon Full'], ['classification error', 'observed on', 'largest data set Amazon Full']]"
"[['temporal max - pooling', 'works', 'best'], ['best', 'on', 'all data sets']]"
[]
[]
"[['raw signal', 'at', 'character level']]"
"[['design', 'is', 'modular'], ['design', 'where', 'gradients'], ['modular', 'where', 'gradients'], ['gradients', 'obtained by', 'back - propagation'], ['back - propagation', 'to perform', 'optimization']]"
"[['dimension', 'of', 'embedding'], ['dimension', 'is', '300'], ['embedding', 'is', '300']]"
"[['number of means', 'is', '5000']]"
[]
"[['Bidirectional Long Short - Term Memory Networks with Two - Dimensional Max Pooling ( BLSTM - 2DPooling )', 'to capture', 'features'], ['features', 'on both', 'time - step dimension'], ['features', 'on both', 'feature vector dimension']]"
"[['Bidirectional Long Short - Term Memory Networks ( BLSTM )', 'to transform', 'text'], ['text', 'into', 'vectors']]"
"[['2D max pooling operation', 'utilized to obtain', 'fixed - length vector']]"
"[['2D convolution ( BLSTM - 2DCNN )', 'to capture', 'more meaningful features'], ['more meaningful features', 'to represent', 'input text']]"
"[['combined framework', 'utilizes', 'BLSTM'], ['BLSTM', 'to capture', 'long - term sentence dependencies'], ['combined framework', 'extracts', 'features'], ['2D convolution and 2D max pooling operation', 'for', 'sequence modeling tasks']]"
"[['six text classification tasks', 'including', 'sentiment analysis'], ['six text classification tasks', 'including', 'question classification'], ['six text classification tasks', 'including', 'subjectivity classification'], ['six text classification tasks', 'including', 'newsgroups classification']]"
"[['dimension', 'of', 'word embeddings'], ['hidden units', 'of', 'LSTM'], ['dimension', 'is', '300'], ['word embeddings', 'is', '300'], ['LSTM', 'is', '300'], ['hidden units', 'of', 'LSTM'], ['hidden units', 'is', '300'], ['LSTM', 'is', '300']]"
"[['100 convolutional filters each', 'for', 'window sizes']]"
"[['mini-batch size', 'as', '10'], ['learning rate', 'of', 'AdaDelta'], ['learning rate', 'as', 'default value 1.0'], ['AdaDelta', 'as', 'default value 1.0']]"
"[['0.5', 'For', 'word embeddings'], ['0.2', 'For', 'BLSTM layer'], ['regularization', 'employ', 'Dropout operation'], ['Dropout operation', 'with', 'dropout rate'], ['dropout rate', 'of', '0.5'], ['0.5', 'for', 'word embeddings'], ['l 2 penalty', 'with', 'coefficient 10 ? 5'], ['coefficient 10 ? 5', 'over', 'parameters']]"
"[['grid search', 'on', 'SST - 1 development set']]"
"[['more finer tuning', 'such as using', 'different numbers of hidden units'], ['more finer tuning', 'such as using', 'wide convolution'], ['different numbers of hidden units', 'of', 'LSTM layer']]"
[]
"[['BLSTM - 2DCNN model', 'achieves', 'excellent performance'], ['excellent performance', 'on', '4 out of 6 tasks']]"
"[['52.4 % and 89.5 % test accuracies', 'on', 'SST - 1 and SST - 2']]"
"[['BLSTM - 2DPooling', 'performs', 'worse'], ['worse', 'than', 'state - of - the - art models']]"
"[['BLSTM - CNN', 'beats', 'all baselines'], ['all baselines', 'on', 'SST - 1 ,'], ['all baselines', 'on', 'TREC datasets']]"
"[['BLSTM - 2DCNN', 'gets', 'second higher accuracies']]"
"[['BLSTM - 2DCNN', 'achieves', 'comparable result']]"
"[['BLSTM-2DCNN', 'extension of', 'BLSTM - 2DPooling'], ['BLSTM -', 'capture', 'more dependencies'], ['more dependencies', 'in', 'text']]"
"[['Ada Sent', 'utilizes', 'more complicated model'], ['more complicated model', 'to form', 'hierarchy'], ['BLSTM - 2DCNN', 'on', 'Subj and MR datasets']]"
"[['Deep recursive neural networks', 'for', 'compositionality in language']]"
"[['Convolutional neural networks', 'for', 'sentence classification']]"
[]
"[['Multichannel variable - size convolution', 'for', 'sentence classification']]"
[]
"[['Long short - term memory', 'over', 'recursive structures']]"
[]
"[['Long short - term memory - networks', 'for', 'machine reading']]"
[]
[]
[]
"[['best accuracy', 'is', '52.6'], ['best accuracy', 'is', '2D max pooling size ( 5 , 5 )'], ['52.6', 'with', '2D filter size ( 5 , 5 )'], ['52.6', 'with', '2D max pooling size ( 5 , 5 )']]"
[]
"[['our simple model', 'able to achieve', 'results'], ['results', 'without', 'attention mechanisms']]"
[]
"[['Nvidia GTX 1080 and RTX 2080 Ti GPUs', 'with', 'PyTorch 0.4.1'], ['PyTorch 0.4.1', 'as', 'backend framework']]"
"[['Scikitlearn 0.19.2', 'for computing', 'tf - idf vectors'], ['Scikitlearn 0.19.2', 'implementing', 'LR and SVMs']]"
"[['HAN', 'use', 'batch size'], ['batch size', 'of', '32'], ['learning rate', 'of', '0.01'], ['32', 'across', 'all the datasets']]"
"[['XML - CNN', 'select', 'dynamic pooling window length'], ['XML - CNN', 'select', '128 output channels'], ['128 output channels', 'with', 'batch sizes'], ['32 and 64', 'for', 'single - label and multilabel datasets']]"
"[['KimCNN', 'use', 'batch size'], ['batch size', 'of', '64'], ['learning rate', 'of', '0.01'], ['batch size', 'with', 'learning rate'], ['64', 'with', 'learning rate'], ['learning rate', 'of', '0.01']]"
"[['LSTM reg and LSTM base', 'use', 'Adam optimizer'], ['Adam optimizer', 'with', 'learning rate'], ['Adam optimizer', 'with', '0.001'], ['learning rate', 'of', '0.01'], ['batch sizes', 'of', '32 and 64'], ['0.01', 'on', 'Reuters'], ['0.001', 'using', 'batch sizes'], ['batch sizes', 'of', '32 and 64'], ['32 and 64', 'for', 'multi-label and single - label tasks']]"
"[['LSTM reg', 'apply', 'temporal averaging ( TA )']]"
"[['default TA exponential smoothing coefficient', 'of', '? EMA'], ['default TA exponential smoothing coefficient', 'to', '0.99']]"
"[['512 hidden units', 'for', 'Bi - LSTM models'], ['Bi - LSTM models', 'whose', 'max - pooled output'], ['regularized', 'using', 'dropout rate'], ['dropout rate', 'of', '0.5']]"
"[['input-hidden and hidden - hidden Bi - LSTM connections', 'using', 'embedding dropout and weight dropping'], ['embedding dropout and weight dropping', 'with', 'dropout rates'], ['dropout rates', 'of', '0.1 and 0.2']]"
"[['optimization objective', 'use', 'crossentropy and binary cross - entropy loss'], ['crossentropy and binary cross - entropy loss', 'for', 'singlelabel and multi-label tasks']]"
"[['300 - dimensional word vectors', 'pre-trained on', 'Google News']]"
"[['all neural models', 'for', '30 epochs'], ['30 epochs', 'with', 'five random seeds'], ['five random seeds', 'reporting', 'mean']]"
"[['our simple LSTM reg model', 'achieves', 'state of the art'], ['state of the art', 'on', 'Reuters and IMDB'], ['state of the art', 'establishing', 'mean scores'], ['87.0 and 52.8', 'for', 'F 1 score']]"
"[['consistently improves', 'upon', 'performance'], ['performance', 'of', 'LSTM base'], ['regularization', 'yields', 'increases'], ['increases', 'of', '1.5 and 0.5 points'], ['1.5 and 0.5 points', 'for', 'F 1 score']]"
"[['accuracy', 'of', 'LSTM reg and our reimplemented version of HAN'], ['LSTM reg and our reimplemented version of HAN', 'to be', 'almost two points lower'], ['almost two points lower', 'than', 'copied result'], ['copied result', 'of', 'HAN']]"
"[['original result', 'by', 'nearly two points'], ['nearly two points', 'for', 'IMDB dataset']]"
"[['non-neural LR and SVM baselines', 'perform', 'remarkably well']]"
"[['SVM', 'beats', 'many neural baselines'], ['many neural baselines', 'including', 'our non-regularized LSTM base']]"
[]
[]
[]
"[['attention - based Transformer network', 'on', '40 GB of text'], ['0.69 F1 score', 'on', 'SemEval Task 1:E - c multidimensional emotion classification problem']]"
[]
"[['language model', 'across', 'large text dataset']]"
"[['contextualized word representation', 'based on', 'deep bidirectional language model'], ['deep bidirectional language model', 'trained on', 'large text corpus']]"
"[['inclusion', 'of', 'easier , more balanced label categories'], ['easier , more balanced label categories', 'improves', 'performance'], ['performance', 'on', 'harder ones']]"
"[['thresholding predictions', 'produced', 'noticeably better results'], ['noticeably better results', 'than using', 'fixed threshold value'], ['fixed threshold value', 'such as', 't * = 0.5']]"
"[['outperform', 'on', 'every emotion category'], ['Watson', 'on', 'every emotion category']]"
[]
"[['Our model', 'achieved', 'top macro-averaged F1 score'], ['top macro-averaged F1 score', 'among', 'all submission'], ['top macro-averaged F1 score', 'with', 'competitive']]"
"[['deep learning architectures', 'of', 'Transformer and m LSTM'], ['m LSTM', 'across', 'Plutchik categories']]"
[]
"[['significantly better', 'than', 'Watson API'], ['Watson API', 'on', 'all categories'], ['all categories', 'for', 'Watson'], ['Watson', 'supplies', 'predictions']]"
"[['SemEval - trained Transformer', 'directly to', 'our company tweets dataset'], ['SemEval - trained Transformer', 'gets', 'reasonably good results'], ['our company tweets dataset', 'gets', 'reasonably good results']]"
"[['rater agreement by dataset', 'see that', 'Plutchik category labels'], ['Plutchik category labels', 'contain', 'large rater dis agreement'], ['large rater dis agreement', 'among', 'vetted raters'], ['vetted raters', 'who passed', 'golden set test']]"
[]
"[['increases', 'with', 'depth']]"
"[['text classification model', 'requires', 'significantly fewer parameters'], ['significantly fewer parameters', 'compared to', 'stateof - the - art CNNs']]"
[]
[]
"[['training', 'performed with', 'SGD'], ['SGD', 'utilizing', 'size batch of 64'], ['size batch of 64', 'with', 'maximum of 100 epochs']]"
"[['initial learning rate', 'of', '0.01'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.001']]"
[]
"[['TDSCs', 'promoted', 'significant reduction'], ['significant reduction', 'in', 'convolutional parameters'], ['significant reduction', 'compared to', 'VDCNN'], ['convolutional parameters', 'compared to', 'VDCNN']]"
"[['network reduction', 'obtained by', 'GAP'], ['GAP', 'is', 'even more representative']]"
"[['performance difference', 'between', 'VDCNN and SVDCNN models'], ['performance difference', 'varies between', '0.4 and 1.3 %'], ['VDCNN and SVDCNN models', 'varies between', '0.4 and 1.3 %']]"
"[['base property', 'of', 'VDCNN model'], ['VDCNN model', 'preserved on', 'squeezed model']]"
"[['performance', 'evaluated for', 'most extensive dataset'], ['most extensive dataset', 'i.e.', 'Yelp Review'], ['accuracy', 'of', 'Char - CNN model']]"
[]
[]
"[['All approaches', 'better than', 'traditional bag - of - words method']]"
"[['state - of - the - art methods', 'on', 'two largest datasets']]"
"[['other methods', 'with', 'different proportion of labeled data']]"
"[['300 - dimensional Glo Ve word embeddings', 'as', 'initialization'], ['initialization', 'for', 'word embeddings and label embeddings'], ['word embeddings and label embeddings', 'in', 'our model']]"
"[['Out - Of - Vocabulary ( OOV ) words', 'initialized from', 'uniform distribution'], ['uniform distribution', 'with', 'range [ ? 0.01 , 0.01 ]']]"
"[[""our model 's parameters"", 'with', 'Adam Optimizer'], [""our model 's parameters"", 'with', 'initial learning rate'], [""our model 's parameters"", 'with', 'minibatch size']]"
"[['Dropout regularization', 'employed on', 'final MLP layer'], ['Dropout regularization', 'with', 'dropout rate 0.5'], ['final MLP layer', 'with', 'dropout rate 0.5']]"
[]
[]
"[['medical code prediction', 'on', 'Electronic Health Records dataset']]"
"[['multi-label classification of clinical text', 'including', 'Condensed Memory Networks ( C - MemNN )'], ['multi-label classification of clinical text', 'including', 'Attentive LSTM'], ['multi-label classification of clinical text', 'including', 'Convolutional Attention ( CAML )']]"
"[['LEAM', 'provides', 'best AUC score'], ['better F1 and P@5 values', 'than', 'all methods'], ['all methods', 'except', 'CNN']]"
"[['logistic regression baseline', 'performs', 'worse'], ['worse', 'than', 'all deep learning architectures']]"
[]
[]
[]
[]
[]
"[['HDLTex', 'combines', 'deep learning architectures'], ['deep learning architectures', 'to allow', 'over all and specialized learning'], ['over all and specialized learning', 'by', 'level of the document hierarchy']]"
[]
"[['document classification', 'taken from', 'deep learning']]"
"[['deep learning approaches', 'to create', 'hierarchical document classification approach']]"
[]
[]
[]
"[['processing', 'done on', 'Xeon E5 ? 2640 ( 2.6 GHz )'], ['processing', 'done on', 'GPU cards'], ['processing', 'done on', 'N vidia Tesla K20c'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '32 cores'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '64GB memory'], ['GPU cards', 'were', 'N vidia Quadro K620'], ['GPU cards', 'were', 'N vidia Tesla K20c']]"
"[['CNN', 'performs', 'secondbest'], ['secondbest', 'for', 'three data sets']]"
"[['SVM with term weighting', 'is', 'third']]"
"[['combination RNN', 'For', 'first level of classification'], ['DNN', 'For', 'second level'], ['best accuracy', 'obtained by', 'combination RNN'], ['combination RNN', 'for', 'first level of classification'], ['combination RNN', 'for', 'DNN'], ['DNN', 'for', 'second level'], ['DNN', 'for', 'second level']]"
"[['significantly better', 'than', 'all of the others'], ['all of the others', 'except for', 'combination of CNN and DNN']]"
"[['best scores', 'achieved by', 'RNN']]"
[]
[]
"[['combinations', 'of', 'RNN'], ['combinations', 'of', 'DNN or CNN'], ['RNN', 'at', 'higher level'], ['RNN', 'at', 'lower level'], ['DNN or CNN', 'at', 'lower level'], ['combinations', 'at', 'lower level'], ['RNN', 'at', 'lower level'], ['DNN or CNN', 'at', 'lower level'], ['combinations', 'produced', 'accuracies'], ['lower level', 'produced', 'accuracies'], ['conventional approaches', 'using', 'nave Bayes or SVM']]"
[]
[]
"[['fullyconnected ( FC ) layer', 'at', 'topmost of the']]"
"[['parameter matrix', 'of', 'FC layer'], ['set', 'of', 'class representations'], ['parameter matrix', 'as', 'set']]"
"[['interaction mechanism', 'capable of incorporating', 'word - level matching signals'], ['word - level matching signals', 'for', 'text classification']]"
"[['word - level representation', 'computes', 'interaction matrix'], ['interaction matrix', 'in which', 'each entry'], ['each entry', 'is', 'matching score'], ['matching score', 'between', 'word and a class ( dot -product'], ['matching score', 'illustrating', 'word - level matching signals'], ['word and a class ( dot -product', 'illustrating', 'word - level matching signals']]"
[]
[]
"[['word - level encoder', 'projects', 'textual contents'], ['textual contents', 'into', 'word - level representations']]"
"[['interaction layer', 'calculates', 'matching scores'], ['matching scores', 'between', 'words and classes'], ['words and classes', 'constructs', 'interaction matrix']]"
"[['threefold', 'present', 'novel framework'], ['novel framework', 'leverages', 'interaction mechanism'], ['EXAM', 'leverages', 'interaction mechanism'], ['interaction mechanism', 'to explicitly compute', 'wordlevel interaction signals'], ['wordlevel interaction signals', 'for', 'text classification']]"
"[['multi -class task', 'chose', 'region embedding'], ['region embedding', 'as', 'Encoder in EXAM']]"
"[['region size', 'is', '7'], ['embedding size', 'is', '128'], ['embedding size', 'is', '128']]"
"[['adam ( Kingma and Ba 2014 )', 'as', 'optimizer'], ['adam ( Kingma and Ba 2014 )', 'with', 'initial learning rate 0.0001'], ['optimizer', 'with', 'initial learning rate 0.0001'], ['batch size', 'set to', '16']]"
"[['aggregation MLP', 'set', 'size'], ['size', 'of', 'hidden layer'], ['size', 'as', '2 times interaction feature length'], ['hidden layer', 'as', '2 times interaction feature length']]"
[]
[]
[]
"[['Models', 'based on', 'feature engineering'], ['Models', 'get', 'worst results'], ['feature engineering', 'get', 'worst results'], ['worst results', 'on', 'all the five datasets'], ['worst results', 'compared to', 'other methods'], ['all the five datasets', 'compared to', 'other methods']]"
"[['Char - based models', 'get', 'highest over all scores'], ['highest over all scores', 'on', 'two Amazon datasets']]"
"[['three char - based baselines', 'gets', 'best performance'], ['VDCNN', 'gets', 'best performance'], ['best performance', 'on', 'almost all the datasets']]"
"[['Word - based baselines', 'exceed', 'other variants'], ['other variants', 'on', 'three datasets'], ['Word - based baselines', 'lose on', 'two Amazon datasets']]"
"[['W.C Region Emb', 'performs', 'best']]"
"[['EXAM', 'achieves', 'best performance'], ['best performance', 'over', 'three datasets']]"
"[['EXAM', 'improves', 'best performance'], ['best performance', 'by', '1.1 %']]"
"[['EXAM', 'beats', 'all the word - based baselines'], ['all the word - based baselines', 'on', 'other two Amazon datasets'], ['1.0 %', 'on', 'Amazon Full'], ['other two Amazon datasets', 'with', 'performance gain'], ['performance gain', 'of', '1.0 %'], ['1.0 %', 'on', 'Amazon Full']]"
"[['EXAM Encoder', 'to preserve', 'only the Encoder component'], ['only the Encoder component', 'with', 'max pooling layer and FC layer'], ['only the Encoder component', 'to derive', 'final probabilities'], ['max pooling layer and FC layer', 'to derive', 'final probabilities']]"
"[['matrix', 'trained by', 'word2vec'], ['word2vec', 'to initialize', 'embedding layer'], ['embedding size', 'is', '256']]"
"[['GRU', 'as', 'Encoder']]"
[]
"[['Adam', 'to optimize', 'models'], ['models', 'on', 'one NVIDIA TITAN Xp'], ['one NVIDIA TITAN Xp', 'with', 'batch size of 1000'], ['initial learning rate', 'is', '0.001']]"
"[['validation set', 'applied for', 'early - stopping'], ['early - stopping', 'to avoid', 'overfitting']]"
"[['hyperparameters', 'chosen', 'empirically']]"
"[['Word - based models', 'better than', 'char - based models'], ['char - based models', 'in', 'Kanshan - Cup dataset']]"
"[['all the baselines', 'have', 'similar performance'], ['simple network', 'on par with', 'deep learning classifiers'], ['deep learning classifiers', 'in', 'text classification']]"
"[['Our models', 'achieve', 'state - of - the - art performance'], ['state - of - the - art performance', 'over', 'two different datasets']]"
[]
[]
[]
"[['data', 'in', 'Reuters Corpus Volume 2'], ['Reuters Corpus Volume 2', 'to define', 'new cross - lingual document classification tasks'], ['new cross - lingual document classification tasks', 'for', 'eight very different languages'], ['eight very different languages', 'namely', 'English'], ['eight very different languages', 'namely', 'French'], ['eight very different languages', 'namely', 'Spanish'], ['eight very different languages', 'namely', 'Italian'], ['eight very different languages', 'namely', 'German'], ['eight very different languages', 'namely', 'Russian'], ['eight very different languages', 'namely', 'Chinese'], ['eight very different languages', 'namely', 'Japanese']]"
[]
"[['initial strong baselines', 'represent', 'two complementary directions'], ['two complementary directions', 'of', 'research'], ['aggregation', 'of', 'multilingual word embeddings']]"
[]
[]
"[['simple one - layer convolutional neural network ( CNN )', 'on top of', 'word embeddings'], ['word embeddings', 'shown to', 'perform']]"
"[['convolutional filters', 'applied to', 'windows'], ['windows', 'of', 'word embeddings'], ['windows', 'with', 'max - over - time pooling']]"
"[['Hyper- parameters', 'such as', 'convolutional output dimension'], ['grid search', 'over', 'Dev set of the same language'], ['Dev set of the same language', 'as', 'train set']]"
[]
[]
"[['Europarl corpus', 'to cover', 'languages'], ['United Nations corpus', 'allows to learn', 'joint sentence embedding'], ['joint sentence embedding', 'for', 'English']]"
"[['one hidden - layer MLP', 'as', 'classifier']]"
"[['performance', 'on', 'original subset of RCV2'], ['cross - lingual document classification', 'able to', 'outperform']]"
[]
"[['classifiers', 'based on', 'MultiCCA embeddings'], ['classifiers', 'perform', 'very well'], ['MultiCCA embeddings', 'perform', 'very well'], ['very well', 'on', 'development corpus']]"
"[['system', 'trained on', 'English'], ['system', 'achieves', 'excellent results'], ['English', 'achieves', 'excellent results'], ['excellent results', 'when transfered to', 'different languages'], ['different languages', 'scores', 'best'], ['best', 'for', 'three out of seven languages ( DE , IT and ZH )']]"
[]
[]
[]
[]
[]
[]
"[['positioninvariance', 'into', 'RNN']]"
"[['position - invariance', 'utilize', 'max pooling'], ['max pooling', 'to extract', 'important information']]"
"[['trade - off', 'between', 'position - invariance and long - term dependencies'], ['position - invariance and long - term dependencies', 'in', 'DRNN']]"
"[['novel model', 'to incorporate', 'position - variance'], ['position - variance', 'into', 'RNN']]"
"[['empirical method', 'to find', 'optimal window size']]"
"[['all the corpus', 'with', ""NLTK 's tokenizer""]]"
"[['300D Glo Ve 840B vectors', 'as', 'pre-trained word embeddings']]"
"[['Adadelta ( Zeiler , 2012 )', 'to optimize', 'all the trainable parameters']]"
"[['hyperparameter', 'of', 'Adadelta'], ['Adadelta', 'set as', 'Zeiler ( 2012 )'], ['Zeiler ( 2012 )', 'suggest', '1 e ? 6']]"
"[['gradient explosion problem', 'apply', 'gradient norm clipping']]"
"[['batch size', 'set to', '128'], ['all the dimensions', 'of', 'input vectors and hidden'], ['input vectors and hidden', 'shows', 'our proposed model'], ['all the other models', 'in', '7 datasets']]"
"[['Fast - Text and region embedding methods', 'achieve', 'comparable performance'], ['comparable performance', 'with', 'other CNN and RNN based models']]"
"[['D - LSTM', 'is', 'discriminative LSTM model']]"
"[['Hierarchical attention network ( HAN )', 'is', 'hierarchical GRU model'], ['hierarchical GRU model', 'with', 'attentive pooling']]"
"[['very deep CNN ( VDCNN )', 'performs', 'well'], ['well', 'in', 'large datasets']]"
[]
"[['positioninvariance', 'of', 'CNN'], ['positioninvariance', 'of', 'long - term dependencies'], ['long - term dependencies', 'of', 'RNN'], ['long - term dependencies', 'of', 'RNN']]"
"[['our model', 'achieves', '10 - 50 % relative error reduction'], ['10 - 50 % relative error reduction', 'compared with', 'char - CRNN']]"
[]
"[['DRNN', 'performs', 'far better'], ['far better', 'than', 'CNN']]"
"[['Our model DRNN', 'achieves', 'much better performance'], ['much better performance', 'than', 'GRU and LSTM']]"
"[['disconnected LSTM ( DLSTM ) and disconnected GRU ( DGRU )', 'when', 'window size'], ['window size', 'is', 'lower than 5']]"
"[['DGRU', 'achieves', 'best performance'], ['best performance', 'when', 'window size'], ['window size', 'is', '15'], ['DLSTM', 'is', '5'], ['best window size', 'for', 'DLSTM'], ['DLSTM', 'is', '5']]"
[]
"[['DRNN model', 'with', 'max pooling'], ['DRNN model', 'performs', 'better'], ['max pooling', 'performs', 'better'], ['better', 'than', 'others']]"
[]
[]
[]
[]
[]
"[['pattern extraction pipelines', 'at', 'multiple levels']]"
"[['300 - dimensional word2vec vectors', 'to initialize', 'embedding vectors']]"
"[['mini-batch', 'with', 'size 50'], ['size 50', 'for', ""AG 's news""]]"
"[['Adam optimization algorithm', 'with', '1e - 3 learning rate'], ['1e - 3 learning rate', 'to train', 'model']]"
"[['3 iteration', 'of', 'routing'], ['routing', 'for', 'all datasets'], ['3 iteration', 'converges to', 'lower loss']]"
"[['several strong baseline methods', 'including', 'LSTM / Bi - LSTM'], ['several strong baseline methods', 'including', 'tree - structured LSTM ( Tree - LSTM )'], ['several strong baseline methods', 'including', 'LSTM regularized by linguistic knowledge ( LR - LSTM )'], ['several strong baseline methods', 'including', 'very deep convolutional network ( VD - CNN )'], ['several strong baseline methods', 'including', 'character - level convolutional network ( CL - CNN )']]"
"[['capsule networks', 'achieve', 'best results'], ['best results', 'on', '4 out of 6 benchmarks'], ['best results', 'verifies', 'effectiveness'], ['4 out of 6 benchmarks', 'verifies', 'effectiveness']]"
[]
[]
[]
[]
"[['Adagrad', 'with', 'learning rate'], ['learning rate', 'of', '0.3']]"
[]
"[['AIDA - train ( multiple epochs )', 'validated on', 'AIDA - A']]"
"[['Adam', 'with', 'learning rate'], ['learning rate', 'of', '1e - 4'], ['1e - 4', 'until', 'validation accuracy'], ['validation accuracy', 'exceeds', '90 %'], ['validation accuracy', 'setting it to', '1e - 5'], ['90 %', 'setting it to', '1e - 5']]"
[]
"[['Hyper- parameters', 'of', 'best validated global model'], ['best validated global model', 'are', '? = 0.01']]"
"[['R = 50', 'was', 'best']]"
"[['does not increase', 'after', '500 epochs']]"
"[['diagonal matrices A , B , C', 'keep', 'number of parameters']]"
[]
"[['outperforms', 'of using', 'less information ( only word - entity statistics']]"
"[['power', 'of', 'our local and joint neural network architectures']]"
[]
[]
[]
[]
[]
"[['sequence of words and entities', 'in', 'input text'], ['contextualized embedding', 'for', 'each word and entity']]"
"[['randomly masked entities', 'based on', 'words and non-masked entities'], ['words and non-masked entities', 'in', 'input text']]"
"[['NED model', 'addresses', 'task'], ['task', 'by capturing', 'word - based and entity - based contextual information'], ['word - based and entity - based contextual information', 'using', 'trained contextualized embeddings']]"
"[['feed - forward / filter size', 'to', '4096'], ['dropout probability', 'applied to', 'all layers'], ['dropout probability', 'was', '0.1'], ['all layers', 'was', '0.1'], ['maximum word length', 'in', 'input sequence'], ['maximum word length', 'set to', '512']]"
"[['Other parameters', 'namely', 'parameters'], ['parameters', 'in', 'MEP and the embeddings'], ['MEP and the embeddings', 'for', 'entities']]"
"[['Adam optimizer', 'with', 'learning rate'], ['Adam optimizer', 'with', 'L2 weight decay'], ['learning rate', 'of', '2 e - 5'], ['L2 weight decay', 'of', '0.01']]"
"[['batch size', 'set to', '252']]"
"[['batch size', 'to', '32'], ['Adam optimizer', 'with', 'learning rate'], ['Adam optimizer', 'with', '?1 = 0.9 , ?2 = 0.999'], ['Adam optimizer', 'with', 'L2 weight decay'], ['learning rate', 'of', '2 e - 5'], ['learning rate', 'of', '2 e - 5'], ['L2 weight decay', 'of', '0.01']]"
[]
"[['pseudo entity annotations', 'boosted', 'accuracy'], ['accuracy', 'by', '0.3 %']]"
[]
[]
"[['traditional word type embeddings', 'in', 'each token'], ['each token', 'assigned', 'representation']]"
"[['vectors', 'derived from', 'bidirectional LSTM'], ['bidirectional LSTM', 'trained with', 'coupled lan - guage model ( LM ) objective'], ['coupled lan - guage model ( LM ) objective', 'on', 'large text corpus']]"
[]
"[['ELMo representations', 'are', 'deep'], ['ELMo representations', 'function of', 'all of the internal layers'], ['all of the internal layers', 'of', 'biLM']]"
"[['linear combination of the vectors', 'stacked above', 'each input word'], ['each input word', 'for', 'each end task'], ['performance', 'over', 'using the top LSTM layer']]"
"[['all of these signals', 'is', 'highly beneficial'], ['all of these signals', 'allowing', 'learned models'], ['highly beneficial', 'allowing', 'learned models'], ['most useful', 'for', 'each end task']]"
"[['subword units', 'through the use of', 'character convolutions'], ['multi-sense information', 'into', 'downstream tasks']]"
"[['context2vec', 'uses', 'bidirectional Long Short Term Memory ( LSTM ;'], ['bidirectional Long Short Term Memory ( LSTM ;', 'to encode', 'context'], ['context', 'around', 'pivot word']]"
"[['similar signals', 'induced by', 'modified language model objective'], ['modified language model objective', 'of', 'our ELMo representations']]"
"[['biLM', 'with', 'unlabeled data'], ['biLM', 'fix', 'weights'], ['additional taskspecific model capacity', 'allowing us to leverage', 'large , rich and universal biLM representations'], ['large , rich and universal biLM representations', 'for cases', 'downstream training data size'], ['downstream training data size', 'dictates', 'smaller supervised model']]"
"[['relative error reductions', 'ranging from', '6 - 20 %'], ['6 - 20 %', 'over', 'strong base models']]"
"[['ELMo', 'to', 'baseline model'], ['81.1 %', 'to', '85.8 %'], ['test set F 1', 'improved by', '4.7 %'], ['4.7 %', 'from', '81.1 %'], ['81.1 %', 'to', '85.8 %'], ['test set F 1', 'improving', 'overall single model state - of - the - art'], ['overall single model state - of - the - art', 'by', '1.4 %']]"
"[['ELMo', 'to', 'ESIM model'], ['ELMo', 'improves', 'accuracy'], ['ESIM model', 'improves', 'accuracy'], ['accuracy', 'by', 'average of 0.7 %'], ['average of 0.7 %', 'across', 'five random seeds']]"
"[['ELMo enhanced biLSTM - CRF', 'achieves', '92. 22 % F 1'], ['92. 22 % F 1', 'averaged over', 'five runs']]"
"[['all layers', 'instead of', 'last layer'], ['all layers', 'improves', 'performance'], ['last layer', 'improves', 'performance'], ['performance', 'across', 'multiple tasks']]"
[]
"[['all biLM layers', 'instead of using', 'last layer'], ['last layer', 'improves', 'F 1'], ['F 1', 'another', '0.3 %'], ['all biLM layers', 'allowing', 'task model'], ['task model', 'to learn', 'individual layer weights'], ['individual layer weights', 'improves', 'F 1'], ['F 1', 'another', '0.2 %']]"
"[['ELMo', 'at', 'output'], ['output', 'of', 'biRNN'], ['biRNN', 'in', 'task - specific architectures'], ['task - specific architectures', 'improves', 'overall results'], ['overall results', 'for', 'some tasks']]"
"[['input and output layers', 'for', 'SNLI and SQuAD'], ['SNLI and SQuAD', 'improves over', 'input layer'], ['input and output layers', 'for', 'SRL']]"
[]
"[['ELMo', 'improves', 'task performance'], ['task performance', 'over', 'word vectors alone']]"
"[['biLM top layer rep-resentations', 'have', 'F 1'], ['F 1', 'of', '69.0'], ['biLM top layer rep-resentations', 'better at', 'WSD'], ['WSD', 'then', 'first layer']]"
"[['accuracies', 'using', 'first biLM layer'], ['first biLM layer', 'higher than', 'top layer'], ['deep biL - STMs', 'in', 'multi-task training and MT']]"
"[['ELMo model', 'with', '1 %'], ['baseline model', 'with', '10 %'], ['1 %', 'of', 'training set'], ['baseline model', 'with', '10 %']]"
"[['output layer weights', 'are', 'relatively balanced'], ['relatively balanced', 'with', 'slight preference'], ['slight preference', 'for', 'lower layers']]"
"[['Glo Ve vectors', 'with', 'biLM character layer'], ['biLM character layer', 'gives', 'slight improvement'], ['slight improvement', 'for', 'all tasks'], ['improvements', 'are', 'small'], ['small', 'compared to', 'full ELMo model']]"
"[['most of the gains', 'in', 'downstream tasks'], ['most of the gains', 'due to', 'contextual information'], ['most of the gains', 'not', 'sub-word information']]"
"[['Glo Ve', 'to', 'models'], ['models', 'with', 'ELMo'], ['models', 'provides', 'marginal improvement'], ['ELMo', 'provides', 'marginal improvement'], ['marginal improvement', 'over', 'ELMo only models']]"
[]
"[['limited quantity of manually sense annotated corpora', 'for', 'task'], ['task', 'of', 'word sense disambiguation'], ['word sense disambiguation', 'by exploiting', 'semantic relationships'], ['semantic relationships', 'between', 'senses'], ['senses', 'such as', 'synonymy'], ['sense vocabulary', 'of', 'Princeton WordNet'], ['semantic relationships', 'reduce', 'number of different sense tags'], ['all words', 'of', 'lexical database']]"
"[['WSD system', 'relies on', 'pre-trained BERT word vectors'], ['pre-trained BERT word vectors', 'to achieve', 'results'], ['results', 'that', 'significantly outperforms'], ['state of the art', 'on', 'all WSD evaluation tasks']]"
[]
"[['two different methods', 'for', 'building'], ['two different methods', 'call them', 'sense vocabulary compression methods']]"
[]
"[['method', 'for grouping together', 'multiple sense tags'], ['multiple sense tags', 'refer in fact to', 'same concept']]"
[]
"[['BERT', 'used', 'model named'], ['"" bert - largecased ""', 'of', 'PyTorch implementation'], ['vectors', 'of', 'dimension 1024'], ['PyTorch implementation', 'consists of', 'vectors'], ['vectors', 'of', 'dimension 1024'], ['vectors', 'trained on', 'Book s Corpus'], ['vectors', 'trained on', 'English Wikipedia']]"
"[['Transformer encoder layers', 'used', 'same parameters'], ['same parameters', 'as', '"" base "" model'], ['6 layers', 'with', '8 attention heads'], ['6 layers', 'with', 'dropout']]"
"[['every training', 'for', '20 epochs']]"
"[['"" all relations "" system', 'applies', 'our second vocabulary compression'], ['our second vocabulary compression', 'through', 'all relations'], ['all relations', 'on', 'training corpus']]"
"[['mini-batches', 'of', '100 sentences'], ['learning rate', 'of', '0.0001'], ['100 sentences', 'truncated to', '80 words'], ['Adam', 'with', 'learning rate'], ['learning rate', 'of', '0.0001'], ['0.0001', 'as', 'optimization method']]"
[]
"[['our systems', 'use', 'sense vocabulary compression'], ['sense vocabulary compression', 'through', 'hypernyms or'], ['sense vocabulary compression', 'through', 'through all relations'], ['through all relations', 'obtain', 'scores'], ['scores', 'that are', 'overall equivalent'], ['overall equivalent', 'to', 'systems that do not use it']]"
"[['Princeton WordNet Gloss Corpus', 'added to', 'training data'], ['Princeton WordNet Gloss Corpus', 'use of', 'BERT'], ['BERT', 'as', 'input embeddings'], ['state of the art', 'on', 'every task']]"
"[['BERT', 'as', 'input embeddings'], ['input embeddings', 'have', 'major impact'], ['major impact', 'on', 'our results']]"
"[['BERT', 'instead of', 'ELMo or Glo Ve'], ['BERT', 'improves', 'score'], ['ELMo or Glo Ve', 'improves', 'score'], ['score', 'by', 'approximately 3 and 5 points'], ['BERT', 'adding', 'WNGC'], ['ELMo or Glo Ve', 'adding', 'WNGC'], ['WNGC', 'to', 'training data']]"
"[['vocabulary compression method', 'through', 'hypernyms'], ['scores', 'obtained by', 'invidual models ( without ensemble )'], ['scores', 'observe on', 'standard deviations'], ['vocabulary compression method', 'through', 'hypernyms']]"
"[['compression method', 'through', 'all relations'], ['all relations', 'seems to', 'negatively impact'], ['results', 'in', 'some cases']]"
[]
[]
"[['GAS', 'models', 'semantic relationship'], ['semantic relationship', 'between', 'context and the gloss'], ['context and the gloss', 'in', 'improved memory network framework']]"
[]
"[['gloss - augmented WSD neural network', 'variant of', 'memory network']]"
"[['GAS', 'jointly encodes', 'context and glosses'], ['context and glosses', 'of', 'target word'], ['GAS', 'models', 'semantic relationship'], ['semantic relationship', 'between', 'context and glosses'], ['context and glosses', 'in', 'memory module']]"
"[['inner relationship', 'between', 'glosses and context'], ['inner relationship', 'employ', 'multiple passes operation'], ['multiple passes operation', 'within', 'memory'], ['memory', 'as', 're-reading process'], ['multiple passes operation', 'adopt', 'two memory updating mechanisms']]"
"[['semantic relationship', 'of', 'context'], ['semantic relationship', 'propose', 'glossaugmented neural network ( GAS )'], ['glossaugmented neural network ( GAS )', 'in', 'improved memory network paradigm']]"
"[['gloss module', 'in', 'GAS'], ['hierarchies of word senses', 'in', 'WordNet'], ['gloss module', 'to', 'hierarchical framework'], ['hierarchical framework', 'to mirror', 'hierarchies of word senses'], ['hierarchies of word senses', 'in', 'WordNet']]"
"[['pre-trained word embeddings', 'with', '300 dimensions'], ['fixed', 'during', 'training process']]"
"[['256 hidden units', 'in both', 'gloss module'], ['256 hidden units', 'in both', 'context module']]"
"[['Orthogonal initialization', 'used for', 'weights'], ['weights', 'in', 'LSTM'], ['random uniform initialization', 'with', 'range [ - 0.1 , 0.1 ]'], ['Orthogonal initialization', 'used for', 'others'], ['random uniform initialization', 'used for', 'others'], ['range [ - 0.1 , 0.1 ]', 'used for', 'others']]"
"[['value', 'of', '4']]"
[]
"[['Adam optimizer', 'in', 'training process'], ['Adam optimizer', 'with', '0.001 initial learning rate'], ['training process', 'with', '0.001 initial learning rate']]"
"[['overfitting', 'use', 'dropout regularization'], ['drop rate', 'to', '0.5']]"
"[['Babelfy', 'exploits', 'semantic network structure'], ['semantic network structure', 'from', 'BabelNet'], ['Babelfy', 'builds', 'unified graph - based architecture'], ['unified graph - based architecture', 'for', 'WSD and Entity Linking']]"
"[['IMS +emb', 'selects', 'IMS'], ['IMS', 'as', 'underlying framework'], ['IMS +emb', 'makes use of', 'word embeddings'], ['word embeddings', 'as', 'features']]"
"[['model parameters', 'among', 'all words']]"
[]
[]
"[['GAS and GAS ext', 'achieves', 'state - of - theart performance'], ['state - of - theart performance', 'on', 'concatenation of all test datasets']]"
"[['GAS ext', 'with', 'concatenation memory updating strategy'], ['concatenation memory updating strategy', 'achieves', 'best results 70.6'], ['best results 70.6', 'on', 'concatenation of the four test datasets']]"
"[['previous best neural network models', 'on', 'every individual test set']]"
"[['IMS + emb', 'on', 'SE3 , SE13 and SE15 test sets']]"
"[['glosses', 'into', 'neural WSD'], ['glosses', 'extending', 'original gloss']]"
"[['our proposed model', 'greatly improves', 'WSD task'], ['WSD task', 'by', '2.2 % F1 - score'], ['2.2 % F1 - score', 'with the help of', 'gloss knowledge']]"
"[['GAS', 'which only uses', 'original gloss'], ['original gloss', 'as', 'background knowledge'], ['GAS ext', 'can further improve', 'performance'], ['performance', 'with the help of', 'extended glosses'], ['extended glosses', 'through', 'semantic relations']]"
"[['multiple passes operation', 'performs', 'better'], ['better', 'than', 'one pass']]"
[]
[]
"[['sequence of words', 'surrounding', 'target word'], ['words', 'using', 'real valued vector representation']]"
"[['source code', 'implemented using', 'TensorFlow'], ['source code', 'released as', 'open source 1'], ['TensorFlow', 'released as', 'open source 1']]"
"[['embeddings', 'initialized using', 'set'], ['set', 'of', 'freely available 2 Glo Ve vectors'], ['freely available 2 Glo Ve vectors', 'trained on', 'Wikipedia and Gigaword']]"
"[['Words', 'initialized from', 'N ( 0 , 0.1 )']]"
"[['winner', 'of', 'SE3 lexical sample task'], ['F 1 score', 'of', '72.9'], ['winner', 'with', 'F 1 score'], ['SE3 lexical sample task', 'with', 'F 1 score'], ['F 1 score', 'of', '72.9']]"
"[['Our proposed model', 'achieves', 'top score'], ['top score', 'on', 'SE2'], ['IMS + adapted CW', 'on', 'SE3'], ['Our proposed model', 'tied with', 'IMS + adapted CW']]"
"[['results', 'on', 'both'], ['results', 'on', 'SE2 and SE3']]"
"[['input words', 'yields', 'substantially worse result'], ['order of the words', 'are', 'significant']]"
[]
"[['formalism', 'of', 'topic model'], ['topic model', 'to design', 'WSD system'], ['WSD system', 'scales', 'linearly'], ['linearly', 'with', 'number of words'], ['number of words', 'in', 'context']]"
[]
[]
"[['novel knowledge - based WSD algorithm', 'for', 'all - word WSD task'], ['all - word WSD task', 'utilizes', 'whole document'], ['whole document', 'as', 'context'], ['context', 'for', 'word']]"
"[['formalism', 'of', 'topic models'], ['topic models', 'especially', 'Latent Dirichlet Allocation ( LDA )']]"
"[['non-uniform', 'prior for', 'synset distribution'], ['synset distribution', 'over', 'words'], ['words', 'to model', 'frequency of words'], ['frequency of words', 'within', 'synset']]"
"[['relationships', 'between', 'synsets'], ['synsets', 'by using', 'logisticnormal'], ['logisticnormal', 'prior for drawing', 'synset proportions'], ['synset proportions', 'of', 'document']]"
"[['state - of - the - art WSD system', 'by', 'significant margin'], ['state - of - the - art WSD system', 'by achieving', 'overall F1 - score']]"
"[['performance', 'of', 'proposed model'], ['not much worse', 'than', 'best supervised system']]"
[]
[]
"[['outperforms', 'resulting in', 'average 8 % improvement'], ['previous state - of - the - art system', 'resulting in', 'average 8 % improvement'], ['average 8 % improvement', 'of', 'final score']]"
[]
"[['entity mention detection and entity disambiguation jointly', 'in', 'single neural model'], ['single neural model', 'that makes', 'whole process']]"
"[['noise', 'in', 'data'], ['noise', 'automatically learn', 'features'], ['features', 'over', 'set of contexts'], ['set of contexts', 'of', 'different granularity levels']]"
"[['features', 'from', 'knowledge base context'], ['knowledge base context', 'of', 'candidate entity'], ['character - level features', 'extracted for', 'entity label'], ['higher - level features', 'produced based on', 'entities'], ['entities', 'surrounding', 'candidate entity'], ['candidate entity', 'in', 'knowledge graph']]"
[]
"[['entity linking on questions', 'derive from', 'publicly available question answering data']]"
"[['heuristics baseline', 'ranks', 'candidate entities']]"
"[['VCG model', 'shows', 'overall F- score result'], ['overall F- score result', 'better than', 'DBPedia Spotlight baseline'], ['DBPedia Spotlight baseline', 'by', 'wide margin']]"
"[['our model', 'achieves', 'higher precision values'], ['our model', 'manages to keep', 'satisfactory level of recall']]"
[]
[]
"[['our supervised WSD model', 'that leverages', 'Bidirectional Long Short - Term Memory ( BLSTM ) network']]"
"[['neural sense vectors ( i.e. sense embeddings )', 'learned during', 'model training'], ['neural word vectors ( i.e. word embeddings )', 'learned through', 'unsupervised deep learning approach'], ['unsupervised deep learning approach', 'called', 'GloVe ( Global Vectors for word representation )'], ['GloVe ( Global Vectors for word representation )', 'for', 'context words']]"
"[['vocabulary size', 'of', '| V | = 29044']]"
[]
"[['WSD', 'considers', 'deep neural networks'], ['IMS + adapted CW', 'uses', 'pre-trained word embeddings'], ['pre-trained word embeddings', 'as', 'inputs']]"
"[['winner', 'of', 'SensEval - 3 lexical sample']]"
"[['kernel methods', 'for', 'pattern abstraction'], ['kernel methods', 'for', 'unsupervised term proximity'], ['unsupervised term proximity', 'on', 'British National Corpus ( BNC )'], ['unsupervised term proximity', 'in', 'SVM classifiers'], ['British National Corpus ( BNC )', 'in', 'SVM classifiers']]"
[]
[]
[]
"[['various neural architectures', 'of', 'different complexities'], ['different complexities', 'ranging from', 'single bidirectional Long Short - Term Memory'], ['single bidirectional Long Short - Term Memory', 'to', 'sequence - tosequence approach']]"
[]
"[['experiment', 'on', 'multilingual WSD'], ['multilingual WSD', 'using', 'Italian , German , French and Spanish data'], ['Italian , German , French and Spanish data', 'of', 'SE13']]"
"[['fixed number of epochs E = 40', 'using', 'Adadelta'], ['Adadelta', 'with', 'learning rate'], ['Adadelta', 'with', 'batch size']]"
"[['both BLSTM and Seq2Seq', 'achieved', 'results'], ['best supervised system', 'in', 'each benchmark'], ['results', 'performing', 'on par'], ['on par', 'with', 'word experts'], ['word experts', 'tuned over', 'explicitly engineered features']]"
"[['BLSTM models', 'tended consistently to', 'outperform'], ['Seq2Seq counterparts', 'suggesting', 'encoder - decoder architecture'], ['suboptimal', 'for', 'WSD']]"
"[['LEX', 'as', 'auxiliary task'], ['POS', 'did not', 'help']]"
[]
"[['classical supervised approaches', 'when dealing with', 'verbs'], ['verbs', 'shown to be', 'highly ambiguous']]"
[]
"[['F - score figures', 'show', 'bilingual and multilingual models'], ['bilingual and multilingual models', 'trained only on', 'English data'], ['bilingual and multilingual models', 'consistently outperformed', 'MFS baseline'], ['bilingual and multilingual models', 'achieved', 'results'], ['competitive', 'with', 'best participating systems']]"
"[['did not change substantially ( and slightly improved )', 'when', 'moving'], ['moving', 'from', 'bilingual to multilingual models']]"
[]
[]
"[['state of the art', 'of', 'lexical sample task']]"
[]
"[['UFSAC 4 BERT', 'performed', 'best']]"
"[['POS restriction', 'increases', 'F 1 scores'], ['F 1 scores', 'for', 'S7 - T7 and S7 - T17']]"
[]
[]
"[['neural network model', 'to jointly learn', 'distributed representations'], ['distributed representations', 'of', 'texts ( i.e. , sentences and paragraphs )'], ['distributed representations', 'of', 'KB entities']]"
"[['every text', 'in', 'KB'], ['each other', 'in', 'continuous vector space'], ['our model', 'aims to', 'predict'], ['our model', 'places', 'text and the relevant entities'], ['text and the relevant entities', 'close to', 'each other'], ['each other', 'in', 'continuous vector space']]"
"[['ESA', 'shows', 'text'], ['text', 'can be', 'accurately represented'], ['accurately represented', 'using', 'small set']]"
"[['simple multi -layer perceptron ( MLP ) classifier', 'with', 'learned representations']]"
[]
"[['model', 'using', 'large amount of entity annotations'], ['large amount of entity annotations', 'extracted directly from', 'Wikipedia']]"
"[['BOW - DT', 'based on', 'BOW baseline'], ['BOW baseline', 'augmented with', 'feature set'], ['feature set', 'with', 'dependency relation indicators']]"
"[['QANTA', 'based on', 'recursive neural network'], ['recursive neural network', 'to derive', 'distributed representations'], ['distributed representations', 'of', 'questions']]"
"[['LR classifier', 'with', 'derived representations'], ['derived representations', 'as', 'features']]"
"[['FTS - BRNN', 'based on', 'bidirectional recurrent neural network ( RNN )'], ['bidirectional recurrent neural network ( RNN )', 'with', 'gated recurrent units ( GRU )']]"
"[['our NTEE model', 'achieved', 'best performance'], ['best performance', 'compared to', 'other proposed models'], ['best performance', 'compared to', 'all the baseline methods'], ['all the baseline methods', 'on', 'history and the literature datasets']]"
"[['our method', 'compared to', 'state - of - the - art methods'], ['state - of - the - art methods', 'i.e.', 'QANTA and FTS - BRNN )']]"
[]
[]
[]
"[['multiple semantic relationships', 'between', 'senses'], ['senses', 'included in', 'WordNet']]"
[]
[]
"[['every training', 'for', '20 epochs']]"
"[['mini-batches', 'of', '100 sentences'], ['100 sentences', 'truncated to', '80 words']]"
[]
"[['difference', 'of', 'scores'], ['scores', 'obtained by', 'our system'], ['scores', 'using', 'sense vocabulary reduction or'], ['our system', 'using', 'sense vocabulary reduction or'], ['difference', 'is', 'overall'], ['scores', 'is', 'overall'], ['sense vocabulary reduction or', 'is', 'overall'], ['not significant', 'regarding', '"" ALL "" column']]"
"[['our systems', 'trained on', 'SemCor alone'], ['SemCor alone', 'expose', 'results'], ['results', 'comparable with', 'best system'], ['best system', 'trained on', 'same corpus']]"
"[['WordNet Gloss Tagged', 'to', 'training data'], ['training data', 'obtain', 'systematically'], ['state of the art results', 'on', 'all tasks'], ['all tasks', 'except on', 'SensEval']]"
"[['sense reduction method', 'does not', 'consistently improves or decreases'], ['score', 'on', 'every task'], ['sense reduction method', 'in', 'overall'], ['result', 'is', 'roughly the same']]"
"[['ensembling', 'is', 'very efficient method'], ['very efficient method', 'in', 'WSD'], ['very efficient method', 'improves', 'systematically']]"
"[['scores', 'are', 'significantly higher'], ['significantly higher', 'when applying', 'vocabulary reduction algorithm']]"
[]
[]
"[['GAS', 'models', 'semantic relationship'], ['semantic relationship', 'between', 'context and the gloss'], ['context and the gloss', 'in', 'improved memory network framework']]"
[]
"[['gloss - augmented WSD neural network', 'variant of', 'memory network']]"
"[['GAS', 'jointly encodes', 'context and glosses'], ['context and glosses', 'of', 'target word'], ['GAS', 'models', 'semantic relationship'], ['semantic relationship', 'between', 'context and glosses'], ['context and glosses', 'in', 'memory module']]"
"[['inner relationship', 'between', 'glosses and context'], ['inner relationship', 'employ', 'multiple passes operation'], ['multiple passes operation', 'within', 'memory'], ['memory', 'as', 're-reading process'], ['multiple passes operation', 'adopt', 'two memory updating mechanisms']]"
"[['semantic relationship', 'of', 'context'], ['semantic relationship', 'propose', 'glossaugmented neural network ( GAS )'], ['glossaugmented neural network ( GAS )', 'in', 'improved memory network paradigm']]"
"[['gloss module', 'in', 'GAS'], ['hierarchies of word senses', 'in', 'WordNet'], ['gloss module', 'to', 'hierarchical framework'], ['hierarchical framework', 'to mirror', 'hierarchies of word senses'], ['hierarchies of word senses', 'in', 'WordNet']]"
"[['pre-trained word embeddings', 'with', '300 dimensions'], ['pre-trained word embeddings', 'keep', 'fixed'], ['fixed', 'during', 'training process']]"
"[['256 hidden units', 'in both', 'gloss module'], ['256 hidden units', 'in both', 'context module']]"
"[['Orthogonal initialization', 'used for', 'weights'], ['weights', 'in', 'LSTM'], ['random uniform initialization', 'with', 'range [ - 0.1 , 0.1 ]'], ['Orthogonal initialization', 'used for', 'others'], ['random uniform initialization', 'used for', 'others'], ['range [ - 0.1 , 0.1 ]', 'used for', 'others']]"
"[['value', 'of', '4']]"
[]
"[['Adam optimizer', 'in', 'training process'], ['Adam optimizer', 'with', '0.001 initial learning rate'], ['training process', 'with', '0.001 initial learning rate']]"
"[['overfitting', 'use', 'dropout regularization'], ['drop rate', 'to', '0.5']]"
"[['glosses', 'important to', 'WSD'], ['glosses', 'enriching', 'gloss information'], ['gloss information', 'via', 'semantic relations'], ['gloss information', 'help to', 'WSD']]"
"[['Babelfy', 'exploits', 'semantic network structure'], ['semantic network structure', 'from', 'BabelNet'], ['Babelfy', 'builds', 'unified graph - based architecture'], ['unified graph - based architecture', 'for', 'WSD and Entity Linking']]"
"[['IMS +emb', 'selects', 'IMS'], ['IMS', 'as', 'underlying framework'], ['IMS +emb', 'makes use of', 'word embeddings'], ['word embeddings', 'as', 'features']]"
"[['model parameters', 'among', 'all words']]"
[]
[]
"[['GAS and GAS ext', 'achieves', 'state - of - theart performance'], ['state - of - theart performance', 'on', 'concatenation of all test datasets']]"
"[['best', 'on', 'all the test sets'], ['best results', 'on', 'concatenation of'], ['70.6', 'on', 'concatenation of'], ['GAS ext', 'with', 'concatenation memory updating strategy'], ['concatenation memory updating strategy', 'achieves', 'best results'], ['70.6', 'on', 'concatenation of']]"
"[['our best model', 'outperforms', 'previous best neural network models'], ['previous best neural network models', 'on', 'every individual test set']]"
"[['IMS + emb', 'on', 'SE3 , SE13 and SE15 test sets']]"
"[['glosses', 'into', 'neural WSD'], ['glosses', 'extending', 'original gloss']]"
"[['our proposed model', 'greatly improves', 'WSD task'], ['WSD task', 'by', '2.2 % F1 - score'], ['2.2 % F1 - score', 'with the help of', 'gloss knowledge']]"
"[['GAS', 'which only uses', 'original gloss'], ['original gloss', 'as', 'background knowledge'], ['GAS ext', 'can further improve', 'performance'], ['performance', 'with the help of', 'extended glosses'], ['extended glosses', 'through', 'semantic relations']]"
[]
[]
[]
[]
[]
"[['label propagation', 'to label', 'unlabeled sentences'], ['unlabeled sentences', 'based on', 'similarity'], ['similarity', 'to', 'labeled ones']]"
[]
"[['Our proposed algorithms', 'achieve', 'highest all - words F 1 scores'], ['highest all - words F 1 scores', 'except for', 'Sem - Eval 2013']]"
"[['Our self - trained word embeddings', 'have', 'similar performance'], ['similar performance', 'to', 'pre-trained embeddings']]"
"[['learning rate', 'is', '0.1']]"
"[['no significant performance difference', 'after', 'training converges']]"
[]
[]
[]
"[['LSTM classifier', 'trained with', 'OMSTI'], ['LSTM classifier', 'performs', 'worse'], ['OMSTI', 'performs', 'worse'], ['worse', 'trained with', 'SemCor']]"
"[['algorithm', 'performs', 'similarly'], ['similarly', 'on', 'different data sets']]"
[]
"[['F1 scores', 'after', 'adding'], ['increase', 'after', 'adding']]"
"[['on a par', 'with', 'NOAD trained classifier'], ['NOAD trained classifier', 'on', 'F1 score']]"
[]
[]
[]
"[['RELIC', 'to', 'entity typing']]"
"[['RELIC', 'accurately captures', 'categorical information'], ['categorical information', 'encoded by', 'human experts'], ['human experts', 'in', 'Freebase and Wikipedia category hierarchies']]"
"[['given category', 'such as', 'Scottish footballers'], ['given category', 'use', 'RELIC'], ['RELIC', 'to recover', 'remaining entities'], ['remaining entities', 'with', 'good precision']]"
"[['RELIC', 'for', 'entity linking'], ['RELIC', 'can match', 'state - of - the - art approaches'], ['entity linking', 'can match', 'state - of - the - art approaches'], ['state - of - the - art approaches', 'that make use of', 'non-local and']]"
"[['RELIC', 'learns', 'better representations'], ['better representations', 'of', 'entity properties'], ['better representations', 'trained to match', 'contexts'], ['entity properties', 'trained to match', 'contexts']]"
"[[""RELIC 's context encoder and entity embeddings"", 'to', 'task'], ['task', 'of', 'end - to - end trivia question answering']]"
"[['outperforms', 'even with', 'only 5 %'], ['prior work', 'even with', 'only 5 %'], ['only 5 %', 'of', 'training data']]"
"[['retrieve - then - read approach', 'taken by', 'ORQA'], ['direct answer retrieval approach', 'taken by', 'RELIC']]"
"[['reading comprehension baseline', 'by', '20 points']]"
[]
[]
"[['contexts', 'based on', 'proposed embedding'], ['proposed embedding', 'with', 'standard NED features'], ['contexts', 'achieved', 'state - of - theart accuracy'], ['proposed embedding', 'achieved', 'state - of - theart accuracy'], ['state - of - theart accuracy', 'of', '93.1 %'], ['93.1 %', 'on', 'standard CoNLL dataset'], ['93.1 %', 'on', '85.2 %'], ['93.1 %', 'on', 'TAC 2010 dataset'], ['85.2 %', 'on', 'TAC 2010 dataset'], ['85.2 %', 'on', 'TAC 2010 dataset']]"
[]
"[['semantic similarity', 'of', 'words'], ['words', 'when', 'similar words'], ['similar words', 'placed near', 'one another'], ['one another', 'in', 'relatively low - dimensional vector space']]"
"[['method', 'to construct', 'novel embedding'], ['words and entities', 'into', 'same continuous vector space']]"
[]
"[['neighboring words', 'given', 'target word'], ['neighboring entities', 'given', 'target entity'], ['target word', 'in', 'text corpora'], ['neighboring entities', 'given', 'target entity'], ['target entity', 'in', 'link graph'], ['link graph', 'of', 'KB']]"
"[['our method', 'simultaneously learns', 'embedding'], ['embedding', 'of', 'words and entities']]"
"[['straightforward NED method', 'computes', 'two contexts'], ['two contexts', 'using', 'proposed embedding']]"
"[['Our', 'combines', 'contexts'], ['NED method', 'combines', 'contexts'], ['contexts', 'with', 'several standard features'], ['several standard features', 'using', 'supervised machine learning']]"
[]
"[['stochastic gradient descent ( SGD )', 'for', 'optimization']]"
"[['iterations', 'of', 'Wikipedia dump']]"
"[['results', 'comparable with', 'some state - of - the - art methods']]"
[]
"[['some state - of - the - art methods', 'without using', 'coherence']]"
[]
[]
"[['construction', 'of', '3 DMM'], ['statistical model', 'of', 'facial texture and shape'], ['3 DMM', 'is', 'statistical model'], ['statistical model', 'of', 'facial texture and shape'], ['facial texture and shape', 'in', 'space'], ['space', 'where there are', 'explicit correspondences']]"
[]
[]
[]
"[['statistical texture model', 'from', '"" in - the -wild "" facial images'], ['full correspondence', 'with', 'statistical shape']]"
"[['featurebased texture models', 'for', '3 DMMs']]"
"[['advantage', 'of using', '"" in - the -wild "" feature - based texture model'], ['"" in - the -wild "" feature - based texture model', 'is', 'fitting strategy'], ['fitting strategy', 'gets', 'simplified']]"
"[['novel and fast algorithm', 'for fitting', '"" in - the -wild "" 3 DMMs']]"
[]
"[['our model', 'label as', 'ITW'], ['our model', 'use', 'variant'], ['both identities', 'drawn from', 'original BFM model']]"
[]
"[['"" in - the -wild "" 3 DMM ( ITW )', 'in terms of', '3D shape estimation accuracy'], ['3D shape estimation accuracy', 'against', 'two popular state - of - the - art alternative 3 DMM formulations']]"
"[['classic 3 DMM', 'with', 'original Basel laboratory texture model'], ['classic 3 DMM', 'with', 'full lighting equation'], ['full lighting equation', 'term', 'Classic']]"
[]
"[['mean mesh', 'of', 'each model'], ['each model', 'under', 'testis landmarked'], ['testis landmarked', 'with', 'same 49 point markup'], ['ground truth mesh', 'by performing', 'Procrustes alignment'], ['Procrustes alignment', 'using', 'sparse annotations'], ['sparse annotations', 'followed by', 'Non-Rigid Iterative Closest Point ( N - ICP )'], ['Non-Rigid Iterative Closest Point ( N - ICP )', 'to iteratively deform', 'two surfaces']]"
"[['texture - free Linear model', 'does', 'better'], ['ITW model', 'most able to recover', 'facial shapes'], ['facial shapes', 'due to', 'ideal feature basis'], ['ideal feature basis', 'for', '"" in - the -wild "" conditions']]"
[]
[]
"[['Our CNN', 'works with', 'just'], ['Our CNN', 'does not require', 'accurate'], ['whole 3 D facial geometry', 'including', 'non-visible parts of'], ['whole 3 D facial geometry', 'bypassing', 'construction'], ['fitting', 'of', '3D Morphable Model']]"
[]
[]
"[['mapping', 'from', 'pixels to 3D coordinates'], ['pixels to 3D coordinates', 'using', 'Convolutional Neural Network ( CNN )']]"
"[['totally unconstrained images', 'downloaded from', 'web'], ['totally unconstrained images', 'including', 'facial images'], ['facial images', 'of', 'arbitrary poses'], ['facial images', 'of', 'occlusions']]"
"[['Each of our architectures', 'trained', 'end - to - end'], ['Each of our architectures', 'using', 'RMSProp'], ['end - to - end', 'using', 'RMSProp'], ['RMSProp', 'with', 'initial learning rate'], ['initial learning rate', 'of', '10 ? 4'], ['initial learning rate', 'lowered after', '40 epochs'], ['40 epochs', 'to', '10 ?5']]"
"[['random augmentation', 'applied to', 'each input sample ( face image )']]"
[]
"[['All VRNs', 'perform', 'well'], ['well', 'across', 'whole spectrum'], ['whole spectrum', 'of', 'facial poses , expressions and occlusions']]"
"[['significant performance discrepancies', 'across', 'different datasets']]"
"[['VRN - Guided', 'uses', 'another stacked hourglass network'], ['another stacked hourglass network', 'for', 'landmark localization']]"
"[['particularly better', 'than', 'plain VRN']]"
[]
"[['performance', 'of', '3D reconstruction']]"
[]
[]
"[['robust and accurate landmark localisation', 'of', 'unconstrained faces'], ['unconstrained faces', 'impacted by', 'variety of'], ['appearance variations', 'e.g. in', 'pose'], ['appearance variations', 'e.g. in', 'expression'], ['appearance variations', 'e.g. in', 'illumination'], ['appearance variations', 'e.g. in', 'image blurring'], ['appearance variations', 'e.g. in', 'occlusion']]"
"[['new loss function', 'namely', 'Wing loss ( )'], ['new loss function', 'for', 'robust facial landmark localisation'], ['Wing loss ( )', 'for', 'robust facial landmark localisation']]"
"[['novel loss function', 'namely', 'Wing loss'], ['novel loss function', 'designed to improve', 'deep neural network training capability'], ['deep neural network training capability', 'for', 'small and medium range errors']]"
[]
"[['server', 'running', 'Ubuntu 16.04'], ['server', 'running', '4 NVIDIA GeForce GTX Titan X ( Pascal ) cards'], ['Ubuntu 16.04', 'with', '2 Intel Xeon E5-2667 v4 CPU'], ['Ubuntu 16.04', 'with', '4 NVIDIA GeForce GTX Titan X ( Pascal ) cards']]"
"[['weight decay', 'to', '5 10 ? 4'], ['momentum', 'to', '0.9'], ['batch size', 'to', '8'], ['8', 'for', 'network training']]"
[]
"[['standard ReLu function', 'used for', 'nonlinear activation'], ['Max pooling', 'with', 'stride of 2'], ['Max pooling', 'used to', 'downsize'], ['stride of 2', 'used to', 'downsize']]"
"[['convolutional layer', 'used', '3 3 kernels'], ['3 3 kernels', 'with', 'stride of 1']]"
"[['number of bins K', 'set to', '17'], ['17', 'for', 'AFLW'], ['17', 'for', '9'], ['9', 'for', '300W']]"
"[['input image size', 'is', '64 64 3'], ['input image size', 'reduced', 'learning rate'], ['learning rate', 'from', '3 10 ? 6'], ['learning rate', 'from', '3 10 ?5'], ['3 10 ? 6', 'to', '3 10 ?8'], ['3 10 ?8', 'for', 'L2 loss']]"
"[['parameters', 'of', 'Wing loss'], ['1 10 ? 5 to 1 10 ? 7', 'For', 'other loss functions'], ['input image size', 'is', '128 128'], ['learning rate', 'from', '1 10 ? 6'], ['1 10 ? 6', 'to', '1 10 ?8'], ['1 10 ?8', 'for', 'L2 loss'], ['learning rate', 'from', '1 10 ? 5 to 1 10 ? 7']]"
"[['parameters', 'of', 'Wing loss']]"
"[['data augmentation', 'randomly rotated', 'each training image'], ['data augmentation', 'between', 'each training image'], ['each training image', 'between', '[ ? 30 , 30 ] degrees'], ['each training image', 'between', '[ ? 10 , 10 ] degrees'], ['[ ? 30 , 30 ] degrees', 'for', 'CNN - 6'], ['each training image', 'between', '[ ? 30 , 30 ] degrees'], ['each training image', 'between', '[ ? 10 , 10 ] degrees'], ['[ ? 10 , 10 ] degrees', 'for', 'CNN - 7']]"
"[['each training image', 'with', 'probability of']]"
"[['bounding box perturbation', 'applied', 'random translations'], ['random translations', 'to', 'upper-left and bottom - right corners'], ['upper-left and bottom - right corners', 'of', 'face bounding box'], ['face bounding box', 'within', '5 %'], ['upper-left and bottom - right corners', 'of', 'face bounding box'], ['5 %', 'of', 'bounding']]"
"[['Gaussian blur (? = 1 )', 'to', 'each training image'], ['each training image', 'with', 'probability']]"
[]
"[['our two - stage facial landmark localisation framework', 'by stacking', 'CNN - 6 and CNN - 7 networks']]"
[]
"[['all the other approaches', 'trained with', 'commonly used L2 loss function ( magenta solid line )']]"
"[['loss function', 'from', 'L2 to L1'], ['performance', 'of', 'our method']]"
"[['our newly proposed Wing loss function', 'further improves', 'accuracy']]"
"[['face images', 'involved in', '300W']]"
"[['final size', 'of', 'test set'], ['final size', 'is', '689'], ['test set', 'is', '689']]"
"[['our two - stage landmark localisation framework', 'with', 'PDB strategy'], ['all the other stateof - the - art algorithms', 'on', '300 W dataset inaccuracy']]"
"[['error', 'reduced by', 'almost 20 %'], ['almost 20 %', 'compared to', 'current best result'], ['current best result', 'reported by', 'RAR algorithm']]"
[]
[]
"[['ResNet', 'is', '224 224 3 colour image']]"
"[['AFLW and 300 W', 'replacing', 'CNN - 6/7 network'], ['CNN - 6/7 network', 'with', 'ResNet - 50'], ['further improved', 'by', 'around 10 %']]"
"[['speed', 'of', 'TR - DRN'], ['TR - DRN', 'is', '83 fps'], ['83 fps', 'on', 'NVIDIA GeForce GTX Titan X card']]"
"[['state - of - the - art approaches', 'by', 'significant margin'], ['170 fps', 'on', 'GPU card']]"
[]
[]
"[['facial recognition network', 'into', 'identity parameters']]"
"[['regression network', 'reliance on', 'inverse rendering'], ['inverse rendering', 'to reproduce', 'image pixels']]"
"[['loss', 'based on', 'facial identity features'], ['facial identity features', 'produced by', 'face recognition network'], ['face recognition network', 'such as', 'VGG - Face'], ['face recognition network', 'such as', ""Google 's FaceNet""]]"
"[['loss', 'that matches', 'identity features'], ['identity features', 'between', 'input photograph'], ['identity features', 'between', 'synthetic rendering'], ['synthetic rendering', 'of', 'predicted face']]"
"[['fooling problem', 'applying', 'three novel losses'], ['batch distribution loss', 'to match', 'statistics'], ['statistics', 'of', 'each training batch'], ['each training batch', 'to', 'statistics'], ['statistics', 'of', 'morphable model'], ['multiple , independent views', 'of', 'predicted shape'], ['loopback loss', 'to ensure', 'regression network'], ['regression network', 'can correctly reinterpret', 'own output'], ['multi-view identity loss', 'that combines', 'features'], ['features', 'from', 'multiple , independent views'], ['multiple , independent views', 'of', 'predicted shape']]"
"[['3D shape and texture regression network', 'using', 'only a face recognition network'], ['3D shape and texture regression network', 'using', 'morphable face model'], ['3D shape and texture regression network', 'using', 'dataset of unlabeled face images']]"
"[['Phong reflection model', 'for', 'shading']]"
"[['further enhanced', 'by using', 'multiple poses'], ['multiple poses', 'for', 'each face']]"
[]
"[['improved likeness and color fidelity', 'over', 'competing methods'], ['competing methods', 'especially in the shape of', 'eyes']]"
[]
[]
[]
"[['absolute error', 'to', 'ground truth'], ['ground truth', 'by', '20 - 25 %']]"
"[['more stable', 'across', 'changing environments']]"
[]
"[['Our method', 'achieves', 'average similarity'], ['average similarity', 'between', 'rendering and photo'], ['rendering and photo', 'of', '0.403'], ['0.403', 'on', 'MoFA test']]"
"[[""Our method 's results"", 'closer to', 'same - person distribution'], ['same - person distribution', 'than', 'differentperson distribution'], ['other methods results', 'closer to', 'different - person distribution']]"
"[['distance', 'between', 'GT distribution and the same - person LFW distribution'], ['GT distribution and the same - person LFW distribution', 'is', 'very low'], ['very low', 'with', 'almost the same mean ( 0.51 vs 0.50 )']]"
"[['smoothly degrade', 'as', 'necessary information']]"
[]
"[['very dense 3D alignment', 'for', 'largepose face images']]"
"[['DeFA', 'offer', 'dense correspondence'], ['dense correspondence', 'between', 'two face images'], ['dense correspondence', 'between', 'face image and'], ['dense correspondence', 'between', 'canonical 3 D face model']]"
"[['idea', 'of', 'fitting'], ['image', 'where', 'model with thousands of vertexes'], ['face alignment', 'to go', 'very "" dense ""']]"
"[['CNN', 'to fit', '3 D face model'], ['3 D face model', 'to', 'face image']]"
"[['first challenge', 'of', 'limited landmark labeling'], ['limited landmark labeling', 'employ', 'additional constraints']]"
"[['contour constraint', 'where', 'contour'], ['contour constraint', 'where', 'SIFT constraint'], ['SIFT constraint', 'where', 'SIFT key points'], ['contour', 'of', 'predicted shape'], ['two face images', 'of', 'same individual'], ['SIFT key points', 'detected on', 'two face images'], ['two face images', 'of', 'same individual'], ['SIFT key points', 'map to', 'same vertexes'], ['same vertexes', 'on', '3D face model']]"
"[['Both constraints', 'integrated into', 'CNN training'], ['CNN training', 'as', 'additional loss function terms'], ['additional loss function terms', 'where', 'end - to - end training'], ['end - to - end training', 'results in', 'enhanced CNN'], ['enhanced CNN', 'for', '3 D face model fitting']]"
"[['alignment', 'of', 'face - region pixels'], ['dense face alignment', 'which seeks', 'alignment'], ['alignment', 'of', 'face - region pixels'], ['face - region pixels', 'beyond', 'sparse set of landmarks']]"
"[['dense face alignment', 'develop', 'novel 3 D face model fitting algorithm'], ['novel 3 D face model fitting algorithm', 'adopts', 'multiple constraints'], ['novel 3 D face model fitting algorithm', 'leverages', 'multiple datasets']]"
"[['300W - LP', 'to train', 'our DeFA network'], ['our DeFA network', 'with', 'parameter constraint ( PL )']]"
"[['training', 'of', 'our network'], ['our network', 'with', 'additional landmark fitting constraint ( LFC )']]"
"[['model', 'with', 'SPC and CFC constraints']]"
"[['large - pose face alignment', 'fine - tune', 'model'], ['model', 'with', 'AFLW - LFPA training set']]"
"[['near - frontal face alignment', 'fine - tune', 'model'], ['model', 'with', '300 W training set']]"
"[['samples', 'at', 'third stage'], ['samples', 'augmented', '20 times'], ['third stage', 'augmented', '20 times'], ['third stage', 'augmented', '15 % random noise'], ['20 times', 'with', 'up to 20 random in - plain rotation'], ['20 times', 'with', '15 % random noise'], ['15 % random noise', 'on', 'center , width , and length of']]"
"[['network', 'use', '20 , 10 , and 10 epochs'], ['20 , 10 , and 10 epochs', 'for', 'stage 1 to 3']]"
"[['initial global learning rate', 'as', '1 e ? 3'], ['learning rate', 'by', 'factor of 10'], ['factor of 10', 'when', 'training error'], ['training error', 'approaches', 'plateau']]"
"[['minibatch size', 'is', '32'], ['Leaky ReLU', 'is', '0.01'], ['weight decay', 'is', '0.005'], ['leak factor', 'for', 'Leaky ReLU'], ['Leaky ReLU', 'is', '0.01']]"
[]
"[['lm', 'for', 'LFC'], ['LFC', 'is', '5']]"
"[['SPC and CFC', 'set as', '5 , 1 and 1']]"
"[['outperforms', 'with', 'large margin'], ['best methods', 'with', 'large margin'], ['large margin', 'of', '17.8 % improvement']]"
"[['our method', 'shows', 'large improvement']]"
"[['images', 'with', 'yaw angle'], ['yaw angle', 'in', '[ 60 , 90 ]'], ['yaw angle', 'in', 'our method'], ['our method', 'improves', 'performance'], ['performance', 'by', '28 % ( from 7.93 to 5.68 )']]"
[]
"[['consistently superior performance', 'of', 'our DeFA'], ['consistently superior performance', 'indicates', 'advanced'], ['our DeFA', 'indicates', 'advanced'], ['state of the art', 'in', 'large - pose face alignment']]"
[]
"[['corresponding landmarks', 'on', 'cheek'], ['corresponding landmarks', 'apply', 'landmark marching algorithm'], ['landmark marching algorithm', 'to move', 'contour landmarks'], ['contour landmarks', 'from', 'self - occluded location'], ['self - occluded location', 'to', 'silhouette']]"
"[['Our method', 'is', 'second best method'], ['second best method', 'on', 'challenging set']]"
"[['performance', 'of', 'our method'], ['performance', 'comparable to', 'other methods'], ['our method', 'comparable to', 'other methods']]"
"[['its fine tuned version', 'with', 'SDM']]"
"[['accuracy', 'of', 'our method'], ['accuracy', 'on', 'AFLW2000 - 3D'], ['our method', 'on', 'AFLW2000 - 3D'], ['consistently improves', 'by adding', 'more datasets']]"
"[['our method', 'achieves', '9.5 % and 20 % relative improvement'], ['9.5 % and 20 % relative improvement', 'by utilizing', 'datasets'], ['datasets', 'in', 'stage 2 and stage 3'], ['stage 2 and stage 3', 'over', 'first stage']]"
"[['datasets', 'from', 'both the second and third stages'], ['both the second and third stages', 'can have', '26 % relative improvement'], ['26 % relative improvement', 'achieve', 'NME'], ['NME', 'of', '3.86 %']]"
"[['effectiveness', 'of', 'CFC and SPC'], ['CFC and SPC', 'more than', 'LFC']]"
"[['LFC + SPC and LFC + CFC performances', 'shows', 'CFC'], ['more helpful', 'than', 'SPC']]"
"[['all constraints', 'achieves', 'best performance']]"
"[['images', 'with', 'NME - lp'], ['NME - lp', 'between', '5 % and 15 %'], ['5 % and 15 %', 'is', 'helpful'], ['SPC', 'is', 'helpful']]"
"[['SPC', 'utilizes', 'SIFT points'], ['SIFT points', 'to cover', 'whole 3D shape'], ['points', 'in', 'highly textured areas'], ['highly textured areas', 'are', 'substantially used']]"
[]
"[['3D Morphable Model ( 3 DMM )', 'widely used in', 'facial analysis'], ['3D Morphable Model ( 3 DMM )', 'e.g.', 'model fitting'], ['facial analysis', 'e.g.', 'model fitting'], ['facial analysis', 'e.g.', 'image synthesis']]"
"[['entire network', 'is', 'end - to - end trainable'], ['end - to - end trainable', 'with', 'only weak supervision']]"
"[['morphable model framework', 'provides', 'two'], ['point - to - point correspondence', 'between', 'reconstruction and all other models'], ['underlying transformations', 'between', 'types of faces ( male to female , neutral to smile , etc . )']]"
[]
"[['nonlinear 3 DMM', 'to model', 'shape / texture'], ['shape / texture', 'via', 'deep neural networks ( DNNs )']]"
"[['in - the - wild face images', 'without', '3 D scans'], ['original images', 'due to', 'inherent nonlinearity']]"
[]
"[['fragile', 'to', 'large variances'], ['large variances', 'in', 'face identity']]"
"[['two network decoders', 'instead of', 'two PCA spaces'], ['two PCA spaces', 'as', 'shape and texture model components']]"
"[['each component', 'design', 'different networks'], ['different networks', 'for', 'shape and texture'], ['multi - layer perceptron ( MLP )', 'for', 'shape'], ['multi - layer perceptron ( MLP )', 'for', 'texture'], ['convolutional neural network ( CNN )', 'for', 'texture'], ['multi - layer perceptron ( MLP )', 'for', 'shape'], ['convolutional neural network ( CNN )', 'for', 'texture']]"
[]
"[['fitting algorithm', 'to', 'our nonlinear 3 DMM'], ['our nonlinear 3 DMM', 'formulated as', 'CNN encoder']]"
"[['encoder', 'takes', '2 D face image'], ['2 D face image', 'as', 'input'], ['encoder', 'generates', 'shape and texture parameters']]"
"[['differentiable rendering layer', 'to generate', 'reconstructed face'], ['reconstructed face', 'by fusing', '3D face , texture']]"
"[['endto - end learning scheme', 'constructed where', 'encoder and two decoders'], ['encoder and two decoders', 'to minimize', 'difference'], ['difference', 'between', 'reconstructed face and the input face']]"
"[['large collection of unconstrained 2D images', 'without relying on', '3D scans']]"
"[['greater representation power', 'than', 'traditional linear counterpart']]"
"[['model and the model fitting algorithm', 'via', 'weak supervision'], ['weak supervision', 'by leveraging', 'large collection of 2D images'], ['large collection of 2D images', 'without', '3D scans']]"
"[['novel rendering layer', 'enables', 'end - to - end training']]"
"[['3 DMM', 'Using', '300W - LP dataset'], ['facial mesh triangle definition', 'by', 'Basel Face Model ( BFM )'], ['facial mesh triangle definition', 'train', '3 DMM'], ['3 DMM', 'using', '300W - LP dataset']]"
"[['Adam optimizer', 'with', 'initial learning rate'], ['Adam optimizer', 'with', '0.0002'], ['initial learning rate', 'of', '0.001'], ['initial learning rate', 'of', '0.0002'], ['0.001', 'when minimizing', 'L 0']]"
"[['losses', 'to have', 'similar magnitudes']]"
[]
"[['significantly smaller reconstruction error', 'than', 'linear model']]"
"[['3 DMM fitting results', 'on', 'CelebA dataset']]"
"[['personal facial characteristic', 'in', 'both shape and texture']]"
[]
"[['low error', 'comparable to', 'optimization - based methods']]"
[]
"[['non-visible regions', 'of', 'face'], ['non-visible regions', 'determined by', 'estimated camera center'], ['non-visible regions', 'determined by', 'estimated 3D shape']]"
"[['simple mean shape', 'deformed to', 'input image'], ['input image', 'at', 'relatively low computational cost'], ['relatively low computational cost', 'compared to', 'other approaches']]"
"[['Landmark locations', 'directly predicted by', 'regression'], ['regression', 'from', 'learned feature space']]"
"[['objective function', 'in', 'GSDM'], ['objective function', 'divided into', 'multiple regions'], ['multiple regions', 'of', 'similar gradient directions']]"
"[['separate cascaded shape regressor', 'for', 'each region']]"
"[['3DDFA', 'fits', 'dense 3 D face model'], ['dense 3 D face model', 'to', 'image'], ['novel cascaded framework', 'incorporating', 'geometric constraints'], ['geometric constraints', 'for localizing', 'landmarks'], ['landmarks', 'in', 'faces and other non-rigid objects']]"
[]
[]
"[['Our network', 'implemented in', 'Caffe framework']]"
"[['new layer', 'created', 'bilinear sampler module'], ['new layer', 'consisting of', '3D TPS transformation module'], ['new layer', 'consisting of', 'bilinear sampler module']]"
"[['whole network', 'can be trained', 'end - to - end']]"
"[['shared feature extraction networks', 'use', 'convolution layers']]"
[]
"[['AlexNet architecture', 'freeze', 'first layer'], ['first 4 layers', 'are', 'frozen']]"
"[['2D landmark regression', 'implemented by', 'attaching'], ['additional layers', 'on top of', 'last convolution layer']]"
"[['N landmarks to regress', 'need', 'NFC layers'], ['NFC layers', 'to compute', 'offsets'], ['offsets', 'for', 'each individual landmark']]"
"[['one Scaling layer', 'followed by', 'Reduction layer and Bias layer']]"
"[['new layers', 'are', 'updated'], ['all previous layers', 'are', 'frozen']]"
[]
"[['AlexNet architecture', 'train for', '100,000 iterations'], ['100,000 iterations', 'with', 'batch size of 50']]"
"[['initial learning rate', 'set to', '0.001'], ['initial learning rate', 'drops by', 'factor of 2'], ['factor of 2', 'after', '50,000 iterations']]"
"[['initial learning rate', 'is', '0.01'], ['initial learning rate', 'drops by', 'factor of 10'], ['factor of 10', 'every', '40,000 iterations']]"
"[['VGG - 16 architecture', 'train for', '200,000 iterations'], ['200,000 iterations', 'with', 'batch size'], ['batch size', 'of', '25']]"
"[['initial learning rate', 'set to', '0.001'], ['initial learning rate', 'drops by', 'factor of 2'], ['factor of 2', 'after', '100,000 iterations']]"
"[['initial learning rate', 'is', '0.01'], ['initial learning rate', 'drops by', 'factor of 10'], ['factor of 10', 'every', '70,000 iterations']]"
"[['momentum', 'for', 'all experiments'], ['momentum', 'set to', '0.9'], ['all experiments', 'set to', '0.9']]"
"[['AlexNet model', 'in', 'all three pose ranges'], ['all three pose ranges', 'on', 'AFLW detected set']]"
"[['greatly helps', 'to improve', 'accuracy']]"
"[['provided bounding box', 'anytime', 'face'], ['face', 'not detected by', 'detector']]"
[]
"[['methods', 'except for', 'CDM'], ['methods', 'retrained on', '300W - LP dataset']]"
"[['our model', 'using', 'VGG - 16 architecture'], ['our model', 'achieved', 'better accuracy'], ['VGG - 16 architecture', 'achieved', 'better accuracy'], ['better accuracy', 'in', 'all pose ranges'], ['better accuracy', 'especially', '( 60 , 90 ] category'], ['all pose ranges', 'especially', '( 60 , 90 ] category'], ['VGG - 16 architecture', 'achieved', 'smaller standard deviation'], ['better accuracy', 'achieved', 'smaller standard deviation'], ['smaller standard deviation', 'in', 'error']]"
"[['more consistent', 'than', 'other methods']]"
[]
"[['3DDFA + SDM', 'performs', 'well'], ['VGG - 16 architecture', 'of', 'our model']]"
"[['VGG - 16 model', 'is', 'second best'], ['second best', 'in', '( 30 , 60 ] range'], ['second best', 'by', 'small amount'], ['( 30 , 60 ] range', 'by', 'small amount'], ['our method', 'generates', 'more accurate and']]"
[]
[]
[]
[]
"[['3D dense face model', 'rather than', 'sparse landmark shape model'], ['sparse landmark shape model', 'to', 'image']]"
[]
"[['fitting process', 'in', '3 DDFA'], ['3 DDFA', 'propose', 'cascaded convolutional neutral network ( CNN ) based regression method']]"
"[['CNN', 'to fit', '3D face model']]"
"[['Weighted Parameter Distance Cost ( WPDC )', 'proposed as', 'cost function']]"
"[['face profiling algorithm', 'to synthesize', '60 k + training samples'], ['60 k + training samples', 'across', 'large poses']]"
[]
"[['performance', 'of', '3DDFA'], ['3DDFA', 'on', 'three'], ['large - pose face alignment', 'on', 'AFLW'], ['mediumpose face alignment', 'on', '300W'], ['large - pose face alignment', 'on', 'AFLW'], ['large - pose face alignment', 'on', 'AFLW2000 - 3D'], ['large - pose face alignment', 'on', 'mediumpose face alignment'], ['large - pose face alignment', 'on', '300W'], ['3 D face alignment', 'on', 'AFLW2000 - 3D'], ['mediumpose face alignment', 'on', '300W']]"
[]
"[['bounding boxes', 'provided by', 'AFLW']]"
"[['training', 'for', '2D methods'], ['2D methods', 'use', 'projected 3D landmarks'], ['projected 3D landmarks', 'as', 'ground truth'], ['projected 3D landmarks', 'for', '3DDFA'], ['3DDFA', 'directly regress', '3 DMM parameters']]"
[]
"[['RCPR', 'is', 'occlusion - robust method'], ['occlusion - robust method', 'with', 'potential'], ['potential', 'to deal with', 'selfocclusion'], ['RCPR', 'train it with', 'landmark visibility labels']]"
"[['all the methods', 'benefits', 'substantially'], ['substantially', 'from', 'face profiling'], ['face profiling', 'when dealing with', 'large poses']]"
"[['improvements', 'in', '[ 60 , 90 ]'], ['improvements', 'are', '44.06 %'], ['[ 60 , 90 ]', 'are', '44.06 %'], ['44.06 %', 'for', 'RCPR'], ['44.06 %', 'for', '42.10 %'], ['40.36 %', 'for', 'ESR']]"
"[['3DDFA', 'reaches', 'state of the art'], ['state of the art', 'above', 'all the 2D methods'], ['all the 2D methods', 'especially beyond', 'medium poses']]"
"[['minimum standard deviation', 'of', '3DDFA'], ['minimum standard deviation', 'demonstrates', 'robustness'], ['3DDFA', 'demonstrates', 'robustness'], ['robustness', 'to pose', 'variations']]"
[]
"[['results', 'in', 'AFLW'], ['results', 'seethe', 'defect'], ['AFLW', 'seethe', 'defect'], ['defect', 'of', 'barely evaluating visible landmarks']]"
"[['ground truth bounding boxes', 'in', 'performance'], ['performance', 'in', '[ 60 , 90 ]'], ['performance', 'in', 'standard deviation'], ['reduced', 'when considering', 'all the landmarks']]"
[]
[]
"[['extra labels', 'of', 'facial attributes'], ['facial attributes', 'for', 'training'], ['samples', 'limits', 'universality']]"
"[['nose', 'can be', 'localized'], ['localized', 'with', 'locations of eyes and mouth'], ['roughly', 'with', 'locations of eyes and mouth']]"
"[['novel deep learning framework', 'named', 'Multi - Center Learning ( MCL )'], ['novel deep learning framework', 'to exploit', 'strong correlations'], ['strong correlations', 'among', 'landmarks']]"
"[['our', 'uses', 'multiple shape prediction layers'], ['multiple shape prediction layers', 'to predict', 'locations of landmarks'], ['each shape prediction layer', 'emphasizes on', 'detection'], ['detection', 'of', 'certain cluster of landmarks']]"
"[['loss', 'of', 'each landmark'], ['each cluster of landmarks', 'is', 'further optimized']]"
"[['model complexity', 'propose', 'model assembling method'], ['model assembling method', 'to integrate', 'multiple shape prediction layers'], ['multiple shape prediction layers', 'into', 'one shape prediction layer']]"
"[['learning process', 'of', 'each landmark'], ['each landmark', 'with', 'low model complexity']]"
"[['strong correlations', 'among', 'landmarks']]"
"[['model assembling method', 'ensures', 'low model complexity']]"
[]
"[['diversity', 'of', 'raw training data'], ['diversity', 'on account of', 'limited variation patterns'], ['raw training data', 'on account of', 'limited variation patterns'], ['limited variation patterns', 'using', 'five steps']]"
"[['our MCL', 'using', 'open source deep learning framework Caffe']]"
"[['maximum learning iterations', 'of', 'pre-training'], ['initial learning rates', 'of', 'pre-training'], ['each finetuning step', 'are', '1810 4 and 610 4'], ['initial learning rates', 'of', 'pre-training'], ['each fine - tuning step', 'are', '0.02 and 0.001']]"
"[['FLD + PDE', 'performs', 'facial landmark detection'], ['pose and deformation estimation', 'in', 'training data'], ['training data', 'of', 'pose and deformation estimation']]"
"[['most of the state - of - the - art methods', 'especially on', 'AFLW dataset']]"
[]
[]
"[['?', 'is', '0.4']]"
"[['left eye model and the right eye model', 'reduce', 'alignment errors'], ['alignment errors', 'of', 'corresponding clusters']]"
"[['errors', 'of', 'landmarks'], ['landmarks', 'of', 'right eye , mouth , and chin'], ['errors', 'of', 'landmarks'], ['landmarks', 'of', 'right eye , mouth , and chin']]"
"[['right eye model', 'improves', 'accuracy'], ['accuracy', 'than', 'left eye model'], ['more significantly', 'than', 'left eye model']]"
"[['Simplified AM', 'acquired', 'good results']]"
"[['better solution', 'on', 'IBUG'], ['Weighting Simplified AM', 'fails to search', 'better solution'], ['better solution', 'on', 'IBUG']]"
[]
[]
"[['fully - supervised one', 'by', 'large margin']]"
[]
[]
"[['style transfer and disentangled representation learning', 'to tackle', 'face alignment problem']]"
[]
"[['new framework', 'to', 'augment training'], ['augment training', 'for', 'facial landmark detection'], ['facial landmark detection', 'without using', 'extra knowledge']]"
"[['face images', 'into', 'space of structure and style']]"
"[['disentanglement', 'design', 'conditional variational auto - encoder model'], ['conditional variational auto - encoder model', 'in which', 'Kullback - Leiber ( KL ) divergence loss and skip connections'], ['Kullback - Leiber ( KL ) divergence loss and skip connections', 'incorporated for', 'compact representation'], ['compact representation', 'of', 'style and structure']]"
"[['visual style translation', 'between', 'existing facial geometry']]"
"[['novel semi-supervised framework', 'based on', 'conditional variational auto - encoder']]"
"[['our model', 'generates', 'style - augmented images'], ['style - augmented images', 'via', 'style translation'], ['style - augmented images', 'further boosting', 'facial landmark detection'], ['style translation', 'further boosting', 'facial landmark detection']]"
"[['Res - 18 baseline', 'receives', 'strong enhancement'], ['strong enhancement', 'using', 'synthetic images']]"
"[['stronger baseline', 'achieves', '4.39 % NME'], ['our model', 'achieves', '4.39 % NME'], ['4.39 % NME', 'under', 'style - augmented training'], ['state - of the - art entries', 'by', 'large margin']]"
"[['our method', 'brings', '15.9 % improvement'], ['our method', 'brings', '9 % boost'], ['15.9 % improvement', 'to', 'SAN model'], ['9 % boost', 'to', 'LAB'], ['5.27 % NME', 'to', '4.76 %'], ['9 % boost', 'to', 'LAB'], ['9 % boost', 'from', '5.27 % NME'], ['LAB', 'from', '5.27 % NME'], ['5.27 % NME', 'to', '4.76 %']]"
"[['our separation component', 'tends to capture', 'weak style information'], ['weak style information', 'such as', 'color and lighting']]"
[]
[]
"[['features', 'used to', 'iteratively refine'], ['estimates', 'of', 'landmark locations']]"
"[['novel face alignment method', 'dub', 'Deep Alignment Network ( DAN )']]"
"[['multistage neural network', 'where', 'each stage'], ['each stage', 'refines', 'landmark positions'], ['landmark positions', 'estimated at', 'previous stage'], ['landmark positions', 'iteratively improving', 'landmark locations']]"
"[['entire face image', 'during', 'process'], ['process', 'of', 'face alignment']]"
"[['convolutional neural network', 'use', 'heatmaps'], ['heatmaps', 'to infer', 'current estimates'], ['current estimates', 'of', 'landmark locations'], ['landmark locations', 'in', 'image']]"
"[['landmark heatmaps', 'transfer', 'information'], ['information', 'about', 'current landmark location estimates'], ['current landmark location estimates', 'between', 'stages of our method']]"
"[['our method', 'to make use of', 'entire image'], ['entire image', 'of', 'face'], ['face', 'instead of', 'local patches'], ['our method', 'avoid falling into', 'local minima']]"
"[['DAN', 'trained on', 'training subset'], ['training subset', 'of', '300W competition data'], ['two models', 'trained on', 'DAN - Menpo'], ['DAN - Menpo', 'trained on', 'Menpo challenge training set']]"
"[['Data augmentation', 'performed by', 'mirroring'], ['Data augmentation', 'performed by', 'random translation'], ['Data augmentation', 'performed by', 'scaling'], ['mirroring', 'around', 'Y axis'], ['mirroring', 'as well as', 'random translation'], ['mirroring', 'as well as', 'scaling'], ['Y axis', 'as well as', 'random translation'], ['random translation', 'sampled from', 'normal distributions'], ['scaling', 'sampled from', 'normal distributions']]"
[]
"[['Training', 'performed using', 'Theano 0.9.0'], ['Training', 'performed using', 'Lasagne 0.2']]"
"[['optimization', 'use', 'Adam stochastic optimization'], ['Adam stochastic optimization', 'with', 'initial step size'], ['Adam stochastic optimization', 'with', 'mini batch size']]"
"[['Python implementation', 'runs at', '73 fps'], ['Python implementation', 'runs at', '45 fps'], ['73 fps', 'for', 'images'], ['45 fps', 'for', 'images'], ['45 fps', 'for', 'images'], ['45 fps', 'processed', 'sequentially'], ['images', 'processed', 'sequentially'], ['sequentially', 'on', 'GeForce GTX 1070 GPU']]"
"[['each test set', 'initialize', 'our method'], ['our method', 'using', 'face detector bounding boxes'], ['face detector bounding boxes', 'provided with', 'datasets']]"
[]
"[['first', 'performs', 'face alignment'], ['face alignment', 'using', 'square initialization bounding box'], ['square initialization bounding box', 'placed in the', 'middle'], ['image', 'with', 'size'], ['size', 'set to', 'percentage of image height']]"
"[['bounding box size', 'was', '46 %'], ['46 %', 'of', 'image height']]"
"[['AUC and the failure rate', 'chosen', 'threshold'], ['threshold', 'of', '0.03'], ['0.03', 'of', 'bounding box diagonal'], ['0.03', 'of', 'bounding box diagonal']]"
"[['second stage', 'increases', 'AUC'], ['0.08', 'by', '20 %'], ['mean error and failure rate', 'reduced by', '14 % and 56 %']]"
"[['third stage', 'does not bring', 'significant benefit'], ['significant benefit', 'in', 'any of']]"
[]
[]
"[['end - to - end deep convolutional cascade architecture', 'for', 'face alignment']]"
"[['significantly outperforms', 'on', '300W , CelebA and WFLW databases'], ['existing approaches', 'on', '300W , CelebA and WFLW databases']]"
"[['rigid transformations', 'such as', 'translation and rotation'], ['rigid transformations', 'in', 'first cascade stages'], ['translation and rotation', 'in', 'first cascade stages'], ['non-rigid deformation', 'due to', 'facial expression'], ['non-rigid deformation', 'due to', 'non-planar rotation']]"
[]
"[['DeCaFA', 'composed of', 'several stages'], ['several stages', 'each produce', 'landmark - wise attention maps'], ['landmark - wise attention maps', 'relatively to', 'heterogeneous annotation markups']]"
"[['fully - convolutional Deep Cascade for', 'unifies', 'cascaded regression and'], ['fully - convolutional Deep Cascade for', 'unifies', 'end - to - end deep approaches'], ['Face Alignment ( DeCaFA )', 'unifies', 'cascaded regression and'], ['Face Alignment ( DeCaFA )', 'unifies', 'end - to - end deep approaches'], ['end - to - end deep approaches', 'by using', 'landmark - wise attention maps'], ['landmark - wise attention maps', 'fused to extract', 'local information'], ['local information', 'around', 'current landmark estimate']]"
"[['intermediate supervision', 'with', 'increasing weights'], ['increasing weights', 'helps', 'DeCaFA'], ['DeCaFA', 'to learn', 'coarse attention maps'], ['coarse attention maps', 'in', 'early stages']]"
"[['DeCaFA', 'integrates', 'heterogeneous data'], ['heterogeneous data', 'annotated with', 'different numbers of landmarks'], ['heterogeneous data', 'model', 'intrinsic relationship']]"
"[['DeCaFA models', 'use', '1 to 4 stages'], ['1 to 4 stages', 'each contains', '12 3 3 convolutional layers'], ['12 3 3 convolutional layers', 'with', '64 ? 64 ? 128 ? 128 ? 256 ? 256 channels'], ['64 ? 64 ? 128 ? 128 ? 256 ? 256 channels', 'for', 'downsampling portion']]"
"[['Each convolution', 'followed by', 'batch normalization layer'], ['batch normalization layer', 'with', 'ReLU activation']]"
"[['smooth feature maps', 'do not use', 'transposed convolution'], ['smooth feature maps', 'bilinear', 'image upsampling'], ['image upsampling', 'followed with', '3 3 convolutional layers']]"
"[['whole architecture', 'trained using', 'ADAM optimizer'], ['ADAM optimizer', 'with', '5e ? 4 learning rate'], ['ADAM optimizer', 'with', 'learning rate'], ['5e ? 4 learning rate', 'with', 'momentum 0.9'], ['5e ? 4 learning rate', 'with', 'momentum 0.9'], ['5e ? 4 learning rate', 'with', 'learning rate'], ['learning rate', 'annealing with', 'power 0.9']]"
"[['400000 updates', 'with', 'batch size 8'], ['batch size 8', 'for', 'each database']]"
"[['accuracy', 'add', 'more stages'], ['steadily increases', 'add', 'more stages'], ['saturates', 'after', 'third'], ['third', 'on', 'LFPW and HELEN']]"
"[['difference', 'is', 'more conspicuous'], ['improvement', 'by', 'stacking']]"
"[['Coarsely annotated data ( 5 landmarks )', 'significantly helps', 'fine - grained landmark localization']]"
"[['accuracy', 'on', 'challenging data'], ['challenging data', 'such as', '300 W - challenging'], ['challenging data', 'such as', 'WFLW - pose']]"
"[['local + global information', 'rivals', 'basic deep approach']]"
"[['local and global cues', 'is', 'best'], ['best', 'by', 'significant margin']]"
[]
"[['Our approach', 'performs', 'better'], ['better', 'than', 'most existing approaches'], ['most existing approaches', 'on', 'common subset'], ['best contenders', 'on', 'challenging subset'], ['Our approach', 'performs', 'very close'], ['very close', 'to', 'its'], ['very close', 'to', 'best contenders'], ['best contenders', 'on', 'challenging subset']]"
"[['DeCaFA', 'trained only on', '300 W trainset'], ['ME', 'of', '3.69 %']]"
"[['competitive', 'with', 'best approaches'], ['LAB and DAN - MENPO', 'as well as', 'JMFA - MENPO'], ['JMFA - MENPO', 'use', 'external data']]"
"[['DeCaFA', 'performs', 'better'], ['better', 'than', 'LAB and Wing'], ['DeCaFA', 'by', 'significant margin'], ['LAB and Wing', 'by', 'significant margin'], ['significant margin', 'on', 'every subset']]"
"[['DeCaFA', 'trained solely on', 'WFLW'], ['WFLW', 'as', 'ME'], ['ME', 'of', '5.01'], ['5.01', 'on', 'whole test set']]"
"[['best', 'by', 'significant margin']]"
"[['new state - of - the - art', 'on', 'three databases'], ['three databases', 'with', 'several evaluation metrics']]"
"[['landmark localization', 'on', 'both datasets'], ['number of training images', 'is', 'very low']]"
"[['DeCaFA', 'trained with', '15 % of 300 W trainset'], ['on par', 'with', 'SAN'], ['SAN', 'on', '300W'], ['substantially better', 'than', 'DVLN'], ['DVLN', 'on', 'WFLW']]"
"[['predicted landmarks', 'close to', 'corresponding ground truth'], ['predicted landmarks', 'in the presence of', 'facial expressions ( CelebA )'], ['corresponding ground truth', 'in the presence of', 'rotations and occlusions ( WFLW )']]"
[]
[]
[]
[]
"[['models', 'trained with', 'MSE loss'], ['MSE loss', 'tend to predict', 'blurry and dilated heatmap'], ['blurry and dilated heatmap', 'with', 'low intensity'], ['low intensity', 'on', 'foreground pixels'], ['low intensity', 'compared to', 'ground truth']]"
"[['Adaptive Wing loss', 'able to', 'significantly improve'], ['quality', 'of', 'heatmap regression results']]"
"[['translation invariance', 'of', 'convolution operation'], ['convolution operation', 'in', 'bottom - up and top - down CNN structures'], ['bottom - up and top - down CNN structures', 'such as', 'stacked Hourglass ( HG )']]"
"[['Coord - Conv layer', 'encode into', 'our model'], ['Coord - Conv layer', 'encode into', 'information'], ['information', 'on', 'boundaries'], ['boundaries', 'predicted from', 'previous HG module'], ['boundaries', 'into', 'our model']]"
"[['encoded coordinate information', 'further improves', 'performance'], ['performance', 'of', 'our approach']]"
"[['boundary coordinates', 'add', 'sub-task'], ['sub-task', 'of', 'boundary prediction'], ['boundary prediction', 'by concatenating', 'additional boundary channel'], ['additional boundary channel', 'into', 'ground truth heatmap'], ['ground truth heatmap', 'jointly trained with', 'other channels']]"
"[['difficult background pixels', 'during', 'training']]"
"[['coordinate information', 'including', 'coordinates'], ['coordinates', 'on', 'boundary'], ['coordinate information', 'into', 'face alignment algorithm'], ['coordinate information', 'using', 'CoordConv'], ['face alignment algorithm', 'using', 'CoordConv']]"
"[['reduced influence', 'of', 'correct estimations'], ['reduced influence', 'of', 'oscillating'], ['reduced influence', 'helps', 'network'], ['correct estimations', 'helps', 'network'], ['network', 'to stay', 'converged'], ['converged', 'instead of', 'oscillating'], ['oscillating', 'like', 'L1 and the Wing loss']]"
[]
"[['not very accurate', 'to ensure', 'all landmarks'], ['all landmarks', 'preserved from', 'cropping'], ['all landmarks', 'enlarge', 'bounding boxes'], ['bounding boxes', 'by', '10 %'], ['10 %', 'on', 'both dimensions']]"
"[['network', 'is', '256 256'], ['each stacked HG', 'is', '64 64'], ['network', 'output of', 'each stacked HG'], ['256 256', 'output of', 'each stacked HG'], ['each stacked HG', 'is', '64 64']]"
"[['training', 'use', 'RM - SProp'], ['RM - SProp', 'with', 'initial learning rate'], ['initial learning rate', 'of', '1 10 ?4']]"
"[['momentum', 'to be', '0'], ['weight decay', 'to be', '1 10 ?5']]"
"[['learning rate', 'reduced to', '1 10 ?5 and 1 10 ? 6'], ['1 10 ?5 and 1 10 ? 6', 'after', '80 and 160 epoches']]"
"[['Data augmentation', 'performed with', 'random rotation ( 50 )'], ['Data augmentation', 'performed with', 'translation ( 25 px )'], ['Data augmentation', 'performed with', 'flipping ( 50 % )'], ['Data augmentation', 'performed with', 'rescaling ( 15 % )']]"
[]
"[['outperforms', 'by', 'significant margin'], ['previous state - of - the - art', 'by', 'significant margin'], ['outperforms', 'especially on', 'failure rate'], ['previous state - of - the - art', 'especially on', 'failure rate'], ['significant margin', 'especially on', 'failure rate']]"
"[['failure rate', 'measured at', '10 % NME'], ['10 % NME', 'from', '3.73 %'], ['3.73 %', 'to', '0.99 %']]"
"[['COFW', 'shows', 'robustness'], ['robustness', 'of', 'our approach'], ['our approach', 'against', 'faces'], ['faces', 'with', 'large pose and heavy occlusion']]"
"[['Our', 'able to achieve', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', '300W testing dataset']]"
[]
"[['Our method', 'achieves', 'best results'], ['best results', 'on', 'WFLW dataset'], ['significantly more difficult', 'than', 'COFW and 300W']]"
[]
[]
"[['fails', 'on', 'only 2.84 %'], ['only 2.84 %', 'of', 'all images']]"
[]
"[['naive weight mask', 'without focus on', 'hard negative pixels'], ['naive weight mask', 'introduced', 'baseline weight map W M base =? W + 1'], ['Adaptive Wing loss', 'improves', 'benchmark'], ['benchmark', 'by', '0.74 %']]"
"[['All other modules', 'contributed', 'incrementally'], ['our Weighted Loss Map', 'improves', '0.25 %'], ['boundary prediction and coordinates encoding', 'able to contribute', 'another'], ['boundary prediction and coordinates encoding', 'able to contribute', '0.09 %']]"
"[['significantly boosts', 'compared with', 'MSE'], ['performance', 'compared with', 'MSE']]"
"[['previous state - of - the - arts', 'in', 'all datasets'], ['all datasets', 'except', 'common subset'], ['all datasets', 'except', 'full dataset of']]"
"[['Runtime', 'evaluated on', 'Nvidia GTX 1080 Ti graphics card'], ['Nvidia GTX 1080 Ti graphics card', 'with', 'batch size of 1']]"
[]
"[['facial landmarks', 'such as', 'eyes , nose and mouth'], ['location parameters', 'of', 'landmarks']]"
[]
[]
"[['CR based methods', 'require', 'multiple regressors'], ['SIR', 'need', 'one regressor'], ['SIR', 'updates', 'parameters']]"
[]
"[['training data', 'obtained by', 'random sampling'], ['random sampling', 'in', 'parameter space'], ['random sampling', 'in', 'test - ing process'], ['training data', 'in', 'test - ing process'], ['parameters', 'updated', 'iteratively'], ['iteratively', 'by calling', 'same regressor'], ['same regressor', 'which is', 'dubbed Self - Iterative Regression']]"
"[['discriminative landmarks features', 'proposed', 'Landmarks - Attention Network ( LAN )'], ['Landmarks - Attention Network ( LAN )', 'focuses on', 'appearance around']]"
[]
"[['discriminative features', 'around', 'each landmarks']]"
"[['more robust', 'than', 'CR']]"
"[['one regressor', 'predicts', 'false direction'], ['final result', 'prone to', 'drift away']]"
"[['NME results', 'shows', 'SIR'], ['NME results', 'shows', 'outperform'], ['SIR', 'performs', 'comparatively'], ['SIR', 'performs', 'outperform'], ['comparatively', 'with', 'RAR']]"
[]
"[['our method', 'obtains', 'state - of - the - art performance'], ['same regressor', 'rather than adding', 'anymore regressors']]"
[]
"[['boundary - aware face alignment algorithm', 'by utilising', 'boundary lines'], ['boundary lines', 'as', 'geometric structure'], ['geometric structure', 'of', 'human face']]"
"[['boundary information', 'of', '300 - W dataset'], ['our method', 'achieves', '3.92 % mean error'], ['3.92 % mean error', 'with', '0.39 % failure rate'], ['3.92 % mean error', 'with', '1.25 % mean error'], ['0.39 % failure rate', 'on', 'COFW dataset'], ['1.25 % mean error', 'on', 'AFLW - Full dataset']]"
"[['facial structure', 'using', '13 boundary lines']]"
"[['Each facial boundary line', 'interpolated from', 'sufficient number of facial landmarks'], ['sufficient number of facial landmarks', 'across', 'multiple datasets'], ['inconsistency', 'of', 'annotation schemes']]"
"[['boundary - aware face alignment algorithm', 'contains', 'two stages']]"
"[['landmarks', 'with the help of', 'boundary heatmaps']]"
"[['adversarial learning ideas', 'by using', 'landmark - based boundary effectiveness discriminator']]"
"[['boundary effectiveness discriminator', 'can be', 'jointly']]"
"[['next', 'deriving', 'facial landmarks'], ['facial landmarks', 'using', 'boundaries']]"
"[['structure information', 'apply', 'boundary heatmaps'], ['boundary heatmaps', 'at', 'multiple stages'], ['multiple stages', 'in', 'landmark regression network']]"
"[['Each image', 'annotated with', '98 landmarks'], ['Each image', 'annotated with', '6 attributes']]"
"[['AFLW dataset', 'contains', '24386 in - the - wild faces'], ['24386 in - the - wild faces', 'with', 'large head pose'], ['24386 in - the - wild faces', 'with', '90'], ['large head pose', 'up to', '120'], ['large head pose', 'up to', '90'], ['120', 'for', 'yaw']]"
"[['Caffe [ 24 ]', 'on', '4 Titan X GPUs']]"
"[['Our method', 'performs', 'best'], ['best', 'among', 'all of the state - of - the - art methods']]"
"[['CED curves', 'of', 'our'], ['CED curves', 'against', 'state - of - the - art methods'], ['our', 'against', 'state - of - the - art methods'], ['state - of - the - art methods', 'on', 'COFW - 68 dataset']]"
"[['outperforms', 'with', 'large margin'], ['previous results', 'with', 'large margin']]"
"[['4.62 % mean error', 'with', '2.17 % failure rate']]"
"[['failure rate', 'is', 'significantly reduced'], ['significantly reduced', 'by', '3.75 %']]"
"[['clear boost', 'between', 'our method'], ['clear boost', 'without and with using', 'boundary information'], ['our method', 'without and with using', 'boundary information']]"
"[['our method', 'uses', 'boundary information'], ['boundary information', 'achieves', '29 % , 32 % and 29 % relative performance improve- ment'], ['29 % , 32 % and 29 % relative performance improve- ment', 'over', 'baseline method ( "" LAB without boundary'], ['29 % , 32 % and 29 % relative performance improve- ment', 'over', 'AFLW - Frontal']]"
"[['Our', 'consists of', 'several pivotal components'], ['several pivotal components', 'i.e.', 'boundary information fusion'], ['several pivotal components', 'i.e.', 'message passing'], ['several pivotal components', 'i.e.', 'adversarial learning']]"
"[['our final model', 'fuses', 'boundary information'], ['boundary information', 'in', 'all four levels'], ['boundary information', 'improves', 'mean error'], ['all four levels', 'improves', 'mean error'], ['mean error', 'from', '7.12 %'], ['7.12 %', 'to', '6.13 %']]"
"[['novel use', 'of', 'facial boundary'], ['facial boundary', 'to derive', 'facial landmarks']]"
"[['runtime', 'of', 'our algorithm'], ['runtime', 'is', '60 ms'], ['our algorithm', 'is', '60 ms'], ['60 ms', 'on', 'TITAN X GPU']]"
[]
"[['coarse - to - fine cascade', 'of', 'ensembles'], ['ensembles', 'of', 'regression trees']]"
"[['3 DDE', 'improves', 'state - of - the - art'], ['state - of - the - art', 'in', '300W , COFW , AFLW and WFLW data sets']]"
"[['robust and efficient face alignment algorithm', 'based on', 'coarse - to - fine cascade']]"
"[['hybrid approach', 'inherits', 'good properties'], ['good properties', 'of', 'ERT'], ['good properties', 'such as', 'ability'], ['ERT', 'such as', 'ability']]"
"[['3 D face model', 'to', 'probability maps'], ['probability maps', 'produced by', 'CNN']]"
"[['regressor', 'in the presence of', 'occlusions and large face rotations']]"
"[['ERT', 'imposes', 'prior face shape'], ['prior face shape', 'on', 'solution'], ['prior face shape', 'addressing', 'shortcomings'], ['shortcomings', 'of', 'deep models'], ['deep models', 'when', 'occlusions and ambiguous face configurations'], ['occlusions and ambiguous face configurations', 'are', 'present']]"
"[['coarse - to - fine structure', 'tackles', 'combinatorial explosion'], ['combinatorial explosion', 'of', 'parts deformation'], ['key limitation', 'of', 'approaches'], ['key limitation', 'of', 'approaches'], ['approaches', 'using', 'shape constraints']]"
"[['initialization', 'by using', 'RANSAC - like procedure'], ['robustness', 'in the presence of', 'occlusions']]"
"[['CNN', 'selecting', 'model parameters'], ['model parameters', 'with', 'lowest validation error']]"
"[['faces', 'using', 'ground truth bounding boxes annotations'], ['ground truth bounding boxes annotations', 'enlarged by', '30 %']]"
"[['different training samples', 'in', 'each epoch'], ['random', 'in', 'plane rotations'], ['different training samples', 'by applying', 'random'], ['each epoch', 'by applying', 'random'], ['each epoch', 'by applying', 'translations'], ['random', 'in', 'plane rotations'], ['plane rotations', 'between', '45'], ['scale changes', 'by', '15 %'], ['translations', 'by', '5 %'], ['5 %', 'of', 'bounding box size'], ['translations', 'randomly mirroring', 'images'], ['different training samples', 'generating', 'random rectangular occlusions'], ['random', 'generating', 'random rectangular occlusions'], ['scale changes', 'generating', 'random rectangular occlusions'], ['translations', 'generating', 'random rectangular occlusions']]"
"[['Adam stochastic optimization', 'with', '? 1 = 0.9 , ? 2 = 0.999 and = 1 e ? 8 parameters']]"
"[['convergence', 'with', 'initial learning rate ? = 0.001']]"
"[['validation error', 'levels', 'out'], ['validation error', 'multiply', 'learning rate'], ['10 epochs', 'multiply', 'learning rate'], ['learning rate', 'by', 'decay'], ['decay', '=', '0.05']]"
"[['cropped input face', 'reduced from', '160160'], ['half their size', 'across', 'B = 8 branches'], ['B = 8 branches', 'applying', 'astride 2 convolution'], ['astride 2 convolution', 'with', 'kernel']]"
"[['batch normalization', 'after', 'each convolution']]"
"[['Gaussian filter', 'with', '? = 33'], ['Gaussian filter', 'to', 'output probability maps'], ['? = 33', 'to', 'output probability maps'], ['output probability maps', 'to stabilize', 'initialization']]"
"[['trees', 'set to', '4']]"
"[['number of tests', 'to choose', 'best split parameters'], ['best split parameters', 'set to', '200']]"
"[['each image', 'to set', 'face size'], ['face size', 'to set', '160160 pixels'], ['face size', 'to', '160160 pixels']]"
"[['FREAK pattern diameter', 'reduced', 'gradually'], ['gradually', 'in', 'each stage']]"
"[['Z = 25 initializations', 'in', 'robust soft POSIT scheme'], ['robust soft POSIT scheme', 'of', 'g 0']]"
"[['overfitting', 'use', 'shrinkage factor ? = 0.1'], ['overfitting', 'use', 'subsampling factor ? = 0.5'], ['subsampling factor ? = 0.5', 'in', 'ERT']]"
"[['CNN and the coarse - to - fine ensemble of trees', 'takes', '48 hours'], ['Training', 'using', 'dual Intel Xeon Silver 4114 CPU'], ['CNN and the coarse - to - fine ensemble of trees', 'using', 'dual Intel Xeon Silver 4114 CPU'], ['48 hours', 'using', 'NVidia GeForce GTX 1080 Ti ( 11 GB ) GPU'], ['48 hours', 'using', 'dual Intel Xeon Silver 4114 CPU'], ['dual Intel Xeon Silver 4114 CPU', 'at', '2.20 GHz'], ['2.20 GHz', 'with', 'batch size']]"
"[['mixed approaches', 'with', 'deep nets and ensembles of regression trees']]"
"[['3 DDE', 'is', 'better'], ['better', 'than', 'any'], ['better', 'providing', 'public implementation'], ['any', 'providing', 'public implementation']]"
"[['other ERT methods', 'as', 'RCPR'], ['other ERT methods', 'as', 'ERT or c GPRT']]"
[]
"[['Our approach', 'obtains', 'best overall performance'], ['best overall performance', 'in', 'indoor and outdoor subsets'], ['best overall performance', 'in', 'full subset'], ['indoor and outdoor subsets', 'of', 'private competition'], ['full subset', 'of', '300W public test set'], ['full subset', 'of', '300W public test set']]"
"[['challenging subset', 'of', '300W public competition'], ['SHN', 'gets', 'better results'], ['better results', 'than', '3DDE']]"
"[['DDE', 'obtains', 'best results']]"
"[['landmark visibility estimation', 'obtained', 'better precision'], ['better precision', 'with', 'overall better recall'], ['overall better recall', 'than', 'best previous approach']]"
"[['regularization', 'together with', 'new initialization'], ['regularization', 'contributes to', 'improve DCFE'], ['new initialization', 'contributes to', 'improve DCFE']]"
"[['NME', 'of', '2.06'], ['2.06', 'with', 'full 21 landmarks set']]"
"[['its competitors', 'in', 'all the WFLW subsets'], ['outperforms', 'by', 'large margin'], ['its competitors', 'by', 'large margin'], ['all the WFLW subsets', 'by', 'large margin']]"
"[['cascaded ERT regressor', 'operating on', 'probabilistic CNN features'], ['cascaded ERT regressor', 'operating on', 'coarse - to - fine scheme']]"
"[['different configurations', 'of', 'our framework'], ['different configurations', 'evaluated on', 'WFLW'], ['our framework', 'evaluated on', 'WFLW']]"
"[['3D initialization', 'key to achieve', 'top overall performance'], ['top overall performance', 'see', 'CNN + MS + DE vs CNN + 3D + DE']]"
"[['largest improvement', 'in', 'pose subset']]"
"[['CNN probability maps', 'improves', 'NME'], ['NME', 'in', 'full data set'], ['full data set', 'in', 'about 20 %'], ['NME', 'in', 'about 20 %'], ['full data set', 'in', 'about 20 %']]"
"[['coarse - to - fine strategy', 'in', 'our cascaded ERT'], ['significative local improvements', 'in', 'difficult cases'], ['coarse - to - fine strategy', 'provides', 'significative local improvements'], ['our cascaded ERT', 'provides', 'significative local improvements'], ['significative local improvements', 'in', 'difficult cases'], ['significative local improvements', 'with', 'rare facial part combinations']]"
[]
"[['data set', 'with', 'greatest diversity']]"
"[['model All', 'trained with', 'training sets of all data bases'], ['model All', 'able to', 'improve'], ['training sets of all data bases', 'able to', 'improve'], ['improve', 'in', 'all cross - dataset experiments'], ['models', 'trained in', 'single data set']]"
"[['landmarks', 'with', 'highest NME'], ['highest NME', 'related to', 'ears']]"
[]
[]
[]
"[['complex network', 'to regress', '68 facial landmarks'], ['68 facial landmarks', 'with', '2D coordinates'], ['2D coordinates', 'from', 'single image']]"
"[['end - to - end method', 'called', 'Position map Regression Network ( PRN )'], ['Position map Regression Network ( PRN )', 'to jointly predict', 'dense alignment'], ['Position map Regression Network ( PRN )', 'reconstruct', '3 D face shape']]"
"[['our method', 'is', 'straightforward'], ['our method', 'with', 'very light - weighted model'], ['straightforward', 'with', 'very light - weighted model'], ['one pass', 'with', '9.8 ms'], ['very light - weighted model', 'provides', 'result'], ['result', 'in', 'one pass'], ['one pass', 'with', '9.8 ms']]"
"[['UV position map', 'which is', '2D image'], ['2D image', 'recording', '3D coordinates'], ['3D coordinates', 'of', 'complete facial point cloud'], ['UV position map', 'keeping', 'semantic meaning'], ['semantic meaning', 'at', 'each UV place']]"
"[['simple encoder - decoder network', 'with', 'weighted loss'], ['weighted loss', 'focuses more on', 'discriminative region'], ['discriminative region', 'to regress', 'UV position map'], ['UV position map', 'from', 'single 2 D facial image']]"
"[['robust', 'to', 'poses , illuminations and occlusions']]"
"[['3D', 'develop', 'novel representation'], ['novel representation', 'called', 'UV position map'], ['novel representation', 'records', 'position information'], ['UV position map', 'records', 'position information'], ['position information', 'of', '3 D face'], ['novel representation', 'provides', 'dense correspondence'], ['dense correspondence', 'to', 'semantic meaning'], ['each point', 'on', 'UV space']]"
"[['training', 'proposed', 'weight mask'], ['weight mask', 'assigns', 'different weight'], ['different weight', 'to', 'each point'], ['each point', 'on', 'position map'], ['weight mask', 'compute', 'weighted loss']]"
"[['light - weighted framework', 'runs at', 'over 100 FPS'], ['over 100 FPS', 'to directly obtain', '3 D face reconstruction and alignment result'], ['3 D face reconstruction and alignment result', 'from', 'single 2 D facial image']]"
"[['training data', 'by scaling', 'color channels'], ['color channels', 'with', 'scale range'], ['scale range', 'from', '0.6']]"
"[['optimization', 'use', 'Adam optimizer'], ['Adam optimizer', 'with', 'learning rate'], ['learning rate', 'begins at', '0.0001'], ['half', 'after', 'each 5 epochs']]"
"[['batch size', 'set as', '16']]"
[]
"[['worst performance', 'compared with', 'other two settings']]"
"[['weights', 'to', 'specific regions'], ['specific regions', 'such as', '68 facial landmarks or'], ['specific regions', 'such as', 'central face region'], ['specific regions', 'such as', 'weight ratio'], ['weight ratio', 'shows', 'considerable improvement'], ['considerable improvement', 'on', '68 points datasets'], ['68 points datasets', 'over', 'weight ratio 2']]"
[]
[]
"[['2', 'introduces', 'four novel self - supervision schemes'], ['four novel self - supervision schemes', 'that view', '2D landmark and 3D landmark prediction'], ['2D landmark and 3D landmark prediction', 'as', 'self - mapping process'], ['self - mapping process', 'including', '2D and 3D landmark self - prediction consistency'], ['cycle - consistency', 'over', '2D landmark prediction'], ['self - critic', 'over', 'predicted 3 DMM coefficients'], ['predicted 3 DMM coefficients', 'based on', 'landmark predictions']]"
"[['demands', 'on', 'conventional paired 2D - to - 3D annotations'], ['2DASL method', 'gives', 'much higher - quality 3 D face models'], ['much higher - quality 3 D face models', 'without requiring', 'additional 3D annotations']]"
[]
[]
"[['novel learning method', 'leverages', '2D "" in - the - wild "" face images'], ['2D "" in - the - wild "" face images', 'to effectively supervise and facilitate', '3D face model learning']]"
"[['novel self - supervised learning method', 'able to train', '3 D face model'], ['3 D face model', 'with', 'weak supervision'], ['weak supervision', 'from', '2D images']]"
"[['our proposed method', 'exploits', 'cycle - consistency'], ['cycle - consistency', 'over', '2D landmark predictions'], ['2D landmark predictions', 'taking', 'recovered 2D landmarks'], ['small difference', 'with', 'annotated ones']]"
"[['our', 'exploits', 'self - critic learning']]"
"[['latent representation and 3 DMM coefficients', 'of', 'face image'], ['critic model', 'to evaluate', 'intrinsic consistency'], ['intrinsic consistency', 'between', 'predicted 3 DMM coefficients and the corresponding face image'], ['intrinsic consistency', 'offering', 'another supervision'], ['predicted 3 DMM coefficients and the corresponding face image', 'offering', 'another supervision'], ['another supervision', 'for', '3 D face model learning']]"
"[['abundant "" in - the - wild "" 2 D face images', 'to assist', '3 D face model learning']]"
"[['3 D face models', 'with', '2 D face images'], ['2 D face images', 'by', 'self - supervised learning']]"
"[['self - critic learning based approach', 'could', 'effectively improve']]"
[]
"[['18 landmarks', 'from', '68 2D facial landmarks']]"
[]
"[['SGD optimizer', 'for', 'CNN regressor'], ['CNN regressor', 'with', 'learning rate'], ['optimizer', 'with', 'fixed learning rate 1 10 ?4'], ['learning rate', 'beginning at', '5 10 ?5'], ['Adam', 'as', 'optimizer'], ['Adam', 'with', 'fixed learning rate 1 10 ?4'], ['optimizer', 'with', 'fixed learning rate 1 10 ?4']]"
"[['our model', 'using', 'Vertex Distance Cost']]"
"[['2D facial landmarks', 'of', 'all the face images'], ['2D facial landmarks', 'detected by', 'advanced 2 D facial landmarks detector'], ['all the face images', 'detected by', 'advanced 2 D facial landmarks detector']]"
"[['Each face', 'annotated with', 'corresponding 3 DMM coefficients'], ['Each face', 'annotated with', '68 3D facial landmarks']]"
"[['Each image', 'annotated with', '34 facial landmarks']]"
"[['our results', 'are', 'more accurate'], ['more accurate', 'than', 'ground truth'], ['ground truth', 'in', 'some cases']]"
"[['our 2 DASL', 'achieves', 'lowest NME ( % )'], ['lowest NME ( % )', 'on the evaluation of', '2 D and 3D coordinates']]"
"[['outperforms', 'by', 'large margin'], ['large margin', 'on both', '68 spare landmarks'], ['large margin', 'on both', 'dense coordinates']]"
"[['Our 2DASL', 'performs', 'better'], ['better', 'than', 'PRNet'], ['Our 2DASL', 'reducing', 'NME'], ['NME', 'by', '0.09 and 0.08'], ['0.09 and 0.08', 'on', 'AFLW2000 - 3D'], ['0.09 and 0.08', 'on', 'AFLW - LFPA']]"
"[['Iterative Closest Points ( ICP ) algorithm', 'to find', 'corresponding nearest points'], ['corresponding nearest points', 'between', 'reconstructed 3 D face'], ['corresponding nearest points', 'between', 'ground truth point cloud']]"
"[['3D reconstruction results', 'of', '2 DASL'], ['2 DASL', 'outperforms', '3 DDFA'], ['3 DDFA', 'by', '0.39 , and 2.29'], ['0.39 , and 2.29', 'for', 'DeFA']]"
"[['reconstructed shape', 'of', 'our 2 DASL'], ['our 2 DASL', 'are', 'more smooth'], ['PRNet and VRN - Guided', 'introduce', 'some artifacts'], ['some artifacts', 'into', 'reconstructed results'], ['some artifacts', 'makes', 'reconstructed faces'], ['reconstructed results', 'makes', 'reconstructed faces'], ['reconstructed faces', 'look', 'unnaturally']]"
"[['2DASL ( cyc )', 'takes as input', 'combination'], ['2DASL ( sc )', 'takes as input', 'RGB face images'], ['RGB face images', 'using', 'self - critic learning']]"
"[['2DASL ( cyc+sc )', 'contains', 'self - supervision'], ['2DASL ( cyc+sc )', 'contains', 'self - critic supervision']]"
"[['weights', 'to', 'central'], ['0.09', 'to', '0.23'], ['points', 'of', 'facial landmarks'], ['facial landmarks', 'reduces', 'NME'], ['NME', 'by', '0.09'], ['0.09', 'to', '0.23'], ['0.23', 'on', 'two stages']]"
"[['self - critic learning', 'is', 'not used'], ['0.04/0.18', 'for', 'with / without weight mask']]"
"[['best result', 'achieved when', 'both these two modules']]"
[]
"[['unconfidently predicted landmarks', 'due to', 'occlusion and low quality'], ['occlusion and low quality', 'propose', 'global heatmap correction unit ( GHCU )'], ['global heatmap correction unit ( GHCU )', 'to correct', 'outliers'], ['outliers', 'by considering', 'global face shape'], ['global face shape', 'as', 'constraint']]"
"[['global heatmap correction unit ( GHCU )', 'maintains', 'global face shape constraint'], ['global heatmap correction unit ( GHCU )', 'recovers', 'unconfidently predicted landmarks'], ['unconfidently predicted landmarks', 'caused by', 'challenging factors'], ['challenging factors', 'such as', 'occlusions']]"
"[['GHCU', 'implicitly learns', 'whole face shape constraint'], ['whole face shape constraint', 'from', 'training data'], ['GHCU', 'always gives', 'facialshape landmarks']]"
"[['data augmentation', 'randomly sample', 'angle of rotation and the bounding box scale'], ['angle of rotation and the bounding box scale', 'from', 'Gaussian distribution']]"
"[['four - stage stacked hourglass network', 'as', 'our backbone'], ['our backbone', 'trained by', 'optimizer RMSprop']]"
"[['our algorithm', 'comprises', 'two parts'], ['real groundtruth searching', 'are', 'alternatively optimized']]"
[]
"[['roughly converged model', 'with', 'human annotations'], ['initial learning rate', 'is', '2.5 10 ?4'], ['2.5 10 ?4', 'is', 'decayed'], ['2.5 10 ? 6', 'after', '120 epochs']]"
"[['initial learning rate', 'is', '2.5 10 ? 6'], ['initial learning rate', 'divided by', '5 , 2 and 2'], ['5 , 2 and 2', 'at', 'epoch 30 , 60 and 90']]"
"[['batch size', 'to', '10'], ['10', 'for', 'network training']]"
"[['PyTorch [ 18 ]', 'on', '2 Titan X GPUs']]"
"[['hourglass architecture', 'with', 'human annotations']]"
"[['HGs', 'with', 'our Semantic Alignment ( HGs + SA )'], ['our Semantic Alignment ( HGs + SA )', 'greatly outperform', 'hourglass ( HGs )'], ['4.37 % vs 5.04 %', 'in terms of', 'NME'], ['NME', 'on', 'Full set']]"
"[['GHCU', 'see', 'HGs + SA + GHCU']]"
"[['in - plane - rotation', 'by training', 'preprocessing network'], ['preprocessing network', 'conduct', 'normalization ( HGs + SA + GHCU + Norm )'], ['state of the art performance', 'on', 'Challenge set and Full set']]"
[]
"[['HGs + SA + GHCU', 'works', 'better'], ['better', 'than', 'HGs + SA']]"
"[['subset Category 3', 'is', 'most challenging one']]"
[]
"[['HGs + SA , HGs + SA + GHCU', 'reduce', 'error rate ( RMSE )'], ['error rate ( RMSE )', 'by', '18 %'], ['18 %', 'on', 'Category 3 test set']]"
[]
"[['GHCU', 'considers', 'global face shape'], ['global face shape', 'as', 'constraint']]"
"[['our CNN based GHCU', 'outperforms', 'PCA based method'], ['PCA based method', 'in terms of', 'both accuracy and efficiency']]"
"[['performance', 'on', 'all subset sets']]"
"[['GHCU', 'is', 'more effective'], ['more effective', 'on', 'challenge data set']]"
[]
[]
[]
"[['popular one - stage RetinaNet method', 'to perform', 'face detection'], ['face detection', 'as', 'our baseline model']]"
"[['high performance face detector', 'namely', 'AInnoFace']]"
"[['two - step classification and regression', 'for', 'detection'], ['Intersection over Union ( IoU ) loss function', 'for', 'regression'], ['multi-scale testing strategy', 'for', 'inference'], ['Intersection over Union ( IoU ) loss function', 'for', 'regression'], ['data augmentation', 'based on', 'data - anchor - sampling'], ['data - anchor - sampling', 'for', 'training'], ['max - out operation', 'for', 'robuster classification'], ['multi-scale testing strategy', 'for', 'inference']]"
"[['focal loss', 'is', 'reshaping'], ['reshaping', 'of', 'cross entropy loss'], ['cross entropy loss', 'down - weights', 'loss'], ['loss', 'assigned to', 'well - classified examples']]"
"[['STR', 'performs', 'two - step regression'], ['two - step regression', 'on', 'three high level detection layers'], ['two - step regression', 'to adjust', 'anchors'], ['three high level detection layers', 'to adjust', 'anchors'], ['STR', 'provide', 'better initialization'], ['two - step regression', 'provide', 'better initialization'], ['three high level detection layers', 'provide', 'better initialization'], ['better initialization', 'for', 'subsequent regressor']]"
"[['backbone network', 'in', 'proposed AInnoFace detector'], ['proposed AInnoFace detector', 'initialized by', 'pretrained model'], ['pretrained model', 'on', 'ImageNet dataset']]"
"[['"" xavier "" method', 'to randomly initialize', 'parameters'], ['parameters', 'in', 'newly added convolutional layers']]"
"[['model', 'with', '0.9 momentum'], ['model', 'with', 'batch size 32']]"
"[['warmup strategy', 'applied to', 'gradually ramp up'], ['learning rate', 'from', '0.0003125'], ['0.0003125', 'to', '0.01'], ['0.01', 'at', 'first 5 epochs']]"
"[['regular learning rate schedule', 'dividing by', '10'], ['10', 'at', '100 and 120 epochs'], ['regular learning rate schedule', 'ending at', '130 epochs']]"
"[['full training and testing codes', 'built on', 'PyTorch library']]"
"[['our face detector', 'sets', 'some new state - of - the - art results'], ['some new state - of - the - art results', 'based on', 'AP score'], ['AP score', 'across', 'three subsets'], ['three subsets', 'on', 'validation and testing subsets'], ['validation and testing subsets', 'i.e.', '97.0 % ( Easy )'], ['validation and testing subsets', 'i.e.', '96.1 % ( Medium )'], ['91.8 % ( Hard )', 'for', 'validation subset'], ['91.2 % ( Hard )', 'for', 'testing subset']]"
[]
"[['new multi-scale face detector', 'having', 'extremely tiny number of parameters ( EXTD )'], ['extremely tiny number of parameters ( EXTD )', 'less than', '0.1 million'], ['new multi-scale face detector', 'achieving', 'comparable performance'], ['comparable performance', 'to', 'deep heavy detectors']]"
[]
"[['network', 'in generating', 'each feature - map']]"
"[['our model', 'does not require', 'any extra layer'], ['our model', 'trained from', 'scratch']]"
"[['multi-stage face detection', 'can', 'significantly reduce'], ['abundant object semantic information', 'to', 'lower stage feature maps']]"
"[['hard negative mining technique', 'balance', 'ratio'], ['hard negative mining technique', 'balance', 'balancing parameter'], ['ratio', 'of', 'positive and negative samples N neg / N pos'], ['positive and negative samples N neg / N pos', 'to', '3']]"
[]
[]
[]
"[['three variations', 'have', 'different number of parameters'], ['lighter one', 'having', '0.063 M parameters'], ['0.063 M parameters', 'with', '32 channels'], ['32 channels', 'for', 'each feature maps'], ['0.1 M parameters', 'with', '48 channels']]"
"[['negative slope', 'of', 'Leaky - ReLU'], ['initial negative slope', 'of', 'PReLU'], ['Leaky - ReLU', 'set to', '0.25'], ['0.25', 'identical to', 'initial negative slope'], ['initial negative slope', 'of', 'PReLU']]"
"[['all the inference processes', 'of', 'models'], ['all the inference processes', 'implemented by', 'PyTorch 1.0']]"
[]
"[['SOTA face detectors', 'such as', 'Pyra - midBox and DSFD'], ['our best model EXTD - FPN - 64 - PReLU', 'achieved', 'lower results']]"
"[['margin', 'between', 'PyramidBox and the proposed model'], ['PyramidBox and the proposed model', 'on', 'WIDER FACE hard case'], ['WIDER FACE hard case', 'was', '3.4 %']]"
"[['m AP gap', 'to', 'DSFD'], ['2860 times more parameters', 'than', 'proposed method']]"
"[['our SSD - based variations', 'got', 'lower mAP results'], ['lower mAP results', 'than', 'FPN - based variants']]"
"[['S3FD version', 'trained with', 'Mo - bile FaceNet backbone network'], ['proposed SSD variants', 'achieved', 'comparable or better detection performance']]"
"[['Detection performance', 'regarding', 'Face Scale']]"
"[['our method', 'achieved', 'higher performance'], ['higher performance', 'in', 'WIDER FACE hard dataset'], ['higher performance', 'than', 'other cases'], ['WIDER FACE hard dataset', 'than', 'other cases']]"
"[['FPN based architecture', 'achieved', 'better detection performance'], ['better detection performance', 'compared to', 'SSD based architecture'], ['better detection performance', 'especially for detecting', 'small faces'], ['SSD based architecture', 'especially for detecting', 'small faces']]"
"[['channel width', 'increased by', '32 to 64'], ['channel width', 'see that', 'detection accuracy'], ['significantly enhanced', 'for', 'all the cases']]"
"[['PReLU', 'was', 'most effective choice'], ['most effective choice', 'when it comes to', 'mAP']]"
"[['Leaky - ReLU', 'with', 'larger margin'], ['larger margin', 'than those using', 'FPN structure']]"
"[['ReLU', 'occurred', 'notable performance decreases'], ['small', 'for', 'SSD and FPN cases']]"
"[['channel width', 'set to', '32'], ['m AP', 'for', 'all the three cases'], ['all the three cases', 'lower than', '10 % to 20 %']]"
"[['stochastic gradient descent optimizer ( SGD )', 'with', 'learning rate'], ['stochastic gradient descent optimizer ( SGD )', 'with', '0.9 momentum'], ['learning rate', 'with', '0.9 momentum'], ['1e ? 3', 'with', '0.9 momentum']]"
"[['maximum iteration number', 'set to', '240K'], ['learning rate', 'set to', '1e ? 4 and 1e ? 5'], ['maximum iteration number', 'drop', 'learning rate'], ['learning rate', 'to', '1e ? 4 and 1e ? 5'], ['learning rate', 'to', '180K iterations'], ['1e ? 4 and 1e ? 5', 'at', '120 K']]"
[]
[]
"[['Region Proposal Network ( RPN )', 'adopted in', 'Faster RCNN'], ['Region Proposal Network ( RPN )', 'employs', 'two stage detection schemes']]"
"[['RPN', 'trained', 'end - to - end'], ['RPN', 'generates', 'highquality region proposals']]"
"[['Single Shot Detector ( SSD ) based one - stage methods', 'get rid of', 'RPN'], ['Single Shot Detector ( SSD ) based one - stage methods', 'directly predict', 'bounding boxes']]"
"[['backbone networks', 'initialized by', 'pretrained VGG / ResNet'], ['pretrained VGG / ResNet', 'on', 'Image Net']]"
"[[""newly added convolution layers ' parameters"", 'initialized by', ""' xavier ' method""]]"
"[['SGD', 'with', '0.9 momentum'], ['0.0005 weight decay', 'to fine - tune', 'our DSFD model']]"
"[['batch size', 'set to', '16']]"
"[['learning rate', 'set to', '10 ?3'], ['10 ?3', 'for', 'first 40 k steps'], ['10 ? 4 and 10 ? 5', 'for', 'two 10 k steps'], ['10 ? 4 and 10 ? 5', 'for', 'two 10 k steps']]"
"[['Non-maximum suppression', 'applied with', 'jaccard overlap'], ['jaccard overlap', 'of', '0.3'], ['0.3', 'to produce', 'top 750 high confident bounding boxes per image']]"
[]
[]
"[['our DSFD', 'to', '96.6 % , 95.7 % , 90.4 %'], ['96.6 % , 95.7 % , 90.4 %', 'with', 'ResNet 152'], ['our improved anchor matching strategy', 'greatly increases', 'number of']]"
[]
"[['Auxiliary loss', 'based on', 'progressive anchor'], ['Auxiliary loss', 'improves', 'performance'], ['performance', 'on', 'easy , medium and hard faces simultaneously']]"
"[['Our improved anchor matching', 'provides', 'better initial anchors and ground - truth faces'], ['better initial anchors and ground - truth faces', 'to', 'regress anchor'], ['regress anchor', 'from', 'faces'], ['regress anchor', 'achieves', 'improvements'], ['improvements', 'of', '0.3 %']]"
"[['training batch size', 'result in', 'hard setting'], ['training batch size', 'can get', '91.2 % AP'], ['hard setting', 'can get', '91.2 % AP']]"
"[['DSFD', 'with', 'SE - ResNeXt101 324d'], ['DSFD', 'got', '95.7 % , 94.8 % , 88.9 %'], ['SE - ResNeXt101 324d', 'got', '95.7 % , 94.8 % , 88.9 %'], ['95.7 % , 94.8 % , 88.9 %', 'on', 'easy , medium and hard settings']]"
"[['Our', 'enjoys', 'high inference speed']]"
"[['our DSFD', 'achieves', 'best performance'], ['best performance', 'among', 'all of the state - of - the - art face detectors'], ['best performance', 'among', '90.0 % ( Hard )'], ['all of the state - of - the - art face detectors', 'based on', 'average precision ( AP )'], ['average precision ( AP )', 'across', 'three subsets'], ['average precision ( AP )', 'i.e.', '96.6 % ( Easy )'], ['three subsets', 'i.e.', '96.6 % ( Easy )'], ['90.4 % ( Hard )', 'on', 'validation set'], ['90.0 % ( Hard )', 'on', 'test set']]"
"[['bounding box annotation', 'while', 'faces'], ['faces', 'in', 'FDDB'], ['faces', 'represented by', 'ellipses'], ['ellipses', 'learn', 'post - hoc ellipses regressor'], ['post - hoc ellipses regressor', 'to transform', 'final prediction results']]"
"[['our DSFD', 'achieves', 'state - of - the - art performance'], ['99.1 % and 86.2 %', 'when', 'number of false positives'], ['number of false positives', 'equals to', '1 , 000']]"
"[['additional annotations', 'to', 'unlabeled faces'], ['false positives', 'of', 'our model'], ['false positives', 'can be', 'further reduced'], ['false positives', 'can be', 'outperform'], ['our model', 'can be', 'further reduced'], ['our model', 'can be', 'outperform']]"
[]
"[['complementary scale - specific detectors', 'combined to produce', 'strong multi-scale object detector']]"
"[['R - CNN', 'samples', 'object proposals'], ['object proposals', 'at', 'multiple scales'], ['R - CNN', 'warps', 'proposals'], ['proposals', 'to', 'size ( e.g. 224224 )'], ['size ( e.g. 224224 )', 'supported by', 'CNN']]"
"[['unified multi-scale deep CNN', 'denoted', 'multi -scale CNN ( MS - CNN )'], ['unified multi-scale deep CNN', 'for', 'fast object detection'], ['multi -scale CNN ( MS - CNN )', 'for', 'fast object detection']]"
[]
"[['complimentary detectors', 'at', 'different output layers'], ['complimentary detectors', 'combined to form', 'strong multi-scale detector'], ['different output layers', 'combined to form', 'strong multi-scale detector']]"
"[['object proposals', 'on', 'detection benchmarks'], ['detection benchmarks', 'with', 'large variation of scale'], ['large variation of scale', 'such as', 'KITTI'], ['large variation of scale', 'achieving', 'recall'], ['recall', 'of', 'over 95 %'], ['over 95 %', 'for', 'only 100 proposals']]"
[]
"[['Learning', 'initialized with', 'model'], ['model', 'generated by', 'first learning stage'], ['first learning stage', 'of', 'proposal network']]"
"[['learning rate', 'set to', '0.0005'], ['learning rate', 'reduced by', 'factor of 10 times'], ['factor of 10 times', 'after', 'every 10,000 iterations']]"
"[['stops', 'after', '25,000 iterations']]"
"[['joint optimization', 'solved by', 'back - propagation'], ['back - propagation', 'throughout', 'unified network']]"
"[['parameters', 'of', 'layers "" conv 1 - 1 ""'], ['layers "" conv 1 - 1 ""', 'fixed during', 'learning'], ['learning', 'for', 'faster training']]"
"[['object patches', 'at', 'original scale'], ['object patches', 'through', 'CNN impairs performance'], ['original scale', 'through', 'CNN impairs performance']]"
[]
[]
"[['C ++', 'within', 'Caffe toolbox']]"
"[['NVIDIA Titan GPU', 'used for', 'CNN computations']]"
"[['highest accuracy', 'for', 'objects'], ['highest accuracy', 'that match', 'its scale'], ['objects', 'that match', 'its scale']]"
"[['individual recall', 'across', 'scales'], ['individual recall', 'is', 'low'], ['scales', 'is', 'low'], ['individual recall', 'combination', 'all detectors'], ['low', 'combination', 'all detectors'], ['all detectors', 'achieves', 'high recall'], ['high recall', 'for', 'all object scales']]"
"[['effect of input size', 'shows', 'proposal network'], ['proposal network', 'is', 'fairly robust'], ['fairly robust', 'to', 'size of input images'], ['size of input images', 'for', 'cars and pedestrians']]"
"[['proposal generation', 'especially for', 'pedestrians']]"
"[['state - of - the - art', 'compares', 'proposal generation network'], ['proposal generation network', 'to', 'BING'], ['proposal generation network', 'to', 'RPN']]"
"[['MS - CNN', 'achieves', 'recall'], ['recall', 'with', 'only 100 proposals'], ['about 98 %', 'with', 'only 100 proposals']]"
"[['mixture', 'are', 'close'], ['random', 'is', 'much worse']]"
"[['deconvoltion layer', 'helps', 'inmost cases']]"
"[['multimodal annotations', 'proposed to achieve', 'instance - aware segmentation'], ['instance - aware segmentation', 'using', 'weakly supervised bounding boxes'], ['run-data - based following algorithm', 'to trace', 'contours'], ['contours', 'of', 'objects']]"
"[['multi-scale pooling segmentation ( MSP - Seg )', 'as', 'underlying segmentation model'], ['underlying segmentation model', 'of', 'WSMA - Seg'], ['detection accuracy', 'of', 'WSMA - Seg.'], ['underlying segmentation model', 'to achieve', 'more accurate segmentation'], ['multi-scale pooling segmentation ( MSP - Seg )', 'to enhance', 'detection accuracy'], ['underlying segmentation model', 'to enhance', 'detection accuracy'], ['detection accuracy', 'of', 'WSMA - Seg.']]"
[]
"[['weakly supervised multimodal annotation segmentation ( WSMA - Seg ) approach', 'which uses', 'segmentation models'], ['segmentation models', 'to achieve', 'accurate and robust'], ['object detection', 'without', 'NMS']]"
"[['two phases', 'namely', 'training'], ['two phases', 'namely', 'testing phase']]"
"[['weakly supervised bounding box annotations', 'In', 'detection tasks'], ['weakly supervised bounding box annotations', 'in', 'detection tasks'], ['detection tasks', 'to', 'multi-channel segmentation'], ['multi-channel segmentation', 'like', 'masks'], ['masks', 'called', 'multimodal annotations'], ['segmentation model', 'trained using', 'multimodal annotations'], ['multimodal annotations', 'as', 'labels'], ['labels', 'to learn', 'multimodal heatmaps'], ['multimodal heatmaps', 'for', 'training images']]"
"[['contours', 'In', 'objects'], ['resulting heatmaps', 'of', 'given test image'], ['circumscribed quadrilaterals', 'of', 'corresponding contours'], ['resulting heatmaps', 'converted into', 'instance - aware segmentation map'], ['instance - aware segmentation map', 'based on', 'pixel - level logic operation'], ['contour tracing operation', 'conducted to generate', 'contours'], ['contours', 'for', 'objects'], ['objects', 'using', 'segmentation map'], ['bounding boxes of objects', 'created as', 'circumscribed quadrilaterals'], ['circumscribed quadrilaterals', 'of', 'corresponding contours']]"
"[['all hyperparameters', 'related to', 'anchor boxes and NMS'], ['topological structure', 'of', 'segmentation']]"
"[['multi-scale pooling segmentation ( MSP - Seg ) model', 'used as', 'underlying segmentation model'], ['underlying segmentation model', 'of', 'WSMA - Seg'], ['detection accuracy', 'of', 'WSMA - Seg'], ['underlying segmentation model', 'to achieve', 'more accurate segmentation'], ['multi-scale pooling segmentation ( MSP - Seg ) model', 'enhances', 'detection accuracy'], ['detection accuracy', 'of', 'WSMA - Seg']]"
"[['weakly supervised multimodal annotation segmentation ( WSMA - Seg ) approach', 'to achieve', 'accurate and']]"
"[['multimodal annotations', 'to achieve', 'instance - aware segmentation'], ['instance - aware segmentation', 'using', 'weakly supervised bounding boxes'], ['run-data - based following algorithm', 'to trace', 'contours of objects']]"
"[['multi-scale pooling segmentation ( MSP - Seg ) model', 'to achieve', 'more accurate segmentation'], ['multi-scale pooling segmentation ( MSP - Seg ) model', 'to enhance', 'detection accuracy'], ['detection accuracy', 'of', 'WSMA - Seg']]"
[]
"[['best performance', 'among', 'all solutions'], ['all solutions', 'in terms of', 'F1 Score']]"
[]
[]
"[['RetinaFace', 'performs', 'pixel - wise face localisation'], ['pixel - wise face localisation', 'on', 'various scales of faces'], ['various scales of faces', 'by taking advantages of', 'joint extra-supervised and self - supervised multi-task learning']]"
"[['selfsupervised mesh decoder branch', 'for predicting', 'pixel - wise 3D shape face information'], ['pixel - wise 3D shape face information', 'in parallel with', 'existing supervised branches']]"
[]
"[['single - stage pixel - wise face localisation method', 'employs', 'extra-supervised and self - supervised multi-task learning'], ['extra-supervised and self - supervised multi-task learning', 'in parallel with', 'existing box classification and regression branches']]"
"[['dense 3 D face vertices', 'projected on', 'image plane']]"
"[['state - of - the - art dense face localisation method', 'by exploiting', 'multi-task losses'], ['multi-task losses', 'coming from', 'strongly supervised and self - supervised signals']]"
"[['MTCNN and STN', 'simultaneously detected', 'faces'], ['MTCNN and STN', 'simultaneously detected', 'five facial landmarks']]"
"[['mesh decoder branch', 'through', 'self - supervision learning'], ['self - supervision learning', 'for predicting', 'pixel - wise 3 D face shape'], ['pixel - wise 3 D face shape', 'in parallel with', 'existing supervised branches']]"
"[['single - stage design', 'propose', 'novel pixel - wise face localisation method'], ['novel pixel - wise face localisation method', 'named', 'Reti- naFace'], ['novel pixel - wise face localisation method', 'employs', 'multi-task learning strategy'], ['multi-task learning strategy', 'to simultaneously predict', 'face score'], ['multi-task learning strategy', 'to simultaneously predict', 'face box'], ['multi-task learning strategy', 'to simultaneously predict', 'five facial landmarks'], ['multi-task learning strategy', 'to simultaneously predict', '3D position and'], ['multi-task learning strategy', 'to simultaneously predict', 'correspondence'], ['correspondence', 'of', 'each facial pixel']]"
"[['negative anchors', 'applied', 'classification loss']]"
"[['shared loss head ( 1 1 conv )', 'across', 'different feature maps']]"
"[['scale step', 'at', '2 1 / 3'], ['ground - truth box', 'when', 'IoU'], ['IoU', 'larger than', '0.5']]"
"[['most of the anchors ( > 99 % )', 'are', 'negative'], ['negative', 'after', 'matching step'], ['most of the anchors ( > 99 % )', 'employ', 'standard OHEM'], ['standard OHEM', 'to alleviate', 'significant imbalance'], ['significant imbalance', 'between', 'positive and negative training examples']]"
"[['negative anchors', 'by', 'loss values'], ['negative anchors', 'select', 'top ones'], ['top ones', 'so that', 'ratio'], ['ratio', 'between', 'negative and positive samples'], ['ratio', 'is', 'at least 3:1'], ['negative and positive samples', 'is', 'at least 3:1']]"
"[['RetinaFace', 'using', 'SGD optimiser']]"
"[['learning rate', 'starts from', '10 ? 3'], ['learning rate', 'rising to', '10 ? 2'], ['10 ? 3', 'rising to', '10 ? 2'], ['10 ? 2', 'after', '5 epochs'], ['learning rate', 'divided by', '10'], ['5 epochs', 'divided by', '10']]"
"[['training process', 'terminates at', '80 epochs']]"
"[['Box voting', 'applied on', 'union set of predicted face boxes'], ['union set of predicted face boxes', 'using', 'IoU threshold'], ['IoU threshold', 'at', '0.4']]"
"[['state - of - the - art techniques', 'i.e.', 'context module'], ['state - of - the - art techniques', 'i.e.', 'deformable convolution'], ['state - of - the - art techniques', 'setup', 'strong baseline ( 91.286 % )'], ['strong baseline ( 91.286 % )', 'slightly better than', 'ISRN ( 90.9 % )']]"
"[['mAP ( 0.775 % )', 'on', 'Hard subset']]"
"[['dense regression branch', 'increases', 'face box AP'], ['face box AP', 'on', 'Easy and Medium subsets'], ['results', 'on', 'Hard subset'], ['results', 'on', 'Hard subset']]"
"[['landmark and dense regression', 'enables', 'further improvement'], ['further improvement', 'compared to', 'adding landmark regression only']]"
"[['landmark regression', 'does help', 'dense regression'], ['landmark regression', 'boosts', 'face detection performance'], ['dense regression', 'boosts', 'face detection performance']]"
"[['state - of - the - art methods', 'in terms of', 'AP']]"
"[['RetinaFace', 'produces', 'best AP'], ['best AP', 'in', 'all subsets'], ['all subsets', 'of', 'validation and test sets'], ['all subsets', 'of', '91.8 % ( Hard )'], ['validation and test sets', 'i.e.', '96.9 % ( Easy )'], ['validation and test sets', 'i.e.', '96.1 % ( Medium )'], ['validation and test sets', 'i.e.', '91.8 % ( Hard )'], ['validation and test sets', 'i.e.', '95.6 % ( Medium )'], ['validation and test sets', 'i.e.', '91.4 % ( Hard )'], ['91.8 % ( Hard )', 'for', 'validation set'], ['91.4 % ( Hard )', 'for', 'test set']]"
"[['Reti - na Face', 'sets up', 'new impressive record ( 91.4 % v.s. 90.3 % )'], ['new impressive record ( 91.4 % v.s. 90.3 % )', 'on', 'Hard subset'], ['Hard subset', 'which contains', 'large number of tiny faces']]"
"[['five facial landmarks', 'predicted by', 'Retina Face'], ['five facial landmarks', 'are', 'very robust'], ['very robust', 'under', 'variations of pose , occlusion and resolution']]"
"[['normalised mean errors ( NME )', 'from', '2.72 %'], ['2.72 %', 'to', '2.21 %'], ['normalised mean errors ( NME )', 'compared to', 'MTCNN'], ['2.21 %', 'compared to', 'MTCNN']]"
"[['failure rate', 'from', '26.31 %'], ['failure rate', 'to', '9.37 %'], ['26.31 %', 'to', '9.37 %']]"
"[['performance', 'of', 'state - of - the - art publicly available face recognition method'], ['state - of - the - art publicly available face recognition method', 'i.e.', 'ArcFace']]"
"[['CFP - FP', 'demonstrate', 'Reti - na Face'], ['Reti - na Face', 'boost', ""ArcFace 's verification accuracy""], [""ArcFace 's verification accuracy"", 'from', '98.37 %'], ['98.37 %', 'to', '99.49 %']]"
"[['two tricks', 'to', 'weigh samples'], ['face detection score', 'to', 'weigh samples'], ['weigh samples', 'within', 'templates'], ['two tricks', 'to progressively improve', 'face verification accuracy']]"
"[['TAR (', 'at', 'FAR = 1 e ? 6 )'], ['significantly improves', 'from', '88 . 29 %'], ['significantly improves', 'to', '89.59 %'], ['88 . 29 %', 'to', '89.59 %'], ['significantly improves', 'by replacing', 'MTCNN'], ['89.59 %', 'by replacing', 'MTCNN'], ['MTCNN', 'with', 'RetinaFace']]"
[]
[]
"[['large - scale face detection dataset', 'called', 'WIDER FACE']]"
"[['WIDER', 'through proposing', 'multi-scale two - stage cascade framework'], ['multi-scale two - stage cascade framework', 'uses', 'divide and conquer strategy'], ['divide and conquer strategy', 'to deal with', 'large scale variations']]"
"[['outperforms', 'on', 'three subsets'], ['other methods', 'on', 'three subsets'], ['outperforms', 'with', 'DPM and ACF'], ['other methods', 'with', 'DPM and ACF'], ['three subsets', 'with', 'DPM and ACF'], ['outperforms', 'as', 'marginal second and third'], ['DPM and ACF', 'as', 'marginal second and third']]"
"[['results', 'of', 'small scale'], ['small scale', 'are', 'abysmal']]"
"[['impact', 'of', 'occlusion'], ['height', 'of', 'at least 30 pixels'], ['occlusion', 'on', 'detecting faces'], ['detecting faces', 'with', 'height'], ['height', 'of', 'at least 30 pixels']]"
"[['maximum AP', 'is', 'only 26.5 %'], ['only 26.5 %', 'achieved by', 'Faceness']]"
"[['best performance', 'of', 'baseline methods']]"
"[['Faceness and DPM', 'perform', 'relatively better'], ['part based models', 'perform', 'relatively better'], ['relatively better', 'than', 'other methods'], ['other methods', 'on', 'occlusion handling']]"
"[['best performance', 'achieved by', 'Faceness'], ['Faceness', 'with', 'recall below 20 %']]"
"[['Faceness', 'tends to', 'outperform']]"
[]
"[['retrained models', 'perform', 'consistently better'], ['consistently better', 'than', 'baseline models']]"
"[['average AP improvement', 'of', 'retrained ACF detector'], ['average AP improvement', 'is', '5.4 %'], ['retrained ACF detector', 'is', '5.4 %'], ['5.4 %', 'in comparison to', 'baseline ACF detector']]"
"[['retrained Faceness model', 'obtain', '4.2 % improvement'], ['4.2 % improvement', 'on', 'WIDER hard test set']]"
"[['retrained ACF detector', 'achieves', 'recall rate'], ['recall rate', 'of', '87.48 %'], ['considerable margin', 'of', '1.4 %'], ['outperforms', 'by', 'considerable margin'], ['baseline ACF', 'by', 'considerable margin'], ['considerable margin', 'of', '1.4 %']]"
"[['recall rate improvement', 'of', 'retrained Faceness detector'], ['recall rate improvement', 'is', '0.8 %'], ['retrained Faceness detector', 'is', '0.8 %'], ['0.8 %', 'in comparison to', 'baseline Faceness detector']]"
"[['multi-scale cascade CNN', 'obtains', '8.5 % AP improvement'], ['8.5 % AP improvement', 'on', 'WIDER Hard subset'], ['WIDER Hard subset', 'compared to', 'retrained Faceness']]"
"[['multi-scale cascade CNN', 'outperforms', 'other baseline methods'], ['other baseline methods', 'with', 'considerable margin']]"
[]
"[['novel face detector', 'named', 'FaceBoxes'], ['novel face detector', 'with', 'superior performance'], ['superior performance', 'on', 'both speed and accuracy']]"
[]
[]
"[['state - of - the - art face detector', 'with', 'real - time speed'], ['real - time speed', 'on', 'CPU']]"
"[['novel face detector', 'named', 'FaceBoxes'], ['FaceBoxes', 'contains', 'single fully convolutional neural network'], ['novel face detector', 'trained', 'end - to - end']]"
"[['Rapidly Digested Convolutional Layers ( RDCL )', 'to enable', 'face detection'], ['face detection', 'to achieve', 'real - time speed'], ['real - time speed', 'on', 'CPU'], ['Multiple Scale Convolutional Layers ( MSCL )', 'to handle', 'various scales of face'], ['various scales of face', 'via', 'enriching receptive fields'], ['various scales of face', 'via', 'discretizing anchors over']]"
"[['randomly initialized', 'with', '"" xavier "" method']]"
"[['resulting model', 'using', 'SGD'], ['resulting model', 'using', 'batch size'], ['SGD', 'with', '0.9 momentum'], ['SGD', 'with', 'batch size']]"
"[['maximum number of iterations', 'is', '120 k'], ['maximum number of iterations', 'use', '10 ? 3 learning rate'], ['10 ? 3 learning rate', 'for', 'first 80 k iterations'], ['training', 'for', '20 k iterations'], ['10 ? 3 learning rate', 'continue', 'training'], ['training', 'for', '20 k iterations'], ['20 k iterations', 'with', '10 ? 4 and 10 ? 5']]"
[]
"[['our FaceBoxes', 'run at', '20 FPS'], ['20 FPS', 'on', 'CPU'], ['CPU', 'with', 'state - of - the - art accuracy']]"
"[['MSCL', 'effectively increases', 'm AP'], ['m AP', 'by', '1.0 %']]"
[]
"[['outperforms', 'by', 'large margin'], ['all others', 'by', 'large margin']]"
[]
[]
[]
[]
[]
"[['novel framework', 'based on', 'CNNs'], ['CNNs', 'for', 'simultaneous face detection'], ['CNNs', 'for', 'head pose estimation'], ['CNNs', 'for', 'gender recognition'], ['gender recognition', 'from', 'given image']]"
"[['CNN architecture', 'to learn', 'common features'], ['common features', 'for', 'tasks'], ['CNN architecture', 'exploit', 'synergy']]"
"[['information', 'contained in', 'features']]"
[]
"[['separate fusion - CNN', 'to fuse', 'hyperfeatures']]"
"[['intermediate layer features', 'provides', 'additional performance boost']]"
[]
"[['mixture of trees', 'with', 'shared pool of parts'], ['every facial landmark', 'modeled as', 'apart'], ['every facial landmark', 'uses', 'global mixtures'], ['global mixtures', 'to capture', 'topological changes'], ['topological changes', 'due to', 'viewpoint variations']]"
"[['all the intermediate layers', 'of', 'CNN'], ['three different scales', 'of', 'image pyramid'], ['CNN', 'at', 'three different scales'], ['three different scales', 'of', 'image pyramid'], ['image pyramid', 'for', 'multi-task training'], ['multi-task training', 'on', 'diverse sets']]"
"[['network architecture', 'such that', 'tasks'], ['tasks', 'exploit', 'low level as well as high level features'], ['low level as well as high level features', 'of', 'network']]"
[]
[]
"[['former', 'learns', 'shape increment'], ['shape increment', 'given', 'mean initial shape'], ['mean initial shape', 'trains', 'appearance model'], ['appearance model', 'to predict', 'keypoint locations']]"
[]
"[['annotations', 'for', '21 landmark points per face'], ['21 landmark points per face', 'along with', 'face bounding - box'], ['21 landmark points per face', 'along with', 'gender information']]"
"[['Selective Search algorithm', 'in', 'R - CNN'], ['faces', 'in', 'image'], ['Selective Search algorithm', 'to generate', 'region proposals'], ['R - CNN', 'to generate', 'region proposals'], ['region proposals', 'for', 'faces'], ['faces', 'in', 'image']]"
"[['21 point markups', 'for', 'face landmarks locations']]"
"[['visibility factor', 'in order to test', 'presence'], ['presence', 'of', 'predicted landmark']]"
[]
"[['two class problem', 'similar to', 'face detection']]"
"[['IRP', 'improves', 'recall'], ['recall', 'by generating', 'more candidate proposals'], ['more candidate proposals', 'by using', 'predicted landmarks information'], ['predicted landmarks information', 'from', 'initial set of region proposals']]"
[]
"[['linear bounding box regression', 'to localize', 'face co-ordinates']]"
[]
"[['Hyperface method', 'tested on', 'machine'], ['Hyperface method', 'tested on', 'GTX TITAN - X GPU'], ['machine', 'with', '8 cores']]"
"[['fast version', 'of', 'HyperFace'], ['HyperFace', 'uses', 'high recall fast face detector'], ['high recall fast face detector', 'instead of', 'Selective Search'], ['Selective Search', 'to generate', 'candidate region proposals']]"
"[['face detector', 'using', 'Single Shot Detector ( SSD ) framework']]"
"[['Fast - HyperFace', 'consumes', 'total time'], ['total time', 'of', '0.15s']]"
"[['Fast - HyperFace', 'achieves', 'm AP'], ['m AP', 'of', '97.6 %'], ['m AP', 'on', 'AFW face detection task'], ['97.6 %', 'on', 'AFW face detection task']]"
"[['Fast - HyperFace', 'improves', 'speed'], ['speed', 'by', 'factor of 12'], ['factor of 12', 'with', 'negligible degradation'], ['negligible degradation', 'in', 'performance']]"
[]
[]
[]
"[['Face R - FCN', 're-weights', 'embedding responses'], ['embedding responses', 'on', 'score maps'], ['Face R - FCN', 'eliminates', 'effect of non-uniformed contribution'], ['effect of non-uniformed contribution', 'in', 'each facial part'], ['each facial part', 'using', 'position - sensitive average pooling']]"
"[['FAN', 'proposes', 'anchor - level attention'], ['anchor - level attention', 'by highlighting', 'features'], ['features', 'from', 'face region'], ['face region', 'to detect', 'occluded faces']]"
"[['semi-supervised solution', 'to generate', 'approximate labels'], ['approximate labels', 'for', 'contextual parts'], ['contextual parts', 'related to', 'faces'], ['series of anchors', 'called', 'PyramidAnchors'], ['PyramidAnchors', 'invented to be easily added to', 'general anchor - based architectures']]"
"[['Context - sensitive prediction module ( CPM )', 'to incorporate', 'context information'], ['context information', 'around', 'target face'], ['context information', 'with', 'wider and deeper network'], ['target face', 'with', 'wider and deeper network']]"
"[['max - in - out layer', 'for', 'prediction module'], ['max - in - out layer', 'to further improve', 'capability'], ['prediction module', 'to further improve', 'capability'], ['capability', 'of', 'classification network']]"
"[['training strategy', 'named as', 'Data - anchor - sampling'], ['Data - anchor - sampling', 'to make', 'adjustment'], ['adjustment', 'on', 'distribution'], ['distribution', 'of', 'training dataset']]"
"[['anchor-based context assisted method', 'called', 'PyramidAnchors'], ['anchor-based context assisted method', 'to introduce', 'supervised information'], ['supervised information', 'on learning', 'contextual features'], ['contextual features', 'for', 'small , blurred and partially occluded faces']]"
"[['Low - level Feature Pyramid Networks ( LFPN )', 'to merge', 'contextual features and facial features']]"
"[['context - sensitive prediction module', 'consisting of', 'mixed network structure'], ['context - sensitive prediction module', 'consisting of', 'max - in - out layer'], ['max - in - out layer', 'to learn', 'accurate location and classification'], ['accurate location and classification', 'from', 'merged features']]"
[]
"[['Focus Loss', 'address', 'class imbalance'], ['class imbalance', 'by reshaping', 'standard cross entropy loss']]"
"[['data augment sample method', 'named', 'Data - anchor - sampling']]"
"[['smaller face samples', 'through', 'larger ones'], ['larger ones', 'to increase', 'diversity of face samples'], ['diversity of face samples', 'of', 'smaller scales']]"
"[['our PyramidBox', 'use', 'pre-trained parameters'], ['pre-trained parameters', 'from', 'VGG16']]"
"[['parameters', 'of', 'conv fc 67 and conv fc 7'], ['sub - sampling parameters', 'of', 'fc 6 and fc 7'], ['conv fc 67 and conv fc 7', 'initialized by', 'sub - sampling parameters'], ['sub - sampling parameters', 'from', 'fc 6 and fc 7'], ['fc 6 and fc 7', 'of', 'VGG16'], ['other additional layers', 'randomly initialized with', '"" xavier ""']]"
"[['learning rate', 'of', '10 ? 3'], ['10 ? 3', 'for', '80 k iterations'], ['last 20 k iterations', 'on', 'WIDER FACE training set'], ['WIDER FACE training set', 'with', 'batch size 16']]"
"[['momentum', 'of', '0.9'], ['weight decay', 'of', '0.0005']]"
[]
"[['LFPN', 'started from', 'middle layer'], ['middle layer', 'using', 'conv fc7'], ['conv fc7', 'in', 'our Pyramid Box'], ['conv fc7', 'is', 'more powerful']]"
"[['LFPN', 'increases', 'm AP'], ['m AP', 'by', '1.9 %'], ['1.9 %', 'on', 'hard subset']]"
"[['Data - anchor - sampling', 'based on', 'LFPN network']]"
"[['mAP', 'increased by', '0.4 % , 0.4 % and 0.6 %'], ['0.4 % , 0.4 % and 0.6 %', 'on', 'easy , medium and hard subset']]"
[]
"[['Wider and deeper context prediction module', 'is', 'better']]"
"[['performance', 'of', 'CPM'], ['performance', 'better than', 'DSSD module and SSH context module'], ['CPM', 'better than', 'both'], ['CPM', 'better than', 'DSSD module and SSH context module']]"
"[['SSH and DSSD', 'gains', 'very little'], ['very little', 'compared to', 'SSH alone']]"
"[['method of Max - in - out', 'improves', 'mAP'], ['mAP', 'on', 'WIDER FACE validation set'], ['WIDER FACE validation set', 'about', '+ 0.2 % ( Easy )'], ['WIDER FACE validation set', 'about', '+ 0.3 % ( Medium )'], ['WIDER FACE validation set', 'about', '+ 0.1 % ( Hard )']]"
"[['m AP', 'increase', '2.1 % , 2.3 % and 4.7 %'], ['2.1 % , 2.3 % and 4.7 %', 'on', 'easy , medium and hard subset']]"
[]
[]
[]
[]
"[['network', 'to simultaneously look at', 'multi-scale features'], ['outside facial regions', 'as', 'potential body regions']]"
"[['challenges', 'in', 'problem of unconstrained face detection']]"
"[['CMS - RCNN method', 'introduces', 'Multi - Scale Region Proposal Network ( MS - RPN )'], ['Multi - Scale Region Proposal Network ( MS - RPN )', 'to generate', 'set'], ['region candidates', 'of', 'facial regions']]"
"[['skip pooling', 'used to', 'extract'], ['information', 'at', 'multiple scales and levels'], ['multiple scales and levels', 'of', 'abstraction']]"
"[['depth descriptor', 'beside', 'RGB channels'], ['our', 'solves', 'problem'], ['problem', 'under', 'deep learning framework'], ['deep learning framework', 'where', 'global and the local context features'], ['global and the local context features', 'synchronized to', 'Faster Region - based Convolutional Neural Networks'], ['Faster Region - based Convolutional Neural Networks', 'to robustly achieve', 'semantic detection']]"
"[['CMS - RCNN', 'implemented in', 'Caffe deep learning framework']]"
"[['first 5 sets', 'of', 'convolution layers'], ['convolution layers', 'have', 'same architecture'], ['same architecture', 'as', 'deep VGG - 16 model'], ['parameters', 'initialized from', 'pre-trained VGG - 16']]"
"[['initial scale', 'of', ""' conv3 ' , ' conv4 '""]]"
"[['features', 'pooled from', ""' conv3 ' , ' conv4 '""], ['scale', 'to be', '57.75 , 81.67 , and 81.67']]"
"[['MS - RPN and the CMS - CNN', 'share', 'same parameters'], ['same parameters', 'for', 'all convolution layers'], ['all convolution layers', 'so', 'computation'], ['computation', 'can be done', 'once'], ['computation', 'resulting in', 'higher efficiency'], ['once', 'resulting in', 'higher efficiency']]"
"[['channel size', 'of', 'concatenated feature map']]"
"[['channel size', 'of', 'final feature map'], ['original fifth convolution layer', 'in', 'Faster R - CNN']]"
"[['strong baseline methods', 'including', 'Two - stage CNN'], ['strong baseline methods', 'including', 'Multi-scale Cascade CNN'], ['strong baseline methods', 'including', 'Faceness'], ['strong baseline methods', 'including', 'Aggregate Channel Features ( ACF )'], ['strong baseline methods', 'by', 'large margin'], ['Aggregate Channel Features ( ACF )', 'by', 'large margin']]"
[]
"[['strong baselines', 'by', 'large margin']]"
"[['best average precision', 'in', 'all level faces'], ['all level faces', 'i.e.', 'AP'], ['second best baseline', 'by', '26.0 % ( Easy )'], ['second best baseline', 'by', '60.8 % ( Hard )']]"
"[['difficulty level', 'goes', 'up'], ['CMS - RCNN', 'can detect', 'challenging faces']]"
[]
"[['context model', 'produces', 'longer PR curve']]"
[]
"[['Our method', 'achieves', 'best recall rate']]"
"[['proposed', 'achieves', 'very high recall rate'], ['CMS - RCNN approach', 'achieves', 'very high recall rate'], ['very high recall rate', 'comparing against', 'all other methods']]"
"[['human facial regions', 'from', 'images']]"
"[['strong baselines', 'on', 'WIDER FACE'], ['state - of - the - art methods', 'on', 'FDDB'], ['our proposed approach', 'consistently achieves', 'very competitive results'], ['very competitive results', 'against', 'state - of - the - art methods'], ['state - of - the - art methods', 'on', 'FDDB']]"
[]
"[['Our method', 'achieves', 'two 1th places'], ['Our method', 'achieves', 'one 2nd place']]"
"[['Our framework', 'achieves', 'two 1st places'], ['Our framework', 'achieves', 'one 2nd place'], ['one 2nd place', 'in', 'three tasks'], ['three tasks', 'over', 'WIDER FACE validation dataset ( easy , medium , hard )']]"
[]
"[['Dense - Box', 'employs', 'fully deep convolutional neural network'], ['fully deep convolutional neural network', 'to directly predict', 'face confidence'], ['fully deep convolutional neural network', 'to directly predict', 'corresponding bounding box']]"
"[['UnitBox', 'introduces', 'novel intersection - over - union ( IoU ) loss'], ['novel intersection - over - union ( IoU ) loss', 'to predict', 'bounding box'], ['bounding box', 'regresses', 'four bounds'], ['four bounds', 'of', 'predicted']]"
"[['S 3 FD', 'presents', 'single shot scale - invariant face detector'], ['single shot scale - invariant face detector', 'achieves', 'good result'], ['good result', 'on', 'WIDER FACE datasets']]"
"[['Single NVIDIA Tesla K80', 'used for', 'training and testing']]"
"[['Mini batch size', 'set to', '1'], ['1', 'considering', 'memory consumption']]"
"[['deformable layer', 'used to output', '"" thin "" feature map'], ['"" thin "" feature map', 'with exploiting', 'image context']]"
"[['scales', 'carefully designed to capture', 'better locations'], ['better locations', 'of', 'faces'], ['faces', 'in', 'RPN stage'], ['number of filters', 'for', 'RPN layer']]"
"[['batch size', 'of', 'RPN and R - CNN'], ['RPN and R - CNN', 'assigned as', '256 and 128']]"
"[['initial learning rate', 'set to', '1e - 3'], ['initial learning rate', 'decrease to', '1e - 4'], ['1e - 4', 'after', '20w iterations']]"
"[['momentum', 'set to', '1e - 4 and 0.9']]"
"[['multi-scale testing strategy', 'adapted to be', 'robust']]"
"[['top - ranked 6000 proposals', 'directly selected without', 'NMS'], ['top - ranked 6000 proposals', 'can', 'boost'], ['testing', 'can', 'boost'], ['0.1 % , 0.3 % and 0.6 %', 'on', 'easy set , medium set and hard set']]"
"[['FDNet1.0', 'wins', 'two 1st places'], ['FDNet1.0', 'wins', 'one 2nd place'], ['one 2nd place', 'on', 'validation set']]"
[]
[]
[]
"[['performance', 'of', 'face detection']]"
"[['R - CNN - like detectors', 'address', 'class imbalance'], ['class imbalance', 'by', 'two - stage cascade']]"
"[['RetinaNet', 'proposes', 'focal loss'], ['focal loss', 'to', 'focus'], ['sparse set', 'of', 'hard examples'], ['down - weight the loss', 'assigned to', 'well - classified examples']]"
[]
"[['cascading', 'with', 'different IoU thresholds'], ['R - CNN', 'with', 'different IoU thresholds']]"
"[['RefineDet', 'applies', 'two - step regression'], ['two - step regression', 'to', 'single - shot detector']]"
"[['two - step classification and regression', 'on', 'different levels'], ['Selective Refinement Network ( SRN )', 'selectively applies', 'two - step classification and regression'], ['two - step classification and regression', 'to', 'specific levels of detection layers']]"
"[['RetinaNet with STC', 'improves', 'recall efficiency'], ['recall efficiency', 'to', 'certain extent']]"
"[['Receptive Field Enhancement ( RFE )', 'to provide', 'more diverse receptive fields'], ['more diverse receptive fields', 'to better capture', 'extreme - pose faces']]"
"[['STC module', 'to filter out', 'most simple negative samples'], ['most simple negative samples', 'from', 'low level layers'], ['most simple negative samples', 'to reduce', 'classification search space'], ['low level layers', 'to reduce', 'classification search space']]"
"[['393 , 703 annotated face bounding boxes', 'in', '32'], ['variations', 'in', 'pose'], ['variations', 'in', 'lighting condition'], ['203 images', 'with', 'variations'], ['variations', 'in', 'pose'], ['variations', 'in', 'scale'], ['variations', 'in', 'facial expression'], ['variations', 'in', 'occlusion'], ['variations', 'in', 'lighting condition']]"
"[['backbone network', 'initialized by', 'pretrained ResNet - 50 model'], ['all the parameters', 'in', 'newly added convolution layers'], ['newly added convolution layers', 'initialized by', '"" xavier "" method']]"
"[['SRN model', 'using', 'SGD'], ['SRN model', 'using', 'batch size'], ['SGD', 'with', '0.9 momentum'], ['SGD', 'with', 'batch size']]"
"[['learning rate', 'to', '10 ?2'], ['10 ?2', 'for', 'first 100 epochs'], ['10 ? 3 and 10 ? 4', 'for', '20 and 10 epochs'], ['10 ? 3 and 10 ? 4', 'for', '20 and 10 epochs']]"
"[['SRN', 'using', 'Py - Torch library']]"
"[['STC', 'first filters', 'regularly tiled anchors'], ['regularly tiled anchors', 'on', 'selected pyramid levels'], ['selected pyramid levels', 'with', 'negative confidence scores'], ['negative confidence scores', 'larger than', 'threshold ? = 0.99'], ['STR', 'adjusts', 'locations and sizes'], ['locations and sizes', 'of', 'selected anchors']]"
"[['non-maximum suppression ( NMS )', 'with', 'jaccard overlap'], ['jaccard overlap', 'of', '0.5'], ['0.5', 'to generate', 'top 750 high confident detections per image']]"
"[['ordinary prediction head', 'instead of', 'proposed RFE']]"
"[['two - step classification', 'to', 'each pyramid level'], ['two - step classification', 'to', 'low pyramid levels'], ['each pyramid level', 'applying', 'two - step classification'], ['two - step classification', 'to', 'low pyramid levels'], ['two - step classification', 'improves', 'performance'], ['low pyramid levels', 'improves', 'performance']]"
"[['STC module', 'selectively applies', 'two - step classification'], ['two - step classification', 'on', 'low pyramid levels ( i.e. , P2 , P3 , and P4 )']]"
"[['our STC', 'effectively reduces', 'false positives'], ['false positives', 'across', 'different recall rates']]"
"[['much better results', 'than', 'baseline'], ['much better results', 'with', '0.8 % , 0.9 % and 0.8 % AP improvements'], ['baseline', 'with', '0.8 % , 0.9 % and 0.8 % AP improvements'], ['0.8 % , 0.9 % and 0.8 % AP improvements', 'on', 'Easy , Medium , and Hard subsets']]"
"[['two - step regression', 'to', 'each pyramid level']]"
"[['STR module', 'produces', 'consistently accurate detection results'], ['consistently accurate detection results', 'than', 'baseline method']]"
"[['gap', 'between', 'AP'], ['AP', 'across', 'all three subsets'], ['gap', 'as', 'IoU threshold'], ['increases', 'as', 'IoU threshold']]"
"[['further improved', 'to', '96.1 % , 95.0 % and 90.1 %'], ['96.1 % , 95.0 % and 90.1 %', 'on', 'Easy , Medium and Hard subsets']]"
"[['receptive fields', 'of', 'detection layers'], ['faces', 'with', 'extreme poses']]"
"[['RFE', 'consistently improves', 'AP scores'], ['AP scores', 'in', 'different subsets'], ['AP scores', 'i.e.', '0.3 % , 0.3 % , and 0.1 % APs'], ['different subsets', 'i.e.', '0.3 % , 0.3 % , and 0.1 % APs'], ['0.3 % , 0.3 % , and 0.1 % APs', 'on', 'Easy , Medium , and Hard categories']]"
[]
"[['SRN', 'achieves', 'state - of - the - art results'], ['state - of - the - art results', 'by improving', '4.99 % AP score'], ['4.99 % AP score', 'compared to', 'second best method STN']]"
"[['our SRN', 'sets', 'new state - of - the - art performance'], ['new state - of - the - art performance', 'i.e.', '98.8 % true positive rate'], ['98.8 % true positive rate', 'when', 'number of false positives'], ['number of false positives', 'equal to', '1000']]"
"[['SRN', 'performs', 'favourably'], ['favourably', 'against', 'state - of - the - art'], ['state - of - the - art', 'based on', 'average precision ( AP )'], ['average precision ( AP )', 'across', 'three subsets'], ['average precision ( AP )', 'especially on', 'Hard subset'], ['Hard subset', 'contains', 'large amount']]"
"[['best AP scores', 'in', 'all subsets'], ['all subsets', 'of', 'validation and testing sets'], ['all subsets', 'of', '89.7 % ( Hard )'], ['validation and testing sets', 'i.e.', '96.4 % ( Easy )'], ['validation and testing sets', 'i.e.', '95.3 % ( Medium )'], ['validation and testing sets', 'i.e.', '90.2 % ( Hard )'], ['validation and testing sets', 'i.e.', '94.9 % ( Medium )'], ['90.2 % ( Hard )', 'for', 'validation set'], ['89.7 % ( Hard )', 'for', 'testing set']]"
[]
"[['classifier learning process', 'follows', 'VJ framework pipeline']]"
"[['variant', 'of', 'channel features'], ['channel features', 'called', 'aggregate channel features'], ['aggregate channel features', 'extracted directly as', 'pixel values'], ['pixel values', 'on', 'subsampled channels']]"
[]
"[['2048', 'as', 'number of weak classifiers'], ['number of weak classifiers', 'contained in', 'soft cascade']]"
[]
"[['our multi-scale detector', 'achieves', 'ap value'], ['ap value', 'of', '96.8 %'], ['outperforming', 'by', 'large margin'], ['other academic methods', 'by', 'large margin']]"
"[['our detector', 'achieves', '83.7 %']]"
"[['continuous score', 'which takes', 'overlap ratio'], ['overlap ratio', 'as', 'score'], ['continuous score', 'gets', '61.9 % true positive rate'], ['our method', 'gets', '61.9 % true positive rate'], ['61.9 % true positive rate', 'at', '1 FPPI'], ['1 FPPI', 'for', 'multiscale version'], ['61.9 % true positive rate', 'surpassing', 'other methods'], ['rectangular detections', 'by', 'notable margin']]"
[]
"[['multi-task Region Proposal Network ( RPN )', 'simultaneously proposes', 'candidate face regions'], ['candidate face regions', 'along with', 'associated facial landmarks']]"
"[['conventional boosting cascade', 'to obtain', 'set of face candidate areas']]"
"[['ROI masks', 'so', 'different'], ['feature', 'in', 'overlapping area']]"
"[['Real - Boost algorithm', 'for', 'cascade classification learning']]"
"[['GoogleNet', 'in both', 'RPN and RCNN networks']]"
"[['multi-task RPN , Supervised Transformer , and feature combination', 'bring about', '1 % , 1 % , and 2 % recall improvement']]"
"[['training phase', 'to increase', 'variation'], ['variation', 'of', 'training samples'], ['training samples', 'randomly select', 'K positive / negative samples'], ['K positive / negative samples', 'from', 'each image'], ['each image', 'for', 'RCNN network']]"
"[['NMS', 'tend to include', 'too much noisy low confidence candidates']]"
"[['PR curves', 'of using', 'all candidates , NMS , and non-top K suppression']]"
"[['Our non - top K suppression', 'achieved', 'consistently better results'], ['consistently better results', 'than', 'NMS'], ['consistently better results', 'under', 'same number of candidates'], ['NMS', 'under', 'same number of candidates']]"
[]
"[['Non- top K ( K = 3 ) suppression', 'adopted in', 'all settings'], ['all settings', 'to make', 'RCNN network']]"
"[['DNN detector', 'run at', '10 FPS'], ['10 FPS', 'on', 'CPU fora VGA image']]"
[]
[]
"[['deformable part based methods', 'e.g.', 'structure model'], ['deformable part based methods', 'e.g.', 'Tree Parts Model ( TSM )']]"
"[['global regression', 'from', '5 facial points'], ['5 facial points', 'to', 'face rectangles'], ['face rectangles', 'to match', 'annotation']]"
[]
"[['challenges', 'in', 'unconstrained face detection'], ['challenges', 'such as', 'arbitrary'], ['unconstrained face detection', 'such as', 'arbitrary']]"
[]
"[['first step', 'in', 'automatic face recognition applications']]"
[]
[]
"[['several desirable properties', 'such as', 'scale invariance'], ['several desirable properties', 'such as', 'boundedness'], ['several desirable properties', 'such as', 'ability'], ['ability', 'to reconstruct', 'original image']]"
"[['NPD features', 'obtained from', 'lookup table'], ['resulting face detection template', 'easily scaled for', 'multiscale face detection']]"
"[['deep quadratic tree learning method', 'construct', 'single soft - cascade AdaBoost classifier'], ['single soft - cascade AdaBoost classifier', 'to handle', 'complex face manifolds'], ['single soft - cascade AdaBoost classifier', 'to handle', 'arbitrary pose'], ['single soft - cascade AdaBoost classifier', 'to handle', 'occlusion conditions']]"
"[['subset of NPD features', 'can be', 'optimally learned'], ['subset of NPD features', 'combined to construct', 'more discriminative features'], ['more discriminative features', 'in', 'deep quadratic tree']]"
"[['different leaves', 'of', 'tree classifier'], ['complex face manifold', 'in', 'high dimensional space'], ['high dimensional space', 'partitioned in', 'learning process']]"
"[['"" divide and conquer "" strategy', 'to tackle', 'unconstrained face detection'], ['unconstrained face detection', 'in', 'single classifier'], ['views', 'in', 'training set of face images'], ['unconstrained face detection', 'without pre-labeling', 'views'], ['single classifier', 'without pre-labeling', 'views'], ['views', 'in', 'training set of face images']]"
"[['resulting face detector', 'robust to', 'variations in'], ['resulting face detector', 'robust to', 'blur and low image resolution']]"
"[['several desirable properties', 'including', 'scale invariance'], ['several desirable properties', 'including', 'boundedness']]"
"[['deep quadratic tree learner', 'proposed to learn and combine', 'optimal subset']]"
"[['only a single soft - cascade AdaBoost classifier', 'to handle', 'unconstrained faces'], ['only a single soft - cascade AdaBoost classifier', 'to handle', 'clustering'], ['unconstrained faces', 'with', 'occlusions and arbitrary viewpoints'], ['unconstrained faces', 'with', 'clustering'], ['unconstrained faces', 'without pose', 'labeling'], ['unconstrained faces', 'without pose', 'clustering'], ['occlusions and arbitrary viewpoints', 'without pose', 'labeling'], ['clustering', 'in', 'training stage']]"
"[['unconstrained face detector', 'does not depend on', 'pose specific cascade structure design']]"
[]
"[['proposed NPD features', 'in', 'deep quadratic tree']]"
"[['different leaves', 'of', 'learned quadratic tree classifier']]"
"[['NPD feature', 'measures', 'relative difference'], ['relative difference', 'between', 'two pixel values']]"
"[['NPD', 'invariant to', 'scale change']]"
[]
"[['bootstrapping nonface images', 'used', 'AFLW images'], ['bootstrapping nonface images', 'masked', 'facial regions'], ['facial regions', 'with', 'random images'], ['random images', 'containing', 'no faces']]"
"[['detection template', 'of', '24 24 pixels']]"
"[['maximum depth', 'of', 'tree classifiers'], ['tree classifiers', 'to be learned as', 'eight']]"
"[['final detector', 'contains', '1,226 deep quadratic trees'], ['final detector', 'contains', '46,401 NPD features']]"
"[['detection template', 'is', '20 20 pixels']]"
"[['detector cascade', 'contains', '15 stages'], ['target false accept rate', 'was', '0.5'], ['0.5', 'with', 'detection rate'], ['detection rate', 'of', '0.999']]"
"[['scale factor', 'of', '1.2'], ['scale factor', 'set for', 'multiscale detection']]"
"[['NPD face detector', 'is', 'second best one'], ['NPD face detector', 'is', 'third best one'], ['second best one', 'at', 'FP = 0'], ['FP = 0', 'for', 'discrete metric'], ['third best one', 'for', 'continuous metric'], ['third best one', 'for', 'continuous metric']]"
"[['proposed NPD detector', 'among', 'top performers'], ['top performers', 'for', 'discrete metric']]"
"[['Joint Cascade algorithm', 'is', 'most competitive one'], ['most competitive one', 'in terms of', 'accuracy and speed']]"
"[['performance', 'of', 'Zhu-Ramanan model'], ['Zhu-Ramanan model', 'is', 'quite impressive']]"
[]
[]
[]
"[['better', 'when', 'FP < 3'], ['SURF cascade method', 'outperforms', 'NPD'], ['NPD', 'at', 'higher FPs']]"
"[['state - of - the - art method', 'on', 'CMU - MIT dataset']]"
"[['proposed NPD method', 'can detect', 'about 80 %'], ['about 80 %', 'of', 'frontal faces'], ['frontal faces', 'without', 'false positives']]"
"[['NPD detector', 'performs', 'better'], ['better', 'than', 'Haar , LBP , and POF detectors'], ['Haar , LBP , and POF detectors', 'with', 'same CART based weak learners']]"
"[['performance improvements', 'due to', 'NPD features'], ['NPD features', 'over', 'Haar , LBP , and POF features'], ['Haar , LBP , and POF features', 'are', 'about 6 % , 19 % , and 15 %'], ['about 6 % , 19 % , and 15 %', 'for', 'discrete metric']]"
"[['NPD', 'better than', 'POF']]"
"[['NPD', 'performs', 'better'], ['better', 'than', 'Haar and LBP'], ['Haar and LBP', 'especially at', 'low false positives']]"
"[['CART', 'instead of', 'stump classifier'], ['CART', 'improves', 'face detection performance'], ['stump classifier', 'improves', 'face detection performance'], ['face detection performance', 'by', 'about 0 % - 17 %'], ['face detection performance', 'by', '0 % - 11 %'], ['about 0 % - 17 %', 'for', 'discrete metric'], ['0 % - 11 %', 'for', 'continuous metric']]"
"[['DQT based detector', 'further improves', 'performance'], ['performance', 'due to', 'quadratic splitting capability'], ['quadratic splitting capability', 'compared to', 'linear splitting']]"
"[['NPD face detector', 'performs', 'best'], ['best', 'on', 'pose and illumination subsets'], ['best', 'thanks to', 'scale - invariant NPD features and the deep quadratic trees']]"
"[['original resolution', 'is', '1280 720']]"
"[['NPD detector', 'achieves', 'similar speed'], ['similar speed', 'as', 'Joint Cascade method']]"
[]
[]
[]
"[['proposed method', 'can achieve', 'superior accuracy']]"
[]
[]
"[['aggregate channel features ( ACF )', 'take advantages of', 'channel features']]"
"[['Two - stage methods', 'consist of', 'proposal selection']]"
"[['Light and Fast Face Detector ( LFFD )', 'for', 'edge devices'], ['Light and Fast Face Detector ( LFFD )', 'considerably balancing', 'running efficiency']]"
"[['cropped image', 'with', 'probability'], ['probability', 'of', '0.5']]"
"[['face classification', 'use', 'softmax'], ['softmax', 'with', 'cross - entropy loss'], ['cross - entropy loss', 'over', 'two classes']]"
"[['bbox regression', 'adopt', 'L2 loss']]"
"[['all parameters', 'with', 'xavier method']]"
"[['optimization method', 'is', 'SGD'], ['SGD', 'with', '0.9 momentum'], ['SGD', 'with', 'batch size']]"
"[['initial learning rate', 'is', '0.1']]"
"[['1,500,000 iterations', 'reduce', 'learning rate'], ['learning rate', 'by multiplying', '0.1'], ['0.1', 'at', 'iteration 600,000']]"
"[['training time', 'is', 'about 5 days'], ['about 5 days', 'with', 'two NVIDIA GTX 1080 TI']]"
"[['DSFD , Pyramid Box , S3FD and SSH', 'can achieve', 'high accuracy'], ['high accuracy', 'with', 'marginal gaps']]"
"[['Pyramid Box', 'obtains', 'best results'], ['best results', 'on', 'Hard parts']]"
"[['results', 'on', 'Medium and Hard parts']]"
"[['proposed method LFFD', 'consistently', 'Face - Boxes']]"
"[['FaceBoxes 3.2', 'instead of', 'FaceBoxes']]"
"[['proposed LFFD', 'runs', 'fastest'], ['proposed LFFD', 'runs', 'FaceBoxes 3.2'], ['fastest', 'at', '38402160'], ['highest speed', 'at', 'other three resolutions'], ['FaceBoxes 3.2', 'obtains', 'highest speed'], ['highest speed', 'at', 'other three resolutions']]"
[]
[]
[]
[]
"[['P- Net', 'randomly crop', 'several patches'], ['several patches', 'from', 'WIDER FACE'], ['WIDER FACE', 'to collect', 'positives']]"
"[['R - Net', 'use', 'first stage'], ['first stage', 'of', 'our framework'], ['our framework', 'to detect', 'faces'], ['faces', 'from', 'WIDER FACE'], ['faces', 'to collect', 'positives , negatives'], ['faces', 'to collect', 'part face'], ['WIDER FACE', 'to collect', 'positives , negatives'], ['WIDER FACE', 'to collect', 'part face'], ['landmark faces', 'detected from', 'CelebA']]"
"[['O - Net', 'use', 'first two stages'], ['first two stages', 'of', 'our framework'], ['our framework', 'to detect', 'faces']]"
"[['beneficial', 'for', 'face classification'], ['beneficial', 'for', 'bounding box regression tasks']]"
[]
[]
"[['train set', 'of', 'WIDER FACE'], ['fails', 'on', 'some of the images'], ['some of the images', 'with', 'extremely hard faces']]"
"[['robust face detector', 'by putting', 'more training focus'], ['more training focus', 'on', 'hard images']]"
"[['mine hard examples', 'at', 'image level'], ['mine hard examples', 'in parallel with', 'anchor level']]"
"[['difficulty scores', 'to', 'training images'], ['training images', 'during', 'learning process']]"
"[['detection quality', 'by exclusively exploiting', 'small faces']]"
[]
"[['computation overhead', 'added on', 'existing detector']]"
"[['single shot detector', 'with', 'only one detection feature map'], ['small faces', 'with', 'specific range of sizes'], ['only one detection feature map', 'focuses on', 'small faces'], ['small faces', 'with', 'specific range of sizes']]"
"[['all images', 'to double', 'size'], ['horizontally', 'to double', 'size'], ['our training dataset', 'to double', '25760'], ['size', 'of', 'our training dataset'], ['our training dataset', 'to', '25760']]"
"[['ImageNet pretrained VGG16 model', 'to initialize', 'our network backbone']]"
"[['model', 'with', 'itersize'], ['model', 'with', 'learning rate'], ['46 k iterations', 'with', 'learning rate'], ['14 k iterations', 'with', 'smaller learning rate'], ['itersize', 'to be', '2'], ['itersize', 'for', '46 k iterations'], ['46 k iterations', 'with', 'learning rate'], ['14 k iterations', 'with', 'smaller learning rate'], ['learning rate', 'of', '0.004'], ['smaller learning rate', 'of', '0.0004'], ['14 k iterations', 'with', 'smaller learning rate']]"
"[['training', 'use', '4 GPUs'], ['4 GPUs', 'to compute', 'gradient'], ['4 GPUs', 'update', 'weight'], ['weight', 'by', 'synchronized SGD'], ['synchronized SGD', 'with', 'Momentum']]"
"[['first two blocks', 'of', 'VGG16'], ['rest layers', 'of', 'VGG16'], ['frozen', 'during', 'training'], ['rest layers', 'of', 'VGG16'], ['rest layers', 'set to have', 'double learning rate']]"
"[['our method', 'achieves', 'best performance'], ['best performance', 'on', 'hard subset'], ['current state - of - the - art', 'by', 'large margin']]"
"[['Our performance', 'on', 'medium subset'], ['performance', 'on', 'easy subset'], ['medium subset', 'comparable to', 'most recent state - of - the - art'], ['performance', 'on', 'easy subset'], ['performance', 'is', 'bit worse'], ['easy subset', 'is', 'bit worse']]"
"[['our method', 'achieves', 'new the state - of - the - art performance'], ['new the state - of - the - art performance', 'of', 'AP = 99.0']]"
"[['our method', 'achieves', 'state - of - the - art and'], ['our method', 'achieves', 'almost perfect performance'], ['almost perfect performance', 'with', 'AP'], ['AP', 'of', '99.60']]"
"[['performance', 'comparable to', 'current : Ablation experiments']]"
"[['face detector', 'similar to', 'SSH'], ['SSH', 'with', 'three detection feature maps']]"
"[['Single', 'is', 'our proposed detector'], ['our proposed detector', 'with', 'single detection feature map']]"
"[['Our model with single detection feature map', 'performs', 'better'], ['better', 'than', 'one with three detection feature maps']]"
[]
"[['ablation results', 'evaluated on', 'WIDER FACE val dataset']]"
"[['short side', 'contains', '100 , 300 , 600 , 1000 and 1400 pixels'], ['100 , 300 , 600 , 1000 and 1400 pixels', 'to build', 'image pyramid']]"
"[['short side', 'to contain', '100 and 300 pixels'], ['performance', 'on', 'easy subset'], ['performance', 'is', 'only 78.2'], ['easy subset', 'is', 'only 78.2']]"
"[['all methods', 'on', 'same machine'], ['all methods', 'with', 'one Titan X ( Maxwell ) GPU'], ['same machine', 'with', 'one Titan X ( Maxwell ) GPU']]"
"[['Caffe1 implementation', 'compiled with', 'CUDA 9.0 and CUDNN 7']]"
"[['officially built Pad - dlePaddle', 'with', 'CUDA 9.0 and CUDNN 7']]"
"[['outperform', 'with', 'smaller inference time'], ['SSH , S 3 FD and PyramidBox', 'with', 'smaller inference time'], ['significantly', 'with', 'smaller inference time']]"
[]
[]
"[['Most of the appearance variations', 'handled in', 'CNN'], ['Most of the appearance variations', 'benefiting from', 'invariance property'], ['Most of the appearance variations', 'benefiting from', 'pooling operations'], ['invariance property', 'of', 'convolution'], ['invariance property', 'of', 'pooling operations']]"
"[['location variations', 'can be', 'naturally'], ['location variations', 'via', 'sliding windows'], ['naturally', 'via', 'sliding windows'], ['sliding windows', 'can be efficiently incorporated into', 'CNN']]"
"[['first', 'handles', 'objects'], ['objects', 'of', 'different scales independently'], ['different scales independently', 'by resizing', 'input'], ['input', 'into', 'different scales'], ['first', 'forwarding', 'resized images'], ['multiple times', 'for', 'detection']]"
"[['objects', 'at', 'multiple scales']]"
"[['feature pyramid', 'in', 'CNN'], ['feature pyramid', 'descends from', 'observations'], ['CNN', 'descends from', 'observations'], ['observations', 'of', 'modern CNN - based detectors'], ['modern CNN - based detectors', 'including', 'Faster - RCNN'], ['modern CNN - based detectors', 'including', 'R - FCN'], ['modern CNN - based detectors', 'including', 'SSD'], ['modern CNN - based detectors', 'including', 'YOLO'], ['modern CNN - based detectors', 'including', 'STN']]"
[]
"[['RSA unit', 'designed to be', 'plugged'], ['some specific depths', 'in', 'network'], ['RSA unit', 'to be fed with', 'initial feature map'], ['initial feature map', 'at', 'largest scale']]"
"[['input', 'in', 'recurrent manner'], ['recurrent manner', 'to generate', 'prediction'], ['prediction', 'of', 'feature map'], ['half the size', 'of', 'input']]"
"[['scale - forecast network', 'to globally predict', 'potential scales'], ['potential scales', 'for', 'novel image']]"
"[['landmark retracing network', 'that retraces', 'location'], ['location', 'of', 'regressed landmarks'], ['regressed landmarks', 'in', 'preceding layers'], ['landmark retracing network', 'generates', 'confidence score'], ['confidence score', 'for', 'each landmark'], ['each landmark', 'based on', 'landmark feature set']]"
[]
"[['deep CNN features', 'for', 'image'], ['deep CNN features', 'approximated from', 'different scales'], ['different scales', 'using', 'portable recurrent unit ( RSA )'], ['portable recurrent unit ( RSA )', 'fully leverages', 'efficiency']]"
[]
"[['numbers of channels', 'set to', 'half'], ['half', 'of', 'original ResNet model']]"
"[['output', 'of', 'predicted scales'], ['predicted scales', 'to launch', 'RSA unit and LRN']]"
"[['batch size', 'is', '4'], ['base learning rate', 'set to', '0.001'], ['0.001', 'with', 'decrease']]"
"[['maximum training iteration', 'is', '1,000,000']]"
"[['stochastic gradient descent', 'as', 'optimizer']]"
"[['our trained scale network', 'recalls', 'almost 99 %'], ['almost 99 %', 'at', 'x = 1']]"
"[['inference', 'set', 'threshold'], ['threshold', 'for predicting', 'potential scales'], ['potential scales', 'of', 'input']]"
[]
[]
"[['image', 'resized to', 'higher dimension'], ['higher dimension', 'being', '2048']]"
"[['RSA', 'at', 'deeper layers']]"
"[['case final feature', 'means', 'RSA'], ['RSA', 'plugged at', 'final convolution layer'], ['final convolution layer', 'after', 'res3c'], ['error rate', 'is', 'almost 100 %']]"
[]
"[['path', 'during', 'one - time forward'], ['one - time forward', 'from', 'image'], ['image', 'to', 'input map'], ['input map', 'right before', 'RSA'], ['RSA', 'is', 'shorter']]"
"[['computation', 'happens before', 'layer res2 b'], ['acceptable error rate', 'of', '3.44 %']]"
[]
[]
"[['original RPN', 'with', 'multiple anchors'], ['multiple anchors', 'denoted as', 'RPN m'], ['multiple anchors', 'to detect', 'faces of various scales']]"
"[['our algorithm', 'achieves', 'AP'], ['AP', 'of', '99.17 %'], ['AP', 'of', '99 . 96 %'], ['AP', 'using', 'original annotation'], ['99.17 %', 'using', 'original annotation'], ['99.17 %', 'using', 'AP'], ['99 . 96 %', 'using', 'revised annotation'], ['AP', 'using', 'revised annotation'], ['AP', 'using', 'revised annotation'], ['99 . 96 %', 'using', 'revised annotation']]"
"[['RSA + LRN', 'recalls', '93.0 % faces'], ['93.0 % faces', 'with', '50 false positives']]"
"[['our method', 'recalls', '82.4 % faces'], ['82.4 % faces', 'with', 'zero false positive']]"
"[['transformer', 'to fit', 'each annotation'], ['each annotation', 'from', 'landmarks']]"
"[['faces', 'at', 'various scales'], ['various scales', 'including', 'green annotations'], ['green annotations', 'provided in', 'AFW'], ['green annotations', 'as well as', 'faces'], ['faces', 'marked in', 'red']]"
"[['proposed algorithm ( Scale - forecast network with', 'tagged by', 'LRN + RSA )'], ['proposed algorithm ( Scale - forecast network with', 'tagged by', 'outperforms'], ['outperforms', 'by', 'large margin'], ['other methods', 'by', 'large margin']]"
[]
"[['scale approximation learning', 'by', 'RSA unit'], ['comparably well', 'on', 'generic region proposal task']]"
[]
"[['single anchor RPN', 'with', 'ResNet - 101']]"
"[['anchors', 'of size', '128 ? 2 squared'], ['anchors', 'of size', '256128']]"
"[['higher dimension of objects', 'in', 'image']]"
"[['RPN + RSA', 'reduces around', '61.05 % computation cost'], ['61.05 % computation cost', 'compared with', 'single - scale RPN'], ['single - scale RPN', 'when', 'number of boxes'], ['number of boxes', 'is', 'over 100']]"
"[['RPN + RSA', 'recalls', 'more objects'], ['more objects', 'than', 'original RPN']]"
"[['Our model and the single - anchor RPN', 'perform', 'better'], ['better', 'than', 'original RPN']]"
"[['RSA plus LRN', 'competes', 'comparably'], ['standard RPN method', 'in terms of', 'computation efficiency and accuracy']]"
[]
"[['region - based face detector', 'applying', 'deep networks'], ['deep networks', 'in', 'fully convolutional fashion'], ['deep networks', 'named', 'Face R - FCN'], ['fully convolutional fashion', 'named', 'Face R - FCN']]"
"[['our face detector', 'is', 'more accurate']]"
[]
"[['ConvNet of R - FCN', 'built with', 'computations'], ['computations', 'shared on', 'entire image'], ['computations', 'leads to', 'improvement'], ['improvement', 'of', 'training and testing efficiency']]"
"[['face detector', 'on the top of', 'R - FCN'], ['R - FCN', 'with', 'elaborate design'], ['elaborate design', 'of', 'details'], ['face detector', 'achieves', 'more decent performance']]"
"[['position - sensitive average pooling', 'to generate', 'embedding features'], ['embedding features', 'for enhancing', 'discrimination'], ['position - sensitive average pooling', 'eliminate', 'effect of non-uniformed contribution'], ['effect of non-uniformed contribution', 'in', 'each facial part']]"
"[['on - line hard example mining ( OHEM ) technique', 'integrated into', 'our network'], ['on - line hard example mining ( OHEM ) technique', 'for boosting', 'learning'], ['learning', 'on', 'hard examples']]"
"[['face detection', 'call it', 'Face R - FCN']]"
"[['our network', 'with', 'pre-trained weights'], ['pre-trained weights', 'of', '101 - layer ResNet'], ['101 - layer ResNet', 'trained on', 'Image Net']]"
"[['few layers', 'at', 'beginning )'], ['beginning )', 'of', 'pre-trained model'], ['pre-trained model', 'throughout', 'entire training process'], ['essential feature extractor', 'trained on', 'ImageNet']]"
"[['Face R - FCN', 'enumerates', 'multiple configurations'], ['multiple configurations', 'of', 'anchor'], ['multiple configurations', 'to accurately search for', 'faces']]"
[]
"[['RPN and R - FCN', 'learned jointly with', 'softmax loss'], ['RPN and R - FCN', 'learned jointly with', 'smooth L1 loss']]"
"[['anchors', 'with', 'certain IoU scores']]"
"[['proposals', 'processed by', 'OHEM'], ['OHEM', 'to train with', 'hard examples']]"
"[['256', 'for', 'size'], ['256', 'for', '128'], ['256', 'for', 'R - FCN'], ['128', 'for', 'R - FCN'], ['128', 'for', 'R - FCN']]"
"[['multi-scale training', 'where', 'input image'], ['input image', 'resized with', 'bilinear interpolation'], ['bilinear interpolation', 'to', 'various scales']]"
"[['multi-scale testing', 'performed by', 'scale image'], ['scale image', 'into', 'image pyramid'], ['image pyramid', 'for', 'better detecting'], ['better detecting', 'on', 'both tiny and general faces']]"
"[['our proposed approach', 'consistently wins', '1st place'], ['1st place', 'across', 'three subsets'], ['three subsets', 'on', 'validation set and test set'], ['validation set and test set', 'of', 'WIDER FACE']]"
"[['our approach', 'superior to', 'prior best'], ['our approach', 'performing one by', 'clear margin']]"
"[['training set', 'of', 'WIDER FACE dataset'], ['WIDER FACE dataset', 'to train', 'our model']]"
"[['Face R - FCN', 'consistently achieves', 'impressive performance'], ['impressive performance', 'in terms of both', 'discrete ROC curve'], ['impressive performance', 'in terms of both', 'continuous ROC curve']]"
"[['discrete ROC curve', 'is', 'superior'], ['superior', 'to', 'prior best - performing method']]"
"[['best true positive rate', 'of', 'discrete ROC curve'], ['best true positive rate', 'at', '1000/2000 false positives'], ['discrete ROC curve', 'at', '1000/2000 false positives']]"
"[['competitive result', 'achieved', 'noticeable']]"
"[['Face R - FCN', 'shows', 'superior performance'], ['prior methods', 'across', 'three subsets'], ['three subsets', 'in', 'validation and test sets']]"
"[['performance', 'of', 'Face R - FCN']]"
[]
"[['detector', 'can find', 'around 800 faces out'], ['around 800 faces out', 'of', 'reportedly 1000 present'], ['novel characterizations', 'of', 'scale , resolution , and context'], ['novel characterizations', 'of', 'scale , resolution , and context'], ['scale , resolution , and context', 'to find', 'small objects']]"
"[['coarse image pyramid', 'to capture', 'extreme scale challenges']]"
"[['performance', 'on', 'small faces'], ['performance', 'model', 'additional context'], ['small faces', 'model', 'additional context'], ['additional context', 'efficiently implemented as', 'fixed - size receptive field'], ['fixed - size receptive field', 'across', 'all scale - specific templates']]"
[]
"[['"" one-size - fitsall "" approach', 'train', 'separate detectors'], ['separate detectors', 'tuned for', 'different scales ( and aspect ratios )']]"
"[['scale - specific detectors', 'in', 'multitask fashion'], ['scale - specific detectors', 'make use of', 'features'], ['multitask fashion', 'make use of', 'features'], ['features', 'defined over', 'multiple layers'], ['multiple layers', 'of', 'single ( deep ) feature hierarchy']]"
"[['users', 'attempt to', 'classify']]"
"[['convolutional deep features', 'extracted from', 'multiple layers'], ['convolutional deep features', 'known as', 'hypercolumn "" features'], ['multiple layers', 'known as', 'hypercolumn "" features'], ['convolutional deep features', 'are', 'effective "" foveal "" descriptors'], ['multiple layers', 'are', 'effective "" foveal "" descriptors'], ['effective "" foveal "" descriptors', 'that capture', 'high - resolution detail'], ['effective "" foveal "" descriptors', 'that capture', 'coarse low - resolution cues'], ['coarse low - resolution cues', 'across', 'large receptive field ( )']]"
"[['highresolution components', 'of', 'our foveal descriptors'], ['our foveal descriptors', 'extracted from', 'lower convolutional layers']]"
"[['prior art', 'on', 'WIDER FACE'], ['our results', 'reduce', 'error'], ['error', 'by', 'factor of']]"
"[['fixed contextual window', 'of', '300 pixels'], ['fixed contextual window', 'dramatically reduces', 'error'], ['300 pixels', 'dramatically reduces', 'error'], ['error', 'on', 'small faces'], ['small faces', 'by', '20 %']]"
"[['fixed learning rate', 'of', '10 ? 4'], ['weight decay', 'of', '0.0005'], ['momentum', 'of', '0.9']]"
"[['our hybrid - resolution model ( HR )', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'all difficulty levels'], ['error', 'on', '"" hard "" set'], ['our hybrid - resolution model ( HR )', 'reduces', 'error'], ['error', 'on', '"" hard "" set'], ['error', 'by', '2X'], ['"" hard "" set', 'by', '2X']]"
"[['Our out - of - the - box detector ( HR )', 'outperforms', 'all published results'], ['all published results', 'on', 'discrete score'], ['discrete score', 'uses', 'standard 50 % intersection - over - union threshold'], ['standard 50 % intersection - over - union threshold', 'to define', 'correctness']]"
"[['Our regressor', 'trained with', '10 - fold cross validation']]"
"[['Resnet 101 - based detector', 'runs at', '1.4 FPS'], ['Resnet 101 - based detector', 'runs at', '3.1 FPS'], ['1.4 FPS', 'on', '1080 p resolution'], ['3.1 FPS', 'on', '720 p resolution'], ['3.1 FPS', 'on', '720 p resolution']]"
[]
"[['massively - large receptive fields', 'can be', 'effectively encoded'], ['foveal descriptor', 'captures', 'coarse context'], ['foveal descriptor', 'captures', 'high - resolution image features']]"
"[['encoding of scale', 'in', 'existing pre-trained deep networks']]"
"[['post - hoc regressor', 'that converts', 'bounding boxes'], ['bounding boxes', 'to', 'ellipses'], ['our approach ( HR - ER )', 'produces', 'state - of the - art continuous overlaps']]"
"[['proposed detector', 'able to detect', 'faces'], ['faces', 'at', 'continuous range of scales'], ['challenges', 'such as', 'expression'], ['challenges', 'such as', 'blur'], ['challenges', 'such as', 'illumination']]"
[]
"[['small threshold ( 0.03 )', 'on', 'classification loss'], ['classification loss', 'to filter', 'out']]"
"[['Our detector', 'mostly affected by', 'object scale'], ['Our detector', 'mostly affected by', 'blur']]"
[]
[]
[]
"[['several competing approaches', 'for', 'producing word embedding vectors']]"
"[['eleven out of eighteen', 'on', 'medical domain subtask'], ['medical domain subtask', 'with', 'Mean Average Precision ( MAP )'], ['Mean Average Precision ( MAP )', 'of', '8.13']]"
"[['our system', 'ranked', '13th out'], ['16 places', 'with', 'MAP'], ['MAP', 'of', '1.88'], ['4th', 'among', 'unsupervised systems']]"
[]
[]
[]
[]
"[['representation for terms', 'including', 'words and phrases']]"
"[['neural network architecture', 'for', 'concerned task'], ['distributed representations', 'for', 'words and phrases'], ['various neural networks', 'to model', 'distributed representations'], ['distributed representations', 'for', 'words and phrases']]"
"[['Our model', 'implemented using', 'Theano']]"
"[['diagonal variant', 'of', 'Ada - Grad'], ['Ada - Grad', 'used for', 'neural network training']]"
"[['hidden dimension', 'of', 'all neural models'], ['all neural models', 'are', '200']]"
"[['batch size', 'set to', '20'], ['word embedding and sense embedding sizes', 'set to', '300']]"
"[['single GPU ( NVIDIA GTX 980 Ti )', 'with', 'roughly 1.5h'], ['roughly 1.5h', 'for', 'general - purpose subtask'], ['general - purpose subtask', 'for', 'English']]"
"[['CNN - based network performance', 'better than', 'RNN - based']]"
"[['All the neural models', 'outperform', 'term embedding averaging'], ['term embedding averaging', 'in terms of', 'all the metrics'], ['better', 'than', 'RNN - based ones'], ['RNN - based ones', 'in', 'most of the metrics'], ['RNN - based ones', 'using', 'word embedding'], ['most of the metrics', 'using', 'word embedding']]"
"[['sense embedding', 'shows', 'much poorer result']]"
[]
"[['preference', 'to', 'syntactic context - types ( dep and joint )']]"
"[['successful', 'in', 'hypernymy detection'], ['PPMI', 'shown to', 'outperform']]"
"[['most effective', 'in', 'discriminating'], ['hypernyms and meronyms', 'under', 'syntactic contexts']]"
"[['SLQS', 'performs', 'worse']]"
[]
"[['Hypernym vs. Synonym SLQS', 'performs', 'well'], ['well', 'in discriminating between', 'hypernyms and synonyms']]"
"[['difference', 'in', 'SLQS scores'], ['difference', 'in', 'SLQS scores'], ['SLQS scores', 'between', 'synonyms and hypernyms'], ['SLQS scores', 'was', 'largest'], ['synonyms and hypernyms', 'was', 'largest']]"
[]
"[['inclusion - based measures', 'showed', 'best results']]"
"[['over all performance', 'of', 'embeddingbased classifiers'], ['embeddingbased classifiers', 'is', 'almost perfect'], ['best performance', 'achieved using', 'concatenation method'], ['best performance', 'achieved using', 'dependency - based embeddings'], ['concatenation method', 'with', 'GloVe'], ['concatenation method', 'with', 'dependency - based embeddings']]"
"[['unsupervised measures', 'perform', 'worse'], ['worse', 'than', 'embedding - based classifiers']]"
[]
"[['supervised distributional framework', 'for', 'hypernym discovery'], ['hypernym discovery', 'enabling', 'large - scale automatic acquisition'], ['large - scale automatic acquisition', 'of', 'dis ambiguated taxonomies']]"
"[['semantic regularities', 'between', 'hyponyms and hypernyms'], ['hyponyms and hypernyms', 'in', 'embeddings spaces'], ['semantic regularities', 'integrating', 'domain clustering algorithm'], ['our model', 'becomes', 'sensitive']]"
[]
"[['hypernym detection algorithm', 'based on', 'sense embeddings'], ['hypernym detection algorithm', 'easily applied to', 'construction'], ['sense embeddings', 'easily applied to', 'construction'], ['construction', 'of', 'lexical taxonomies']]"
"[['hypernymic relations', 'by exploiting', 'linear transformations'], ['linear transformations', 'in', 'embedding spaces'], ['specific semanticallyaware transformation matrix', 'for', 'each domain of knowledge']]"
"[['word - level taxonomy learning', 'results in', 'more refined and unambiguous hypernymic relations'], ['TAXO - EMBED', 'results in', 'more refined and unambiguous hypernymic relations'], ['more refined and unambiguous hypernymic relations', 'at', 'sense level']]"
"[['different OIE systems', 'into', 'single unified and dis ambiguated knowledge repository']]"
"[['unification algorithm', 'takes as input', 'set K of OIE - derived resources'], ['set K of OIE - derived resources', 'modeled as', 'set'], ['sense inventory', 'of', 'Babel Net']]"
"[['Yago and WiBi', 'achieve', 'best over all results']]"
[]
"[['hypernym sets', 'based on', 'word embedding'], ['word embedding', 'to measure', 'contextual similarities'], ['contextual similarities', 'between', 'words']]"
[]
"[['Word2vec', 'to produce', 'word embeddings']]"
"[['skip - gram model ( - cbow 0 )', 'used with', 'embedding dimension'], ['embedding dimension', 'set to', '300']]"
[]
"[['our best F - value', 'on', 'validation set'], ['our best F - value', 'is', '0.68'], ['0.68', 'when', 'best cluster number'], ['best cluster number', 'is', '2'], ['threshold', 'is', '( 17.7 , 17.3 )']]"
[]
[]
[]
[]
[]
"[['Our hybrid system', 'ranked', '1st'], ['1st', 'on', 'all three sub - tasks']]"
"[['runs', 'see that', 'data augmentation'], ['data augmentation', 'improved', 'our scores'], ['our scores', 'on', '1A and 2B'], ['slightly', 'on', '1A and 2B'], ['several points', 'on', '2A']]"
"[['Our cross-evaluation results', 'are', 'better'], ['supervised baseline', 'computed using', 'normal evaluation setup']]"
[]
"[['outputs', 'of', '2 systems'], ['best score', 'of', 'either system'], ['outputs', 'improves', 'best score'], ['2 systems', 'improves', 'best score'], ['best score', 'of', 'either system'], ['best score', 'on', 'all test sets'], ['either system', 'on', 'all test sets'], ['best score', 'by', 'as much as 10 points'], ['all test sets', 'by', 'as much as 10 points']]"
"[['only the supervised system', 'indicate', 'data augmentation'], ['data augmentation', 'had', 'positive effect'], ['positive effect', 'on', 'our 2A scores only']]"
"[['run 1', 'is', 'best'], ['best', 'on', 'all 3 test sets'], ['best', 'when', 'hybrid system']]"
"[['No subsampling', 'sample', 'positive examples'], ['positive examples', 'from', 'training set'], ['uniformly', 'from', 'training set']]"
"[['No', 'use', 'single classifier'], ['MTL', 'use', 'single classifier'], ['single classifier', 'for', 'named entities and concepts']]"
[]
[]
[]
[]
[]
[]
[]
[]
"[['hypernym', 'in', 'domain - specific corpus'], ['domain - specific corpus', 'provide', 'participants'], ['data', 'for', 'two specific domains']]"
"[['path - based technique and distributional technique', 'via concatenating', 'two feature vectors'], ['feature vector', 'constructed using', 'dependency parser output'], ['feature vector', 'obtained using', 'term embeddings']]"
"[['concatenated vector', 'create', 'binary supervised classifier model'], ['binary supervised classifier model', 'based on', 'support vector machine ( SVM ) algorithm']]"
"[['our system', 'performs', 'better'], ['better', 'than', 'STJU system'], ['our system', 'performs', 'better'], ['better', 'than', 'MFH system'], ['better', 'on', 'English corpora'], ['MFH system', 'on', 'English corpora']]"
"[['candidate hypernym extraction ( CHE ) coverage', 'for', 'English testing terms'], ['English testing terms', 'is', '950 ( 63 % )']]"
"[['non-negative sparse coding', 'for', 'word translation'], ['sparse word vectors', 'for', 'two languages'], ['word translation', 'by training', 'sparse word vectors'], ['sparse word vectors', 'for', 'two languages'], ['two languages', 'such that', 'coding bases'], ['coding bases', 'correspond to', 'each other']]"
"[['sparse feature pairs', 'to', 'hypernym extraction']]"
[]
[]
"[['Generating', 'provides', 'some additional performance boost'], ['more negative samples', 'provides', 'some additional performance boost']]"
[]
[]
[]
[]
"[['rule - based system', 'exploits', 'syntactic dependency paths'], ['syntactic dependency paths', 'that generalize', 'Hearst - style lexical patterns']]"
[]
[]
[]
[]
"[['help', 'of', 'referring expressions'], ['referring expressions', 'which denote', 'same real - world entity']]"
"[['term', 'in', 'update equations'], ['update equations', 'for', 'Gated Recurrent Units ( GRU )'], ['Gated Recurrent Units ( GRU )', 'depends on', 'hidden state'], ['hidden state', 'of', 'coreferent antecedent'], ['coreferent antecedent', 'of', 'current token']]"
"[['clear improvements', 'of using', 'C - GRU layers'], ['C - GRU layers', 'over', 'GRU layers']]"
[]
"[['task - wise performance', 'Comparing', 'C - GRU'], ['C - GRU', 'to', 'GRU based method'], ['C - GRU', 'find', 'main gains']]"
"[['QRN baseline', 'found that', 'C - GRU'], ['C - GRU', 'was', 'significantly worse'], ['significantly worse', 'on', 'task']]"
"[['C - GRU', 'was', 'significantly better'], ['significantly better', 'than', 'QRN']]"
"[['coreference features', 'as', '1 - hot vectors'], ['1 - hot vectors', 'appended to', 'input word vectors ( GA w/ GRU + 1 - hot )']]"
"[['sharp drop', 'in', 'performance']]"
"[['higher performance', 'for', 'C - GRU model'], ['C - GRU model', 'in', 'low data regime'], ['better generalization', 'throughout', 'training curve']]"
"[['best reported result', 'of', 'BiDAf']]"
"[['significant gain', 'in', 'performance'], ['significant gain', 'when using', 'layer'], ['performance', 'when using', 'layer'], ['layer', 'with', 'coreference bias']]"
"[['1 - hot baseline', 'uses', 'same coreference information'], ['1 - hot baseline', 'with', 'sequential recency bias'], ['sequential recency bias', 'fails to', 'improve'], ['improve', 'over', 'regular GRU layer']]"
"[['maximum number of coreference clusters', 'across', 'all tasks'], ['maximum number of coreference clusters', 'was', 'C = 13'], ['all tasks', 'was', 'C = 13']]"
"[['dropout', 'of', '0.2'], ['0.2', 'in between', 'intermediate layers'], ['word embeddings', 'with', 'Glove']]"
[]
[]
[]
"[['novel context zoom - in network ( ConZNet )', 'for', 'RC tasks'], ['novel context zoom - in network ( ConZNet )', 'skip through', 'irrelevant parts'], ['irrelevant parts', 'of', 'document'], ['novel context zoom - in network ( ConZNet )', 'generate', 'answer'], ['answer', 'using', 'only the relevant regions of text']]"
"[['ConZNet architecture', 'consists of', 'two phases']]"
"[['relevant regions of text', 'by employing', 'reinforcement learning algorithm']]"
"[['encoder - decoder architecture', 'comprehends', 'identified regions of text'], ['encoder - decoder architecture', 'generates', 'answer'], ['answer', 'by using', 'residual self - attention network'], ['answer', 'by using', 'RNNbased sequence generator'], ['residual self - attention network', 'as', 'encoder'], ['residual self - attention network', 'as', 'RNNbased sequence generator'], ['RNNbased sequence generator', 'along with', 'pointer network'], ['pointer network', 'as', 'decoder']]"
"[['our decoder', 'combines', 'span prediction and sequence generation']]"
"[['span prediction layer', 'with', 'answer generation layer']]"
"[['1', 'refer for', 'more details attention based seq2seq layer'], ['more details attention based seq2seq layer', 'without using', 'copy mechanism'], ['copy mechanism', 'in', 'answer generation unit']]"
"[['each document', 'into', 'sentences'], ['sentences', 'using', 'sentence tokenizer'], ['sentence tokenizer', 'of', 'NLTK toolkit']]"
"[['each sentence', 'using', 'word tokenizer'], ['word tokenizer', 'of', 'NLTK']]"
[]
"[['weights', 'of', 'model'], ['weights', 'initialized by', 'Glorot Initialization'], ['model', 'initialized by', 'Glorot Initialization'], ['biases', 'initialized with', 'zeros']]"
"[['300 dimensional word vectors', 'from', 'GloVe'], ['GloVe', 'with', '840 billion pre-trained vectors'], ['300 dimensional word vectors', 'to initialize', 'word embeddings']]"
"[['sampling', 'from', 'uniform random distribution']]"
"[['dropout', 'between', 'layers'], ['dropout', 'with', 'keep probability'], ['keep probability', 'of', '0.8']]"
"[['number of hidden units', 'set to', '100']]"
"[['our model', 'with', 'AdaDelta ( Zeiler , 2012 ) optimizer'], ['our model', 'with', 'minibatch size'], ['AdaDelta ( Zeiler , 2012 ) optimizer', 'for', '50 epochs']]"
"[[""' sample size ' ( number of relevant sentences )"", 'based on', 'model performance'], ['model performance', 'on', 'devset']]"
[]
"[['best ROUGE - L score', 'by', '12.62 %']]"
"[['hybrid approach ( ConZNet )', 'of', 'generating words'], ['hybrid approach ( ConZNet )', 'for', 'generating words'], ['generating words', 'from', 'fixed vocabulary'], ['better suited', 'than', 'span prediction models ( Seq2Seq , ASR , BiDAF , MRU )']]"
[]
"[['simpler fully - neural approach', 'to', 'Story Cloze Test'], ['Story Cloze Test', 'using', 'skip - thought embeddings'], ['skip - thought embeddings', 'of', 'stories'], ['stories', 'in', 'feed - forward network'], ['feed - forward network', 'achieves close to', 'state - of - the - art performance'], ['state - of - the - art performance', 'without', 'feature engineering']]"
"[['just the last sentence', 'of', 'prompt'], ['prompt', 'instead of', 'whole prompt'], ['considering', 'yields', 'higher accuracy'], ['just the last sentence', 'yields', 'higher accuracy'], ['whole prompt', 'yields', 'higher accuracy'], ['higher accuracy', 'with', 'our approach']]"
"[['two layer and three layer fully connected networks', 'with', 'Rectified Linear ( ReLU ) non-linearities']]"
"[['Full Context ( FC )', 'use', 'Gated Recurrent Unit ( GRU )'], ['Gated Recurrent Unit ( GRU )', 'to encode', 'entire story prompt'], ['entire story prompt', 'into', '4800 - dimensional vector'], ['Gated Recurrent Unit ( GRU )', 'add it to', 'skipthought embedding'], ['4800 - dimensional vector', 'add it to', 'skipthought embedding'], ['skipthought embedding', 'of', 'story ending'], ['Gated Recurrent Unit ( GRU )', 'pass it as', 'input'], ['input', 'to', 'neural network']]"
"[['SGD', 'with', 'learning rate'], ['learning rate', 'of', '0.01']]"
"[['3 - layer feed - forward neural network', 'trained on', 'validation set'], ['validation set', 'by summing', 'skip - thought embeddings'], ['skip - thought embeddings', 'of', 'last sentence ( LS )'], ['skip - thought embeddings', 'of', 'last sentence ( LS )'], ['last sentence ( LS )', 'of', 'story prompt'], ['ending', 'gives', 'best accuracy']]"
[]
"[['model', 'trained using', 'only the last sentence ( LS )'], ['only the last sentence ( LS )', 'of', 'story context'], ['higher accuracy', 'compared to', 'model'], ['model', 'uses', 'GRU'], ['GRU', 'to encode', 'full context ( FC )']]"
[]
[]
[]
"[['end - to - end neural network', 'for', 'question answering']]"
"[['coattentive encoder', 'captures', 'interactions'], ['interactions', 'between', 'question and the document'], ['coattentive encoder', 'well as', 'dynamic pointing decoder'], ['dynamic pointing decoder', 'alternates', 'estimating']]"
"[['corpus', 'use', 'tokenizer'], ['tokenizer', 'from', 'Stanford CoreNLP']]"
"[['Glo Ve word vectors', 'pretrained on', '840B Common Crawl corpus']]"
"[['vocabulary', 'to', 'words'], ['out - of - vocabulary words', 'to', 'zero'], ['words', 'present in', 'Common Crawl corpus'], ['embeddings', 'for', 'out - of - vocabulary words'], ['out - of - vocabulary words', 'to', 'zero']]"
"[['max sequence length', 'of', '600'], ['hidden state size', 'of', '200'], ['600', 'during', 'training'], ['200', 'for', 'all recurrent units'], ['200', 'for', 'linear layers']]"
[]
"[['Sentinel vectors', 'are', 'randomly initialized and optimized'], ['randomly initialized and optimized', 'during', 'training']]"
"[['dynamic decoder', 'set', 'maximum number of iterations'], ['maximum number of iterations', 'to', '4'], ['dynamic decoder', 'use', 'maxout pool size'], ['maxout pool size', 'of', '16']]"
"[['dropout', 'to regularize', 'our network'], ['our network', 'during', 'training'], ['dropout', 'optimize', 'model'], ['model', 'using', 'ADAM']]"
[]
"[['performance', 'of', 'Dynamic Coattention Network'], ['start and end points', 'of', 'answer span'], ['capability', 'to estimate', 'start and end points'], ['start and end points', 'of', 'answer span']]"
"[['decoder side', 'experiment with', 'various pool sizes'], ['various pool sizes', 'for', 'HMN maxout layers'], ['HMN maxout layers', 'using', '2 - layer MLP'], ['2 - layer MLP', 'instead of', 'HMN'], ['various pool sizes', 'forcing', 'HMN decoder'], ['HMN decoder', 'to', 'single iteration']]"
"[['best performance', 'on', 'development set'], ['development set', 'with', 'iterative HMN'], ['iterative HMN', 'with', 'pool size 16'], ['iterative HMN', 'with', 'pool size 16'], ['model', 'consistently benefits from', 'deeper , iterative decoder network']]"
"[['improves', 'as', 'number of maximum allowed iterations']]"
"[['encoder side', 'replacing', 'coattention mechanism'], ['coattention mechanism', 'with', 'attention mechanism'], ['attention mechanism', 'setting', 'CD'], ['CD', 'to', 'QA D'], ['QA D', 'results in', '1.9 point F1 drop']]"
[]
"[['notable performance degradation', 'for', 'longer documents and questions']]"
"[['increasingly challenging', 'to compute', 'correct word span'], ['correct word span', 'as', 'number of words']]"
"[['mean F1', 'of', 'DCN'], ['mean F1', 'exceeds', 'previous systems'], ['previous systems', 'across', 'all question types']]"
[]
"[['relational reasoning', 'find out', 'question relevant information']]"
"[['external memory', 'enables', 'model'], ['external memory', 'to deal with', 'knowledge base'], ['model', 'to deal with', 'knowledge base'], ['knowledge base', 'without loss of', 'information']]"
[]
"[['neural network based models', 'like', 'end - to - end memory network ( Mem N2N )'], ['neural network based models', 'like', 'gated end - to - end memory network ( GMe m N2N )'], ['neural network based models', 'like', 'dynamic memory network ( DMN )'], ['neural network based models', 'like', 'dynamic memory network + ( DMN + )']]"
"[['"" Relation Memory Network "" ( RMN )', 'able to find', 'complex relation'], ['complex relation', 'when', 'lot of information']]"
"[['MLP', 'to find out', 'relevant information'], ['relevant information', 'with', 'new generalization']]"
"[['Relation Memory Network ( RMN )', 'composed of', 'four components']]"
[]
"[['attention component', 'applied', 'simple MLP'], ['simple MLP', 'represented as', 'gt ?']]"
"[['Neural Turing Machine', 'reads from', 'memory']]"
"[['information', 'use', 'intuitive updating component'], ['intuitive updating component', 'to renew', 'memory']]"
[]
"[['relatedness of sentences', 'in', 'question and memory'], ['question and memory', 'by taking', 'inner product'], ['sentence', 'with', 'highest relatedness'], ['highest relatedness', 'selected as', 'first supporting sentence'], ['first supporting sentence', 'for', 'given question']]"
[]
"[['batch normalization', 'For', 'all MLPs'], ['regularization', 'use', 'batch normalization'], ['batch normalization', 'for', 'all MLPs']]"
"[['softmax output', 'optimized with', 'cross - entropy loss function'], ['cross - entropy loss function', 'using', 'Adam optimizer'], ['cross - entropy loss function', 'with', 'learning rate'], ['Adam optimizer', 'with', 'learning rate'], ['learning rate', 'of', '2 e ?4']]"
"[['RMN', 'learns', 'different solutions'], ['different solutions', 'for', 'each task']]"
"[['attention component', 'focuses', 'sequentially']]"
"[['significantly improved', 'compared to', 'plain condition'], ['performance', 'compared to', 'plain condition']]"
"[['RMN', 'yields', 'same error rate 25.1 %'], ['same error rate 25.1 %', 'with', 'MemN2N and GMe m N2N']]"
"[['number of hops', 'correlated with', 'number of supporting sentences']]"
[]
[]
[]
"[['same', 'applied to', 'machine comprehension'], ['machine comprehension', 'of', 'natural language']]"
"[['deep , end - to - end , neural comprehension model', 'call', 'EpiReader']]"
[]
[]
"[[""Reasoner 's evidence"", 'with', ""Extractor 's probability estimates""], [""Extractor 's probability estimates"", 'to produce', 'final ranking'], ['final ranking', 'of', 'answer candidates']]"
[]
"[['Extractor', 'is', 'Pointer Network']]"
"[['biGRU', 'outputs', 'two d-dimensional encoding vectors'], ['two d-dimensional encoding vectors', 'one for', 'forward direction'], ['two d-dimensional encoding vectors', 'one for', 'backward direction']]"
"[['our model', 'used', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', 'ADAM optimizer'], ['stochastic gradient descent', 'with', 'initial learning rate'], ['stochastic gradient descent', 'with', 'initial learning rate'], ['initial learning rate', 'of', '0.001']]"
"[['word embeddings', 'drawing from', 'uniform distribution'], ['initialized randomly', 'drawing from', 'uniform distribution']]"
"[['batches', 'of', '32 examples'], ['patience', 'of', '2 epochs'], ['early stopping', 'with', 'patience'], ['patience', 'of', '2 epochs']]"
"[['Theano', 'using', 'Keras framework']]"
"[['2 - regularization', 'at', '0.001']]"
"[['EpiReader', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'across', 'board']]"
"[['CNN', 'score', '2.2 % higher'], ['2.2 % higher', 'on', 'test'], ['2.2 % higher', 'than', 'best previous model']]"
"[['improvement', 'on', 'CBT - NE'], ['improvement', 'is', 'more modest'], ['CBT - NE', 'is', 'more modest'], ['more modest', 'at', '1.1 %']]"
"[['2 norm', 'of', 'whole gradient'], ['whole gradient', 'of', 'all parameters'], ['whole gradient', 'of', 'all parameters'], ['all parameters', 'measured', '5']]"
"[['not decreased', 'after', 'one epoch'], ['learning rate', 'scaled down by', 'factor 1.5']]"
"[['Training', 'terminates when', 'learning rate']]"
"[['Weights', 'initialized using', 'N ( 0 , 0.05 )'], ['batch size', 'set to', '128']]"
"[['Penn tree dataset', 'repeat', 'each training'], ['10 times', 'with', 'different random initializations']]"
"[['baseline architectures', 'tuned in to give', 'optimal perplexity']]"
"[['number of hops and memory size', 'of', 'our MemN2N']]"
"[['Mem N2N', 'operates', 'on memory'], ['on memory', 'with', 'multiple hops']]"
[]
"[['max operation ( rather than softmax )', 'at', 'each layer'], ['each layer', 'trained directly with', 'supporting facts']]"
"[['adaptive number of hops', 'per', 'query']]"
"[['LSTM', 'trained using', 'question / answer pairs only']]"
[]
"[['training', 'apply', 'ReLU operations'], ['ReLU operations', 'to', 'half of the units'], ['half of the units', 'in', 'each layer']]"
"[['query weights', 'of', 'each layer'], ['output weights', 'of', 'each layer']]"
[]
[]
[]
"[['neural - network - based NLI models', 'with', 'external knowledge'], ['external knowledge', 'in', 'coattention'], ['external knowledge', 'in', 'local inference collection'], ['external knowledge', 'in', 'inference composition components']]"
"[['advantage', 'of using', 'external knowledge'], ['external knowledge', 'is', 'more significant'], ['size of training data', 'is', 'restricted'], ['external knowledge', 'when', 'size of training data'], ['more significant', 'when', 'size of training data'], ['size of training data', 'is', 'restricted']]"
"[['dimension', 'of', 'hidden states'], ['hidden states', 'of', 'LSTMs'], ['hidden states', 'of', 'LSTMs'], ['hidden states', 'are', '300'], ['word embeddings', 'are', '300']]"
"[['word embeddings', 'initialized by', '300D GloVe 840B']]"
"[['word embeddings', 'updated during', 'training']]"
"[['Adam ( Kingma and Ba , 2014 )', 'used for', 'optimization'], ['Adam ( Kingma and Ba , 2014 )', 'with', 'initial learning rate'], ['optimization', 'with', 'initial learning rate'], ['initial learning rate', 'of', '0.0004']]"
"[['mini - batch size', 'set to', '32']]"
[]
"[['Knowledge - based Inference Model ( KIM )', 'enriches', 'ESIM'], ['ESIM', 'with', 'external knowledge'], ['accuracy', 'of', '88.6 %'], ['best single - model performance', 'reported on', 'SNLI dataset']]"
[]
"[['external knowledge', 'add', 'TransE relation embedding']]"
"[['baseline ESIM', 'achieves', '76.8 % and 75.8 %'], ['76.8 % and 75.8 %', 'on', 'in - domain and cross - domain test set']]"
"[['ESIM', 'with', 'external knowledge'], ['ESIM', 'achieve', 'significant gains'], ['external knowledge', 'achieve', 'significant gains'], ['significant gains', 'to', '77.2 % and 76.4 %']]"
"[['model', 'obtains', 'large gain'], ['large gain', 'when using', 'more than half of external knowledge']]"
"[['antonym category', 'in', 'cross - domain set']]"
[]
"[['new state of the art', 'on', 'all evaluated datasets']]"
[]
[]
[]
"[['stochastic gradient descent', 'with', 'ADAM update rule'], ['stochastic gradient descent', 'with', 'learning rate'], ['learning rate', 'of', '0.001 or 0.0005']]"
"[['initial weights', 'in', 'word embedding matrix']]"
"[['Weights', 'in', 'GRU networks'], ['Weights', 'initialized by', 'random orthogonal matrices'], ['GRU networks', 'initialized by', 'random orthogonal matrices'], ['biases', 'initialized to', 'zero']]"
"[['gradient clipping threshold', 'of', '10']]"
"[['training', 'randomly shuffled', 'all examples'], ['all examples', 'in', 'each epoch']]"
"[['each batch', 'of', 'CNN and Daily Mail datasets'], ['assignment', 'of', 'named entities'], ['CNN and Daily Mail datasets', 'randomly reshuffled', 'assignment'], ['assignment', 'of', 'named entities'], ['assignment', 'to', 'corresponding word embedding vectors'], ['named entities', 'to', 'corresponding word embedding vectors']]"
"[['new state - of - the - art results', 'on', 'all evaluated datasets']]"
[]
"[['our single model', 'with', 'best validation accuracy'], ['best validation accuracy', 'achieves', 'test accuracy'], ['test accuracy', 'of', '69.5 %']]"
"[['average performance', 'of', 'top 20 % models'], ['top 20 % models', 'according to', 'validation accuracy'], ['validation accuracy', 'is', '69.9 %'], ['69.9 %', 'is', 'even 0.5 % better'], ['even 0.5 % better', 'than', 'single best - validation model']]"
"[['multiple models', 'gives', 'significant further increase'], ['significant further increase', 'in', 'accuracy']]"
"[['our best single model', 'with', 'accuracy of'], ['MemNN', 'with', 'self supervision'], ['68.6 %', 'performs', '2 % absolute better'], ['2 % absolute better', 'than', 'MemNN'], ['MemNN', 'with', 'self supervision']]"
"[['our single models', 'is', '0.4 % absolute better'], ['0.4 % absolute better', 'than', 'Mem NN'], ['performance', 'to', '69 %']]"
[]
[]
"[['online evaluation platform and leaderboard', 'based primarily on', 'privately - held test data']]"
"[['model - agnostic', 'allowing for', 'any kind of']]"
"[['GLUE', 'diverges from', 'SentEval'], ['SentEval', 'in', 'selection of'], ['evaluation tasks', 'included in', 'suite']]"
"[['Interannotator agreement', 'is', 'high'], ['high', 'with', ""Fleiss 's ?""], [""Fleiss 's ?"", 'of', '0.73']]"
[]
[]
"[['Adam ( Kingma & Ba , 2015 )', 'with', 'initial learning rate'], ['Adam ( Kingma & Ba , 2015 )', 'with', 'batch size'], ['Adam ( Kingma & Ba , 2015 )', 'with', 'initial learning rate'], ['Adam ( Kingma & Ba , 2015 )', 'with', 'batch size']]"
[]
"[['weight initialization', 'to', 'optimization dynamics'], ['optimization dynamics', 'of', 'specific learning task']]"
"[['"" adaptive initialization ""', 'for', 'neural network training'], ['neural network training', 'where', 'cyclical batch size schedules'], ['"" adaptive initialization ""', 'use', 'cyclical batch size schedules'], ['cyclical batch size schedules', 'to control', 'noise ( or temperature )'], ['noise ( or temperature )', 'of', 'SGD']]"
[]
"[['ensembling method', 'combines', 'models'], ['models', 'saved during', 'different cycles']]"
[]
[]
"[['best performing CBS schedules', 'result in', 'significant improvements'], ['significant improvements', 'in', 'perplexity ( up to 7.91 )'], ['reductions', 'in', 'number of SGD training iterations'], ['significant improvements', 'over', 'baseline schedules'], ['perplexity ( up to 7.91 )', 'over', 'baseline schedules'], ['significant improvements', 'offer', 'reductions'], ['reductions', 'in', 'number of SGD training iterations'], ['number of SGD training iterations', 'up to', '33 %']]"
[]
"[['CBS schedules', 'match', 'baseline performance'], ['number of training iterations', 'used in', 'CBS schedules'], ['number of training iterations', 'up to', '2 fewer'], ['CBS schedules', 'up to', '2 fewer']]"
"[['CBS', 'achieves', 'similar performance'], ['similar performance', 'to', 'baseline']]"
"[['CBS - 15', 'see', '90.71 % training accuracy'], ['CBS - 15', 'see', '56. 44 % testing accuracy']]"
"[['CBS - 15 on C2', 'improves', 'accuracy'], ['accuracy', 'to', '94.82 %']]"
"[['snapshot ensembling', 'on', 'C3'], ['snapshot ensembling', 'trained with', 'CBS - 15 - 2 leads'], ['C3', 'trained with', 'CBS - 15 - 2 leads'], ['improved accuracy', 'of', '93. 56 %']]"
"[['ResNet50', 'on', 'Imagenet'], ['Imagenet', 'with', 'snapshots'], ['performance', 'increases to', '76.401 %'], ['76.401 %', 'from', '75.336 %']]"
"[['training', 'crop', 'image'], ['image', 'to', '224 224']]"
"[['total vocabulary size', 'is', '10 k'], ['all words', 'outside', 'vocabulary'], ['all words', 'replaced by', 'placeholder token']]"
[]
"[['TBCNNpair model', 'to recognize', 'entailment and contradiction'], ['entailment and contradiction', 'between', 'two sentences']]"
[]
"[['TBCNN - pair neural model', 'to recognize', 'entailment and contradiction'], ['entailment and contradiction', 'between', 'two sentences']]"
[]
"[['model', 'is', 'mostly robust'], ['dimension', 'is', 'large , e.g. , several hundred'], ['mostly robust', 'when', 'dimension'], ['dimension', 'is', 'large , e.g. , several hundred']]"
"[['Word embeddings', 'pretrained ourselves by', 'word2vec'], ['word2vec', 'on', 'English Wikipedia corpus'], ['Word embeddings', 'fined tuned during', 'training'], ['training', 'as', 'apart']]"
"[['2 penalty', 'of', '310 ? 4'], ['dropout', 'chosen by', 'validation']]"
"[['Initial learning rate', 'set to', '1']]"
"[['stochastic gradient descent', 'with', 'batch size'], ['batch size', 'of', '50']]"
"[['TBCNN sentence pair model', 'followed by', 'simple concatenation alone'], ['existing sentence encoding - based approaches', 'without', 'pretraining'], ['existing sentence encoding - based approaches', 'including', 'feature - rich method'], ['feature - rich method', 'using', '6 groups'], ['6 groups', 'of', 'humanengineered features']]"
[]
"[['each heuristic', 'using', 'element - wise product alone'], ['element - wise product alone', 'is', 'significantly worse'], ['significantly worse', 'than', 'concatenation or element - wise difference']]"
"[['different matching heuristics', 'improves', 'result'], ['TBCNN - pair model', 'with', 'concatenation'], ['highest performance', 'of', '82.1 %']]"
"[['element - wise product', 'improves', 'accuracy'], ['accuracy', 'by', 'another 0.5 %']]"
"[['all existing sentence encoding - based approaches', 'in - cluding', '1024d gated recurrent unit ( GRU ) - based RNN'], ['1024d gated recurrent unit ( GRU ) - based RNN', 'with', '"" skip - thought "" pretraining']]"
[]
[]
[]
"[['spaCy tool', 'used to', 'tokenize']]"
"[['word embedding', 'with', '300 - dimensional GloVe word vectors']]"
"[['character encoding', 'use', 'concatenation'], ['concatenation', 'of', 'multi-filter Convolutional Neural Nets'], ['multi-filter Convolutional Neural Nets', 'with', 'windows 1 , 3 , 5'], ['multi-filter Convolutional Neural Nets', 'with', 'hidden size']]"
"[['lexicon embeddings', 'are', 'd =600 - dimensions']]"
"[['embedding', 'for', 'out - of - vocabulary'], ['embedding', 'is', 'zeroed'], ['out - of - vocabulary', 'is', 'zeroed']]"
"[['hidden size', 'of', 'LSTM'], ['input size', 'of', 'output layer'], ['LSTM', 'in', 'contextual encoding layer'], ['memory generation layer', 'set to', '128'], ['input size', 'of', 'output layer'], ['output layer', 'is', '1024 ( 128 * 2 * 4 )']]"
"[['projection size', 'in', 'attention layer'], ['projection size', 'set to', '256']]"
[]
"[['dropout rate', 'is', '0.2'], ['dropout mask', 'fixed through', 'time steps'], ['time steps', 'in', 'LSTM']]"
"[['mini - batch size', 'set to', '32']]"
"[['Our optimizer', 'is', 'Adamax'], ['learning rate', 'initialized as', '0.002'], ['learning rate', 'decreased by', '0.5'], ['0.5', 'after', 'each 10 epochs']]"
"[['outperforms', 'in', 'RepEval 2017'], ['best system', 'in', 'RepEval 2017']]"
"[['SAN', 'works', 'extremely well'], ['extremely well', 'on', '"" Active / Passive "" and "" Paraphrase "" categories']]"
"[['biggest improvement', 'of', 'SAN']]"
[]
"[['NTI', 'constructs', 'full n-ary tree'], ['full n-ary tree', 'by processing', 'input text'], ['input text', 'with', 'node function'], ['node function', 'in', 'bottom - up fashion']]"
[]
"[['tree structure', 'for', 'NTI'], ['tree structure', 'is', 'relaxed'], ['NTI', 'is', 'relaxed']]"
"[['sequential leaf node transformer', 'such as', 'LSTM'], ['LSTM', 'chosen', 'NTI network'], ['NTI network', 'forms', 'sequence - tree hybrid model'], ['sequence - tree hybrid model', 'taking advantage of', 'conditional and compositional powers'], ['conditional and compositional powers', 'of', 'sequential and recursive models']]"
"[['NTI', 'learns', 'representations'], ['representations', 'for', 'premise and hypothesis sentences']]"
"[['NTI', 'using', 'Adam']]"
[]
"[['word embeddings', 'fixed during', 'training']]"
"[['embeddings', 'for', 'out - ofvocabulary words'], ['embeddings', 'set to', 'zero vector']]"
"[['size', 'of', 'hidden units'], ['hidden units', 'of', 'NTI modules'], ['size', 'of', 'hidden units'], ['hidden units', 'of', 'NTI modules'], ['size', 'set to', '300'], ['hidden units', 'set to', '300']]"
[]
[]
"[['batch size', 'to', '32']]"
"[['number of epoch', 'to', 'trained']]"
"[['NTI - SLSTM', 'uses', 'S - LSTM units'], ['S - LSTM units', 'for', 'non-leaf node function']]"
"[['initial learning rate', 'to', '1e - 3'], ['regularizer strength', 'to', '3 e - 5'], ['regularizer strength', 'to', '3 e - 5'], ['model', 'for', '90 epochs']]"
"[['neural net', 'regularized by', '10 % input dropouts'], ['neural net', 'regularized by', '20 % output dropouts']]"
[]
[]
"[['initial learning rate', 'to', '3e - 4'], ['regularizer strength', 'to', '1 e - 5'], ['regularizer strength', 'to', '1 e - 5'], ['model', 'for', '40 epochs']]"
"[['neural net', 'regularized by', '15 % input dropouts'], ['neural net', 'regularized by', '15 % output dropouts']]"
[]
"[['initial learning rate', 'to', '3e - 4'], ['regularizer strength', 'to', '1 e - 5'], ['regularizer strength', 'to', '1 e - 5'], ['model', 'for', '10 epochs']]"
"[['neural net', 'regularized by', '10 % input dropouts'], ['neural net', 'regularized by', '15 % output dropouts']]"
[]
"[['Tree matching NTI - SLSTM - LSTM global attention', 'first constructs', 'premise and hypothesis'], ['Tree matching NTI - SLSTM - LSTM global attention', 'computes', 'matching vector'], ['matching vector', 'by using', 'global attention and an additional LSTM']]"
"[['initial learning rate', 'to', '3e - 4'], ['regularizer strength', 'to', '3 e - 5'], ['regularizer strength', 'to', '3 e - 5'], ['model', 'for', '20 epochs']]"
"[['neural net', 'regularized by', '20 % input dropouts'], ['neural net', 'regularized by', '20 % output dropouts']]"
"[['Tree matching NTI - SLSTM - LSTM tree attention', 'replace', 'global attention'], ['global attention', 'with', 'tree attention']]"
[]
"[['best score', 'is', '87.3 % accuracy'], ['87.3 % accuracy', 'obtained with', 'full tree matching NTI model']]"
"[['NTI - SLSTM', 'improved', 'performance'], ['performance', 'of', 'sequential LSTM encoder'], ['sequential LSTM encoder', 'by', 'approximately 2 %']]"
"[['LSTM', 'as', 'leaf node function'], ['LSTM', 'helps in', 'learning']]"
"[['NTI - SLSTM - LSTM', 'is', 'hybrid model'], ['hybrid model', 'encodes', 'sequence sequentially'], ['sequence sequentially', 'through', 'leaf node function'], ['hybrid model', 'hierarchically composes', 'output representations']]"
"[['node - by - node attention models', 'improve', 'performance']]"
"[['outperform', 'by', 'large margin'], ['previous best result', 'by', 'large margin']]"
"[['NASM', 'improves', 'result'], ['NASM', 'sets', 'strong baseline'], ['strong baseline', 'by combining', 'variational autoencoder'], ['variational autoencoder', 'with', 'soft attention']]"
"[['attention degree', 'for', 'single word expression'], ['single word expression', 'like', '"" stone ""']]"
"[['robust', 'to', 'length of the phrases']]"
"[['padding size', 'is', 'less ( up to 10 )'], ['NTI - SLSTM - LSTM model', 'performs', 'better']]"
"[['significant performance drop', 'for', 'both models'], ['significant performance drop', 'as', 'padding size'], ['both models', 'as', 'padding size']]"
[]
"[['N - best re-ranking strategy', 'to double check', 'validity'], ['validity', 'of', 'candidates']]"
"[['novel neural network architecture', 'called', 'attention - over - attention model']]"
"[['N - best re-ranking strategy', 'to re-score', 'candidates'], ['candidates', 'in', 'various aspects']]"
[]
[]
"[['embedding weights', 'are', 'randomly initialized']]"
[]
"[['Internal weights', 'of', 'GRUs'], ['Hidden Layer', 'initialized with', 'random orthogonal matrices']]"
"[['ADAM optimizer', 'for', 'weight updating'], ['ADAM optimizer', 'with', 'initial learning rate'], ['weight updating', 'with', 'initial learning rate'], ['initial learning rate', 'of', '0.001']]"
"[['GRU units', 'suffer from', 'gradient exploding issues'], ['GRU units', 'set', 'gradient clipping threshold'], ['gradient exploding issues', 'set', 'gradient clipping threshold'], ['gradient clipping threshold', 'to', '5']]"
"[['batched training strategy', 'of', '32 samples']]"
"[['re-ranking step', 'generate', '5 - best list'], ['5 - best list', 'from', 'baseline neural network model']]"
"[['language model features', 'trained on', 'training proportion'], ['language model features', 'trained on', 'Kneser - Ney smoothing'], ['training proportion', 'of', 'each dataset'], ['training proportion', 'with', '8 - gram wordbased setting'], ['each dataset', 'with', '8 - gram wordbased setting'], ['Kneser - Ney smoothing', 'trained by', 'SRILM toolkit']]"
"[['ensemble model', 'made up of', 'four best models'], ['four best models', 'trained using', 'different random seed']]"
"[['Implementation', 'done with', 'Theano ( Theano Development Team , 2016 ) and Keras']]"
"[['state - of - the - art systems', 'by', 'large margin'], ['large margin', 'where', '2.3 % and 2.0 % absolute improvements'], ['2.3 % and 2.0 % absolute improvements', 'over', 'EpiReader'], ['EpiReader', 'in', 'CBTest NE and CN test sets']]"
"[['additional features', 'in', 're-ranking step'], ['Ao A Reader', 'in', 'CBTest NE / CN test sets'], ['additional features', 'there is', 'another significant boost 2.0 % to 3.7 %'], ['re-ranking step', 'there is', 'another significant boost 2.0 % to 3.7 %'], ['another significant boost 2.0 % to 3.7 %', 'over', 'Ao A Reader'], ['Ao A Reader', 'in', 'CBTest NE / CN test sets']]"
"[['on par', 'with', 'previous best ensemble system'], ['absolute improvement', 'of', '0.9 %'], ['0.9 %', 'beyond', 'best ensemble model ( Iterative Attention )'], ['best ensemble model ( Iterative Attention )', 'in', 'CBTest NE validation set']]"
"[['our AoA Reader', 'shows', 'significant improvements'], ['significant improvements', 'over', 'previous best ensemble models'], ['significant improvements', 'by', 'large margin'], ['previous best ensemble models', 'by', 'large margin'], ['significant improvements', 'setup', 'new state - of - the - art system'], ['previous best ensemble models', 'setup', 'new state - of - the - art system']]"
"[['model', 'explicitly learn', 'weights'], ['weights', 'between', 'individual attentions'], ['weights', 'results in', 'significant boost'], ['individual attentions', 'results in', 'significant boost'], ['significant boost', 'in', 'performance']]"
[]
[]
[]
"[['general semantic retrieval framework', 'that combines', 'our proposed model and the Approximate Nearest Neighbor ( ANN ) technology'], ['most similar question from all available candidates', 'during', 'online serving']]"
[]
[]
"[['Paraphrase Identification ( PI ) problem', 'known as', 'sentence matching']]"
"[['connected graph', 'to depict', 'paraphrase relation'], ['paraphrase relation', 'between', 'sentences'], ['sentences', 'for', 'PI task'], ['connected graph', 'propose', 'multi-task sentence - encoding model'], ['multi-task sentence - encoding model', 'solves', 'paraphrase identification task'], ['multi-task sentence - encoding model', 'solves', 'sentence intent classification task']]"
"[['semantic retrieval framework', 'integrates', 'encoding - based sentence matching model'], ['encoding - based sentence matching model', 'with', 'approximate nearest neighbor search technology'], ['most similar question', 'from', 'all available questions']]"
[]
[]
[]
"[['Quora dataset', 'use', 'Glove - 840B - 300D vector'], ['Glove - 840B - 300D vector', 'as', 'pre-trained word embedding']]"
"[['randomly initialized', 'with', '150 D'], ['hidden size', 'of', 'BiGRU']]"
"[['= 0.8', 'in', 'multi - task loss function']]"
"[['Dropout layer', 'applied to', 'output'], ['output', 'of', 'attentive pooling layer'], ['dropout rate', 'of', '0.1'], ['Dropout layer', 'with', 'dropout rate'], ['attentive pooling layer', 'with', 'dropout rate'], ['dropout rate', 'of', '0.1']]"
"[['Adam optimizer', 'to optimize', 'all the trainable weights']]"
"[['learning rate', 'set to', '4e - 4'], ['batch size', 'set to', '200']]"
"[['performance', 'of', 'model'], ['learning rate', 'of', '1e - 3'], ['performance', 'is', 'no longer improved'], ['model', 'is', 'no longer improved'], ['SGD optimizer', 'with', 'learning rate'], ['learning rate', 'of', '1e - 3'], ['1e - 3', 'to find', 'better local optimum']]"
"[['Enhanced Sequential Inference Model', 'is', 'interaction - based model'], ['interaction - based model', 'for', 'natural language inference']]"
"[['BiLSTM', 'to encode', 'sentence contexts'], ['BiLSTM', 'uses', 'attention mechanism'], ['attention mechanism', 'to calculate', 'information'], ['information', 'between', 'two sentences']]"
"[['ESIM', 'shown', 'excellent performance'], ['excellent performance', 'on', 'SNLI dataset']]"
"[['Bilateral Multi- Perspective Matching model', 'is', 'interaction - based sentence matching model'], ['interaction - based sentence matching model', 'with', 'superior']]"
"[['BiLSTM layer', 'to learn', 'sentence representation'], ['four different types of multiperspective matching layers', 'to match', 'two sentences'], ['additional BiLSTM layer', 'to aggregate', 'matching results'], ['two - layer feed - forward network', 'for', 'prediction']]"
"[['Shortcut - Stacked Sentence Encoder', 'is', 'encodingbased sentence - matching model'], ['encodingbased sentence - matching model', 'enhances', 'multi - layer BiLSTM'], ['multi - layer BiLSTM', 'with', 'short - cut connections']]"
"[['Densely Interactive Inference Network', 'is', 'interaction - based model'], ['interaction - based model', 'for', 'natural language inference ( NLI )']]"
"[['semantic features', 'from', 'interaction space'], ['semantic features', 'to achieve', 'high - level understanding'], ['high - level understanding', 'of', 'sentence pair']]"
[]
"[['state - of - the - art models', 'by', 'large margin'], ['state - of - the - art models', 'reaching', '83 . 62 %'], ['large margin', 'reaching', '83 . 62 %'], ['state - of - the - art models', 'recording', 'state - of - the - art performance'], ['83 . 62 %', 'recording', 'state - of - the - art performance']]"
"[['our MSEM model', 'achieves', 'best performance']]"
"[['model', 'with', 'multi-task learning'], ['multi-task learning', 'further improved', 'performance'], ['performance', 'ranging from', '0.4 %']]"
"[['great advantages', 'on', 'datasets'], ['datasets', 'with', 'low average overlap rate']]"
"[['attentive pooling', 'better than', 'max pooling']]"
"[['drop', 'to', '88.36 %']]"
"[['drop', 'to', '88.26 %']]"
"[['F 1 score', 'of', 'new system'], ['F 1 score', 'is', '14 . 26 %'], ['new system', 'is', '14 . 26 %'], ['14 . 26 %', 'higher than', 'baseline system']]"
[]
[]
[]
"[['deep fusion strategy', 'to model', 'strong interactions'], ['strong interactions', 'of', 'two sentences']]"
"[['text matching', 'regarded as', 'modelling'], ['interaction', 'of', 'two texts'], ['two texts', 'in', 'recursive matching way']]"
"[['deep fusion long short - term memory neural networks ( DF - LSTMs )', 'to model', 'interactions']]"
"[['DF - LSTMs', 'consist of', 'two interconnected conditional LSTMs'], ['two interconnected conditional LSTMs', 'models', 'apiece of'], ['apiece of', 'under', 'influence'], ['text', 'under', 'influence']]"
"[['output vector', 'of', 'DF - LSTMs'], ['DF - LSTMs', 'fed into', 'task - specific output layer'], ['task - specific output layer', 'to compute', 'match - ing score']]"
"[['strong interactions', 'of', 'two texts'], ['two texts', 'in', 'recursive matching way'], ['strong interactions', 'consist of', 'two inter -and intra-dependent LSTMs'], ['recursive matching way', 'consist of', 'two inter -and intra-dependent LSTMs']]"
[]
[]
[]
[]
"[['Each sequence', 'represented as', 'sum'], ['sum', 'of', 'embeddings'], ['embeddings', 'of', 'words it contains'], ['embeddings', 'of', 'words it contains'], ['concatenated and fed', 'to', 'MLP']]"
[]
[]
"[['Two sequences', 'encoded by', 'LSTMs'], ['LSTMs', 'with', 'attention mechanism']]"
[]
[]
"[['all the competitor models', 'with', 'same number of hidden states'], ['comparable results', 'to', 'state - of - the - art']]"
"[['evaluation results', 'of', 'questionanswer matching'], ['evaluation results', 'can see', 'strong interaction models ( attention LSTMs , our DF - LSTMs )'], ['questionanswer matching', 'can see', 'strong interaction models ( attention LSTMs , our DF - LSTMs )'], ['strong interaction models ( attention LSTMs , our DF - LSTMs )', 'consistently outperform', 'weak interaction models ( NBOW , parallel LSTMs )'], ['weak interaction models ( NBOW , parallel LSTMs )', 'with', 'large margin']]"
[]
[]
"[['Wikipedia', 'as', 'collection of articles']]"
"[['MRS', 'focused on', 'simultaneously']]"
"[['MRS', 'by requiring', 'open - domain system'], ['MRS', 'to perform', 'well'], ['well', 'on', 'all of them']]"
"[['module', 'using', 'bigram hashing and TF - IDF matching'], ['question answering', 'efficiently return', 'subset'], ['bigram hashing and TF - IDF matching', 'efficiently return', 'subset'], ['subset', 'of', 'relevant articles']]"
[]
[]
"[['3 - layer bidirectional LSTMs', 'with', 'h = 128 hidden units'], ['h = 128 hidden units', 'for', 'both'], ['h = 128 hidden units', 'for', 'paragraph and question encoding']]"
"[['Stanford CoreNLP toolkit', 'for', 'tokenization'], ['Stanford CoreNLP toolkit', 'generating', 'named entity tags']]"
"[['Adamax', 'for', 'optimization']]"
"[['Dropout', 'with', 'p = 0.3'], ['Dropout', 'applied to', 'word embeddings and all the hidden units'], ['p = 0.3', 'applied to', 'word embeddings and all the hidden units'], ['word embeddings and all the hidden units', 'of', 'LSTMs']]"
"[['Our system ( single model )', 'achieve', '70.0 % exact match'], ['Our system ( single model )', 'achieve', '79.0 % F 1 scores'], ['79.0 % F 1 scores', 'on', 'test set']]"
"[['performance', 'of', 'our final system']]"
"[['our system', 'able to achieve', 'F1'], ['F1', 'over', '77 %']]"
"[['single Document Reader model', 'trained on', 'SQuAD training set'], ['SQuAD', 'used on', 'all evaluation sets']]"
"[['each dataset independently', 'using', 'distant supervision ( DS ) training set']]"
[]
[]
[]
[]
"[['deep cascade model', 'combines', 'advantages'], ['advantages', 'in', 'coarse - to - fine manner']]"
"[['selected paragraphs', 'passed to', 'attention - based deep MRC model'], ['attention - based deep MRC model', 'for extracting', 'actual answer span'], ['actual answer span', 'at', 'word level']]"
"[['answer extraction', 'introduce', 'document extraction and paragraph extraction'], ['document extraction and paragraph extraction', 'as', 'two auxiliary tasks']]"
"[['all the three tasks', 'in', 'unified deep MRC model'], ['unified deep MRC model', 'shares', 'some common bottom layers']]"
"[['models', 'to perform', 'coarse - to - fine pruning'], ['coarse - to - fine pruning', 'at', 'different stages']]"
[]
"[['module', 'at', 'each subsequent stage'], ['module', 'consumes', 'output'], ['each subsequent stage', 'consumes', 'output'], ['output', 'from', 'previous stage'], ['module', 'further prunes', 'documents'], ['answer spans', 'given', 'question']]"
[]
"[['ranking function', 'used as', 'preliminary filter'], ['preliminary filter', 'to discard', 'most of the irrelevant documents or paragraphs'], ['ranking function', 'to keep', 'our framework efficient']]"
"[['extraction function', 'designed to deal with', 'auxiliary document and paragraph extraction tasks'], ['auxiliary document and paragraph extraction tasks', 'jointly optimized with', 'final answer extraction module'], ['final answer extraction module', 'for', 'better extraction performance']]"
[]
"[['auxiliary document extraction and paragraph extraction tasks', 'to', 'pure answer span prediction']]"
[]
[]
"[['documents', 'by merging', 'consecutive paragraphs'], ['consecutive paragraphs', 'to', 'maximum size'], ['maximum size', 'of', '600 words'], ['600 words', 'for', 'each paragraph']]"
"[['Adam optimizer', 'For', 'training'], ['multi-task deep attention framework', 'adopt', 'Adam optimizer'], ['Adam optimizer', 'for', 'training'], ['Adam optimizer', 'with', 'mini-batch size'], ['Adam optimizer', 'with', 'initial learning rate'], ['training', 'with', 'mini-batch size'], ['training', 'with', 'initial learning rate']]"
"[['GloVe 300 dimensional word embeddings', 'in', 'TriviaQA'], ['word2 vec word embeddings', 'with', 'whole DuReader corpus'], ['whole DuReader corpus', 'for', 'DuReader']]"
"[['word embeddings', 'fixed during', 'training']]"
"[['hidden size', 'of', 'LSTM'], ['hidden size', 'set as', '150'], ['LSTM', 'set as', '150'], ['150', 'for', 'TriviaQA'], ['128', 'for', 'DuReader']]"
[]
"[['Nvidia Tesla M40 GPU', 'with', 'Cudnn LSTM cell'], ['Cudnn LSTM cell', 'in', 'Tensorflow 1.3']]"
"[['previous state - of - the - art methods', 'by', 'evident margin']]"
"[['answer extraction', 'among', 'multiple documents'], ['content probability score', 'from', 'multiple documents'], ['shared LSTM', 'can keep', 'ranking order'], ['ranking order', 'from', 'document ranking component']]"
"[['vital', 'serve as', 'good trade - off'], ['final performance', 'serve as', 'good trade - off'], ['good trade - off', 'between', 'pure pipeline method and fully joint learning method']]"
"[['three extraction tasks', 'provide', 'great benefits'], ['great benefits', 'shows', 'three tasks'], ['each other', 'with', 'shared representations'], ['shared representations', 'at', 'bottom layers']]"
[]
[]
"[['more documents or paragraphs', 'into', 'consideration'], ['performance', 'of', 'model']]"
"[['time cost', 'can be', 'largely reduced'], ['time cost', 'by removing', 'more irrelevant documents and paragraphs'], ['largely reduced', 'by removing', 'more irrelevant documents and paragraphs'], ['more irrelevant documents and paragraphs', 'in', 'cascade ranking stage']]"
"[['performance', 'of', 'jointly training']]"
"[['auxiliary document extraction or paragraph extraction task', 'in', 'joint learning framework'], ['performance', 'can', 'always improve']]"
"[['performance gain', 'by adding', 'document extraction task'], ['document extraction task', 'is', 'larger']]"
[]
"[['performance', 'with respect to', 'F 1 score']]"
[]
"[['answer extraction module', 'performs', 'rather poorly'], ['rather poorly', 'both in', 'effectiveness and efficiency'], ['rather poorly', 'as', 'document length']]"
[]
[]
[]
"[['Elmo embedding', 'used as', 'basic embeddings']]"
"[['Spacy', 'to process', 'each question and passage'], ['each question and passage', 'to obtain', 'tokens'], ['lemmas tags', 'of', 'each text']]"
"[['12 dimensions', 'to embed', 'POS tags'], ['POS tags', 'for', 'NER tags'], ['8', 'for', 'NER tags']]"
"[['3 binary features', 'between', 'question and'], ['3 binary features', 'between', 'passage'], ['lemma match', 'between', 'question and'], ['lemma match', 'between', 'passage']]"
[]
"[['LSTM blocks', 'are', 'bi-directional'], ['bi-directional', 'with', 'one single layer']]"
"[['hidden layer dimension', 'as', '125']]"
"[['dropout layer', 'overall', 'modeling layers'], ['modeling layers', 'including', 'embedding layer'], ['dropout layer', 'at', 'dropout rate'], ['dropout rate', 'of', '0.3']]"
"[['Adam optimizer', 'with', 'learning rate'], ['learning rate', 'of', '0.002']]"
"[['Our model', 'achieves', 'F 1 score'], ['Our model', 'achieves', 'EM score'], ['Our model', 'achieves', 'F 1 score'], ['Our model', 'achieves', 'EM score']]"
[]
"[['best - performing systems', 'is', 'end - to - end model']]"
"[['all the end - to - end models', 'achieve', 'best F1 scores']]"
[]
[]
[]
"[['large gain', 'when using', 'multi - task model']]"
"[['answer boundary detection task', 'find that', 'multi -task setup'], ['multi -task setup', 'does not', 'help']]"
"[['our model', 'achieves', 'good score'], ['good score', 'in', 'SQuAD 2.0 test']]"
"[['our multi-task model', 'works', 'well'], ['performance', 'of', 'unanswerability classification'], ['improves', 'when', 'answer pointer and answer verifier'], ['significantly', 'when', 'answer pointer and answer verifier'], ['answer pointer and answer verifier', 'work', 'simultaneously']]"
"[['threshold', 'set to', '0.5'], ['F1 score', 'of', 'answerable questions'], ['answerable questions', 'similar to', 'unanswerable questions']]"
"[['performance', 'for', 'answerable questions']]"
"[['overall F 1 score', 'is', 'slightly better']]"
"[['threshold', 'to be', '0.7'], ['0.7', 'for', 'submission system'], ['submission system', 'to', 'SQuAD evaluation']]"
[]
[]
[]
[]
"[['contextual attention - based deep neural network', 'for', 'task']]"
"[['SDNet', 'leverages', 'latest breakthrough'], ['latest breakthrough', 'in', 'NLP']]"
"[['training', 'use', 'all questions / answers'], ['all questions / answers', 'for', 'one passage'], ['all questions / answers', 'as', 'batch']]"
[]
"[['SDNet', 'achieves', 'significantly better results'], ['significantly better results', 'than', 'baseline models']]"
"[['single SDNet model', 'improves', 'overall F 1'], ['overall F 1', 'by', '1.6 %'], ['previous state - of - art model', 'on', 'CoQA']]"
"[['Ensemble SDNet model', 'further improves', 'overall F 1 score'], ['overall F 1 score', 'by', '2.7 %']]"
"[['SDNet', 'overpasses', 'all but one baseline models'], ['all but one baseline models', 'after', 'second epoch'], ['SDNet', 'achieves', 'state - of - the - art results'], ['state - of - the - art results', 'after', '8 epochs']]"
"[['F 1 score', 'on', 'development set'], ['F 1 score', 'by', '7.15 %'], ['development set', 'by', '7.15 %']]"
"[['proposed weight sum', 'of', 'per-layer output'], ['per-layer output', 'from', 'BERT'], ['per-layer output', 'is', 'crucial'], ['crucial', 'can', 'boost'], ['performance', 'by', '1.75 %'], ['boost', 'compared with using', ""only last layer 's output""], ['performance', 'compared with using', ""only last layer 's output""], ['1.75 %', 'compared with using', ""only last layer 's output""]]"
"[['BERT - base', 'instead of', 'BERT - large pretrained model'], ['BERT - large pretrained model', 'hurts', 'F 1 score'], ['F 1 score', 'by', '2.61 %']]"
"[['performance', 'by', '0.24 % and 0.75 %']]"
[]
"[['basic rules', 'of', 'approximate ( logical ) inference'], ['same category', 'tend to have', 'similar properties']]"
"[['new kind of memory - augmented neural network', 'uses', 'distributed memory and processor architecture']]"
[]
"[['MemN2N', 'set', 'number of hops'], ['number of hops', 'equal to', 'T ? 2']]"
"[['ADAM', 'with', 'initial learning rates'], ['initial learning rates', 'set by', 'grid search'], ['grid search', 'over', '{ 0.1 , 0.01 , 0.001 }'], ['grid search', 'divided by', '2 every 10,000 updates']]"
"[['degrades', 'as', 'length of the sequence'], ['quickly', 'as', 'length of the sequence']]"
"[['LSTM', 'performs', 'better'], ['loses', 'as', 'length of the sequence'], ['accuracy', 'as', 'length of the sequence']]"
"[['EntNet', 'able to solve', 'task'], ['task', 'in', 'all cases']]"
"[['model', 'able to achieve', 'good performance']]"
[]
"[['ADAM', 'using', 'learning rate'], ['learning rate', 'of', '? = 0.01'], ['? = 0.01', 'divided by', '2 every 25 epochs'], ['2 every 25 epochs', 'until', '200 epochs']]"
[]
"[['Our model', 'able to', 'solve'], ['other models', 'in terms of', 'number of solved tasks'], ['other models', 'in terms of', 'average error']]"
"[['useful or correct information', 'in', 'memory slots'], ['memory slots', 'corresponding to', 'locations']]"
[]
"[['standard stochastic gradient descent ( SGD )', 'with', 'fixed learning rate'], ['fixed learning rate', 'of', '0.001']]"
"[['separate input encodings', 'for', 'update and gating functions'], ['dropout rate', 'of', '0.5'], ['0.5', 'to', 'word embedding dimensions']]"
"[['general EntNet', 'performs', 'better'], ['better', 'than', 'LSTMs and n-gram model'], ['LSTMs and n-gram model', 'on', 'Named Entities Task']]"
"[['simplified EntNet', 'performs', 'better'], ['better', 'than', 'Memory Network'], ['Memory Network', 'which does not use', 'self - supervision heuristic']]"
"[['simplified EntNet', 'able to obtain', 'decent performance'], ['decent performance', 'is', 'encouraging']]"
"[['general framework PhaseCond', 'for the use of', 'multiple attention layers']]"
"[['different attention - based architecture', 'containing', 'two sequential phases']]"
"[['several meaningful trends', 'during', 'questionpassage attention phase'], ['several meaningful trends', 'during', 'self - attention phase'], ['questionpassage attention phase', 'repeatedly attending', 'passage'], ['passage', 'with', 'same question representation'], ['same question representation', 'forces', 'each passage word'], ['each passage word', 'to become', 'increasingly closer'], ['several meaningful trends', 'during', 'self - attention phase'], [""self - attention 's alignment weights"", 'of', 'second layer'], [""self - attention 's alignment weights"", 'become', 'noticeably "" sharper ""'], ['second layer', 'become', 'noticeably "" sharper ""'], ['noticeably "" sharper ""', 'than', 'first layer']]"
"[['binary features', 'of', 'exact matching']]"
"[['question type ( what , how , who , when , which , where , why , be , and other ) features', 'where', 'each type'], ['each type', 'represented by', 'trainable embedding']]"
"[['CNN', 'with', '100 one - dimensional filters'], ['100 one - dimensional filters', 'with', 'width 5'], ['100 one - dimensional filters', 'with', 'width 5'], ['width 5', 'to encode', 'character level embedding']]"
"[['hidden size', 'set as', '128'], ['128', 'for', 'all the LSTM layers']]"
"[['Dropout', 'used for', 'all the learnable parameters'], ['all the learnable parameters', 'with', 'ratio'], ['ratio', 'as', '0.2']]"
"[['Adam optimizer ( Kingma & Ba , 2014 )', 'with', 'initial learning rate'], ['initial learning rate', 'of', '0.0006']]"
[]
"[['EM result', 'of', 'our'], ['EM result', 'of', 'baseline Iterative Aligner'], ['baseline Iterative Aligner', 'lower than', 'RNET']]"
"[['question - passage attention phase', 'using', 'single layer'], ['single layer', ""does n't degrade"", 'performance'], ['performance', 'from', 'default setting'], ['significantly', 'from', 'default setting'], ['default setting', 'of', 'two layers']]"
[]
"[['first layer', 'of', 'question - passage attention phase'], ['first layer', 'successfully align', 'question keywords'], ['question - passage attention phase', 'successfully align', 'question keywords'], ['question keywords', 'with', 'corresponding passage keywords']]"
[]
[]
"[['question - answer pairs', 'annotated through', 'crowdsourcing']]"
"[['bi-directional attention flow ( BIDAF )', 'used', 'bi-directional attention'], ['bi-directional attention', 'to obtain', 'question - aware context representation']]"
"[['syntactic information', 'to encode', 'questions'], ['questions', 'with', 'specific form of recursive neural networks']]"
"[['tree - structured LSTM', 'extends', 'linear - chain long short - term memory ( LSTM )'], ['linear - chain long short - term memory ( LSTM )', 'to', 'recursive structure'], ['long - distance interactions', 'over', 'structures']]"
[]
"[['pre-trained 300 - D Glove 840B vectors', 'to initialize', 'our word embeddings']]"
"[['initialized randomly', 'with', 'Gaussian samples']]"
"[['CharCNN filter length', 'is', '1 , 3 , 5'], ['CharCNN filter length', 'is', '50 dimensions']]"
"[['cluster number K', 'in', 'discriminative block'], ['discriminative block', 'is', '100']]"
"[['Adam method', 'used for', 'optimization']]"
"[['initial learning rate', 'is', '0.0004'], ['batch size', 'is', '32']]"
"[['hidden states', 'of', 'GRUs , and TreeLSTMs'], ['GRUs , and TreeLSTMs', 'are', '500 dimensions'], ['word - level embedding d w', 'is', '300 dimensions']]"
"[['max length', 'of', 'document'], ['document', 'to', '500'], ['question - document pairs', 'on', 'training set']]"
"[['dropout', 'to', 'Encoder layer and aggregation layer'], ['Encoder layer and aggregation layer', 'with', 'dropout rate'], ['dropout rate', 'of', '0.5']]"
"[['Our model', 'achieves', '68.73 % EM score'], ['Our model', 'achieves', '77.39 % F1 score'], ['77.39 % F1 score', 'ranked among', 'state of the art single models']]"
"[['Our baseline model', 'using', 'no Q- code'], ['no Q- code', 'achieved', '68.00 % and 77.36 % EM and F 1 scores']]"
"[['explicit question type T - code', 'into', 'baseline model'], ['performance', 'improved slightly to', '68.16 % ( EM )'], ['performance', 'improved slightly to', '77.58 % ( F1 )']]"
"[['TreeLSTM', 'introduce', 'syntactic parses'], ['syntactic parses', 'for', 'question representation and understanding']]"
"[['number of hidden question types ( K )', 'to be', '20'], ['improves', 'to be', '68.73%/77.74 %'], ['68.73%/77.74 %', 'on', 'EM and F1']]"
[]
[]
[]
"[['conventional notion', 'of', 'similarity']]"
"[['deep neural network models', 'adapt', 'convolutional strategy'], ['convolutional strategy', 'to', 'natural language']]"
"[['novel model', 'can naturally host', 'simple - to - comprehensive fusion'], ['simple - to - comprehensive fusion', 'of', 'matching patterns'], ['matching patterns', 'with', 'same convolutional architecture']]"
"[['better', 'with', 'mini-batch ( 100 ? 200 in sizes )'], ['single machine', 'with', 'multi-cores'], ['mini-batch ( 100 ? 200 in sizes )', 'can be easily', 'parallelized'], ['single machine', 'with', 'multi-cores']]"
"[['regularization', 'find that for', 'both architectures'], ['early stopping', 'is enough for', 'models'], ['models', 'with', 'medium size and large training sets ( with']]"
"[['50 - dimensional word embedding', 'trained with', 'Word2 Vec']]"
"[['ReLu', 'as', 'activation function'], ['activation function', 'for', 'all of models ( convolution and MLP )'], ['activation function', 'yields', 'comparable or better results'], ['all of models ( convolution and MLP )', 'yields', 'comparable or better results'], ['comparable or better results', 'to', 'sigmoid - like functions']]"
"[['each short - text', 'as', 'sum'], ['embedding', 'of', 'words it contains']]"
"[['matching score', 'of', 'two short - texts'], ['embedding', 'of', 'two documents'], ['two short - texts', 'calculated with', 'MLP'], ['MLP', 'with', 'embedding'], ['our datasets', 'with', '3 hidden layers'], ['embedding', 'of', 'two documents'], ['DEEPMATCH', 'train it on', 'our datasets'], ['our datasets', 'with', '3 hidden layers'], ['our datasets', 'with', '1,000 hidden nodes'], ['1,000 hidden nodes', 'in', 'first hidden layer']]"
"[['Unfolding Recursive Autoencoder', 'to get', '100 dimensional vector representation'], ['100 dimensional vector representation', 'of', 'each sentence'], ['MLP', 'on', 'top'], ['top', 'as in', 'WORDEMBED']]"
"[['SENNA - type sentence model', 'for', 'sentence representation']]"
"[['SENMLP', 'take', 'whole sentence'], ['whole sentence', 'as', 'input'], ['input', 'with', 'word embedding aligned sequentially'], ['SENMLP', 'use', 'MLP'], ['MLP', 'to obtain', 'score of coherence']]"
[]
"[['two proposed', 'get', 'nearly half'], ['nearly half', 'of', 'cases right'], ['cases right', 'with', 'large margin'], ['large margin', 'over', 'other sentence models']]"
[]
"[['SENNA + MLP', 'performs', 'fairly well']]"
"[['ARC', 'beats', 'other models'], ['other models', 'with', 'large margins']]"
[]
"[['External memory', 'allows', 'MANNs'], ['MANNs', 'to learn', 'algorithmic solutions'], ['algorithmic solutions', 'to', 'problems'], ['External memory', 'to generalize', 'longer sequence lengths']]"
"[['MANN', 'named', 'SAM ( sparse access memory )']]"
"[['memory modifications', 'to', 'sparse subset'], ['efficient data structures', 'for', 'content - based read operations'], ['our model', 'is', 'optimal'], ['optimal', 'in', 'space and time'], ['space and time', 'with respect to', 'memory size'], ['our model', 'retaining', 'end - to - end gradient based optimization']]"
"[['Sparse Differentiable Neural Computer ( SDNC )', 'is', 'over 400 faster'], ['over 400 faster', 'than', 'canonical dense variant'], ['canonical dense variant', 'fora', 'memory size'], ['memory size', 'of', '2,000 slots'], ['Sparse Differentiable Neural Computer ( SDNC )', 'achieves', 'best reported result'], ['best reported result', 'in', 'Babi tasks'], ['best reported result', 'without supervising', 'memory access'], ['Babi tasks', 'without supervising', 'memory access']]"
[]
[]
"[['MANNs', 'except', 'NTM'], ['MANNs', 'able to learn', 'solutions'], ['solutions', 'comparable to', 'previous best results']]"
"[['SDNC', 'manages to', 'solve']]"
"[['end - to - end memory networks', 'which did not use', 'supervision'], ['fails', 'at', '6 of the tasks']]"
"[['Both the sparse and dense', 'perform', 'comparably']]"
[]
"[['SAM', 'able to', 'outperform']]"
[]
"[['SDNC', 'achieves', 'best reported result'], ['best reported result', 'with', 'unsupervised memory access'], ['best reported result', 'solving', 'all but 1 task']]"
[]
"[['novel deep neural network architecture', 'to handle', 'long - range dependency'], ['long - range dependency', 'in', 'RC tasks']]"
[]
"[['customized memory controller', 'along with', 'external memory augmentation'], ['external memory augmentation', 'for', 'complicated RC tasks']]"
"[['memory controller', 'with', 'residual connection'], ['residual connection', 'to alleviate', 'information distortion']]"
"[['gated recurrent unit ( GRU )', 'with', 'dense connection'], ['dense connection', 'conveys', 'enriched features'], ['enriched features', 'to', 'next layer'], ['next layer', 'containing', 'original']]"
"[['extended memory controller module', 'for', 'RC tasks']]"
"[['NLTK', 'used for', 'tokenizing words']]"
"[['memory controller', 'use', 'four read heads'], ['memory controller', 'use', 'one write head'], ['memory size', 'set to', '100 36']]"
"[['hidden vector dimension l', 'set to', '200']]"
"[['AdaDelta ( Zeiler , 2012 )', 'as', 'optimizer'], ['AdaDelta ( Zeiler , 2012 )', 'with', 'learning rate'], ['optimizer', 'with', 'learning rate'], ['learning rate', 'of', '0.5']]"
"[['batch size', 'set to', '20'], ['20', 'for', 'TriviaQA'], ['30', 'for', 'SQuAD']]"
"[['exponential moving average', 'of', 'weights'], ['decaying factor', 'of', '0.001'], ['weights', 'with', 'decaying factor'], ['decaying factor', 'of', '0.001']]"
"[['best results', 'published on', 'TriviaQA and SQuAD datasets']]"
"[['BiDAF + DNC', 'augmented with', 'existing external memory architecture'], ['existing external memory architecture', 'just before', 'answer prediction layer'], ['answer prediction layer', 'in', 'BiDAF']]"
"[['lengthy - document cases', 'such as', 'Trivi aQA'], ['short - document case', 'achieve', 'best results']]"
[]
"[['existing state - of - the - art method', 'such as', ""BiDAF + SA + SN '""], [""BiDAF + SA + SN '"", 'by', 'large margin']]"
"[['Our model with', 'replaces', 'BiGRU encoder blocks'], ['DEBS', 'replaces', 'BiGRU encoder blocks'], ['Our model with', 'performs', 'even better'], ['DEBS', 'performs', 'even better'], ['all the cases', 'except for', 'combination of']]"
"[['our method', 'achieves', 'outstanding results'], ['BiDAF + DNC', 'involves', 'existing memory architecture'], ['performance', 'over', 'BiDAF']]"
"[['our model', 'with', 'proposed memory controller'], ['our model', 'achieves', 'significantly better results'], ['proposed memory controller', 'achieves', 'significantly better results'], ['significantly better results', 'compared to', 'other models']]"
"[['ELMo', 'to', 'our model ( without DEBS )'], ['ELMo', 'uses', 'word embedding'], ['our model ( without DEBS )', 'uses', 'word embedding'], ['word embedding', 'as', 'weighted']]"
"[['F 1 score', 'of', 'our model'], ['our model', 'up to', '85.13']]"
"[['our model', 'without', 'DEBS'], ['our model', 'performs', 'worse'], ['worse', 'than', 'baseline'], ['worse', 'than', 'BiDAF + Self Attention + ELMo.']]"
[]
"[['DEBS', 'in', 'all the places'], ['DEBS', 'improves', 'performance'], ['all the places', 'improves', 'performance'], ['memory controller', 'with', 'DEBS'], ['memory controller', 'gives', 'largest performance margin'], ['DEBS', 'gives', 'largest performance margin']]"
[]
"[['sentence similarity', 'to determine', 'two sentences'], ['two sentences', 'are', 'paraphrases']]"
[]
"[['size', 'of', 'word vector dimension'], ['word vector dimension', 'as', 'd = 300'], ['vectors', 'with', 'word2 vec toolkit'], ['word2 vec toolkit', 'on', 'English Gigaword ( LDC2011T07 )']]"
[]
"[['vector', 'used for', 'various downstream tasks'], ['various downstream tasks', 'e.g.', 'sentiment analysis'], ['various downstream tasks', 'e.g.', 'natural language inference']]"
"[['Self - attention', 'computes', 'attention weights'], ['attention weights', 'by', 'inner product'], ['inner product', 'between', 'words and the learnable weight vector']]"
"[['weight vector', 'detects', 'informative words'], ['weight vector', 'is', 'static'], ['static', 'during', 'inference']]"
"[['new self - attention mechanism', 'for', 'sentence embedding'], ['sentence embedding', 'namely', 'Dynamic Self - Attention ( DSA )']]"
"[['dynamic routing', 'functions as', 'self - attention'], ['self - attention', 'with', 'dynamic weight vector']]"
[]
"[['dynamic weight vector', 'with', 'DSA'], ['dynamic weight vector', 'computes', 'attention weights']]"
[]
"[['DSA and self - attention', 'stacked on', 'CNN with Dense Connection']]"
"[['word embeddings', 'by', '300D Glo Ve 840B pretrained vectors'], ['word embeddings', 'fix them during', 'training']]"
"[['cross-entropy loss', 'as', 'objective function']]"
[]
[]
"[['tradeoffs', 'in terms of', 'parameters and learning time per epoch'], ['multiple DSA', 'outperforms', 'other models'], ['other models', 'by', 'large margin ( + 1.1 % )']]"
"[['single DSA', 'shows', 'better performance'], ['better performance', 'than', 'self - attention']]"
"[['our implementation', 'of', 'baseline'], ['selfattention', 'stacked on', 'CNN'], ['CNN', 'with', 'Dense Connection'], ['baseline', 'shows', 'better performance ( + 0.4 % )'], ['selfattention', 'shows', 'better performance ( + 0.4 % )'], ['Dense Connection', 'shows', 'better performance ( + 0.4 % )']]"
[]
"[['all the baseline models', 'in', 'SST - 2 dataset'], ['comparative results', 'in', 'SST - 5'], ['Single DSA', 'achieves', 'comparative results'], ['comparative results', 'in', 'SST - 5']]"
"[['SNLI dataset', 'in', 'SST dataset'], ['performance', 'between', 'DSA and the previous self - attentive models']]"
[]
[]
[]
"[['lack of real natural language training data', 'by introducing', 'novel approach'], ['novel approach', 'to building', 'supervised reading comprehension data set']]"
"[['two new corpora', 'of', 'roughly a million news stories'], ['roughly a million news stories', 'with', 'associated queries'], ['associated queries', 'from', 'CNN and Daily Mail websites']]"
[]
"[['two machine reading corpora', 'by exploiting', 'online newspaper articles'], ['two machine reading corpora', 'by exploiting', 'matching summaries']]"
"[['maximum penalty per word ( m = 8 )', 'on', 'validation data']]"
[]
[]
"[['sentence encoding - based model', 'for recognizing', 'text entailment']]"
"[['existing best sentence encoding - based approach', 'by', 'large margin']]"
[]
"[['unified deep learning framework', 'for recognizing', 'textual entailment']]"
[]
"[['training objective', 'use', 'minibatch SGD'], ['minibatch SGD', 'with', 'Rmsprop']]"
"[['batch size', 'is', '128']]"
"[['dropout layer', 'applied in', 'output'], ['output', 'of', 'network'], ['dropout layer', 'with', 'dropout rate'], ['output', 'with', 'dropout rate'], ['network', 'with', 'dropout rate'], ['dropout rate', 'set to', '0.25']]"
"[['pretrained 300D Glove 840B vectors', 'to initialize', 'word embedding']]"
"[['Out - of - vocabulary words', 'in', 'training set'], ['randomly initialized', 'by sampling', 'values'], ['values', 'from', '( 0.05 , 0.05 )'], ['uniformly', 'from', '( 0.05 , 0.05 )']]"
"[['representation', 'stays close to', 'unseen similar words'], ['unseen similar words', 'in', 'inference time'], ['inference time', 'improved', 'model']]"
[]
"[['short and long answers', 'in', 'single model'], ['each document', 'into', 'multiple training instances'], ['multiple training instances', 'by using', 'overlapping windows'], ['overlapping windows', 'of', 'tokens'], ['null instances ( i.e. instances without an answer )', 'at', 'training time'], ['null instances ( i.e. instances without an answer )', 'to create', 'balanced training set'], ['training time', 'to create', 'balanced training set'], ['null instances ( i.e. instances without an answer )', 'at', 'training time']]"
[]
"[['our model', 'from', 'BERT model'], ['our model', 'finetuned on', 'SQ u AD 1.1'], ['BERT model', 'finetuned on', 'SQ u AD 1.1']]"
"[['model', 'by', 'minimizing'], ['loss L', 'with', 'Adam optimizer'], ['minimizing', 'with', 'batch size'], ['Adam optimizer', 'with', 'batch size'], ['batch size', 'of', '8']]"
"[['Our BERT model', 'for', 'NQ'], ['Our BERT model', 'performs', 'dramatically better'], ['NQ', 'performs', 'dramatically better']]"
