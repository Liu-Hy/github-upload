2	0	27	Parameter Re-Initialization
4	0	32	Optimal parameter initialization
19	9	17	explores
19	27	29	of
19	30	38	adapting
19	43	64	weight initialization
19	65	67	to
19	72	93	optimization dynamics
20	32	62	improved weight initialization
20	70	79	viewed as
20	80	93	starting with
20	96	108	better prior
20	117	125	leads to
20	128	151	more accurate posterior
20	161	190	better generalization ability
22	40	54	adaptive prior
22	58	73	implemented via
22	74	115	Markov Chain Monte Carlo ( MCMC ) methods
23	30	41	incorporate
23	45	72	" adaptive initialization "
23	73	76	for
23	77	100	neural network training
23	142	145	use
23	146	175	cyclical batch size schedules
23	176	186	to control
23	191	215	noise ( or temperature )
23	216	218	of
23	219	222	SGD
26	34	42	studying
26	43	82	different cyclical annealing strategies
26	83	86	for
26	89	111	wide range of problems
82	0	16	Language Results
83	0	17	Language modeling
85	0	13	CBS schedules
85	34	39	avoid
85	40	51	overfitting
85	70	89	snapshot ensembling
85	90	97	enables
85	98	122	even greater performance
88	20	49	best performing CBS schedules
88	50	59	result in
88	60	84	significant improvements
88	85	87	in
88	88	98	perplexity
88	114	118	over
88	123	141	baseline schedules
88	151	156	offer
88	157	167	reductions
88	168	170	in
88	175	208	number of SGD training iterations
90	12	36	almost all CBS schedules
90	37	47	outperform
90	52	69	baseline schedule
97	21	34	CBS schedules
97	35	47	do not yield
97	48	78	large performance improvements
97	79	81	on
97	82	88	models
97	103	110	exhibit
97	111	130	smaller disparities
97	131	138	between
97	139	171	training and testing performance
102	0	28	Image Classification Results
103	17	32	training curves
103	33	35	of
103	36	49	CBS schedules
103	55	62	exhibit
103	67	97	aforementioned cyclical spikes
103	103	105	in
103	106	140	training loss and testing accuracy
105	3	10	observe
105	16	19	CBS
105	20	28	achieves
105	29	48	similar performance
105	49	51	to
105	56	64	baseline
107	0	4	With
107	5	13	CBS - 15
107	19	22	see
107	23	48	90.71 % training accuracy
107	53	78	56. 44 % testing accuracy
107	92	110	larger improvement
107	111	115	than
107	136	138	on
107	139	159	convolutional models
109	0	9	Combining
109	10	18	CBS - 15
109	19	21	on
109	22	24	C2
109	44	52	improves
109	53	61	accuracy
109	62	64	to
109	65	72	94.82 %
111	0	8	Applying
111	9	28	snapshot ensembling
111	29	31	on
111	32	34	C3
111	35	47	trained with
111	48	60	CBS - 15 - 2
111	61	69	leads to
111	70	87	improved accuracy
111	88	90	of
111	91	99	93. 56 %
111	103	114	compared to
111	115	122	92.58 %
112	0	5	After
112	6	16	ensembling
112	17	25	ResNet50
112	26	28	on
112	29	37	Imagenet
112	38	42	with
112	43	52	snapshots
112	53	57	from
112	62	77	last two cycles
112	84	95	performance
112	96	105	increases
112	106	108	to
112	109	117	76.401 %
112	118	122	from
112	123	131	75.336 %
