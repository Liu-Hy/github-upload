2	18	50	Reasoning over Multiple Mentions
12	3	7	call
12	13	42	coreference - based reasoning
20	15	20	given
20	24	63	input sequence and coreference clusters
20	64	78	extracted from
20	82	97	external system
20	103	112	introduce
20	115	119	term
20	120	122	in
20	127	143	update equations
20	144	147	for
20	148	177	Gated Recurrent Units ( GRU )
20	184	194	depends on
20	199	211	hidden state
20	212	214	of
20	219	240	coreferent antecedent
20	241	243	of
20	248	261	current token
21	9	22	hidden states
21	27	43	propagated along
21	44	62	coreference chains
21	71	88	original sequence
21	89	100	in parallel
22	3	10	compare
22	15	32	Coref - GRU layer
22	33	37	with
22	42	59	regular GRU layer
22	85	97	recent model
22	98	101	for
22	102	123	reading comprehension
94	0	13	BAbi AI tasks
100	16	19	see
100	20	38	clear improvements
100	39	47	of using
100	48	62	C - GRU layers
100	63	67	over
100	68	78	GRU layers
105	0	12	Comparing to
105	17	29	QRN baseline
105	35	45	found that
105	46	53	C - GRU
105	54	57	was
105	58	77	significantly worse
105	78	80	on
105	81	108	task 15 ( basic deduction )
107	20	27	C - GRU
107	32	57	significantly better than
107	32	52	significantly better
107	53	57	than
107	58	61	QRN
107	62	64	on
107	65	92	task 16 ( basic induction )
112	0	15	Wikihop dataset
120	3	6	see
120	7	25	higher performance
120	26	29	for
120	34	47	C - GRU model
120	48	50	in
120	55	70	low data regime
120	77	98	better generalization
120	99	109	throughout
120	114	128	training curve
