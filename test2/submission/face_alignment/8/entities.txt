2	0	53	Joint 3D Face Reconstruction and Dense Face Alignment
31	0	23	3 D face reconstruction
41	88	95	propose
41	98	119	novel learning method
41	125	134	leverages
41	135	169	2D " in - the - wild " face images
41	170	209	to effectively supervise and facilitate
41	214	236	3D face model learning
45	3	9	design
45	12	51	novel self - supervised learning method
45	60	73	able to train
45	76	90	3 D face model
45	91	95	with
45	96	112	weak supervision
45	113	117	from
45	118	127	2D images
47	20	35	able to recover
47	36	48	2D landmarks
47	49	53	from
47	54	71	predicted 3D ones
47	72	75	via
47	76	106	direct 3D - to - 2D projection
49	40	48	exploits
49	49	68	cycle - consistency
49	69	73	over
49	78	101	2D landmark predictions
49	111	117	taking
49	122	144	recovered 2D landmarks
49	193	205	2D landmarks
49	261	277	small difference
49	278	282	with
49	287	301	annotated ones
51	0	13	To facilitate
51	18	44	overall learning procedure
51	63	71	exploits
51	72	94	self - critic learning
205	4	19	proposed 2 DASL
205	23	39	implemented with
205	40	47	Pytorch
206	3	6	use
206	7	20	SGD optimizer
206	21	24	for
206	29	42	CNN regressor
206	43	47	with
206	50	63	learning rate
206	64	76	beginning at
206	77	84	5 10 ?5
206	89	95	decays
206	96	109	exponentially
206	116	129	discriminator
206	130	134	uses
206	139	156	Adam as optimizer
206	157	161	with
206	166	193	fixed learning rate 1 10 ?4
209	3	6	use
209	9	29	two - stage strategy
209	30	38	to train
209	39	48	our model
210	7	18	first stage
210	24	29	train
210	34	39	model
210	40	45	using
210	50	65	overall loss L.
211	25	36	fine - tune
211	37	46	our model
211	47	52	using
211	57	77	Vertex Distance Cost
227	0	20	Dense face alignment
239	44	54	our 2 DASL
239	55	63	achieves
239	68	84	lowest NME ( % )
239	85	87	on
239	111	133	2 D and 3D coordinates
239	134	139	among
239	140	155	all the methods
240	0	3	For
240	4	25	3 DMM - based methods
240	28	43	3 DDFA and DeFA
240	46	56	our method
240	57	68	outperforms
240	74	76	by
240	79	91	large margin
240	92	94	on
240	104	122	68 spare landmarks
240	131	148	dense coordinates
245	21	31	our method
245	32	40	achieves
245	45	60	lowest mean NME
245	61	63	on
245	64	88	both of the two datasets
245	99	109	lowest NME
245	110	116	across
245	117	126	all poses
245	127	129	on
245	130	143	AFLW2000 - 3D
246	0	9	Our 2DASL
246	15	23	performs
246	24	30	better
246	31	35	than
246	36	41	PRNet
246	44	52	reducing
246	53	56	NME
246	57	59	by
246	60	73	0.09 and 0.08
246	74	76	on
246	77	106	AFLW2000 - 3D and AFLW - LFPA
247	14	16	on
247	17	28	large poses
247	49	55	2 DASL
247	56	64	achieves
247	65	78	0.2 lower NME
247	79	83	than
247	84	89	PRNet
249	0	23	3 D face reconstruction
255	21	46	3D reconstruction results
255	47	49	of
255	50	56	2 DASL
255	57	68	outperforms
255	69	75	3 DDFA
255	76	78	by
255	79	83	0.39
255	95	98	for
255	99	103	DeFA
255	116	140	significant improvements
265	4	10	Adding
265	11	18	weights
265	19	21	to
265	22	36	central points
265	37	39	of
265	44	60	facial landmarks
265	61	68	reduces
265	73	76	NME
265	77	79	by
265	80	84	0.09
265	88	92	0.23
265	93	95	on
265	100	110	two stages
267	7	29	self - critic learning
267	30	32	is
267	33	41	not used
267	48	51	NME
267	52	61	increases
267	62	64	by
267	65	74	0.04/0.18
267	75	78	for
267	79	105	with / without weight mask
268	10	35	self - supervision scheme
268	36	42	reduce
268	43	46	NME
268	47	49	by
268	50	53	0.1
268	54	58	when
268	63	74	weight mask
268	78	82	used
268	89	93	0.23
268	94	96	if
268	101	112	weight mask
268	116	123	removed
270	35	40	found
270	41	47	taking
270	52	56	FLMs
270	57	59	as
270	60	65	input
270	70	80	accelerate
270	85	96	convergence
270	97	99	of
270	100	116	training process
