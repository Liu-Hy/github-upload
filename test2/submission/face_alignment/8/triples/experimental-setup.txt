(proposed 2 DASL||implemented with||Pytorch)
(Experimental setup||has||proposed 2 DASL)
(SGD optimizer||for||CNN regressor)
(CNN regressor||with||learning rate)
(Adam as optimizer||with||fixed learning rate 1 10 ?4)
(learning rate||beginning at||5 10 ?5)
(SGD optimizer||decays||exponentially)
(discriminator||uses||Adam as optimizer)
(Adam as optimizer||with||fixed learning rate 1 10 ?4)
(Experimental setup||use||SGD optimizer)
(two - stage strategy||to train||our model)
(Experimental setup||use||two - stage strategy)
(first stage||train||model)
(model||using||overall loss L.)
(our model||using||Vertex Distance Cost)
(Experimental setup||fine - tune||our model)
(Contribution||has||Experimental setup)
