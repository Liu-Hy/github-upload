(training||use||document - size minibatches)
(document - size minibatches||allows for||efficient pre-computation)
(efficient pre-computation||of||RNN states)
(document - size minibatches||minimize||loss)
(loss||with||AdaGrad)
(AdaGrad||after clipping||LSTM gradients)
(Experimental setup||For||training)
(initial learning rate||chosen for||AdaGrad)
(significant impact||on||results)
(initial learning rate||choose||learning rates)
(learning rates||for||each layer)
(each layer||out of||{ 0.1 , 0.02 , 0.01 , 0.002 , 0.001 })
(initial learning rate||has||AdaGrad)
(Experimental setup||find||initial learning rate)
(ha ( x n ) , h c ( x n ) , and h ( m )||to be||? R 200)
(Experimental setup||set||ha ( x n ) , h c ( x n ) , and h ( m ))
(single - layer LSTM||implemented in||element - rnn library)
(Experimental setup||use||single - layer LSTM)
(regularization||apply||Dropout)
(Dropout||with||rate)
(Dropout||with||rate)
(rate||of||0.4)
(rate||of||0.3)
(rate||before applying||linear weights u)
(0.4||before applying||linear weights u)
(Dropout||apply||Dropout)
(Dropout||with||rate)
(rate||of||0.3)
(0.3||to||LSTM states)
(LSTM states||before forming||dot -product scores)
(rate||has||0.3)
(Experimental setup||For||regularization)
(GPU||for||training)
(Experimental setup||makes use of||GPU)
(Contribution||has||Experimental setup)
