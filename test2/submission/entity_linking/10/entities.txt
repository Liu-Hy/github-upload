2	0	40	Deep contextualized word representations
4	27	66	deep contextualized word representation
9	0	32	Pre-trained word representations
12	19	28	introduce
13	20	31	differ from
13	32	64	traditional word type embeddings
13	73	83	each token
13	87	95	assigned
13	98	112	representation
13	123	134	function of
13	139	160	entire input sentence
14	3	6	use
14	7	14	vectors
14	15	27	derived from
14	30	48	bidirectional LSTM
14	57	69	trained with
14	72	114	coupled lan - guage model ( LM ) objective
14	115	117	on
14	120	137	large text corpus
15	21	25	call
15	31	87	ELMo ( Embeddings from Language Models ) representations
16	70	90	ELMo representations
16	91	94	are
16	95	99	deep
16	131	142	function of
16	170	172	of
16	177	181	biLM
17	23	28	learn
17	31	64	linear combination of the vectors
17	57	64	vectors
17	65	78	stacked above
17	79	94	each input word
17	95	98	for
17	99	112	each end task
17	121	138	markedly improves
17	139	150	performance
17	151	155	over
17	171	185	top LSTM layer
19	6	27	intrinsic evaluations
19	33	37	show
19	47	73	higher - level LSTM states
19	74	81	capture
19	82	109	context - dependent aspects
19	110	112	of
19	113	125	word meaning
19	243	260	lowerlevel states
19	261	266	model
19	267	274	aspects
19	278	284	syntax
103	0	18	Question answering
107	6	12	adding
107	13	17	ELMo
107	18	20	to
107	25	39	baseline model
107	42	54	test set F 1
107	55	63	improved
107	64	66	by
107	67	72	4.7 %
107	73	77	from
107	78	94	81.1 % to 85.8 %
107	99	130	24.9 % relative error reduction
107	131	135	over
107	140	148	baseline
107	155	164	improving
107	169	212	overall single model state - of - the - art
107	213	215	by
107	216	221	1.4 %
109	4	12	increase
109	13	15	of
109	16	21	4.7 %
109	22	26	with
109	27	31	ELMo
109	40	60	significantly larger
109	61	65	then
109	70	87	1.8 % improvement
109	88	99	from adding
109	100	104	CoVe
109	105	107	to
109	110	124	baseline model
112	0	18	Textual entailment
116	10	16	adding
116	17	21	ELMo
116	22	24	to
116	29	39	ESIM model
116	40	48	improves
116	49	57	accuracy
116	58	60	by
116	64	80	average of 0.7 %
116	81	87	across
116	88	105	five random seeds
118	0	22	Semantic role labeling
124	19	23	with
124	28	61	OntoNotes coreference annotations
124	62	66	from
124	71	93	CoNLL 2012 shared task
124	96	102	adding
124	103	107	ELMo
124	108	116	improved
124	121	132	average F 1
124	133	135	by
124	136	141	3.2 %
124	142	146	from
124	147	159	67.2 to 70.4
125	0	23	Named entity extraction
128	18	44	ELMo enhanced biLSTM - CRF
128	45	53	achieves
128	54	66	92. 22 % F 1
128	67	80	averaged over
128	81	90	five runs
