2	47	85	Word Sense Disambiguation of Text Data
5	73	116	Word Sense Disambiguation ( WSD ) algorithm
16	20	27	develop
16	32	52	supervised WSD model
16	58	67	leverages
16	70	126	Bidirectional Long Short - Term Memory ( BLSTM ) network
17	13	23	works with
17	24	70	neural sense vectors ( i.e. sense embeddings )
17	83	97	learned during
17	98	112	model training
17	119	126	employs
17	127	171	neural word vectors ( i.e. word embeddings )
17	184	199	learned through
17	203	238	unsupervised deep learning approach
17	239	245	called
17	295	298	for
17	303	316	context words
110	0	34	Between - all - models comparisons
114	3	7	show
114	25	35	sits among
114	30	35	among
114	40	69	5 top - performing algorithms
115	0	5	shows
115	10	17	results
115	18	20	of
115	25	84	top - performing and low - performing supervised algorithms
128	0	32	Within - our - model comparisons
136	3	10	observe
136	14	21	reverse
136	26	43	sequential follow
136	44	46	of
136	47	58	information
136	59	63	into
136	64	86	our Bidirectional LSTM
136	92	99	shuffle
136	104	109	order
136	110	112	of
136	117	130	context words
136	141	148	replace
136	149	172	our Bidirectional LSTMs
136	173	177	with
136	178	218	two different fully - connected networks
136	219	221	of
136	226	238	same size 50
136	279	295	achieved results
136	319	325	72.5 %
