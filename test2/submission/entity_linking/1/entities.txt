2	73	100	Named Entity Disambiguation
5	19	26	propose
5	67	85	words and entities
5	86	89	for
5	90	125	named entity disambiguation ( NED )
9	26	36	addressing
9	37	40	NED
9	41	46	using
9	49	65	simple NED model
9	66	74	based on
9	79	112	trained contextualized embeddings
18	65	68	for
18	69	87	words and entities
18	88	91	for
18	92	95	NED
19	34	42	based on
19	47	80	bidirectional transformer encoder
20	3	8	takes
20	11	41	sequence of words and entities
20	42	44	in
20	49	59	input text
20	66	74	produces
20	77	101	contextualized embedding
20	102	105	for
20	106	126	each word and entity
21	29	53	masked entity prediction
22	3	10	trained
22	15	20	model
22	21	26	using
22	27	61	texts and their entity annotations
22	62	76	retrieved from
22	77	86	Wikipedia
113	11	21	our models
113	22	34	outperformed
113	35	65	all previously proposed models
114	14	19	using
114	20	45	pseudo entity annotations
114	46	53	boosted
114	58	66	accuracy
114	67	69	by
114	70	75	0.3 %
118	0	10	Our models
118	11	19	achieved
118	20	54	new state - of - the - art results
118	55	57	on
118	58	83	four of the five datasets
118	86	92	namely
118	93	98	MSNBC
118	101	108	AQUAINT
118	111	118	ACE2004
118	125	136	WNED - WIKI
118	143	152	performed
118	153	164	competitive
118	165	167	on
118	172	194	WNED - CLUEWEB dataset
119	14	19	using
119	20	45	pseudo entity annotations
119	46	54	improved
119	59	70	performance
119	71	73	on
119	78	106	AQUAINT and ACE2004 datasets
