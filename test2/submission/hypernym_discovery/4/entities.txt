3	0	18	Hypernym discovery
11	123	133	treated as
82	0	8	Word2vec
82	17	27	to produce
82	32	47	word embeddings
83	4	34	skip - gram model ( - cbow 0 )
83	38	47	used with
83	52	71	embedding dimension
83	72	78	set to
83	79	97	300 ( - size 300 )
87	17	36	Projection Learning
91	37	39	as
91	40	43	PRF
91	69	83	best F - value
91	84	86	on
91	91	105	validation set
91	106	108	is
91	109	113	0.68
91	143	147	when
91	152	171	best cluster number
91	172	174	is
91	175	176	2
91	185	194	threshold
91	195	197	is
96	5	31	projection learning method
96	32	40	performs
96	41	54	not very well
96	55	57	on
96	58	63	task9
96	128	141	formalized as
96	144	166	classification problem
99	17	19	NN
102	4	15	performance
102	16	31	evaluated using
102	39	72	cross validation or the test data
102	73	75	is
102	76	86	much worse
102	87	91	than
102	102	134	typical hypernym prediction task
104	69	72	are
104	77	80	1st
104	81	83	on
104	84	91	Spanish
104	98	101	2nd
104	102	104	on
104	105	112	Italian
104	119	122	6th
104	123	125	on
104	126	133	English
104	136	145	ranked by
104	150	156	metric
104	160	163	MAP
106	33	49	cross validation
106	56	67	performance
106	85	94	test data
106	97	104	dropped
106	105	118	significantly
106	119	121	on
106	122	129	English
106	132	135	MAP
106	136	146	dropped by
106	147	150	4 %
106	171	181	dropped by
106	182	185	8 %
106	194	206	increased by
106	209	215	margin
106	216	218	on
106	219	226	Spanish
106	233	245	increased by
106	246	251	3.6 %
