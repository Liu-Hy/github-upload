(jPTDP v 2.0||implemented using||DYNET v2.0)
(DYNET v2.0||with||fixed random seed)
(Hyperparameters||has||jPTDP v 2.0)
(character and POS tag embeddings||has||randomly initialized)
(Hyperparameters||has||Word embeddings)
(dropout||with||67 % keep probability)
(67 % keep probability||to||inputs)
(inputs||of||BiLSTMs and MLPs)
(dropout||has||67 % keep probability)
(Hyperparameters||apply||dropout)
(word dropout||to learn||embedding)
(embedding||for||unknown words)
(embedding||replace||each word token w)
(each word token w||with||special " unk " symbol)
(training set||with||special " unk " symbol)
(special " unk " symbol||with||probability punk ( w ))
(Hyperparameters||apply||word dropout)
(objective loss||using||Adam ( Kingma and Ba , 2014 ))
(Adam ( Kingma and Ba , 2014 )||with||initial learning rate)
(initial learning rate||at||0.001)
(initial learning rate||no||mini-batches)
(initial learning rate||has||0.001)
(Hyperparameters||optimize||objective loss)
(Hyperparameters||use||100 - dimensional word embeddings)
(number of hidden nodes||in||MLPs)
(number of hidden nodes||at||100)
(MLPs||at||100)
(Hyperparameters||fix||number of hidden nodes)
(Contribution||has||Hyperparameters)
