4	0	30	Syntactic constituency parsing
21	23	27	work
21	28	34	poorly
21	57	114	standard human - annotated parsing datasets ( 1M tokens )
21	123	134	constructed
21	138	156	artificial dataset
21	157	169	by labelling
21	172	184	large corpus
21	185	189	with
21	194	208	BerkeleyParser
25	3	10	trained
25	13	43	sequence - to - sequence model
25	44	48	with
25	49	58	attention
25	59	61	on
25	66	105	small human - annotated parsing dataset
25	115	130	able to achieve
25	134	143	F 1 score
25	144	146	of
25	147	151	88.3
25	152	154	on
25	177	184	without
25	199	207	ensemble
25	212	216	90.5
25	217	221	with
25	225	233	ensemble
25	242	249	matches
26	13	24	constructed
26	27	52	second artificial dataset
26	53	66	consisting of
26	72	101	high - confidence parse trees
26	107	118	measured by
26	123	132	agreement
26	133	135	of
26	136	147	two parsers
27	3	10	trained
27	13	43	sequence - to - sequence model
27	44	48	with
27	49	58	attention
27	76	84	achieved
27	88	97	F 1 score
27	98	100	of
27	101	105	92.5
27	106	108	on
67	22	26	used
67	29	34	model
67	35	39	with
67	40	53	3 LSTM layers
67	58	67	256 units
67	68	70	in
67	71	81	each layer
67	93	97	call
67	98	106	LSTM + A
70	0	11	Training on
70	14	27	small dataset
70	49	65	2 dropout layers
70	68	71	one
70	72	79	between
70	80	97	LSTM 1 and LSTM 2
70	108	115	between
70	116	133	LSTM 2 and LSTM 3
82	4	19	embedding layer
82	20	23	for
82	28	42	90K vocabulary
82	43	49	can be
82	50	70	initialized randomly
82	74	79	using
82	80	116	pre-trained word - vector embeddings
83	3	14	pre-trained
83	15	37	skip - gram embeddings
83	38	45	of size
83	46	49	512
83	50	55	using
83	56	64	word2vec
83	71	73	on
83	76	93	10B - word corpus
118	6	28	single attention model
118	29	36	gets to
118	37	41	88.3
118	49	80	ensemble of 5 LSTM + A+D models
118	81	89	achieves
118	90	94	90.5
118	95	103	matching
118	106	135	single - model BerkeleyParser
118	136	138	on
118	139	142	WSJ
119	5	15	trained on
119	20	50	large high - confidence corpus
119	55	76	single LSTM + A model
119	77	85	achieves
119	86	90	92.5
119	98	109	outperforms
119	123	140	best single model
119	156	176	best ensemble result
120	3	11	ensemble
120	12	14	of
120	15	31	5 LSTM+ A models
120	32	48	further improves
120	54	59	score
120	60	62	to
120	63	67	92.8
122	4	18	LSTM + A model
122	19	29	trained on
122	30	41	WSJ dataset
122	47	55	produced
122	56	71	malformed trees
122	72	75	for
122	76	100	25 of the 1700 sentences
122	101	103	in
122	104	123	our development set
122	163	173	trained on
122	174	204	full high - confidence dataset
122	214	217	for
122	218	240	14 sentences ( 0.8 % )
130	4	14	difference
130	15	22	between
130	27	36	F 1 score
130	37	39	on
130	40	49	sentences
130	85	87	is
130	88	91	1.3
130	92	95	for
130	100	114	BerkeleyParser
130	117	120	1.7
130	121	124	for
130	129	142	baseline LSTM
130	149	152	0.7
130	153	156	for
130	157	165	LSTM + A
157	0	8	LSTM + A
157	9	19	trained on
157	24	48	high - confidence corpus
157	88	96	achieved
157	100	109	F 1 score
157	110	112	of
157	113	117	95.7
157	118	120	on
157	121	124	QTB
157	129	133	84.6
157	134	136	on
157	137	140	WEB
