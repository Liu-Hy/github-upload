(bag - of - words model||constructed by selecting||50,000 most frequent words)
(50,000 most frequent words||from||training subset)
(each dataset||has||bag - of - words model)
(bag - of - ngrams models||constructed by selecting||500,000 most frequent n-grams ( up to 5 - grams ))
(500,000 most frequent n-grams ( up to 5 - grams )||from||training subset)
(training subset||for||each dataset)
(character - level ConvNets||work for||text classification)
(text classification||need for||words)
(Traditional methods||like||n-grams TFIDF)
(n-grams TFIDF||remain||strong candidates)
(strong candidates||for||dataset)
(of size||up to||several hundreds of thousands)
(character - level ConvNets||start to do||better)
(dataset||has||of size)
(Conv Nets||work||well)
(well||for||user - generated data)
(Conv Nets||has||well)
(Choice of alphabet||makes||difference)
(Choice of alphabet||has||difference)
(Contribution||has||Experiments)
