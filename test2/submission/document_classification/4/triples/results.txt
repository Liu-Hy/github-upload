(300 - dimensional Glo Ve word embeddings||as||initialization)
(initialization||for||word embeddings and label embeddings)
(word embeddings and label embeddings||in||our model)
(Results||use||300 - dimensional Glo Ve word embeddings)
(our model 's parameters||with||Adam Optimizer)
(our model 's parameters||with||initial learning rate)
(our model 's parameters||with||minibatch size)
(our model 's parameters||with||initial learning rate)
(our model 's parameters||with||minibatch size)
(initial learning rate||of||0.001)
(minibatch size||of||100)
(initial learning rate||has||0.001)
(minibatch size||has||100)
(Results||train||our model 's parameters)
(LEAM||provides||best AUC score)
(better F1 and P@5 values||than||all methods)
(all methods||except||CNN)
(LEAM||has||best AUC score)
(Results||has||LEAM)
(CNN||consistently outperforms||basic Bi - GRU architecture)
(logistic regression baseline||performs||worse)
(worse||than||all deep learning architectures)
(Contribution||has||Results)
