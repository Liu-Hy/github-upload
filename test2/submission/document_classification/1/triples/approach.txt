(weakly supervised learning||such as||unsupervised pre-training)
(weakly supervised learning||such as||unsupervised data augmentation)
(unsupervised data augmentation||to simultaneously close||language gap)
(unsupervised data augmentation||to simultaneously close||domain gap)
(domain gap||in||XLU)
(Approach||combine||state - of - the - art cross - lingual methods)
(two approaches||for||domain adaptation)
(masked language model ( MLM ) pre-training||using||unlabeled target language corpora)
(Approach||based on||masked language model ( MLM ) pre-training)
(unsupervised data augmentation ( UDA ) )||where||synthetic paraphrases)
(synthetic paraphrases||generated from||unlabeled corpus)
(model||trained on||label consistency loss)
(Approach||has||unsupervised data augmentation ( UDA ) ))
(Contribution||has||Approach)
