2	47	85	Word Sense Disambiguation of Text Data
11	0	33	Word Sense Disambiguation ( WSD )
16	20	27	develop
16	28	52	our supervised WSD model
16	53	67	that leverages
16	70	126	Bidirectional Long Short - Term Memory ( BLSTM ) network
17	13	23	works with
17	24	70	neural sense vectors ( i.e. sense embeddings )
17	83	97	learned during
17	98	112	model training
17	119	126	employs
17	127	171	neural word vectors ( i.e. word embeddings )
17	184	199	learned through
17	203	238	unsupervised deep learning approach
17	239	245	called
17	246	294	GloVe ( Global Vectors for word representation )
17	295	298	for
17	303	316	context words
106	5	15	results in
106	18	33	vocabulary size
106	34	36	of
106	37	50	| V | = 29044
114	3	7	show
114	25	35	sits among
114	40	69	5 top - performing algorithms
119	0	16	IMS + adapted CW
119	28	31	WSD
119	43	52	considers
119	53	73	deep neural networks
119	83	87	uses
119	88	115	pre-trained word embeddings
119	116	118	as
119	119	125	inputs
122	0	6	htsa 3
122	15	21	winner
122	22	24	of
122	29	56	SensEval - 3 lexical sample
124	0	4	IRST
124	15	23	utilizes
124	24	38	kernel methods
124	39	42	for
124	43	62	pattern abstraction
124	65	105	paradigmatic and syntagmatic information
124	110	137	unsupervised term proximity
124	138	140	on
124	141	172	British National Corpus ( BNC )
124	175	177	in
124	178	193	SVM classifiers
