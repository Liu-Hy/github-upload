2	60	83	Question Answering Data
7	0	12	Our approach
7	13	24	outperforms
7	29	67	previous state - of - the - art system
7	83	95	resulting in
7	99	122	average 8 % improvement
7	123	125	of
7	130	141	final score
10	0	40	Knowledge base question answering ( QA )
27	85	92	perform
27	93	151	entity mention detection and entity disambiguation jointly
27	152	154	in
27	157	176	single neural model
27	177	187	that makes
27	192	205	whole process
27	206	235	end - to - end differentiable
29	0	11	To overcome
29	16	21	noise
29	22	24	in
29	29	33	data
29	39	58	automatically learn
29	59	67	features
29	68	72	over
29	75	90	set of contexts
29	91	93	of
29	94	122	different granularity levels
32	20	27	extract
32	28	36	features
32	37	41	from
32	46	68	knowledge base context
32	69	71	of
32	76	92	candidate entity
32	95	121	character - level features
32	126	139	extracted for
32	144	156	entity label
32	161	184	higher - level features
32	189	206	produced based on
32	211	219	entities
32	220	231	surrounding
32	236	252	candidate entity
32	253	255	in
32	260	275	knowledge graph
47	22	40	EL on Twitter data
178	32	59	entity linking on questions
178	68	79	derive from
178	80	122	publicly available question answering data
178	125	131	WebQSP
178	136	150	GraphQuestions
216	8	15	include
216	18	37	heuristics baseline
216	43	48	ranks
216	49	67	candidate entities
216	68	80	according to
216	97	99	in
216	100	109	Wikipedia
238	4	13	VCG model
238	14	19	shows
238	24	47	overall F- score result
238	56	67	better than
238	72	98	DBPedia Spotlight baseline
238	99	101	by
238	104	115	wide margin
239	25	34	our model
239	35	43	achieves
239	44	67	higher precision values
239	83	99	other approaches
239	104	119	manages to keep
239	122	150	satisfactory level of recall
