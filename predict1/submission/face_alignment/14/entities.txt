2	24	40	Facial Alignment
20	4	23	non-visible regions
20	24	26	of
20	31	35	face
20	40	53	determined by
20	58	81	estimated camera center
20	90	108	estimated 3D shape
33	40	47	observe
33	53	79	fairly accurate 3 D models
33	80	83	can
33	108	125	simple mean shape
33	126	137	deformed to
33	142	153	input image
33	154	156	at
33	159	192	relatively low computational cost
33	193	204	compared to
33	205	221	other approaches
49	0	18	Landmark locations
49	26	47	directly predicted by
49	50	60	regression
49	61	65	from
49	68	89	learned feature space
51	4	22	objective function
51	23	25	in
51	26	30	GSDM
51	34	46	divided into
51	47	63	multiple regions
51	64	66	of
51	67	94	similar gradient directions
52	8	18	constructs
52	21	54	separate cascaded shape regressor
52	55	58	for
52	59	70	each region
57	0	5	3DDFA
57	6	10	fits
57	13	33	dense 3 D face model
57	34	36	to
57	41	46	image
57	47	50	via
57	51	54	CNN
57	63	71	proposes
57	74	98	novel cascaded framework
57	99	112	incorporating
57	113	134	geometric constraints
57	135	149	for localizing
57	150	159	landmarks
57	160	162	in
57	163	196	faces and other non-rigid objects
60	0	38	Nonlinear statistical model approaches
63	9	27	3D Object Modeling
203	0	11	Our network
203	15	29	implemented in
203	34	49	Caffe framework
204	2	11	new layer
204	15	22	created
204	23	36	consisting of
204	41	69	3D TPS transformation module
204	76	100	camera projection module
204	109	132	bilinear sampler module
205	16	30	differentiable
205	43	56	whole network
205	57	71	can be trained
205	72	86	end - to - end
206	3	8	adopt
206	9	26	two architectures
206	29	49	AlexNet and VGG - 16
206	52	54	as
206	78	81	for
206	86	120	shared feature extraction networks
206	134	137	use
206	142	160	convolution layers
206	161	165	from
206	189	202	to initialize
207	29	36	extract
207	119	125	freeze
207	126	133	some of
207	138	164	earlier convolution layers
207	169	177	finetune
207	182	186	rest
208	0	3	For
208	8	28	AlexNet architecture
208	34	40	freeze
208	45	56	first layer
208	63	66	for
208	71	92	VGG - 16 architecture
208	99	113	first 4 layers
208	114	117	are
208	118	124	frozen
209	4	26	2D landmark regression
209	30	44	implemented by
209	45	54	attaching
209	55	72	additional layers
209	73	82	on top of
209	87	109	last convolution layer
210	0	4	With
210	5	27	N landmarks to regress
210	33	37	need
210	38	48	NFC layers
210	49	59	to compute
210	64	71	offsets
210	72	75	for
210	76	100	each individual landmark
211	88	105	one Scaling layer
211	106	117	followed by
211	120	150	Reduction layer and Bias layer
212	0	6	During
212	7	15	training
212	25	35	new layers
212	36	39	are
212	40	47	updated
212	52	71	all previous layers
212	76	82	frozen
213	0	11	Training on
213	12	21	300W - LP
216	0	3	For
216	8	28	AlexNet architecture
216	34	43	train for
216	44	62	100,000 iterations
216	63	67	with
216	70	86	batch size of 50
217	4	25	initial learning rate
217	29	35	set to
217	36	41	0.001
217	46	54	drops by
217	57	68	factor of 2
217	69	74	after
217	75	92	50,000 iterations
218	5	13	training
218	18	37	landmark regression
218	44	65	initial learning rate
218	66	68	is
218	69	73	0.01
218	78	86	drops by
218	89	101	factor of 10
218	102	107	every
218	108	125	40,000 iterations
219	0	3	For
219	8	29	VGG - 16 architecture
219	35	44	train for
219	45	63	200,000 iterations
219	64	68	with
219	71	81	batch size
219	82	84	of
219	85	87	25
220	4	25	initial learning rate
220	29	35	set to
220	36	41	0.001
220	46	54	drops by
220	57	68	factor of 2
220	69	74	after
220	75	93	100,000 iterations
221	18	37	landmark regression
221	44	65	initial learning rate
221	66	68	is
221	69	73	0.01
221	78	86	drops by
221	89	101	factor of 10
221	102	107	every
221	108	125	70,000 iterations
222	4	12	momentum
222	13	16	for
222	17	32	all experiments
222	36	42	set to
222	43	46	0.9
229	4	18	VGG - 16 model
229	19	30	outperforms
229	35	48	AlexNet model
229	49	51	in
229	52	73	all three pose ranges
229	74	76	on
229	81	98	AFLW detected set
233	0	5	shows
233	15	39	landmark regression step
233	40	53	greatly helps
233	54	64	to improve
233	69	77	accuracy
235	0	4	AFLW
235	87	90	use
235	95	116	provided bounding box
235	117	124	anytime
235	129	133	face
235	137	152	not detected by
235	157	165	detector
238	3	10	compare
238	66	72	namely
238	73	113	Cascaded Deformable Shape Models ( CDM )
238	116	156	Robust Cascaded Pose Regression ( RCPR )
238	159	192	Explicit Shape Regression ( ESR )
238	195	198	SDM
238	203	208	3DDFA
239	4	11	methods
239	12	22	except for
239	23	26	CDM
239	32	44	retrained on
239	49	66	300W - LP dataset
241	8	13	shows
241	19	28	our model
241	29	34	using
241	39	60	VGG - 16 architecture
241	65	73	achieved
241	74	89	better accuracy
241	90	92	in
241	93	108	all pose ranges
241	111	121	especially
241	126	146	( 60 , 90 ] category
241	157	165	achieved
241	168	194	smaller standard deviation
241	195	197	in
241	202	207	error
242	33	42	landmarks
242	43	56	more accurate
242	68	83	more consistent
242	84	88	than
242	93	106	other methods
247	0	13	AFLW2000 - 3D
251	24	35	3DDFA + SDM
251	36	44	performs
251	45	49	well
251	56	77	VGG - 16 architecture
251	78	80	of
251	81	90	our model
251	97	105	performs
251	106	110	best
251	111	118	in both
252	10	24	VGG - 16 model
252	25	27	is
252	33	44	second best
252	45	47	in
252	52	69	( 30 , 60 ] range
252	70	72	by
252	75	87	small amount
252	147	157	our method
252	158	167	generates
252	168	185	more accurate and
254	0	13	Running Speed
257	15	27	evaluated on
257	30	61	3.40 GHz Intel Core i7-6700 CPU
257	69	99	NVIDIA GeForce GTX TITAN X GPU
