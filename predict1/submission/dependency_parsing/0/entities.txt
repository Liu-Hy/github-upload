2	33	36	for
2	37	77	joint POS tagging and dependency parsing
9	63	101	https://github.com/datquocnguyen/jPTDP
18	19	26	present
18	64	75	for jointly
18	85	118	POS tagging and dependency paring
71	60	71	j PTDP v1.0
71	72	76	with
71	77	101	2.5 + % LAS improvements
71	102	104	on
71	105	144	universal dependencies ( UD ) treebanks
73	51	84	https://github.com/datquocnguyen/
75	19	36	implemented using
75	37	47	DYNET v2.0
75	48	52	with
75	55	72	fixed random seed
77	0	15	Word embeddings
77	20	31	initialized
77	39	47	randomly
77	54	78	pre-trained word vectors
77	87	119	character and POS tag embeddings
77	120	123	are
77	124	144	randomly initialized
78	0	3	For
78	4	46	learning character - level word embeddings
78	52	55	use
78	56	78	one - layer BiLSTM seq
78	85	88	set
78	93	97	size
78	98	100	of
78	101	119	LSTM hidden states
78	120	134	to be equal to
78	139	153	vector size of
78	154	174	character embeddings
79	3	8	apply
79	9	16	dropout
79	17	21	with
79	24	45	67 % keep probability
79	46	48	to
79	53	79	inputs of BiLSTMs and MLPs
80	24	29	apply
80	30	42	word dropout
80	43	51	to learn
80	55	64	embedding
80	65	68	for
80	69	82	unknown words
80	88	95	replace
80	96	111	each word token
80	114	137	appearing # ( w ) times
80	138	140	in
80	145	157	training set
80	158	162	with
80	165	187	special " unk " symbol
80	188	192	with
80	193	215	probability punk ( w )
82	3	11	optimize
82	16	30	objective loss
82	31	36	using
82	37	66	Adam ( Kingma and Ba , 2014 )
82	67	71	with
82	75	96	initial learning rate
82	97	99	at
82	100	105	0.001
83	0	3	For
83	4	12	training
83	18	25	run for
83	26	35	30 epochs
83	42	49	restart
83	54	68	Adam optimizer
83	73	79	anneal
83	84	105	initial learning rate
83	106	108	at
83	111	121	proportion
83	122	124	of
83	125	128	0.5
83	129	134	every
83	135	144	10 epochs
86	49	52	use
86	53	86	100 - dimensional word embeddings
86	89	126	50 - dimensional character embeddings
86	131	165	100 dimensional POS tag embeddings
87	8	11	fix
87	16	38	number of hidden nodes
87	39	41	in
87	42	46	MLPs
87	47	49	at
87	50	53	100
88	84	91	perform
88	94	113	minimal grid search
88	114	116	of
88	117	135	hyper - parameters
88	136	145	to select
88	150	192	number of BiLSTM pos and BiLSTM dep layers
88	193	197	from
88	198	207	{ 1 , 2 }
88	216	242	size of LSTM hidden states
88	243	245	in
88	246	256	each layer
88	257	261	from
88	262	275	{ 128 , 256 }
89	51	54	fix
89	59	82	number of BiLSTM layers
89	83	85	at
89	86	87	2
89	96	103	size of
89	104	117	hidden states
89	118	120	at
89	121	124	128
94	0	15	Word embeddings
94	20	34	initialized by
94	35	70	100 dimensional Glo Ve word vectors
94	71	85	pre-trained on
94	86	108	Wikipedia and Gigaword
96	33	40	perform
96	43	50	minimal
96	63	65	of
96	89	98	find that
96	103	125	highest mixed accuracy
96	126	128	on
96	133	148	development set
96	152	171	obtained when using
96	172	187	2 BiLSTM layers
99	10	19	our model
99	20	28	produces
99	29	61	very competitive parsing results
100	26	33	obtains
100	36	45	UAS score
100	46	48	at
100	49	56	94.51 %
100	63	72	LAS score
100	76	83	92.87 %
101	0	9	Our model
101	15	19	does
101	20	26	better
101	27	31	than
101	36	76	previous transition - based joint models
101	104	130	similar UAS and LAS scores
101	131	133	to
101	138	153	joint model JMT
102	3	10	achieve
102	11	37	0.9 % lower parsing scores
102	38	42	than
102	47	87	state - of - the - art dependency parser
103	13	45	BiLSTM - and graph - based model
103	51	55	uses
103	58	96	more sophisticated attention mechanism
103	99	107	biaffine
103	110	129	for better decoding
103	130	164	dependency arcs and relation types
104	25	31	extend
104	32	41	our model
104	42	46	with
104	51	79	biaffine attention mechanism
104	80	94	to investigate
104	99	106	benefit
104	107	110	for
104	111	120	our model
106	8	14	obtain
106	17	39	state - of - the - art
106	40	60	POS tagging accuracy
106	61	63	at
106	64	71	97.97 %
106	72	74	on
106	79	91	test Section
108	42	44	on
108	45	55	UD parsing
114	0	3	For
114	4	30	each big or small treebank
114	36	41	train
114	44	55	joint model
114	56	59	for
114	60	104	universal POS tagging and dependency parsing
114	107	112	using
114	115	132	fixed random seed
121	10	17	utilize
121	22	67	tokenization , word and sentence segmentation
121	68	80	predicted by
121	81	90	UD - Pipe
125	4	19	final test runs
125	24	38	carried out on
125	43	56	TIRA platform
126	54	74	multilingual parsing
127	0	4	Over
127	5	21	all 82 test sets
127	27	37	outperform
127	42	61	baseline UDPipe 1.2
127	62	66	with
127	67	110	0.6 % absolute higher average UPOS F1 score
127	115	159	2.5 + % higher average UAS and LAS F1 scores
128	16	19	for
128	24	40	" big " category
128	41	54	consisting of
128	55	76	61 treebank test sets
128	82	88	obtain
128	89	101	0.8 % higher
128	102	106	UPOS
128	111	123	3.1 % higher
128	124	127	UAS
128	132	148	3.6 % higher LAS
128	149	153	than
128	154	164	UDPipe 1.2
129	0	41	Our ( UniMelb ) official LAS - based rank
129	42	47	is at
129	48	59	14 th place
129	70	89	baseline UDPipe 1.2
129	90	95	is at
129	96	107	18 th place
129	108	112	over
129	113	143	total 26 participating systems
136	13	20	present
136	63	78	with respect to
136	90	118	gold - standard tokenization
136	121	151	word and sentence segmentation
151	19	27	achieved
151	32	50	highest F 1 scores
151	51	54	for
151	60	87	biomedical event extraction
151	92	108	opinion analysis
