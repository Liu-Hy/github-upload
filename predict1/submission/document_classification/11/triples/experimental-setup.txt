(document embedding||as||document feature)
(document embedding||trained||linear classifier)
(linear classifier||using||Liblinear)
(Experimental setup||regard||document embedding)
(corpus||with||Stanford Tokenizer)
(lowercase||removed||stop words)
(Experimental setup||tokenized||corpus)
(dimensionality||of||vectors)
(size||of||context window)
(vectors||is||300)
(context window||is||5)
(number of negative samples||is||25)
(all word embeddings||has||dimensionality)
(number of negative samples||has||25)
(Experimental setup||has||all word embeddings)
(recommended N||is||150)
(150||with||constraint)
(recommended N||has||150)
(150||has||constraint)
(constraint||has||total)
(Experimental setup||has||recommended N)
(0 to 1||with||step size)
(step size||of||0.1)
(Experimental setup||tuned from||0 to 1)
(Contribution||has||Experimental setup)
