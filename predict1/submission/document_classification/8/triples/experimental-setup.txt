(all the corpus||with||NLTK 's tokenizer)
(Experimental setup||tokenize||all the corpus)
(300D Glo Ve 840B vectors||as||pre-trained word embeddings)
(Experimental setup||utilize||300D Glo Ve 840B vectors)
(Adadelta ( Zeiler , 2012 )||to optimize||all the trainable parameters)
(Experimental setup||use||Adadelta ( Zeiler , 2012 ))
(hyperparameter||of||Adadelta)
(Adadelta||set as||Zeiler ( 2012 ))
(Zeiler ( 2012 )||suggest||1 e ? 6)
(Experimental setup||has||hyperparameter)
(gradient explosion problem||apply||gradient norm clipping)
(Experimental setup||To avoid||gradient explosion problem)
(batch size||set to||128)
(all the dimensions||of||input vectors and hidden)
(input vectors and hidden||shows||our proposed model)
(all the other models||in||7 datasets)
(batch size||has||128)
(our proposed model||has||significantly outperforms)
(significantly outperforms||has||all the other models)
(Experimental setup||has||batch size)
(Contribution||has||Experimental setup)
