(CNN and LSTM||to||model sentences)
(Model||introduce||C - LSTM)
(output||of||one - layer CNN)
(simple end - to - end , unified architecture||by feeding||output)
(output||of||one - layer CNN)
(one - layer CNN||into||LSTM)
(advantages||has||simple end - to - end , unified architecture)
(Model||To benefit from||advantages)
(CNN||constructed on top of||pre-trained word vectors)
(pre-trained word vectors||from||massive unlabeled text data)
(massive unlabeled text data||to learn||higher - level representions)
(higher - level representions||of||n-grams)
(Model||has||CNN)
(sequential correlations||from||higher - level suqence representations)
(feature maps||of||CNN)
(feature maps||organized as||sequential window features)
(CNN||organized as||sequential window features)
(sequential window features||to serve||input)
(input||of||LSTM)
(Model||to learn||sequential correlations)
(LSTM||directly from||input sentence)
(LSTM||first transform||each sentence)
(each sentence||into||successive window ( n- gram ) features)
(successive window ( n- gram ) features||to help disentangle||factors)
(factors||of||variations)
(variations||within||sentences)
(constructing||has||LSTM)
(factors||has||variations)
(Contribution||has||Model)
