2	0	18	Text Understanding
8	23	27	sets
8	28	48	new state of the art
8	49	51	on
8	52	74	all evaluated datasets
11	18	35	teaching machines
56	0	21	Children 's Book Test
79	3	7	call
79	17	37	contextual embedding
172	22	26	used
172	27	54	stochastic gradient descent
172	55	59	with
172	64	80	ADAM update rule
172	85	98	learning rate
172	99	101	of
172	102	117	0.001 or 0.0005
177	8	23	initial weights
177	24	26	in
177	31	52	word embedding matrix
177	58	72	drawn randomly
177	83	87	from
177	92	116	interval [ ? 0.1 , 0.1 ]
178	0	7	Weights
178	8	10	in
178	15	27	GRU networks
178	33	47	initialized by
178	48	74	random orthogonal matrices
178	79	85	biases
178	91	105	initialized to
178	106	110	zero
179	8	12	used
179	15	42	gradient clipping threshold
179	43	45	of
179	46	48	10
179	53	60	batches
179	69	71	32
180	0	6	During
180	7	15	training
180	19	36	randomly shuffled
180	37	49	all examples
180	50	52	in
180	53	63	each epoch
183	0	3	For
183	4	14	each batch
183	15	17	of
183	22	49	CNN and Daily Mail datasets
183	53	72	randomly reshuffled
183	77	87	assignment
183	88	90	of
183	91	105	named entities
183	106	108	to
183	113	149	corresponding word embedding vectors
183	150	158	to match
211	24	27	set
211	28	62	new state - of - the - art results
211	63	65	on
211	66	88	all evaluated datasets
214	33	44	outperforms
215	0	2	On
215	7	18	CNN dataset
215	19	35	our single model
215	36	40	with
215	41	65	best validation accuracy
215	66	74	achieves
215	77	90	test accuracy
215	91	93	of
215	94	100	69.5 %
216	4	23	average performance
216	24	26	of
216	31	46	top 20 % models
216	47	59	according to
216	60	79	validation accuracy
216	80	82	is
216	83	89	69.9 %
216	96	98	is
216	99	116	even 0.5 % better
216	117	121	than
216	126	156	single best - validation model
218	0	6	Fusing
218	7	22	multiple models
218	28	33	gives
218	36	64	significant further increase
218	65	67	in
218	68	76	accuracy
218	77	79	on
220	0	2	In
220	3	26	named entity prediction
220	27	48	our best single model
220	49	53	with
220	54	65	accuracy of
220	66	72	68.6 %
220	73	81	performs
220	82	101	2 % absolute better
220	102	106	than
220	111	116	MemNN
220	117	121	with
220	122	138	self supervision
221	0	2	In
221	3	25	common noun prediction
221	26	43	our single models
221	44	46	is
221	47	68	0.4 % absolute better
221	69	73	than
221	74	80	Mem NN
221	102	110	improves
221	115	126	performance
221	127	129	to
221	130	134	69 %
