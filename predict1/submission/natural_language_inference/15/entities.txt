2	0	40	Neural Natural Language Inference Models
4	0	35	Modeling natural language inference
12	0	34	Natural language inference ( NLI )
12	51	89	recognizing textual entailment ( RTE )
23	17	23	enrich
23	24	59	neural - network - based NLI models
23	60	64	with
23	65	83	external knowledge
23	84	86	in
23	87	98	coattention
23	101	127	local inference collection
23	134	166	inference composition components
25	0	3	The
25	4	13	advantage
25	14	22	of using
25	23	41	external knowledge
25	42	44	is
25	45	61	more significant
25	62	66	when
25	71	92	size of training data
25	93	95	is
25	96	106	restricted
160	47	56	dimension
160	57	59	of
160	64	77	hidden states
160	78	80	of
160	81	86	LSTMs
160	91	106	word embeddings
160	107	110	are
160	111	114	300
161	4	19	word embeddings
161	24	38	initialized by
161	39	54	300D GloVe 840B
161	61	88	out - of - vocabulary words
161	89	94	among
161	104	115	initialized
161	116	124	randomly
162	4	19	word embeddings
162	24	38	updated during
162	39	47	training
163	0	29	Adam ( Kingma and Ba , 2014 )
163	33	41	used for
163	42	54	optimization
163	55	59	with
163	63	84	initial learning rate
163	85	87	of
163	88	94	0.0004
164	4	21	mini - batch size
164	25	31	set to
164	32	34	32
166	0	4	ESIM
166	5	7	is
166	79	112	https://github.com/lukecq1231/nli
170	21	27	namely
170	28	69	Knowledge - based Inference Model ( KIM )
170	78	86	enriches
170	87	91	ESIM
170	92	96	with
170	97	115	external knowledge
170	118	125	obtains
170	129	137	accuracy
170	138	140	of
170	141	147	88.6 %
170	154	185	best single - model performance
170	186	197	reported on
170	202	214	SNLI dataset
173	30	33	use
173	34	63	15 semantic relation features
173	72	80	does not
173	107	118	performance
175	23	41	external knowledge
175	47	50	add
175	51	76	TransE relation embedding
175	115	126	observed on
175	167	192	TransE relation embedding
175	196	200	used
175	227	252	semantic relation vectors
178	4	17	baseline ESIM
178	18	26	achieves
178	27	44	76.8 % and 75.8 %
178	45	47	on
178	48	87	in - domain and cross - domain test set
179	6	12	extend
179	17	21	ESIM
179	22	26	with
179	27	45	external knowledge
179	51	58	achieve
179	59	76	significant gains
179	77	79	to
179	80	97	77.2 % and 76.4 %
205	11	16	under
205	21	68	condition of restricted training data ( 0.8 % )
205	75	80	model
205	81	88	obtains
205	91	101	large gain
205	102	112	when using
205	113	149	more than half of external knowledge
222	13	16	for
222	17	33	antonym category
222	34	36	in
222	37	55	cross - domain set
222	58	61	KIM
222	62	72	outperform
222	73	77	ESIM
222	78	91	significantly
222	92	111	(+ absolute 5.0 % )
