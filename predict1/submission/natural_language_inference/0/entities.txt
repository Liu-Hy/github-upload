2	18	50	Reasoning over Multiple Mentions
11	36	61	Question Answering ( QA )
12	3	7	call
12	13	42	coreference - based reasoning
12	153	166	tied together
12	167	171	with
12	176	180	help
12	181	183	of
12	184	205	referring expressions
12	206	218	which denote
12	223	247	same real - world entity
20	64	78	extracted from
20	103	112	introduce
20	115	119	term
20	120	122	in
20	127	143	update equations
20	144	147	for
20	148	177	Gated Recurrent Units ( GRU )
20	184	194	depends on
20	199	211	hidden state
20	212	214	of
20	219	240	coreferent antecedent
20	241	243	of
20	248	261	current token
100	16	19	see
100	20	38	clear improvements
100	39	47	of using
100	48	62	C - GRU layers
100	63	67	over
100	68	78	GRU layers
102	4	22	Bi - C - GRU model
102	23	45	significantly improves
103	15	17	of
103	18	41	task - wise performance
103	66	75	Comparing
103	76	83	C - GRU
103	84	86	to
103	91	107	GRU based method
103	113	117	find
103	127	137	main gains
105	0	12	Comparing to
105	17	29	QRN baseline
105	35	45	found that
105	46	53	C - GRU
105	54	57	was
105	58	77	significantly worse
105	78	80	on
105	81	85	task
107	20	27	C - GRU
107	28	31	was
107	32	52	significantly better
107	53	57	than
107	58	61	QRN
108	33	37	uses
108	38	58	coreference features
108	59	61	as
108	62	77	1 - hot vectors
108	78	89	appended to
108	94	136	input word vectors ( GA w/ GRU + 1 - hot )
111	25	35	sharp drop
111	36	38	in
111	39	50	performance
120	3	6	see
120	7	25	higher performance
120	26	29	for
120	34	47	C - GRU model
120	48	50	in
120	55	70	low data regime
120	77	98	better generalization
120	99	109	throughout
120	114	128	training curve
125	12	16	note
125	22	33	both models
125	34	51	vastly outperform
125	56	76	best reported result
125	77	79	of
125	80	85	BiDAf
125	86	90	from
138	3	6	see
138	9	25	significant gain
138	26	28	in
138	29	40	performance
138	41	51	when using
138	56	61	layer
138	62	66	with
138	67	83	coreference bias
139	18	34	1 - hot baseline
139	41	45	uses
139	50	78	same coreference information
139	85	89	with
139	90	113	sequential recency bias
139	114	122	fails to
139	123	130	improve
139	131	135	over
139	140	157	regular GRU layer
160	4	42	maximum number of coreference clusters
160	43	49	across
160	50	59	all tasks
160	60	63	was
160	64	70	C = 13
166	3	7	used
166	8	15	dropout
166	16	18	of
166	19	22	0.2
166	23	33	in between
166	38	57	intermediate layers
166	64	75	initialized
166	76	91	word embeddings
166	92	96	with
166	97	102	Glove
