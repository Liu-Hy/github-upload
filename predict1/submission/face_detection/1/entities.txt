2	0	4	EXTD
2	7	35	Extremely Tiny Face Detector
4	19	26	propose
4	29	58	new multi-scale face detector
4	59	65	having
4	69	113	extremely tiny number of parameters ( EXTD )
4	116	125	less than
4	126	137	0.1 million
4	151	160	achieving
4	161	183	comparable performance
4	184	186	to
4	187	207	deep heavy detectors
28	19	26	propose
28	64	73	extremely
29	34	39	share
29	44	51	network
29	52	65	in generating
29	66	84	each feature - map
37	3	7	note
37	13	22	our model
37	23	39	does not require
37	40	55	any extra layer
37	88	100	trained from
37	101	108	scratch
40	3	10	propose
40	46	49	for
40	50	76	multi-stage face detection
40	83	86	can
40	87	107	significantly reduce
40	112	126	parameter size
40	148	184	abundant object semantic information
40	185	187	to
40	192	216	lower stage feature maps
135	0	5	Using
135	10	40	hard negative mining technique
135	46	53	balance
135	58	63	ratio
135	64	66	of
135	67	110	positive and negative samples N neg / N pos
135	111	113	to
135	114	115	3
135	124	143	balancing parameter
136	3	9	set to
136	10	11	4
140	23	39	implemented with
140	40	96	PyTorch and NAVER Smart Machine Learning ( NSML ) system
142	26	54	https ://github.com/clovaai.
159	19	27	designed
159	28	44	three variations
159	51	55	have
159	58	88	different number of parameters
159	91	102	lighter one
159	103	109	having
159	110	128	0.063 M parameters
159	129	133	with
159	134	145	32 channels
159	146	149	for
159	150	167	each feature maps
159	170	186	intermediate one
159	194	210	0.1 M parameters
159	211	215	with
159	216	227	48 channels
159	238	249	heavier one
159	255	287	64 channels and 0.16M parameters
159	305	308	FPN
163	4	18	negative slope
163	19	21	of
163	26	38	Leaky - ReLU
163	42	48	set to
163	49	53	0.25
163	65	77	identical to
163	82	104	initial negative slope
163	105	107	of
163	112	117	PReLU
176	24	51	all the inference processes
176	52	54	of
176	59	65	models
176	70	84	implemented by
176	85	96	PyTorch 1.0
177	0	34	Comparison to the Existing Methods
179	5	16	compared to
179	17	36	SOTA face detectors
179	37	44	such as
179	45	67	Pyra - midBox and DSFD
179	70	108	our best model EXTD - FPN - 64 - PReLU
179	109	117	achieved
179	118	131	lower results
180	4	10	margin
180	11	18	between
180	19	52	PyramidBox and the proposed model
180	53	55	on
180	56	76	WIDER FACE hard case
180	77	80	was
180	81	86	3.4 %
182	4	12	m AP gap
182	13	15	to
182	16	20	DSFD
182	32	52	tremendously heavier
182	55	63	is about
182	64	69	5.0 %
182	173	183	uses about
182	184	210	2860 times more parameters
182	211	215	than
182	220	235	proposed method
186	8	16	comes to
186	17	43	our SSD - based variations
186	51	54	got
186	55	72	lower mAP results
186	73	77	than
186	78	98	FPN - based variants
187	15	28	compared with
187	33	45	S3FD version
187	46	58	trained with
187	59	93	Mo - bile FaceNet backbone network
187	100	121	proposed SSD variants
187	122	130	achieved
187	131	173	comparable or better detection performance
194	0	21	Detection performance
194	22	31	regarding
194	36	46	Face Scale
196	24	27	see
196	33	43	our method
196	44	52	achieved
196	53	71	higher performance
196	72	74	in
196	75	98	WIDER FACE hard dataset
196	99	103	than
196	104	115	other cases
204	8	11	for
204	12	43	all the different channel width
204	46	68	FPN based architecture
204	69	77	achieved
204	78	106	better detection performance
204	107	118	compared to
204	119	141	SSD based architecture
204	144	168	especially for detecting
204	169	180	small faces
209	7	20	channel width
209	21	33	increased by
209	34	42	32 to 64
209	52	60	see that
209	65	83	detection accuracy
209	84	106	significantly enhanced
209	107	110	for
209	111	124	all the cases
209	127	151	Easy , Medium , and Hard
213	17	26	including
213	27	30	FPN
213	64	69	PReLU
213	70	73	was
213	78	99	most effective choice
213	100	116	when it comes to
213	117	120	mAP
213	131	134	gap
213	143	155	Leaky - ReLU
213	160	180	not that significant
214	5	16	tested with
214	17	39	SSD based architecture
214	42	47	PReLU
214	48	60	outperformed
214	61	73	Leaky - ReLU
214	74	78	with
214	79	92	larger margin
214	93	109	than those using
214	110	123	FPN structure
215	6	18	worth noting
215	24	28	ReLU
215	29	37	occurred
215	38	67	notable performance decreases
215	88	95	channel
215	106	111	small
215	112	115	for
215	121	138	SSD and FPN cases
216	9	22	channel width
216	27	33	set to
216	34	36	32
216	39	43	m AP
216	44	47	for
216	48	67	all the three cases
216	73	83	lower than
216	84	96	10 % to 20 %
216	97	108	compared to
216	115	120	using
216	121	147	other activation functions
226	0	3	For
226	43	88	stochastic gradient descent optimizer ( SGD )
226	89	93	with
226	94	107	learning rate
226	108	114	1e ? 3
226	117	121	with
226	122	134	0.9 momentum
226	137	156	0.0005 weight decay
226	163	176	batch size 16
228	4	28	maximum iteration number
228	42	48	set to
228	49	53	240K
228	63	67	drop
228	72	85	learning rate
228	86	88	to
228	89	106	1e ? 4 and 1e ? 5
228	107	109	at
228	110	115	120 K
228	120	135	180K iterations
