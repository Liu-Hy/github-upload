2	0	33	Recurrent Neural Network Grammars
12	19	28	introduce
12	29	70	recurrent neural network grammars ( RNNGs
12	116	118	of
12	119	128	sentences
12	134	151	explicitly models
12	152	187	nested , hierarchical relationships
12	188	193	among
12	194	211	words and phrases
15	3	7	give
15	8	20	two variants
15	21	23	of
15	28	37	algorithm
15	40	47	one for
15	48	55	parsing
15	128	138	generation
20	85	102	greedy prediction
20	103	107	with
20	108	111	our
20	118	124	yields
20	127	135	linear -
25	3	10	present
25	13	49	simple importance sampling algorithm
25	50	60	which uses
25	61	68	samples
25	69	73	from
25	78	99	discriminative parser
25	100	108	to solve
25	109	127	inference problems
25	128	130	in
25	135	151	generative model
85	0	31	Transition Sequences from Trees
164	4	12	training
164	16	20	used
164	21	48	stochastic gradient descent
164	49	53	with
164	56	69	learning rate
164	70	72	of
164	73	76	0.1
222	69	79	fixed RNNG
222	86	97	outperforms
222	100	141	highly optimized sequential LSTM baseline
